<!-- build time:Tue Jun 30 2020 21:47:25 GMT+0800 (China Standard Time) --><!DOCTYPE html><html class="theme-next mist use-motion" lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-240x240-playpi.png?v=5.1.3"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-playpi.png?v=5.1.3"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-playpi.png?v=5.1.3"><link rel="mask-icon" href="/images/logo-playpi.svg?v=5.1.3" color="#222"><meta name="keywords" content="Hadoop,HBase,Elasticsearch,HDFS,MapReduce,Spark,Storm,Kafka,Zookeeper"><link rel="alternate" href="/atom.xml" title="虾丸派" type="application/atom+xml"><meta name="description" content="本文记录大数据平台框架的一些常用参数，这些参数基本是我见过的或者实际使用过的，我会列出参数的含义以及使用效果，具有一定的参考意义。当然，根据实际的场景不同，参数值并不能随便设置为一样，必须要考虑到实际的情况，否则可能没有效果，或者具有反作用。会保持更新。"><meta name="keywords" content="Hadoop,HBase,Elasticsearch,HDFS,MapReduce,Spark,Storm,Kafka,Zookeeper"><meta property="og:type" content="article"><meta property="og:title" content="大数据平台框架常用参数优化"><meta property="og:url" content="https://www.playpi.org/2019121901.html"><meta property="og:site_name" content="虾丸派"><meta property="og:description" content="本文记录大数据平台框架的一些常用参数，这些参数基本是我见过的或者实际使用过的，我会列出参数的含义以及使用效果，具有一定的参考意义。当然，根据实际的场景不同，参数值并不能随便设置为一样，必须要考虑到实际的情况，否则可能没有效果，或者具有反作用。会保持更新。"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200407021026.png"><meta property="og:updated_time" content="2019-12-19T14:54:12.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="大数据平台框架常用参数优化"><meta name="twitter:description" content="本文记录大数据平台框架的一些常用参数，这些参数基本是我见过的或者实际使用过的，我会列出参数的含义以及使用效果，具有一定的参考意义。当然，根据实际的场景不同，参数值并不能随便设置为一样，必须要考虑到实际的情况，否则可能没有效果，或者具有反作用。会保持更新。"><meta name="twitter:image" content="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200407021026.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"5.1.3",sidebar:{position:"left",display:"hide",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="https://www.playpi.org/2019121901.html"><title>大数据平台框架常用参数优化 | 虾丸派</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">虾丸派</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">烂笔头</h1></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-books"><a href="/books/" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i><br>书籍</a></li><li class="menu-item menu-item-guide"><a href="/guide/" rel="section"><i class="menu-item-icon fa fa-fw fa-location-arrow"></i><br>指南</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://www.playpi.org/2019121901.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="虾丸派"><meta itemprop="description" content="记录知识 | 分享技术"><meta itemprop="image" content="/images/favicon-1536x1536-playpi.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="虾丸派"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">大数据平台框架常用参数优化</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-19T22:54:12+08:00">2019-12-19 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/big-data-technical-knowledge/" itemprop="url" rel="index"><span itemprop="name">大数据技术知识</span> </a></span></span><span id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-divider">|</span> 阅读次数 <span id="busuanzi_value_page_pv"></span></span><div class="post-wordcount"><span class="post-meta-item-text">字数统计</span> <span title="字数统计">7,567字 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">29分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p>本文记录大数据平台框架的一些常用参数，这些参数基本是我见过的或者实际使用过的，我会列出参数的含义以及使用效果，具有一定的参考意义。当然，根据实际的场景不同，参数值并不能随便设置为一样，必须要考虑到实际的情况，否则可能没有效果，或者具有反作用。</p><p>会保持更新。</p><a id="more"></a><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><p>选择 <code>HBase</code>、<code>Hadoop</code> 时注意版本适配的问题，<code>Hadoop</code> 选择 <code>v2.7.1</code> 还是很好的，能适配 <code>HBase v1.2.x</code> 以及以上的版本【<code>Hbase</code> 兼容的 <code>Hadoop</code> 版本参见：<a href="http://hbase.apache.org/book.html#configuration" target="_blank" rel="noopener">hbase-configuration</a> 】，也能适配 <code>Hive v0.10.0</code> 以及以上的版本【<code>Hive</code> 兼容的 <code>Hadoop</code> 版本参见：<a href="http://hive.apache.org/downloads.html" target="_blank" rel="noopener">hive-downloads</a> 】。</p><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><ul><li><code>fs.hdfs.impl.disable.cache</code>，如果设置为 <code>true</code>，表示关闭文件系统的缓存，这样多线程手动处理 <code>HDFS</code> 文件时，不会 <code>IOException: Filesystem closed</code></li></ul><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>配置文件：<code>mapred-site.xml</code>。</p><p><code>Yarn</code> 资源模型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Node Manager -&gt; yarn.nodemanager.resource.memory-mb</span><br><span class="line">YARN container -&gt; yarn.scheduler.minimum-allocation-mb、yarn.scheduler.maximum-allocation-mb</span><br><span class="line">Mapper/Reducer -&gt; mapreduce.map.memory.mb、mapreduce.reduce.memory.mb</span><br><span class="line">JVM -&gt; mapred.map.child.java.opts、mapred.reduce.child.java.opts</span><br></pre></td></tr></table></figure><p>对于内存参数的配置，注意它们之间的受限关系，取值不能乱设置，总体来说越具体的参数取值越小，例如常见的一般把 <code>mapreduce.map.java.opts</code> 的值配置成 <code>mapreduce.map.memory.mb * 0.9</code> 。</p><ul><li><code>map</code> 并发大小：<code>mapreduce.job.running.map.limit</code>，可以设置大点，50、100 随便</li><li><code>map</code> 内存大小：<code>mapreduce.map.memory.mb</code>，单位为 <code>MB</code>，一般 <code>4GB</code> 够用</li><li><code>reduce</code> 启动延迟：<code>mapred.reduce.slowstart.completed.maps</code>，表示 <code>reduce</code> 在 <code>map</code> 执行到什么程度可以启动，例如设置为 <code>1.0</code> 表示等待 <code>map</code> 全部完成后才能执行 <code>reduce</code></li><li><code>reduce</code> 内存大小：<code>mapreduce.reduce.memory.mb</code>，单位为 <code>MB</code>，要根据实际情况设置，一般 <code>4GB</code> 够用</li><li><code>reduce</code> 虚拟内存：<code>yarn.nodemanager.vmem-pmem-ratio</code>，一般 2-5 即可</li><li><code>reduce</code> 并发大小：<code>mapreduce.job.running.reduce.limit</code>，一般 5-10 个够用【根据业务场景、机器资源而定】</li><li><code>mapred.map.child.java.opts</code>，<code>Map</code> 的 <code>JVM</code> 参数，例如：<code>-Xmx200m</code></li><li><code>mapred.reduce.child.java.opts</code>，<code>Reduce</code> 的 <code>JVM</code> 参数，例如：<code>-Xmx200m</code></li><li><code>mapreduce.admin.map.child.java.opts</code>，作用同 <code>mapred.map.child.java.opts</code>，优先级最高，会覆盖掉用户设置的</li><li><code>mapreduce.admin.reduce.child.java.opts</code>，作用同 <code>mapred.reduce.child.java.opts</code>，优先级最高，会覆盖掉用户设置的</li></ul><h2 id="es-hadoop"><a href="#es-hadoop" class="headerlink" title="es-hadoop"></a>es-hadoop</h2><p>使用 <code>es-hadoop</code> 框架处理 <code>Elasticsearch</code> 数据，可以专注于数据 <code>ETL</code> 处理逻辑，其它与集群交互的读写操作交给 <code>es-hadoop</code> 框架处理，这里面有一些常用的参数。</p><p>参考官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html" target="_blank" rel="noopener">configuration</a> 。</p><ul><li>读取，只读取指定的字段：<code>es.read.field.include</code>，默认为空，读取全部字段，注意，在 <code>query</code> 中设置 <code>_source</code> 是无效的</li><li>读取，排除指定的字段：<code>es.read.field.exclude</code>，默认为空，则不排除任何字段</li><li>读取，关闭日期的处理：<code>es.mapping.date.rich</code>，默认为 <code>true</code>，关闭后，读取 <code>Elasticsearch</code> 的 <code>date</code> 类型的字段，会自动转换为 <code>long</code> 类型，不再是 <code>date</code> 类型</li><li>读取，解析指定字段为数组类型：<code>es.read.field.as.array.include</code>，默认为空，则不解析任何字段【字段类型保持原样】</li><li>读取，排除解析指定字段为数组字段：<code>es.read.field.as.array.exclude</code>，默认为空，则不排除任何字段【字段该是数组的还是数组，不是数组的仍旧保持原样】</li></ul><h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><p>配置文件：<code>mapred-site.xml</code> 。</p><ul><li><code>yarn.nodemanager.local-dirs</code>，临时目录</li></ul><h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h2 id="架构图"><a href="# 架构图" class="headerlink" title="架构图"></a> 架构图</h2><p>如下</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200407021026.png" alt="架构图" title="架构图"></p><h2 id="部分知识点"><a href="# 部分知识点" class="headerlink" title="部分知识点"></a> 部分知识点</h2><p>1、以下内容是关于 <code>major compaction</code>【大合并】、<code>minor compaction</code>【小合并】 的说明。</p><p><code>minor compaction</code> 操作只用来做部分文件【触发时相关的几个 <code>StoreFile</code> 文件】的合并操作，不做任何清除数据、多版本数据清理工作。</p><p><code>major compaction</code> 操作是对一个 <code>Region</code> 下的 <code>HStore</code> 下的所有 <code>StoreFile</code> 执行合并操作，最终的结果是整理合并出一个文件。此过程会真正删除标记为需要清理的数据，而且会消耗大量的磁盘 <code>IO</code>、网络 <code>IO</code>，甚至导致部分节点无法响应，严重影响读写性能，读请求会变慢，写请求会被阻塞。</p><p><code>major compaction</code> 的操作目的：</p><ul><li>合并文件</li><li>真正清除标记为删除、过期、多余版本的数据【<code>minor compaction</code> 并不会真正清除数据】</li><li>提高读写数据的效率，当然，由于磁盘 <code>IO</code>、网络 <code>IO</code> 的消耗，此操作过程会严重影响读写性能，读请求会变慢，写请求会被阻塞【有时候甚至会降低 10 倍】</li></ul><p>一般情况下，<code>HBase</code> 集群的 <code>major compact</code> 都是关闭的，如果开启默认是 7 天执行一次，因此离线的 <code>major compact</code> 是必要的，可以定期手动触发，可以使用 <code>major_compact 表名称</code> 对某个表进行操作。如果手动触发，操作命令很快就返回结果，但是后台操作其实一直在运行，可以通过 <code>grafana</code> 监控查看压缩队列的长度，当压缩队列长度超过 100 的时候，应该延迟操作。由于 <code>major compact</code> 是很重的后台操作，因此操作之前需要有仔细的观察和分析，例如通过 <code>grafana</code> -&gt; <code>HBase</code> 监控可以获得，关于触发时期的选择建议：</p><ul><li>业务低峰时段运行，即读写请求不大的时候，可以避免影响正常的业务</li><li>分表执行【或者分 <code>Region</code> 执行】，不要整个集群集体执行，并且优先考虑含有 <code>TTL</code> 的表</li><li><code>StoreFile</code> 短期内增加比较多的时候</li><li>表中 <code>StoreFile</code> 平均大小比较小的时候</li></ul><p>2、以下内容是关于租约时间的说明。</p><p>参考官网的配置示例、异常信息：<a href="https://hbase.apache.org/1.4/book.html#hbase_default_configurations" target="_blank" rel="noopener">default_configurations</a> 。</p><p>一些默认配置：<a href="https://svn.apache.org/repos/asf/hbase/hbase.apache.org/trunk/0.94/hbase-default.xml" target="_blank" rel="noopener">hbase-default.xml</a> 。</p><p>关于客户端和 <code>Regionserver</code> 之间的租约时间【<code>LeaseException</code>】，所谓租约，是指 <code>Hbase client</code> 端每次和 <code>Regionserver</code> 交互的时候，都会在服务器端生成一个租约【<code>Lease</code>】，租约的有效期由参数 <code>hbase.client.scanner.timeout.period</code> 指定，默认的租约有效时间是 60 秒。</p><p>在 <code>scan</code> 操作过程中，客户端去 <code>Regionserver</code> 取数据的时候，<code>Hbase</code> 中存的数据量很大并且有很多 <code>Region</code> 的时候的，客户端请求的 <code>Region</code> 不在内存中，或是没有被 <code>cache</code> 住，需要从磁盘中加载。如果这时候加载过程需要的时间超过 <code>hbase.client.scanner.timeout.period</code> 所配置的时间，并且客户端没有向 <code>Regionserver</code> 报告其还活着，那么 <code>Regionserver</code> 就会认为本次租约已经过期，并从 <code>LeaseQueue</code> 中从删除掉本次租约。此后，当 <code>Regionserver</code> 加载完成后，拿已经被删除的租约再去取数据的时候，就会出现如下的错误现象。</p><p>异常示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.hbase.regionserver.LeaseException: lease &apos;-8841369309248784313&apos; does not exist</span><br></pre></td></tr></table></figure><p>一般的做法，就是在配置文件中增大 <code>hbase.client.scanner.timeout.period</code> 的时间，但也不能忽略 <code>RPC</code> 连接的超时问题，所以在增大 <code>hbase.client.scanner.timeout.period</code> 的时候应该同时增大 <code>hbase.rpc.timeout</code>，同时注意 <code>hbase.rpc.timeout</code> 的值应该等于或大于 <code>hbase.client.scanner.timeout.period</code> 的值。</p><blockquote><p>很多人都会误认为一次 <code>Scan</code> 操作就是一次 <code>RPC</code> 请求，其实是不对的。实际上，一次请求大量数据的 <code>Scan</code> 操作可能会导致多个很严重的后果：服务器端可能因为大量 <code>IO</code> 操作导致 <code>IO</code> 利用率很高，影响其它正常的业务请求；大量数据传输会导致网络带宽等系统资源被大量占用；客户端也可能因为内存无法缓存这些数据导致 <code>OOM</code>。基于此，<code>HBase</code> 会将一次大的 <code>Scan</code> 操作根据设置条件拆分为多个 <code>RPC</code> 请求，每次只返回规定数量的结果。代码示例 <code>ResultScanner rs = table.getScanner (scan); foreach (Result r ：rs){...}</code> 语句实际上等价于 <code>ResultScanner rs = table.getScanner (scan); Result r = rs.next ()</code>，每执行一次 <code>next ()</code> 操作就会调用客户端发送一次 <code>RPC</code> 请求，参数 <code>hbase.client.scanner.timeout.period</code> 就用来表示这么一次 <code>RPC</code> 请求的超时时间，默认为 <code>60000ms</code>，一旦请求超时，就会抛出 <code>SocketTimeoutException</code> 异常。</p></blockquote><h2 id="相关配置项"><a href="# 相关配置项" class="headerlink" title="相关配置项"></a>相关配置项</h2><p><code>HBase</code> 相关配置说明：</p><ul><li><code>hbase.hregion.majorcompaction</code>，<code>HBase</code> 自动做 <code>major compaction</code> 的周期，会严重影响写入性能，建议定期手动做</li><li><code>hbase.hregion.majorcompaction=0</code>，关闭定期的 <code>major compaction</code> 操作，必要时只能手动执行</li><li><code>hbase.client.retries.number</code>，客户端连接重试次数，建议设置大一点，例如 24</li><li><code>hbase.rootdir</code>，<code>HBase</code> 在 <code>HDFS</code> 中的根目录</li><li><code>zookeeper.znode.parent</code>，<code>HBase</code> 在 <code>Zookeeper</code> 的根目录，例如使用 <code>Phoenix</code> 登录时需要</li><li><code>hbase.hregion.max.filesize</code>，设置 <code>HBase</code> 分区大小，超过此值时自动分裂，避免一个分区过大，默认值 10GB【10737418240B】，在创建表时合理预估数据大小，预设置合理的分区规则【利用 <code>rowkey</code>】，可以避免频繁分裂，也使数据分布更加均匀</li><li><code>hbase.rpc.timeout</code>，<code>RPC</code> 连接失效时间，默认 60 秒</li><li><code>hbase.client.scanner.timeout.period</code>，客户端和 <code>Regionserver</code> 之间租约过期的时间，默认是 60 秒，注意：参数 <code>hbase.regionserver.lease.period</code> 已经不建议使用</li><li><code>hbase.client.scanner.caching</code>，设置 <code>HBase Scanner</code> 一次从服务端读取的数据条数，默认情况下 1 次 1 条，通过将其设置成一个合理的值【例如 100-500 之间的数字】，可以减少 <code>Scan</code> 过程中 <code>next ()</code> 的时间开销，代价是 <code>Scanner</code> 需要通过客户端的内存来维持这些被 <code>cache</code> 的行记录</li><li><code>hbase.rootdir</code>，这个目录是 <code>region server</code> 的共享目录，用来持久化 <code>HBase</code></li><li><code>hbase.master.port</code>，<code>HBase</code> 的 <code>Master</code> 的端口，默认: 60000</li><li><code>hbase.cluster.distributed</code>，<code>HBase</code> 的运行模式，<code>false</code> 表示单机模式，<code>true</code> 表示分布式模式</li><li><code>hbase.tmp.dir</code>，本地文件系统的临时文件夹，可以设置为一个更为持久的目录上【<code>/tmp</code> 在重启时会被清楚】，默认：<code>${java.io.tmpdir}/hbase-${user.name}</code></li><li><code>hbase.local.dir</code>，作为本地存储，位于本地文件系统的路径，默认:<code>${hbase.tmp.dir}/local/</code></li></ul><h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><p>总述，在设置 <code>Elasticsearch</code> 堆大小时需要通过 <code>$ES_HEAP_SIZE</code> 环境变量，遵循两个规则：</p><ul><li>不要超过可用 <code>RAM</code> 的 50%，<code>Lucene</code> 能很好利用文件系统的缓存，它是通过系统内核管理的，如果没有足够的文件系统缓存空间，性能会受到影响。 此外，专门用于堆的内存越多意味着其它可用的内存越少，例如 <code>fielddata</code></li><li>不要超过 <code>32GB</code>，如果堆大小小于 <code>32GB</code>，<code>JVM</code> 可以利用指针压缩，这可以大大降低内存的使用，每个指针是 4 字节而不是 8 字节</li></ul><p>分片的分配：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/shards-allocation.html" target="_blank" rel="noopener">shards-allocation</a> 。<br>脚本的使用：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-using.html" target="_blank" rel="noopener">modules-scripting-using</a> 。<br>熔断器相关：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/circuit-breaker.html" target="_blank" rel="noopener">circuit-breaker</a> 。<br>节点选举、故障检测：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/modules-discovery-zen.html" target="_blank" rel="noopener">modules-discovery-zen</a> 。</p><p><code>fielddata</code>，对字段进行 <code>agg</code> 时，会把数据加载到内存中【索引数据时不会】，记录的是占用内存空间情况，超过指定的值，开始回收内存，防止 <code>OOM</code>。</p><p><code>allocate</code> 表示分片的分配【第一次分配、负载均衡过程中的再次分配】；<code>relocate</code> 【负载均衡过程中的再次分配】表示分片再次进行 <code>allocate</code>。<code>Recovery</code> 表示将一个索引的未分配 <code>shard</code> <code>allocate</code> 到一个结点的过程，在快照恢复、更改索引副本数量、结点故障、结点启动时发生。</p><p><code>Elasticsearch</code> 慢查询日志、慢索引日志等一些配置信息只在 <code>master</code> 节点配置即可，不需要每个节点都配置。</p><p>如果设置索引副本数为 1，同一个索引的主分片、副本分片不会被分配在同一个节点上面，这才能保证数据高可用，挂了一个节点也没关系【如果一台物理节点开启了两个 <code>Elasticsearch</code> 节点，需要注意使用 <code>cluster.routing.allocation.same_shard.host</code> 参数】。</p><ul><li>磁盘空间使用占比上限：<code>cluster.routing.allocation.disk.watermark.high</code>，默认为 90%，表示如果当前节点的磁盘使用占比超过这个值，则分片【针对所有类型的分片：主分片、副本分片】会被自动 <code>relocate</code> 到其它节点，并且任何分片都不会 <code>allocate</code> 到当前节点【此外，对于新创建的 <code>primary</code> 分片也是如此，除非整个 <code>Elasticsearch</code> 集群只有一个节点了】</li><li>磁盘空间使用占比下限：<code>cluster.routing.allocation.disk.watermark.low</code>，默认为 85%，表示如果当前节点的磁盘使用占比超过这个值，则分片【新创建的 <code>primary</code> 分片、从来没有进行过 <code>allocate</code> 的分片除外】不会被 <code>allocate</code> 到当前节点</li><li>索引的分片副本数：<code>number_of_replicas</code>，一般设置为 1，表示总共有 2 份数据</li><li><code>index.auto_expand_replicas</code>：副本数自动扩展，会根据可用 <code>Elasticsearch</code> 节点数来设置副本数，默认为 <code>false</code>，可以设置为 <code>0-all</code>、<code>0-5</code> 等等</li><li>每个节点分配的分片个数：<code>total_shards_per_node</code>，一般设置为 2，一个节点只分配 2 个分片，分别为主分片、副本分片</li><li>索引的分片个数：<code>number_of_shards</code>，当索引数据很大时，一般设置为节点个数【例如 <code>索引数据大小 / 50GB</code> 大于节点个数，例如 10 个节点，索引大小 <code>800GB</code>，此时按照官方建议应该设置 16 个分片，但是分片过多也不好，就可以设置 10 个分片，每个分片大小 <code>80GB</code>】，再配合 <strong>分片副本数为 1</strong>、<strong> 每个节点分配的分片个数为 2</strong>，就可以确保分片分配在所有的节点上面，并且每个节点上有 2 个分片，分别为主分片、副本分片</li><li>数据刷新时间：<code>refresh_interval</code>，表示数据写入后等待多久可以被搜索到，默认值 <code>1s</code>，每次索引的 <code>refresh</code> 会产生一个新的 <code>lucene</code> 段，这会导致频繁的合并行为，如果业务需求对实时性要求没那么高，可以将此参数调大，例如调整为 <code>60s</code>，会大大降低 <code>cpu</code> 的使用率</li><li>索引的分片大小，官方建议是每个分片大小在 <code>30GB</code> 到 <code>50GB</code> 不要超过 <code>50GB</code>，所以当索引的数据很大时，就要考虑增加分片的数量</li><li>设置 <code>terms</code> 最大个数：<code>index.max_terms_count</code>，默认最大个数为 65535，可以根据集群情况降低，例如设置为 10000，为了集群稳定，一般不需要设置那么大</li><li>设置 <code>Boolean Query</code> 的子语句数量：<code>indices.query.bool.max_clause_count</code>，默认为 1024，不建议增大这个值，也可以根据集群情况适当减小</li><li>查看热点线程：<code>http://your_ip:your_port/_nodes/your_node_name/hot_threads</code>，可以判断热点线程是 <code>search</code>，<code>bulk</code>，还是 <code>merge</code>，从而进一步分析是查询还是写入导致负载过高</li><li>数据目录：<code>path.data: /path/to/data</code>，多个目录使用逗号分隔，里面存放数据文件</li><li>日志目录：<code>path.logs: /path/to/logs</code>，里面存放的是节点的日志、慢查询日志、慢索引日志</li><li>家目录：<code>path.home: /path/to/home</code>，<code>elasticsearch</code> 的家目录，里面有插件、<code>lib</code>、配置文件等</li><li>插件目录：<code>path.plugins: /path/to/plugins</code>，插件目录，里面存放的是插件，例如：分词器</li><li>设置慢获取时间边界：<code>index.search.slowlog.threshold.fetch.warn: 30s</code>，超过这个时间的信息会被记录在日志文件中，<code>path.logs</code> 参数指定的目录中 <code>cluster-name_index_fetch_slowlog.log</code> 文件</li><li>设置慢查询时间边界：<code>index.search.slowlog.threshold.query.warn: 60s</code>，超过这个时间的信息会被记录在日志文件中，<code>path.logs</code> 参数指定的目录中 <code>cluster-name_index_search_slowlog.log</code> 文件</li><li>设置慢索引时间边界：<code>index.search.slowlog.threshold.index.warn: 60s</code>，超过这个时间的信息会被记录在日志文件中，<code>path.logs</code> 参数指定的目录中 <code>cluster-name_index_indexing_slowlog.log</code> 文件</li><li>禁止集群重分配：<code>cluster.routing.allocation.enable=none</code>，手动操作分片前需要关闭，否则会引起分片的移动，造成不必要的 <code>IO</code></li><li>开启集群重分配：<code>cluster.routing.allocation.enable=all</code>，集群的分片管理权限交由集群，保持数据均衡</li><li>设置集群均衡分片时可以同时 <code>rebalance</code> 分片的个数，<code>cluster.routing.allocation.cluster_concurrent_rebalance:2</code>，不宜设置过大，一般 2-4 个为好，当然如果集群资源足够或者需要快速均衡分片，可以设置大一点</li><li>允许分片分配，<code>cluster.routing.allocation.enable=all</code>，开启后分片的分配交由集群管理，如果偶尔需要手动管理分片或者集群停机重启，可以临时关闭，取值设置为 <code>none</code> 即可</li><li>推迟索引的分片分配时间，在分片节点出故障或者重启时，可以避免分片数据的移动，前提是及时把节点恢复：<code>index.unassigned.node_left.delayed_timeout=5m</code>，通俗点说，就是趁分片不注意，节点已经恢复了，此时数据分片保持不变，避免了不必要的 <code>IO</code></li><li><code>index.max_slices_per_scroll</code>，除了传统的 <code>scroll</code> 读取数据的方式，<code>v5.x</code> 之后 <code>Elasticsearch</code> 又增加了对每个分片读取数据的功能，称之为切片处理【<code>sliced scroll</code>】，这种读取方式可以对多个分片并行读取数据，大大提高了取数效率，<code>elasticsearch-hadoop</code> 就是采用这种方式读取数据的。但是，这里面有一个限制，<code>Elasticsearch</code> 默认一个 <code>scroll</code> 最大的切片数量为 1024【一般小于等于分片数，也可以通过指定切片字段来创建大于分片数的切片】，可以通过 <code>index.max_slices_per_scroll</code> 参数来变更【不建议更改】</li><li><code>cluster.routing.allocation.same_shard.host</code>，在单台物理节点配置多个 <code>Elasticsearch</code> 实例时，这个参数才生效，用来检查同一个分片的多个实例【主分片、副本分片】是否能分配在同一台主机上面，默认值为 <code>false</code>。如果设置为 <code>true</code>，表示开启检查机制，一台物理机上面启动 2 个 <code>Elasticsearch</code> 节点，则分配相同编号的分片时，不会都在这台机器上面，尽管可以满足主分片、副本分片不在同一个 <code>Elasticsearch</code> 节点上</li><li><code>script.groovy.sandbox.enabled: false</code>，禁用 <code>Grovvy</code> 脚本，默认是关闭的</li><li><code>script.inline: false</code>，允许使用内置 <code>painless</code> 脚本</li><li><code>script.stored: false</code>，允许使用保存在 <code>config/scripts</code> 中的脚本，调用时使用 <code>id</code> 即可，类似方法名</li><li><code>script.file: false</code>，允许使用外部脚本文件</li><li><code>http.port: 9200</code>，集群的 <code>HTTP</code> 端口号</li><li><code>transport.tcp.port: 9300</code>，集群的 <code>TCP</code> 端口号</li><li><code>thread_pool.bulk.queue_size: 1500</code>，<code>bulk</code> 队列的大小</li><li><code>indices.breaker.total.use_real_memory: true</code>，熔断器回收内存，防止 <code>OOM</code>，决定父熔断器是考虑实际内存使用情况，还是仅考虑子熔断器内存使用情况</li><li><code>indices.breaker.total.limit: 70%</code>，熔断器回收内存，防止 <code>OOM</code>，当 <code>use_real_memory</code> 为 <code>true</code> 时，设置为 70%，否则默认为 70%</li><li><code>indices.breaker.fielddata.limit: 40%</code>，熔断器回收内存，防止 <code>OOM</code>，默认 40%</li><li><code>indices.breaker.request.limit: 60%</code>，熔断器回收内存，防止 <code>OOM</code>，默认 60%</li><li><code>indices.fielddata.cache.size</code>，可以设置 <code>20%</code>，要低于 <code>fielddata.limit</code>，默认无界限</li><li><code>discovery.zen.fd.ping_timeout: 60s</code>，集群故障检测</li><li><code>discovery.zen.fd.ping_interval: 10s</code>，集群故障检测</li><li><code>discovery.zen.fd.ping_retries: 10</code>，集群故障检测</li><li><ul><li><code>discovery.zen.master_election.ignore_non_master_pings: true</code>，选举主节点，设置为 <code>true</code> 时非 <code>node.master</code> 节点不能参与选举，投票也无效</li></ul></li><li><code>discovery.zen.minimum_master_nodes: 2</code>，选举主节点，最少有多少个备选主节点参加选举，防止脑裂现象</li><li><code>discovery.zen.ping_timeout: 10s</code>，选举主节点</li><li><code>discovery.zen.ping.unicast.hosts: [&quot;ip1:port&quot;,&quot;ip2:port&quot;]</code>，选举主节点，主机列表</li><li><code>node.data: true</code>，数据节点</li><li><code>node.master: true</code>，有资格被选举为主节点</li><li><code>action.destructive_requires_name=true</code>，设置严格校验，对于删除数据、删除索引的破坏性行为进行严格校验，不支持通配符，防止类似于 <code>rm -rf /*</code> 的悲剧</li><li><code>network.host</code>，绑定主机名或者 <code>ip</code> 地址，用于向集群广播自己</li><li><code>cluster.routing.allocation.exclude._ip</code>，临时下线节点，类似于黑名单，分片不会往指定的主机移动，同时会把分片从指定的节点全部移除，最终可以下线该节点，可通过 <code>put transient</code> 设置临时生效</li></ul><h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p><a href="https://spark.apache.org/docs/1.6.2/running-on-yarn.html" target="_blank" rel="noopener">v1.6.2 官方说明文档</a> 。</p><ul><li>序列化方式：<code>spark.serializer</code>，可以选择：<code>org.apache.spark.serializer.KryoSerializer</code></li><li><code>executor</code> 附加参数：<code>spark.executor.extraJavaOptions</code>，例如可以添加：<code>-Dxx=yy</code>【如果仅仅在 <code>driver</code> 端设置，<code>executor</code> 是不会有的】</li><li><code>driver</code> 附加参数：<code>spark.driver.extraJavaOptions</code>，例如可以添加：<code>-Dxx=yy</code></li><li>日志配置文件设置，<code>Spark</code> 使用的是 <code>log4j</code>，默认在 <code>Spark</code> 安装目录的 <code>conf</code> 下面，如果想要增加 <code>log4j</code> 相关配置，更改 <code>driver</code> 机器上面的 <code>log4j.properties</code> 配置文件是无效的，必须把所有的 <code>executor</code> 节点上的配置文件全部更新。如果没有权限，也可以自己上传配置文件，然后需要在 <code>executor</code> 附加参数中指定：<code>-Dlog4j.configuration=file:/path/to/file</code>，启动 <code>Spark</code> 任务时还需要使用 <code>--files</code> 指定配置文件名称，多个用逗号分隔，用来上传配置文件到 <code>Spark</code> 节点</li><li>开启允许多 <code>SparkContext</code> 存在：<code>spark.driver.allowMultipleContexts</code>，设置为 <code>true</code> 即可，在使用多个 <code>SparkContext</code> 时，需要先停用当前活跃的，使用 <code>stop</code> 方法【在 <code>Spark v2.0</code> 以及以上版本，已经取消了这个限制】</li><li><code>spark.executor.cores</code>，每个执行器上面的占用核数，会消耗 <code>CPU</code>，一般设置为 2-3</li><li><code>spark.executor.memory</code>，执行器上面的堆内存大小，一般设置为 <code>2048M</code>、<code>4096M</code></li><li><code>spark.port.maxRetries</code>，提交任务的 <code>Spark UI</code> 重试次数</li><li><code>spark.default.parallelism</code>，默认并行度</li><li><code>spark.cores.max</code>，最大核心数</li><li><code>spark.executor.logs.rolling.strategy</code></li><li><code>spark.executor.logs.rolling.maxRetainedFiles</code></li><li><code>spark.executor.logs.rolling.size.maxBytes</code></li><li><code>spark.ui.showConsoleProgress</code></li><li><code>spark.yarn.max.executor.failures</code>，<code>task</code> 失败重试次数，默认为 <code>spark.executor.cores</code> 的 2 倍，最小值为 3，如果重试最大次数后 <code>task</code> 仍旧失败，则整个 <code>Application</code> 执行失败【容错性】</li><li><code>spark.yarn.maxAppAttempts</code>，提交申请的最大尝试次数，小于等于 <code>yarn</code> 配置中的全局最大尝试次数，尝试最大次数后仍旧无法提交，则 <code>Application</code> 提交失败【<code>yarn</code> 配置为 <code>yarn.resourcemanager.am.max-attempts</code>，默认为 2，即有 2 次提交机会】</li></ul><h2 id="Kafka- 输入数据源"><a href="#Kafka- 输入数据源" class="headerlink" title="Kafka 输入数据源"></a>Kafka 输入数据源</h2><p><code>Spark Streaming</code> 配置：</p><ul><li><code>spark.streaming.backpressure.enabled</code>，开启反压机制</li><li><code>spark.streaming.backpressure.pid.minRate</code>，</li><li><code>spark.streaming.kafka.maxRatePerPartition</code>，每个 <code>partition</code> 的最大读取速度，单位秒，一般设置 500-100 即可</li><li><code>spark.streaming.receiver.maxRate</code>，<code>receiver</code> 最大处理数据量，单位秒，与 <code>maxRatePerPartition</code>、<code>Durations</code> 有关，实际运行时由于反压机制，数据处理速度会低于这个值</li><li><code>spark.streaming.receiver.writeAheadLog.enable</code>，</li><li><code>spark.streaming.stopGracefullyOnShutdown</code>，优雅地退出</li><li><code>spark.streaming.gracefulStopTimeout</code>，</li><li><code>xx</code>，</li></ul><p><code>Kakfa</code> 配置：</p><ul><li><code>metadata.broker.list</code>，</li><li><code>offsets.storage</code>，设置为 <code>kafka</code></li><li><code>zookeeper.connect</code>，</li><li><code>zookeeper.connection.timeout.ms</code></li><li><code>group.id</code></li><li><code>fetch.message.max.bytes</code></li><li><code>auto.offset.reset</code>，消费的起始位置，这个参数高低版本之间的名称、值都会不同，需要注意</li><li><code>consumer.timeout.ms</code></li><li><code>rebalance.max.retries</code></li><li><code>rebalance.backoff.ms</code></li></ul><h2 id="集群参数"><a href="# 集群参数" class="headerlink" title="集群参数"></a> 集群参数</h2><p><code>yarn</code> 集群：</p><ul><li><code>yarn.resourcemanager.am.max-attempts</code>，最大应用尝试次数，它是所有 <code>AM</code> 的全局设置，每个应用都可以通过 <code>API</code> 的参数指定其各自的最大应用尝试次数【参数 <code>spark.yarn.maxAppAttempts</code>】，但是单个数字不能超过这个全局上限，如果超过了，资源管理器将覆盖它。默认数量设置为 2，以允许至少 1 次重试，即有 2 次提交的机会</li></ul><p><code>standalone</code> 集群</p><ul><li>临时目录：<code>SPARK_LOCAL_DIRS</code>，用来存放 <code>Spark</code> 任务运行过程中的临时数据，例如内存不足时把数据缓存到磁盘，就会有数据写入这个目录，当然，在启动 <code>Spark</code> 任务时也可以单独指定，但是最好还是设置在集群上面，可以在 <code>spark-env.sh</code> 脚本中设置，键值对的形式，例如：<code>SPARK_LOCAL_DIRS=/your_path/spark/local</code>。需要注意的是，启动 <code>Excutor</code> 的用户必须有这个目录的写权限，并且保证这个目录的磁盘空间足够使用，否则在 <code>Spark</code> 任务中会出现异常：<code>java.io.IOException: Failed to create local dir in xx</code>，进而导致 <code>Task</code> 失败</li><li><code>Work</code> 目录：<code>SPARK_WORKER_DIR</code>，用来存放 <code>Work</code> 的信息，设置方式同上面的 <code>SPARK_LOCAL_DIRS</code>，如果 <code>Spark</code> 任务里面有 <code>System.out ()</code>，输出的内容在此目录下</li><li><code>SPARK_LOG_DIR</code>，<code>Spark</code> 集群自身的日志文件，例如 <code>Work</code> 接收 <code>Spark</code> 任务后通信的内容</li></ul><h1 id="Storm"><a href="#Storm" class="headerlink" title="Storm"></a>Storm</h1><ul><li><code>StormUI nimbus</code> 内容传输大小限制：<code>nimbus.thrift.max_buffer_size: 1048576</code>，取值的单位是字节，默认为 <code>1048576</code>，如果 <code>nimbus</code> 汇报的内容过多，超过这个值，则在 <code>StormUI</code> 上面无法查看 <code>Topology Summary</code> 信息，会报错：<code>Internal Server Error org.apache.thrift7.transport.TTransportException: Frame size (3052134) larger than max length (1048576)</code></li><li>执行实例 <code>worker</code> 对应的端口号：<code>supervisor.slots.ports:</code>，可以设置多个，和 <code>CPU</code> 的核数一致，或者稍小，提高机器资源的使用率</li><li><code>worker</code> 的 <code>JVM</code> 参数：<code>WORKER_GC_OPTS</code>，取值参考：<code>-Xms1G -Xmx5G -XX:+UseG1GC</code>，根据集群机器的资源多少而定，<code>G1</code> 是一种垃圾回收器</li><li><code>supervisor</code> 的 <code>JVM</code> 参数：<code>SUPERVISOR_GC_OPTS</code>，取值参考：<code>-Xms1G -Xmx5G -XX:+UseG1GC</code>，根据集群机器的资源多少而定，<code>G1</code> 是一种垃圾回收器</li><li><code>Storm UI</code> 的服务端口：<code>ui.port</code>，可以使用浏览器打开网页查看 <code>Topology</code> 详细信息</li><li><code>ZooKeeper</code> 服务器列表：<code>storm.zookeeper.servers</code></li><li><code>ZooKeeper</code> 连接端口：<code>storm.zookeeper.port</code></li><li><code>ZooKeeper</code> 中 <code>Storm</code> 的根目录位置：<code>storm.zookeeper.root</code>，用来存放 <code>Storm</code> 集群元信息</li><li>客户端连接 <code>ZooKeeper</code> 超时时间：<code>storm.zookeeper.session.timeout</code></li><li><code>Storm</code> 使用的本地文件系统目录：<code>storm.local.dir</code>，注意此目录必须存在并且 <code>Storm</code> 进程有权限可读写</li><li><code>Storm</code> 集群运行模式：<code>storm.cluster.mode</code>，取值可选：<code>distributed</code>、<code>local</code></li></ul><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><p>注意，<code>Kafka</code> 的不同版本参数名、参数值会有变化，特别是 <code>v0.9.x</code> 之后，与之前的低版本差异很大，例如数据游标的参数可以参考我的另外一篇博文：<a href="https://www.playpi.org/2017060101.html">记录一个 Kafka 错误：OffsetOutOfRangeException</a> ，<code>Kafka</code> 官网参见：<a href="https://kafka.apache.org/090/documentation.html#consumerconfigs" target="_blank" rel="noopener">Kafka-v0.9.0.x-configuration</a> 。</p><p>配置优化都是修改 <code>server.properties</code> 文件中参数值。</p><ul><li><code>JVM</code> 参数：<code>KAFKA_HEAP_OPTS</code>，取值参考：<code>-Xmx2G</code></li><li>文件存放位置：<code>log.dirs</code>，多个使用逗号分隔，注意所有的 <code>log</code> 级别需要设置为 <code>INFO</code></li><li>单个 <code>Topic</code> 的文件保留策略：<code>log.retention.hours=72</code>【数据保留 72 小时，超过时旧数据被删除】，<code>log.retention.bytes=1073741824</code>【数据保留 1GB，超过时旧数据被删除】</li><li>数据文件刷盘策略：<code>log.flush.interval.messages=10000</code>【每当 <code>producer</code> 写入 10000 条消息时，刷数据到磁盘】，<code>log.flush.interval.ms=1000</code>【每间隔 1 秒钟时间，刷数据到磁盘】</li><li><code>Topic</code> 的分区数量：<code>num.partitions=8</code></li><li>启动 <code>Fetch</code> 线程给副本同步数据传输大小限制：<code>replica.fetch.max.bytes=10485760</code>，要比 <code>message.max.bytes</code> 大</li><li><code>message.max.bytes=10485700</code>，这个参数决定了 <code>broker</code> 能够接收到的最大消息的大小，要比 <code>max.request.size</code> 大</li><li><code>max.request.size=10480000</code>，这个参数决定了 <code>producer</code> 生产消息的大小</li><li><code>fetch.max.bytes=10485760</code>，这个参数决定了 <code>consumer</code> 消费消息的大小，要比 <code>message.max.bytes</code> 大</li><li><code>broker</code> 处理消息的最大线程数：<code>num.network.threads=17</code>，一般 <code>num.network.threads</code> 主要处理网络 <code>IO</code>，读写缓冲区数据，基本没有 <code>IO</code> 等待，配置线程数量为 <code>CPU</code> 核数加 1</li><li><code>broker</code> 处理磁盘 <code>IO</code> 的线程数：<code>num.io.threads=32</code>，<code>num.io.threads</code> 主要进行磁盘 <code>IO</code> 操作，高峰期可能有些 <code>IO</code> 等待，因此配置需要大些，配置线程数量为 <code>CPU</code> 核数 2 倍，最大不超过 3 倍</li><li>强制新建一个 <code>segment</code> 的时间：<code>log.roll.hour=72</code></li><li>是否允许自动创建 <code>Topic</code>：<code>auto.create.topics.enable=true</code>，如果设置为 <code>false</code>，则代码无法创建，需要通过 <code>kafka</code> 的命令创建 <code>Topic</code></li><li><code>auto.offset.reset</code>，关于数据游标的配置【<code>earliest</code> 与 <code>latest</code>、<code>smallest</code>、<code>largest</code>】，由于不同版本之间的差异，可以参考：<a href="https://www.playpi.org/2017060101.html">记录一个 Kafka 错误：OffsetOutOfRangeException</a></li><li><code>advertised.host.name</code>、<code>advertised.port</code>，关于外网集群可以访问的配置，跨网络生产、消费数据，<code>v082</code> 以及之前的版本【之后的版本有保留这两个参数，但是不建议使用】</li><li><code>advertised.listeners</code>、<code>listeners</code>，关于外网集群可以访问的配置，跨网络生产、消费数据，<code>v090</code> 以及之后的版本</li></ul><p>留意参数取值大小的限制：<code>fetch.max.bytes</code> 大于 <code>message.max.bytes</code> 大于 <code>max.request.size</code>，<code>replica.fetch.max.bytes</code> 大于 <code>message.max.bytes</code> 大于 <code>max.request.size</code>。</p><h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><p>配置 <code>zoo.cfg</code> 文件：</p><ul><li><code>dataDir</code>，表示快照日志目录</li><li><code>dataLogDir</code>，表示事务日志目录，不配置的时候事务日志目录同 <code>dataDir</code></li><li><code>clientPort=2181</code>，服务的监听端口</li><li><code>tickTime=2000</code>，<code>Zookeeper</code> 的时间单元，<code>Zookeeper</code> 中所有时间都是以这个时间单元的整数倍去配置的，例如，<code>session</code> 的最小超时时间是 <code>2*tickTime</code>【单位：毫秒】</li><li><code>syncLimit=5</code>，表示 <code>Follower</code> 和 <code>Observer</code> 与 <code>Leader</code> 交互时的最大等待时间，只不过是在与 <code>leader</code> 同步完毕之后，进入正常请求转发或 <code>ping</code> 等消息交互时的超时时间</li><li><code>initLimit=10</code>，<code>Observer</code> 和 <code>Follower</code> 启动时，从 <code>Leader</code> 同步最新数据时，<code>Leader</code> 允许 <code>initLimit * tickTime</code> 的时间内完成，如果同步的数据量很大，可以相应地把这个值设置大一些</li><li><code>maxClientCnxns=384</code>，最大并发客户端数，用于防止 <code>Ddos</code> 的，默认值是 10，设置为 0 是不加限制</li><li><code>maxSessionTimeout=120000</code>，<code>Session</code> 超时时间限制，如果客户端设置的超时时间不在这个范围，那么会被强制设置一个最大时间，默认的 <code>Session</code> 超时时间是在 <code>2 * tickTime ~ 20 * tickTime</code> 这个范围</li><li><code>minSessionTimeout=4000</code>，同 <code>maxSessionTimeout</code></li><li><code>server.x=hostname:2888:3888</code>，<code>x</code> 是一个数字，与每个服务器的 <code>myid</code> 文件中的 <code>id</code> 是一样的，<code>hostname</code> 是服务器的 <code>hostname</code>，右边配置两个端口，第一个端口用于 <code>Follower</code> 和 <code>Leader</code> 之间的数据同步和其它通信，第二个端口用于 <code>Leader</code> 选举过程中投票通信</li><li><code>autopurge.purgeInterval=24</code>，在 <code>v3.4.0</code> 及之后的版本，<code>Zookeeper</code> 提供了自动清理事务日志文件和快照日志文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个 1 或更大的整数。默认是 0，表示不开启自动清理功能</li><li><code>autopurge.snapRetainCount=30</code>，参数指定了需要保留的事务日志文件和快照日志文件的数目，默认是保留 3 个，和 <code>autopurge.purgeInterval</code> 搭配使用</li></ul></div><div><div id="wechat_subscriber" style="display:block;padding:10px 0;margin:20px auto;width:100%;text-align:center"><img id="wechat_subscriber_qcode" src="/images/wechat-qr-personal.jpg" alt="虾丸派 wechat" style="width:200px;max-width:100%"><div>扫一扫添加博主，进技术交流群，共同学习进步</div></div></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>永不止步</div><button id="rewardButton" disable="enable" onclick='var e=document.getElementById("QR");"none"===e.style.display?e.style.display="block":e.style.display="none"'><span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/wechat-pay-playpi.png" alt="虾丸派 微信支付"><p>微信支付</p></div></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong> 虾丸派</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://www.playpi.org/2019121901.html" title="大数据平台框架常用参数优化">https://www.playpi.org/2019121901.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Elasticsearch/" rel="tag"><i class="fa fa-tag"></i> Elasticsearch</a> <a href="/tags/Hadoop/" rel="tag"><i class="fa fa-tag"></i> Hadoop</a> <a href="/tags/Spark/" rel="tag"><i class="fa fa-tag"></i> Spark</a> <a href="/tags/HDFS/" rel="tag"><i class="fa fa-tag"></i> HDFS</a> <a href="/tags/HBase/" rel="tag"><i class="fa fa-tag"></i> HBase</a> <a href="/tags/Zookeeper/" rel="tag"><i class="fa fa-tag"></i> Zookeeper</a> <a href="/tags/MapReduce/" rel="tag"><i class="fa fa-tag"></i> MapReduce</a> <a href="/tags/Kafka/" rel="tag"><i class="fa fa-tag"></i> Kafka</a> <a href="/tags/Storm/" rel="tag"><i class="fa fa-tag"></i> Storm</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2019120101.html" rel="next" title="解决 jar 包冲突的神器：maven-shade-plugin"><i class="fa fa-chevron-left"></i> 解决 jar 包冲突的神器：maven-shade-plugin</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2019122901.html" rel="prev" title="写入 Elasticsearch 异常：413 Request Entity Too Large">写入 Elasticsearch 异常：413 Request Entity Too Large <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="vcomments"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/favicon-1536x1536-playpi.png" alt="虾丸派"><p class="site-author-name" itemprop="name">虾丸派</p><p class="site-description motion-element" itemprop="description">记录知识 | 分享技术</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">142</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">12</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">294</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/iplaypi" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://weibo.com/u/3086148515" target="_blank" title="微博"><i class="fa fa-fw fa-weibo"></i>微博</a> </span><span class="links-of-author-item"><a href="mailto:playpi@qq.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div><div class="cc-license motion-element" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank" rel="external nofollow"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="https://github.com/iplaypi" title="GitHub" target="_blank" rel="external nofollow">GitHub</a></li><li class="links-of-blogroll-item"><a href="https://weibo.com/u/3086148515" title="Weibo" target="_blank" rel="external nofollow">Weibo</a></li><li class="links-of-blogroll-item"><a href="https://www.playpi.org" title="虾丸派" target="_blank" rel="external nofollow">虾丸派</a></li><li class="links-of-blogroll-item"><a href="https://www.playpi.org" title="playpi" target="_blank" rel="external nofollow">playpi</a></li><li class="links-of-blogroll-item"><a href="https://www.liaoxuefeng.com" title="廖雪峰" target="_blank" rel="external nofollow">廖雪峰</a></li><li class="links-of-blogroll-item"><a href="http://www.ruanyifeng.com" title="阮一峰" target="_blank" rel="external nofollow">阮一峰</a></li><li class="links-of-blogroll-item"><a href="https://travis-ci.org/iplaypi/iplaypi.github.io" title="travis-ci" target="_blank" rel="external nofollow">travis-ci</a></li><li class="links-of-blogroll-item"><a href="https://www.vultr.com/?ref=7861302-4F" title="Vultr" target="_blank" rel="external nofollow">Vultr</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop"><span class="nav-number">1.</span> <span class="nav-text">Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS"><span class="nav-number">1.1.</span> <span class="nav-text">HDFS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce"><span class="nav-number">1.2.</span> <span class="nav-text">MapReduce</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#es-hadoop"><span class="nav-number">1.3.</span> <span class="nav-text">es-hadoop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#yarn"><span class="nav-number">1.4.</span> <span class="nav-text">yarn</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HBase"><span class="nav-number">2.</span> <span class="nav-text">HBase</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#架构图"><span class="nav-number">2.1.</span> <span class="nav-text">架构图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#部分知识点"><span class="nav-number">2.2.</span> <span class="nav-text">部分知识点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相关配置项"><span class="nav-number">2.3.</span> <span class="nav-text">相关配置项</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Elasticsearch"><span class="nav-number">3.</span> <span class="nav-text">Elasticsearch</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark"><span class="nav-number">4.</span> <span class="nav-text">Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka- 输入数据源"><span class="nav-number">4.1.</span> <span class="nav-text">Kafka 输入数据源</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集群参数"><span class="nav-number">4.2.</span> <span class="nav-text">集群参数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Storm"><span class="nav-number">5.</span> <span class="nav-text">Storm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka"><span class="nav-number">6.</span> <span class="nav-text">Kafka</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Zookeeper"><span class="nav-number">7.</span> <span class="nav-text">Zookeeper</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2016&ndash;<span itemprop="copyrightYear">2020</span> <span class="post-meta-divider">|</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">虾丸派</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">全站字数统计</span> <span title="全站字数统计">322.8k 字</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io" rel="external nofollow">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题&nbsp;<a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next" rel="external nofollow">NexT.Mist</a><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-divider">|</span> 总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-divider">|</span> 总访客 <span id="busuanzi_value_site_uv"></span> 人</span></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script><script src="//unpkg.com/valine@1.3.7/dist/Valine.min.js"></script><script type="text/javascript">new Valine({av:AV,el:"#comments",verify:!1,notify:!1,app_id:"FC5Jijeg1meo2K2OzPYWK327-gzGzoHsz",app_key:"6A1ReY8tjhPutK00F01YbJSq",placeholder:"没有问题吗？"})</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var t=$("#local-search-input");t.attr("autocapitalize","none"),t.attr("autocorrect","off"),t.focus()}var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(t){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")},searchFunc=function(t,e,o){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:t,dataType:isXml?"xml":"json",async:!0,success:function(t){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var n=isXml?$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():t,r=document.getElementById(e),s=document.getElementById(o),a=function(){var t=r.value.trim().toLowerCase(),e=t.split(/[\s\-]+/);e.length>1&&e.push(t);var o=[];if(t.length>0&&n.forEach(function(n){function r(e,o,n,r){for(var s=r[r.length-1],a=s.position,i=s.word,l=[],h=0;a+i.length<=n&&0!=r.length;){i===t&&h++,l.push({position:a,length:i.length});var p=a+i.length;for(r.pop();0!=r.length&&(s=r[r.length-1],a=s.position,i=s.word,p>a);)r.pop()}return c+=h,{hits:l,start:o,end:n,searchTextCount:h}}function s(t,e){var o="",n=e.start;return e.hits.forEach(function(e){o+=t.substring(n,e.position);var r=e.position+e.length;o+='<b class="search-keyword">'+t.substring(e.position,r)+"</b>",n=r}),o+=t.substring(n,e.end)}var a=!1,i=0,c=0,l=n.title.trim(),h=l.toLowerCase(),p=n.content.trim().replace(/<[^>]+>/g,""),u=p.toLowerCase(),f=decodeURIComponent(n.url),d=[],g=[];if(""!=l&&(e.forEach(function(t){function e(t,e,o){var n=t.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(e=e.toLowerCase(),t=t.toLowerCase());(s=e.indexOf(t,r))>-1;)a.push({position:s,word:t}),r=s+n;return a}d=d.concat(e(t,h,!1)),g=g.concat(e(t,u,!1))}),(d.length>0||g.length>0)&&(a=!0,i=d.length+g.length)),a){[d,g].forEach(function(t){t.sort(function(t,e){return e.position!==t.position?e.position-t.position:t.word.length-e.word.length})});var v=[];0!=d.length&&v.push(r(l,0,l.length,d));for(var $=[];0!=g.length;){var C=g[g.length-1],m=C.position,x=C.word,w=m-20,y=m+80;w<0&&(w=0),y<m+x.length&&(y=m+x.length),y>p.length&&(y=p.length),$.push(r(p,w,y,g))}$.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hits.length!==e.hits.length?e.hits.length-t.hits.length:t.start-e.start});var T=parseInt("1");T>=0&&($=$.slice(0,T));var b="";b+=0!=v.length?"<li><a href='"+f+"' class='search-result-title'>"+s(l,v[0])+"</a>":"<li><a href='"+f+"' class='search-result-title'>"+l+"</a>",$.forEach(function(t){b+="<a href='"+f+'\'><p class="search-result">'+s(p,t)+"...</p></a>"}),b+="</li>",o.push({item:b,searchTextCount:c,hitCount:i,id:o.length})}}),1===e.length&&""===e[0])s.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x" /></div>';else if(0===o.length)s.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';else{o.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hitCount!==e.hitCount?e.hitCount-t.hitCount:e.id-t.id});var a='<ul class="search-result-list">';o.forEach(function(t){a+=t.item}),a+="</ul>",s.innerHTML=a}};r.addEventListener("input",a),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(t){t.stopPropagation(),isfetched===!1?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(t){t.stopPropagation()}),$(document).on("keyup",function(t){var e=27===t.which&&$(".search-popup").is(":visible");e&&onPopupClose()})</script><script>!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.3"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{scale:1,jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"left",width:100,height:200,hOffset:0,vOffset:-20},mobile:{show:!1,motion:!0,scale:.3},log:!1})</script></body></html><!-- rebuild by neat -->