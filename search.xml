<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Android 逆向系列 0-- 初识 Android 以及逆向工程</title>
    <url>/2018100901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p> 本文简单介绍一下 Android 开发以及关于 Android 的逆向工程，算是入门了解。</p><a id="more"></a><p> 待整理。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Android 逆向系列</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>逆向工程</tag>
      </tags>
  </entry>
  <entry>
    <title>Android 逆向系列 1-- 编写第一个 Android 程序</title>
    <url>/2018101001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p> 本文简单介绍一下 Android 开发的入门程序，编写一个简单的 Android 程序。</p><a id="more"></a><p> 待整理。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Android 逆向系列</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>逆向工程</tag>
      </tags>
  </entry>
  <entry>
    <title>Android 逆向系列 2-- 破解第一个 Android 程序</title>
    <url>/2018101101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p> 本文简单介绍一下对一个简单的 Android 程序的逆向破解，算是对 Android 逆向的入门了解。</p><a id="more"></a><p> 待整理。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Android 逆向系列</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>逆向工程</tag>
      </tags>
  </entry>
  <entry>
    <title>Charset：一个转换网页编码的工具</title>
    <url>/2017082101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在 <code>Web</code> 项目的开发、测试过程中，有时候会遇到显示乱码问题，而引起问题的原因可能是代码出错、缺少设置等，此时可以通过浏览器查看，进而修复问题。</p><p>但是，如果在使用一些第三方网站的工具时，遇到显示乱码的问题，就不能要求网站修复了，毕竟没那么及时，如果是碰到一些编码设置不规范或者不正确的网站【长期不更改】，浏览器无法准确判断其使用的编码，导致网站显示乱码。此时可以使用浏览器的编码设置，强制指定一种编码，使内容显示正确。</p><p>但是，有的浏览器不支持编码选择，例如 <code>Chrome</code> 浏览器【<code>v55</code> 以及之后】，此时就可以借助 <code>Charset</code> 插件来解决这个问题。</p><a id="more"></a><h1 id="现状说明"><a href="# 现状说明" class="headerlink" title="现状说明"></a>现状说明 </h1><p><code>Chrome v55</code> 以后，去掉了网页编码设置的选项，用户不再能自定义指定网页的编码，而 <code>Chrome</code> 也会自动识别网页的编码。但是对于不规范的网页【没有指明解析编码】，则 <code>Chrome</code> 使用系统默认的编码，但是有时候这会导致显示乱码，<code>Chrome</code> 的变更可以参考 <code>Chrome</code> 的官方通知：<a href="https://bugs.chromium.org/p/chromium/issues/detail?id=597488" target="_blank" rel="noopener">issues-597488</a> 。</p><p> 官方的说明：</p><blockquote><p>This is a part of the effort Project Eraser. Encoding-related UI will go away.</p></blockquote><blockquote><p>Quoted from email thread:</p></blockquote><blockquote><p>1) “Auto Detect” option in the hamburger menu. It’s a sticky global boolean that turns on a heavy text analyzer to guess the encoding better. It’s off by default because it regresses page load time by 10%-20%. By selecting this, users see less gibberish but they make Chrome slower (and don’t realize that).</p></blockquote><blockquote><p>2) Manual encoding selection in the hamburger menu. This is a temporary setting that forces the current tab to the specified encoding, no matter what. It will turn pages into gibberish if the user selects the wrong one.</p></blockquote><blockquote><p>3) “Default encoding” selector buried in chrome://settings. This specifies which encoding is selected if “Auto Detect” is disabled and the web page doesn’t specify its encoding. It defaults to the UI language of the Chrome installation.</p></blockquote><p>如果需要自定义编码，例如开发人员、测试人员，可以安装第三方扩展插件，以下两个都可以，链接：<a href="https://chrome.google.com/webstore/detail/set-character-encoding/bpojelgakakmcfmjfilgdlmhefphglae" target="_blank" rel="noopener">set-character-encoding</a> 、<a href="https://chrome.google.com/webstore/detail/charset/oenllhgkiiljibhfagbfogdbchhdchml" target="_blank" rel="noopener">Charset</a> 。</p><h1 id="举例演示"><a href="# 举例演示" class="headerlink" title="举例演示"></a>举例演示 </h1><p> 下面使用中国天气网的数据演示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://www.weather.com.cn/data/cityinfo/101190408.html</span><br></pre></td></tr></table></figure><p>上述网页返回的是一组 <code>JSON</code> 数据，包含了 <strong>太仓 </strong>城市的天气情况，但是这个网页的返回信息中，没有指明编码的方式【<code>Response Headers</code> 里面的 <code>Content-Type</code> 属性】，而 <code>JSON</code> 数据内容实际使用的是 <code>UTF-8</code> 编码。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200401223432.png" alt="返回头信息" title="返回头信息"></p><p>如果像上面那样使用 <code>Chrome</code> 浏览器打开，由于无法识别对方的编码信息，就会使用当前系统默认的编码方式显示，接着就会出现乱码显示的问题。因为 <code>Chrome</code> 浏览器使用系统默认编码 <code>GBK</code>，当然无法正常显示，还由于我这里安装的 <code>v80</code> 版本不支持手动设置显示编码，只能看着乱码的内容。</p><p>当然，如果直接查看 <code>JSON</code> 数据，是可以看到正确的数据显示的，查看 <code>Response</code> 里面的数据。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200401223424.png" alt="查看 JSON 数据正常" title="查看 JSON 数据正常"></p><p>此时，为了直接看清楚返回的内容，可以使用 <code>Charset</code> 插件来更改解析显示数据使用的编码，我在这里选择 <code>Unicode (UTF-8)</code>，网页会自动刷新，数据显示正常。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200401223415.png" alt="更改解析显示编码" title="更改解析显示编码"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200401223401.png" alt="刷新后正常显示" title="刷新后正常显示"></p><p>同时，可以留意到 <code>Response Headers</code> 里面的 <code>Content-Type</code> 属性变化了，指定了编码，这也就是 <code>Charset</code> 插件的作用。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Charset</tag>
        <tag>UTF8</tag>
        <tag>Chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 写入数据文本过长：IllegalArgumentException</title>
    <url>/2018053002.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在使用 <code>elasticsearch-hadoop</code> 处理数据时，写入数据报错：<code>IllegalArgumentException</code>，具体原因显示字符过长，也就是写入的文本太长了，<code>Elasticsearch</code> 自身无法支持【本质还是底层的 <code>Lucene</code> 无法支持】。</p><p>开发环境基于 <code>elasticsearch-hadoop v2.1.0</code>、<code>Elasticsearch v1.7.5</code> 。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 处理数据后写回 <code>Elasticsearch</code> 时出现异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.10.170:9202] returned Internal Server Error (500) - [IllegalArgumentException [Document contains at least one immense term in field=&quot;content_seg&quot; (whose UTF8 encoding is longer than the max length 32766)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200329200432.png" alt="写入异常" title="写入异常"></p><p>在代码中，业务逻辑是把 <code>content</code> 分词取 <code>top5</code> 放入 <code>content_seg</code> 字段里面，字段 <code>content_seg</code> 是存放一个分词结果的数组。</p><p>此外还有提示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: &apos;[-17, -69, -65, -17, -69, -65, -17, -69, -65, -17, -69, -65</span><br></pre></td></tr></table></figure><p>建议正确设置字段的类型，分词字段比较合适。</p><h1 id="问题分析"><a href="# 问题分析" class="headerlink" title="问题分析"></a>问题分析 </h1><p> 由上面的异常信息以及提示信息可见，分词的结果文本过长，无法写入一个 <code>string term</code> 类型的字段，本质就是文本过长【和字段类型不匹配】。</p><p>更为详细的信息参考我的另外一篇博客：<a href="https://www.playpi.org/2017061401.html">在 Elasticsearch 中一个字段支持的最大字符数 </a> 。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a> 问题解决 </h1><p> 解决办法有两种，都是基于业务逻辑考虑的，在技术上并没有什么方案【底层的 <code>Lucene</code> 无法支持】。</p><h2 id="思路一"><a href="# 思路一" class="headerlink" title="思路一"></a>思路一 </h2><p> 一种方案是过滤掉无意义的分词结果，保证分词结果的长度在固定数值之内，例如 100，大于 100 的默认为无意义分析结果，可以舍弃。</p><p>可以通过过滤逻辑把分词后的词筛选，长度大于 100 的当作废词，舍弃，比如下面这样的就不要了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200329200845.png" alt="无意义的可舍弃的词" title="无意义的可舍弃的词"></p><p>这种一看就是无意义的分词结果，前面的异常也就表明了这些分词结果是很长的字符串，导致写回 <code>Elasticsearch</code> 时超过最大长度，报错。</p><p>代码如下。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200329200539.png" alt="过滤代码" title="过滤代码"></p><p>当然也可以更换效果更好的分词器，或者添加黑名单，不让它产生这种无意义的分词结果。</p><p>上面使用的是 <code>ansj_seg</code> 分词器，版本是 <code>v5.0.3</code>。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.ansj&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;ansj_seg&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;5.0.3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200329200416.png" alt="分词器依赖" title="分词器依赖"></p><h2 id="思路二"><a href="# 思路二" class="headerlink" title="思路二"></a>思路二 </h2><p> 另一种方案是不对文本分词了，而是给 <code>content</code> 本身设置合适的分词器，直接使用 <code>Elasticsearch</code> 的全文检索功能进行搜索。当然，如果想统计分词的分布是不可行了。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 错误：None of the configured nodes are available</title>
    <url>/2018041301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在使用 <code>Elasticsearch</code> 的 <code>TransportClient</code> 的时候，遇到异常：<code>None of the configured nodes are available</code>，后来发现是 <code>Elasticsearch</code> 集群网络不稳定，通过增加请求重试次数的方式解决。本文涉及的开发环境：<code>Elasticsearch v1.7.5</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 本文中提及的 <code>Elasticsearch</code> 版本为 <code>v1.7.5</code>，是一个比较陈旧的版本，读者在阅读时可能会发现某些方法与高版本不一样，可以不用理会。</p><p>涉及到的业务场景很简单，就是使用 <code>TransportClient</code> 方式去连接 <code>Elasticsearch</code> 集群，然后发送请求、获取结果，解析结果后得到需要的数值。</p><p>在某一次常规的运行过程中，出现异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: []</span><br><span class="line">    at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable (TransportClientNodesService.java:305)</span><br><span class="line">    at org.elasticsearch.client.transport.TransportClientNodesService.execute (TransportClientNodesService.java:200)</span><br><span class="line">    at org.elasticsearch.client.transport.support.InternalTransportClient.execute (InternalTransportClient.java:106)</span><br><span class="line">    at org.elasticsearch.client.support.AbstractClient.search (AbstractClient.java:338)</span><br><span class="line">    at org.elasticsearch.client.transport.TransportClient.search (TransportClient.java:430)</span><br><span class="line">    at org.elasticsearch.action.search.SearchRequestBuilder.doExecute (SearchRequestBuilder.java:1112)</span><br><span class="line">    at org.elasticsearch.action.ActionRequestBuilder.execute (ActionRequestBuilder.java:91)</span><br><span class="line">    at org.elasticsearch.action.ActionRequestBuilder.execute (ActionRequestBuilder.java:65)</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure><p>核心在于 <code>NoNodeAvailableException: None of the configured nodes are available: []</code>，无法获取可用的节点，说明无法连接上指定的主机。可能是主机 <code>ip</code> 指定错误，也可能是 <code>Elasticsearch</code> 集群故障，也可能是网络不好。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><p> 如果上面的主机 <code>ip</code> 配置正确，就没问题，接着查看配置，是正确的。而且进一步考虑，并不是一开始运行就失败抛出异常，而是运行一段时间后才抛出异常，这可以说明网络环境，或者 <code>Elasticsearch</code> 集群偶然性有问题。</p><p>其中，生成 <code>TransportClient</code> 的代码如下，需要指定 <code>ip</code>、集群名称、其它多个参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 获取 Es TransportClient</span><br><span class="line">     *</span><br><span class="line">     * @param clusterName: 集群名 </span><br><span class="line">     * @param hosts        : IPs</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">public static TransportClient getEsClient (String clusterName, String hosts) &#123;</span><br><span class="line">	Settings settings = ImmutableSettings.settingsBuilder ()</span><br><span class="line">	                .put (&quot;cluster.name&quot;, clusterName)</span><br><span class="line">	                .put (&quot;client.transport.ping_timeout&quot;, &quot;120s&quot;)</span><br><span class="line">	                .put (&quot;discovery.zen.fd.ping_retries&quot;, 5)</span><br><span class="line">	                // 嗅探整个集群的状态，不用手动设置集群里所有集群的 ip 到连接客户端 </span><br><span class="line">	.put (&quot;client.transport.sniff&quot;, true)</span><br><span class="line">	                .build ();</span><br><span class="line">	TransportClient client = new TransportClient (settings);</span><br><span class="line">	String [] host = hosts.split (&quot;,&quot;);</span><br><span class="line">	for (String h : host) &#123;</span><br><span class="line">		String [] vals = h.split (&quot;:&quot;);</span><br><span class="line">		int port = vals.length &gt; 1 ? Integer.parseint (vals [1]) : 9300;</span><br><span class="line">		client.addTransportAddress (new InetSocketTransportAddress (vals [0], port));</span><br><span class="line">	&#125;</span><br><span class="line">	return client;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而在抛出异常的地方，代码为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">searchRequestBuilder.execute ().actionGet (new TimeValue (timeOutMinute * 60 * 1000))</span><br></pre></td></tr></table></figure><p>其中，<code>searchRequestBuilder</code> 是请求构造器，包含索引名称、查询条件等信息，来自于 <code>TransportClient</code> 对象，代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//boolQueryBuilder 是查询条件对象 </span><br><span class="line">SearchRequestBuilder searchRequestBuilder = client.prepareSearch (indexName)</span><br><span class="line">                .setTypes (indexType)</span><br><span class="line">                .clearRescorers ()</span><br><span class="line">                .setQuery (boolQueryBuilder)</span><br><span class="line">                .setSize (size);</span><br></pre></td></tr></table></figure><p>以上，理清代码逻辑后，观察 <code>Elasticsearch</code> 集群的状态多次，没有发现异常，那就可能是网络问题了，准备在代码中加上请求重试机制。</p><p>在 <code>searchRequestBuilder.execute ()</code> 抛出异常后等待 5 秒再次重试，最多重试 5 次。</p><p>再次运行程序，观察日志后，发现仍旧有部分请求会失败，但是由于有等待重试的逻辑，不会影响到业务结果。</p><p>这种偶尔的网络问题只能反馈给运维人员继续排查了。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>TransportClient</tag>
        <tag>SearchRequestBuilder</tag>
      </tags>
  </entry>
  <entry>
    <title>FFmpeg 使用总结</title>
    <url>/2019032701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>FFmpeg 是一款开源的软件，可以进行多种格式的视频、音频编码转换、片段剪辑。它包含了 libavcodec – 这是一个用于多个项目中音频和视频的解码器库，以及 libavformat – 一个音频与视频格式转换库。<strong>FFmpeg</strong> 这个单词中的 <strong>FF</strong> 指的是 <strong>Fast Forward</strong>。FFmpeg 官网：<a href="https://ffmpeg.org" target="_blank" rel="noopener">https://ffmpeg.org</a> ，下载时会跳转到这里：<a href="https://ffmpeg.zeranoe.com/builds" target="_blank" rel="noopener">https://ffmpeg.zeranoe.com/builds</a> ，请选择合适的版本下载使用。本文记录 FFmpeg 的使用方法，基于 Windows X64 平台。</p><a id="more"></a><h1 id="下载安装"><a href="# 下载安装" class="headerlink" title="下载安装"></a>下载安装 </h1><h2 id="下载"><a href="# 下载" class="headerlink" title="下载"></a> 下载 </h2><p> 在 <a href="https://ffmpeg.zeranoe.com/builds" target="_blank" rel="noopener">https://ffmpeg.zeranoe.com/builds</a> 下载页面，选择适合自己操作系统的版本，我这里选择 Windows X64 的 static zip 包，解压后直接使用，无需安装。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3ly1g1ivhlcgh4j21hc0q9dkh.jpg" alt="FFmpeg 下载页面" title="FFmpeg 下载页面"></p><h2 id="解压配置环境变量"><a href="# 解压配置环境变量" class="headerlink" title="解压配置环境变量"></a>解压配置环境变量 </h2><p> 下载到指定的目录【最好放在方便管理的目录，不显得混乱】，直接解压，得到一个文件夹，里面有 bin、doc、presets 这 3 个子文件夹，其中 bin 里面就包含了主程序：ffmpeg、ffplay、ffprobe，这里不涉及安装的概念，程序可以直接使用。</p><p>解压主目录 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3ly1g1ivi9q552j20o00hgt9m.jpg" alt="解压主目录" title="解压主目录"></p><p> 子文件夹 bin<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3ly1g1ividmkdbj20o00hg753.jpg" alt="子文件夹 bin" title="子文件夹 bin"></p><p>为了方便使用这 3 个主程序，需要把 bin 所在目录配置到环境变量 PATH 中【我这里是 D:\Program Files\ffmpeg\bin】，这里就不再赘述，如果不配置，每次使用命令时都要给出完整的目录，我觉得很麻烦。</p><h1 id="使用示例"><a href="# 使用示例" class="headerlink" title="使用示例"></a>使用示例 </h1><p>ffmpeg 的命令行参数的位置会影响执行的结果，例如时间参数，这与我所知道的其它工具不一样，所以参数位置不能乱放。此外，还需要注意涉及到转码的操作会比较耗时，几十分钟的视频不是几分钟能处理完的，和视频的清晰度也有关系，这个要有一定的心理准备。</p><p>1、把 mkv 格式的视频文件转为 mp4 格式的文件，视频使用 <strong>libx264</strong> 编码。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 如果没有配置环境变量 PATH, 命令需要指定 D:\Program Files\ffmpeg\bin\ffmpeg</span><br><span class="line">ffmpeg -i imput.mkv -c:v libx264 output.mp4</span><br></pre></td></tr></table></figure><p> 里面的字幕信息如果是和视频一起的，会自动携带输出。</p><p>2、查看视频文件的流信息，包括视频、音频、字幕。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 其中类似 Stream #0:0 格式的内容就是流信息，指定参数时可以直接使用数字编号表示流 </span><br><span class="line">ffmpeg -i input.mkv</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3ly1g1ivijvhopj20l50cpjso.jpg" alt="查看视频文件的流信息" title="查看视频文件的流信息"></p><p>3、mkv 文件剪辑，截取片段，指定音轨。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- -ss 表示开始时间，-to 表示结束时间，</span><br><span class="line">ffmpeg -ss 01:22:08 -to 01:32:16 -accurate_seek -i in.mkv -map 0:v -map 0:a:1 -codec copy -avoid_negative_ts 1 out.mkv</span><br></pre></td></tr></table></figure><p>其中，<strong>-accurate_seek</strong> 表示画面帧数校准，<strong>-avoid_negative_ts 1</strong> 表示修复结尾可能的空白帧，<strong>-map 0:v</strong> 表示截取所有视频，<strong>-map 0:a:1</strong> 表示截取第 2 道音轨。</p><p>此外，如果把时间参数放在 -i 前面，结果总会多截取 1-2 秒【如上面示例】。但是如果放在后面，截取的视频片段时间准确了，然而开头的音频正常，视频有 20-30 秒的漆黑一片，不知道为啥。</p><p>注意，如果视频带有内嵌字幕【mkv 携带的一般是 ASS 字幕】，也需要一起剪辑的话，需要指定参数：<strong>-map 0:s</strong>，格式和指定视频、音频的格式一致。如果是其它格式的字幕，只要确保 ffmpeg 支持即可使用字幕相关的参数，那么怎么查看呢，很简单，使用 <strong>ffmpeg -codecs |grep title</strong> 命令即可搜索。</p><p>4、rmvb 文件转为 mp4 文件，涉及到编码转换。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 视频使用 h264 编码，音频使用 aac 编码 </span><br><span class="line">ffmpeg -i input.rmvb -c:v h264 -c:a aac out.mp4</span><br></pre></td></tr></table></figure><p>这里需要注意，涉及到编码转换的比较消耗 CPU，上面这个命令把我的 CPU 消耗到 100%，动态视频详见微博：<a href="https://weibo.com/3086148515/HmVcnm7Kl" target="_blank" rel="noopener">FFmpeg 视频转码 CPU 飙升到 100%</a> 。其中，留意流输出信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Stream mapping:</span><br><span class="line">  Stream #0:1 -&gt; #0:0 (rv40 (native) -&gt; h264 (libx264))</span><br><span class="line">  Stream #0:0 -&gt; #0:1 (cook (native) -&gt; aac (native))</span><br></pre></td></tr></table></figure><p>此外，FFmpeg 不支持 rmvb 格式的文件，只能转码为 mp4 的格式再使用，这里的不支持不是指不能处理，而是不能直接输出 rmvb 格式的文件，处理输入是可以的。</p><p>5、多个 mp4 文件拼接，先转为同样的编码格式的 ts 流，再拼接 ts 流接着转换为 mp4 格式的输出。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ffmpeg -i 1.mp4 -vcodec copy -acodec copy -vbsf h264_mp4toannexb 1.ts</span><br><span class="line">ffmpeg -i 2.mp4 -vcodec copy -acodec copy -vbsf h264_mp4toannexb 2.ts</span><br><span class="line">ffmpeg -i &quot;concat:1.ts|2.ts&quot; -acodec copy -vcodec copy -absf aac_adtstoasc output.mp4</span><br></pre></td></tr></table></figure><p>简单高效，而且视频质量没有损失。</p><h1 id="其它"><a href="# 其它" class="headerlink" title="其它"></a>其它</h1><p>1、如果只是为了转换 mkv 文件的格式为 mp4，也可以使用一款软件：<a href="https://www.videohelp.com/software/MkvToMp4" target="_blank" rel="noopener">MkvToMp4</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>FFmpeg</tag>
        <tag>视频剪辑</tag>
        <tag>音频剪辑</tag>
        <tag>视频转码</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 异常之 Unlink of file</title>
    <url>/2019100801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在使用 <code>Git</code> 的时候，出现错误：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Unlink of file &apos;.git/objects/pack/pack-xx.idx&apos; failed. Should I try again? (y/n)</span><br></pre></td></tr></table></figure><p>连续出现几十次，看起来像是 <code>Git</code> 在操作索引文件时被拒绝了，可能是文件权限问题，或者文件被占用。</p><p>本文内容中涉及的 <code>Git</code> 版本为：<code>2.18.0.windows.1</code>，操作系统为：<code>Windows 7x64</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在对一个普通的 <code>Git</code> 项目进行 <code>git pull</code> 操作的时候，出现错误，显示如下的交互询问内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Unlink of file &apos;.git/objects/pack/pack-61113bb66bb6a4dcc0893ee5e0b36bf30cf917e6.idx&apos; failed. Should I try again? (y/n) </span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-670222495fa872c140e7e231e36cb2701d76c86b.idx&apos; failed. Should I try again? (y/n) </span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-6acdf7d3bbb7394f39b68e0e40b47ca0116fbfa2.idx&apos; failed. Should I try again? (y/n) </span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-6ffde68d8af2eafb0803063b895291418ed5f465.idx&apos; failed. Should I try again? (y/n)</span><br></pre></td></tr></table></figure><p>尝试手动输入 <code>y</code> 或者 <code>n</code>，并没有什么效果，输入 <code>y</code> 后同样的错误会继续出现，输入 <code>n</code> 会接着提示下一个类似的文件错误。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Unlink of file &apos;.git/objects/pack/pack-61113bb66bb6a4dcc0893ee5e0b36bf30cf917e6.idx&apos; iled. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-61113bb66bb6a4dcc0893ee5e0b36bf30cf917e6.idx&apos; failed. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-61113bb66bb6a4dcc0893ee5e0b36bf30cf917e6.idx&apos; failed. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-61113bb66bb6a4dcc0893ee5e0b36bf30cf917e6.idx&apos; failed. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-61113bb66bb6a4dcc0893ee5e0b36bf30cf917e6.idx&apos; failed. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-61113bb66bb6a4dcc0893ee5e0b36bf30cf917e6.idx&apos; failed. Should I try again? (y/n) n</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-670222495fa872c140e7e231e36cb2701d76c86b.idx&apos; failed. Should I try again? (y/n) n</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-6acdf7d3bbb7394f39b68e0e40b47ca0116fbfa2.idx&apos; failed. Should I try again? (y/n) n</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-6ffde68d8af2eafb0803063b895291418ed5f465.idx&apos; failed. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-6ffde68d8af2eafb0803063b895291418ed5f465.idx&apos; failed. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-6ffde68d8af2eafb0803063b895291418ed5f465.idx&apos; failed. Should I try again? (y/n) y</span><br><span class="line">Unlink of file &apos;.git/objects/pack/pack-6ffde68d8af2eafb0803063b895291418ed5f465.idx&apos; failed. Should I try again? (y/n) y</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191008210804.png" alt="Git 文件被占用" title="Git 文件被占用"></p><p>可见是要把所有同类型的文件全部询问一次，看起来问题没那么简单。</p><p>如果有耐心的话，连续输入几十次 <code>n</code>，可能会把所有的文件都忽略掉，提示也就结束了，或者直接使用 <code>ctrl + c</code> 结束操作，强制退出，但是这样操作并没有从根本上解决这个问题。</p><h1 id="分析解决"><a href="# 分析解决" class="headerlink" title="分析解决"></a>分析解决 </h1><p> 经过查询分析，这个问题的根本原因是 <code>Git</code> 项目的文件被其它程序占用，导致 <code>Git</code> 没有权限变更这些文件。这些文件是 <code>Git</code> 产生的临时文件，需要从 <code>Git</code> 的工作区移除。</p><p>上面提及的其它程序极有可能是 <code>IDEA</code>、<code>Eclipse</code>、<code>Visual Studio</code> 等常用的开发工具。</p><p>参考：<a href="https://stackoverflow.com/questions/4389833/unlink-of-file-failed-should-i-try-again" target="_blank" rel="noopener">stackoverflow.com</a> 。</p><p>解决方案也很简单，把占用文件的程序关闭就行。但是有时候找不到是哪个程序占用了文件，怎么办，可以利用微软的 <code>Process Explorer</code> 工具，具体介绍参考备注内容。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p>1、<code>Process Explorer</code> 是一个任务管理器，目前由微软开发，仅用于 <code>Windows</code> 操作系统平台，可以查看系统的进程信息、资源占用信息、文件占用信息，官网地址：<a href="https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer" target="_blank" rel="noopener">Process Explorer</a> 。</p><p> 同时，这个工具目前在 <code>GitHub</code> 上已经开源，并重新命名为：<code>sysinternals</code>，<code>GitHub</code> 的地址：<a href="https://github.com/MicrosoftDocs/sysinternals/tree/live" target="_blank" rel="noopener">sysinternals</a> 。</p><p>使用时无需安装，解压后直接可以运行，在主界面依次选择 <code>Find</code> -&gt; <code>Find Handle or DLL</code>，在搜索框中输入程序的名字、文件的名字，点击搜索，就可以看到搜索结果了，例如正在运行的进程、文件的使用情况等。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191008210836.png" alt="使用 Process Explorer 查看文件占用情况" title="使用 Process Explorer 查看文件占用情况"></p><p>2、我留意到在上述的 <code>stackoverflow</code> 链接中，也有人建议先使用 <code>git gc</code> 来手动执行一下垃圾清理，把临时文件给清理掉，然才进行 <code>git pull</code> 操作。我没有测试过，但感觉也有道理，读者可以试试。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS 异常之 Filesystem closed</title>
    <url>/2018122701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天通过 Hadoop 的 api 去操作 HDFS 里面的文件，读取文本内容，但是在代码里面总是抛出以下异常：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Caused by: java.io.IOException: Filesystem closed</span><br></pre></td></tr></table></figure><p>然而文本内容又是正常读取出来的，但是我隐隐觉得读取的文本内容可能不全，应该只是所有文本内容的一部分。本文就记录这个问题的原因、影响以及解决方法。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 通过查看日志发现，有大量的异常日志打印出来，全部都是操作 HDFS 的时候产生的，有的是使用 Spark 连接 HDFS 读取文本数据，有的是使用 Hadoop 的 Java api 通过文件流来读取数据，每次读取操作都会产生一个如下异常信息（会影响实际读取的内容，多个 DataNode 的内容会漏掉）：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2018</span>-<span class="number">12</span>-<span class="number">26_23</span>:<span class="number">25</span>:<span class="number">46</span> [SparkListenerBus] ERROR scheduler.LiveListenerBus:<span class="number">95</span>: Listener EventLoggingListener threw an exception</span><br><span class="line">java.lang.reflect.InvocationTargetException</span><br><span class="line">	at sun.reflect.GeneratedMethodAccessor33.invoke (Unknown Source)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">	at java.lang.reflect.Method.invoke (Method.java:<span class="number">498</span>)</span><br><span class="line">	at org.apache.spark.scheduler.EventLoggingListener$$anonfun$logEvent$<span class="number">3</span>.apply (EventLoggingListener.scala:<span class="number">150</span>)</span><br><span class="line">	at org.apache.spark.scheduler.EventLoggingListener$$anonfun$logEvent$<span class="number">3</span>.apply (EventLoggingListener.scala:<span class="number">150</span>)</span><br><span class="line">	at scala.Option.foreach (Option.scala:<span class="number">236</span>)</span><br><span class="line">	at org.apache.spark.scheduler.EventLoggingListener.logEvent (EventLoggingListener.scala:<span class="number">150</span>)</span><br><span class="line">	at org.apache.spark.scheduler.EventLoggingListener.onJobStart (EventLoggingListener.scala:<span class="number">173</span>)</span><br><span class="line">	at org.apache.spark.scheduler.SparkListenerBus$class.onPostEvent (SparkListenerBus.scala:34)</span><br><span class="line">	at org.apache.spark.scheduler.LiveListenerBus.onPostEvent (LiveListenerBus.scala:<span class="number">31</span>)</span><br><span class="line">	at org.apache.spark.scheduler.LiveListenerBus.onPostEvent (LiveListenerBus.scala:<span class="number">31</span>)</span><br><span class="line">	at org.apache.spark.util.ListenerBus$class.postToAll (ListenerBus.scala:55)</span><br><span class="line">	at org.apache.spark.util.AsynchronousListenerBus.postToAll (AsynchronousListenerBus.scala:<span class="number">37</span>)</span><br><span class="line">	at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>$$anonfun$run$<span class="number">1</span>$$anonfun$apply$mcV$sp$<span class="number">1</span>.apply$mcV$sp (AsynchronousListenerBus.scala:<span class="number">80</span>)</span><br><span class="line">	at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>$$anonfun$run$<span class="number">1</span>$$anonfun$apply$mcV$sp$<span class="number">1</span>.apply (AsynchronousListenerBus.scala:<span class="number">65</span>)</span><br><span class="line">	at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>$$anonfun$run$<span class="number">1</span>$$anonfun$apply$mcV$sp$<span class="number">1</span>.apply (AsynchronousListenerBus.scala:<span class="number">65</span>)</span><br><span class="line">	at scala.util.DynamicVariable.withValue (DynamicVariable.scala:<span class="number">57</span>)</span><br><span class="line">	at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>$$anonfun$run$<span class="number">1</span>.apply$mcV$sp (AsynchronousListenerBus.scala:<span class="number">64</span>)</span><br><span class="line">	at org.apache.spark.util.Utils$.tryOrStopSparkContext (Utils.scala:<span class="number">1181</span>)</span><br><span class="line">	at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>.run (AsynchronousListenerBus.scala:<span class="number">63</span>)</span><br><span class="line">Caused by: java.io.IOException: Filesystem closed</span><br><span class="line">	at org.apache.hadoop.hdfs.DFSClient.checkOpen (DFSClient.java:<span class="number">795</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync (DFSOutputStream.java:<span class="number">1986</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.DFSOutputStream.hflush (DFSOutputStream.java:<span class="number">1947</span>)</span><br><span class="line">	at org.apache.hadoop.fs.FSDataOutputStream.hflush (FSDataOutputStream.java:<span class="number">130</span>)</span><br><span class="line">	... <span class="number">20</span> more</span><br></pre></td></tr></table></figure><p>最直接清晰的描述就是：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Caused by: java.io.IOException: Filesystem closed</span><br></pre></td></tr></table></figure><p>上述异常信息表明 HDFS 的 Filesystem 被关闭了，但是代码仍旧试图打开文件流读取内容。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><h2 id="分析一下"><a href="# 分析一下" class="headerlink" title="分析一下"></a> 分析一下 </h2><p> 根据上述信息，查看代码，每次操作 HDFS 都是独立的，会先根据统一的 conf 创建 Filesystem，然后根据文件路径创建 Path，打开输入流，读取内容，读取完成后关闭 Filesystem，没有什么异常的地方。</p><p>同时，根据异常信息可以发现，异常的抛出点并不是业务逻辑代码，更像是已经开始开启文件流读取文件，读着读着 Filesystem 就被关闭了，然后引发了异常，而业务逻辑中并没有突然关闭 Filesystem 的地方，也没有多线程操作 Filesystem 的地方。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取文件内容 </span></span><br><span class="line"><span class="comment"> * 纯文本，不做转换 </span></span><br><span class="line"><span class="comment"> * 如果传入目录，返回空内容 </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> hdfsFile</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Set&lt;String&gt; <span class="title">getFileContent</span><span class="params">(String hdfsFile)</span> </span>&#123;</span><br><span class="line">    Set&lt;String&gt; dataResult = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 连接 hdfs</span></span><br><span class="line">        fs = FileSystem.get (CONF);</span><br><span class="line">        Path path = <span class="keyword">new</span> Path (hdfsFile);</span><br><span class="line">        <span class="keyword">if</span> (fs.isFile (path)) &#123;</span><br><span class="line">            FSDataInputStream fsDataInputStream = fs.open (path);</span><br><span class="line">            BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader (<span class="keyword">new</span> InputStreamReader (fsDataInputStream));</span><br><span class="line">            String line = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">null</span> != (line = bufferedReader.readLine ())) &#123;</span><br><span class="line">                dataResult.add (line);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            LOGGER.error (<span class="string">"!!!! 当前输入参数为目录，不读取内容:&#123;&#125;"</span>, hdfsFile);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        LOGGER.error (<span class="string">"!!!! 处理 hdfs 出错:"</span> + e.getMessage (), e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != fs) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                fs.close ();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                LOGGER.error (<span class="string">"!!!! 关闭文件流出错:"</span> + e.getMessage (), e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dataResult;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过查找文档发现，这个异常是 Filesystem 的缓存导致的。</p><p>当任务提交到集群上面以后，多个 datanode 在 getFileSystem 过程中，由于 Configuration 一样，会得到同一个 FileSystem。如果有一个 datanode 在使用完关闭连接，其它的 datanode 在访问时就会出现上述异常，导致数据缺失（如果数据恰好只存在一个 datanode 上面，可能没问题）。</p><h2 id="找到方法"><a href="# 找到方法" class="headerlink" title="找到方法"></a>找到方法 </h2><p> 通过上面的分析，找到了原因所在，那么解决方法有 2 种：</p><p>1、可以在 HDFS 的 core-site.xml 配置文件里面把 fs.hdfs.impl.disable.cache 设置为 true，这样设置会全局生效，所有使用这个配置文件的连接都会使用这种方式，有时候可能不想这样更改，那就使用第 2 种方式；</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.hdfs.impl.disable.cache<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2、在 HDFS 提供的 Java api 里面更改配置信息，则会只针对使用当前 conf 的连接有效，相当于临时参数。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 缓存 fs, 避免多 datanode 异常：Caused by: java.io.IOException: Filesystem closed</span></span><br><span class="line">CONF.setBoolean (<span class="string">"fs.hdfs.impl.disable.cache"</span>, <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure><p>上面 2 种方法的目的都是为了关闭缓存 Filesyetem 实例，这样每次获得的 Filesystem 实例都是独立的，不会产生上述的异常，但是缺点就是会增加网络的 I/O，频繁开启、关闭文件流。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结</h1><p>1、参考：<a href="https://stackoverflow.com/questions/23779186/ioexception-filesystem-closed-exception-when-running-oozie-workflow" target="_blank" rel="noopener">https://stackoverflow.com/questions/23779186/ioexception-filesystem-closed-exception-when-running-oozie-workflow</a> ；</p><p>2、保留日志，查看日志很重要；</p><p>3、FileSytem 类内部有一个 static CACHE，用来保存每种文件系统的实例集合，FileSystem 类中可以通过参数 fs.% s.impl.disable.cache 来指定是否禁用缓存 FileSystem 实例（其中 % s 替换为相应的 scheme，比如 hdfs、local、s3、s3n 等）。如果没禁用，一旦创建了相应的 FileSystem 实例，这个实例将会保存在缓存中，此后每次 get 都会获取同一个实例，但是如果被关闭了，则再次用到就会无法获取（多 datanode 读取数据的时候）；</p><p>4、源码分析放在以后，留坑。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Hadoop 从零基础到入门系列</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
        <tag>Filesystem</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 框架 Next 主题添加自定义 Page</title>
    <url>/2017050701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在整理博客的过程中，发现需要新增一些页面，对于 Hexo 框架来说是 <strong>page</strong> 的概念，例如 <strong>首页 </strong>、<strong> 关于 </strong>、<strong> 分类 </strong>、<strong> 搜索 </strong>等页面。这种页面不同于每一篇博客文章那种发表的内容，对于 Hexo 框架来说是 <strong>post</strong>，而是可以交互的页面，例如可以在 <strong>搜索 </strong>页面中搜索博客的内容，可以在 <strong>分类 </strong>页面中查看博客文章的分类统计。当然，类似于 <strong>关于 </strong>这种页面也是静态的，没有交互的概念。</p><p>上面提到的这些页面都是 Next 主题自带的，只要在 <strong>_config.yml</strong> 配置文件中开启相关配置即可，不需要关心它是怎么实现的，例如开启了 <strong>分类 </strong>页面，它会自动把博客的分类统计好，展示出来。但是我的想法其实是新增一个页面，并且自定义图标、名称、内容，其实也可以实现，本文记录这个过程。</p><a id="more"></a><h1 id="自带的页面"><a href="# 自带的页面" class="headerlink" title="自带的页面"></a>自带的页面 </h1><p>Hexo 自带的页面有好几种，例如：关于、首页、分类、搜索、站点地图、404 页面等，可以在主题的配置文件中查看 menu 选项 。例如我使用的是 Next 主题，在 <strong>themes/next/_config.yml</strong> 中查看 <strong>menu</strong> 选项，我这里已经配置好 <strong>home、about、tags、categories、archives</strong>，此外还有没有开启的 schedule、sitemap、commonweal 等，先忽略我新增的 books 页面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f8d8zazwj20j508ldg9.jpg" alt="Hexo 自带的页面配置" title="Hexo 自带的页面配置"></p><p> 这里面的配置有固定的格式，一共有四列：第一列是展示的名字以及页面标识、第二列是 url 地址、第三列是固定的双竖线、第四列是图标名称。我这里使用 <strong>about: /about/ || user</strong> 举例，<strong>about</strong> 就是页面的名字【虽然配置的是英文，但是有汉化字典转为中文，汉化字典文件为：themes/next/languages/zh-Hans.yml】，<strong>/about/</strong> 是页面的 url 地址，表示从主页跳转的地址，前面加上域名可以直接访问，<strong>||</strong> 双竖线是固定标识符，<strong>user</strong> 是图标名称，来自于一个图标库：<a href="https://fontawesome.com" target="_blank" rel="noopener">https://fontawesome.com</a> 。</p><p>只要开启这个配置，就可以看到关于的页面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f8eqfnloj214i0bj0t7.jpg" alt="关于页面" title="关于页面"></p><p>这些页面都不需要特殊的处理，直接配置完成就可以直接使用，可以在项目的 source 目录里面查看子文件夹，每个子文件夹都会对应一个页面，文件夹里面有一个 index.md 文件，就是页面的原始数据。但是对于搜索、分类、归档等可以交互的页面，Hexo 在渲染时还会重新计算，这里面的 index.md 文件没有内容，只是表示开启了这个页面。而对于静态页面，直接在相应的 index.md 文件里面写上内容就行了，Hexo 值了渲染不会再重新计算内容。例如关于页面，就可以使用 Markdown 语法在 about/index.md 文件里面写上关于作者的简介，我下面要新增的页面也是类似这种格式。</p><p>各种页面对应的子文件夹 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f8ihzp17j20ng09d3zp.jpg" alt="各种页面对应的子文件夹" title="各种页面对应的子文件夹"></p><h1 id="新增页面"><a href="# 新增页面" class="headerlink" title="新增页面"></a> 新增页面 </h1><p> 了解完了自带的页面，接下来准备新增自定义页面。</p><p>我需要新增的是一个静态页面，名称为 <strong>书籍 </strong>，里面会列出我的读书清单，并给出书籍的部分信息。</p><h2 id="生成页面并编辑"><a href="# 生成页面并编辑" class="headerlink" title="生成页面并编辑"></a>生成页面并编辑 </h2><p> 经过查询 Hexo 的语法，生成新页面的命令为：<strong>hexo new page name</strong>，page 是关键字，name 表示页面的名字，我直接使用 <strong>hexo new page books</strong> 即可。</p><p>执行完命令后，可以在 <strong>source</strong> 目录看到生成了一个 <strong>books</strong> 目录，里面有一个 index.md 文件，直接编辑这个页面即可。</p><p>简单编辑内容如图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f90i7b71j20so0iyt9a.jpg" alt="编辑内容" title="编辑内容"></p><p>这里需要注意文件头的内容，有固定的格式：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 书籍 </span><br><span class="line">date: 2019-04-25 00:16:58</span><br><span class="line">type: books</span><br><span class="line">comments: false</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>其中，title 就是渲染后 html 网页的居中标题以及网页的 title 标签值，会在浏览器的 tab 页上面显示【这里也可以使用英文名称 books，但是需要在汉化文件的 title 选项下面增加中英文配置，和后面的 menu 汉化类似】。type 就是页面的类别，与自定义页面名称保持一致。此外 comments 切记关闭，因为博客如果开启了评论功能，会默认在所有的页面都开启评论框，而这种自定义页面是不需要评论框的，因此选择关闭，即设置为 false。</p><h2 id="开启页面配置"><a href="# 开启页面配置" class="headerlink" title="开启页面配置"></a>开启页面配置 </h2><p> 在主题的配置文件 <strong>themes/next/_config.yml</strong> 中，配置自定义页面，在 <strong>menu</strong> 选项下面，配置内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">books: /books/ || book</span><br></pre></td></tr></table></figure><p>截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f93rrtmnj20ke07ft8w.jpg" alt="配置自定义页面" title="配置自定义页面"></p><p>其中，<strong>books</strong> 是新建的页面名称，<strong>/books/</strong> 是链接，<strong>book</strong> 是图标【因为没有 books 图标可以使用，只能使用 book 图标了，原因在最后会描述，主要是收费问题】。</p><h2 id="汉化页面名称"><a href="# 汉化页面名称" class="headerlink" title="汉化页面名称"></a>汉化页面名称 </h2><p> 配置 <strong>themes/next/languages/zh-Hans.yml</strong> 文件，也是在 <strong>menu</strong> 选项下面，配置内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">books: 书籍 </span><br></pre></td></tr></table></figure><p>截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f91cim2zj209v0740ss.jpg" alt="汉化内容" title="汉化内容"></p><h2 id="打开页面预览"><a href="# 打开页面预览" class="headerlink" title="打开页面预览"></a>打开页面预览 </h2><p> 在博客点击书籍页面或者直接输入 <strong>域名 /books/</strong> 链接，打开页面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f91ppnacj214n0n1411.jpg" alt="预览书籍页面" title="预览书籍页面"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a>注意事项 </h1><p> 注意，图标是来自于图标库：<a href="https://fontawesome.com" target="_blank" rel="noopener">https://fontawesome.com</a> ，只要提供图标的名字即可，Hexo 会自动匹配对应的图标展示。需要特别注意的是，这里面的图标有大部分是收费的【搜索时会显示灰色状态，能免费使用的才会显示黑色状态】，所以不能使用，即使配置了名称 Hexo 也不会展示出来。例如我想使用一个名字为 <strong>books</strong> 的图标，是收费的，发现 Hexo 不会展示，我换成了另外一个名字为 <strong>book</strong> 的免费图标，Hexo 就可以正常展示了。</p><p>搜索图标结果<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2f92ey3d0j21g80k3dif.jpg" alt="搜索图标结果" title="搜索图标结果"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>page</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 博客静态资源压缩优化</title>
    <url>/2018112101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>使用 <code>hexo-cli</code> 生成的静态网页 html 文件，使用文本编辑器打开，可以看到内容中有大量的回车换行等空白符。尽管是空白符，但是也占据着空间大小，而且那么多，导致 html 文件偏大，网页加载时不仅浪费流量，而且还影响速度。同时，最重要的是对于手机端来说，静态页面 html 文件太大了的确不友好。所以要做优化，用术语说是压缩，其实目的就是在生成 html 文件时，尽量去除内容中多余的空白符，减小 html 文件的大小。此外，顺便也把 <code>css</code> 文件、<code>js</code> 文件一起压缩了。</p><a id="more"></a><h1 id="当前现象"><a href="# 当前现象" class="headerlink" title="当前现象"></a>当前现象 </h1><p> 为了简单起见，只是列举 html 文件来看现象，目前查看生成的 8 个 html 静态页面（为了具有对比性，不包含当前页面），大小为 314 K。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxg5iuthmbj20sr0guta4.jpg" alt="8 个 html 文件" title="8 个 html 文件"></p><p>打开其中一个 html 文件查看内容，可以看到很多回车换行符。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxg5kn3bz2j20u00iidgy.jpg" alt="连续多个回车换行符" title="连续多个回车换行符"></p><p>接下来就是要想办法消除这些空白符。</p><h1 id="压缩方式选择"><a href="# 压缩方式选择" class="headerlink" title="压缩方式选择"></a>压缩方式选择 </h1><p> 通过查看 <code>hexo</code> 官网（附上插件库：<a href="https://hexo.io/plugins/" target="_blank" rel="noopener">hexo 插件库 </a>），搜索资料了解别人的例子，发现有两种方式：</p><ul><li> 一种是先全局（-g 参数）安装 <code>gulp</code> 模块，根据压缩需求再安装需要的模块，例如 <code>gulp-htmlclean</code>、<code>gulp-htmlmin</code>、<code>gulp-imagemin</code>、<code>gulp-minify-css</code>、<code>gulp-uglify</code>，每个模块都有自己的功能，另外需要单独配置一个 <code>js</code> 脚本（放在站点根目录下），指明使用的模块，文件所在目录或者通配符文件名，然后每次使用 <code>hexo generate</code> 之后再使用 <code>gulp</code> 就可以压缩文件了。这种方式灵活度高，可以自定义，而且 <code>gulp</code> 的功能与 <code>hexo</code> 解耦，如果有其它静态文件，也可以使用 <code>gulp</code> 进行压缩。但是缺点也显而易见，门槛太高了，根据我的折腾经验，如果出了问题肯定要捣鼓半天，对于我这种零基础的人来说不够友好，我不选择；</li><li>另一种是类似于 <code>hexo</code> 的一个插件，像其它插件或者主题一样，直接安装一个模块，在配置文件中配置你想要的压缩内容，在 <code>hexo generate</code> 的时候就可以实现压缩，无需关心具体流程，也不用配置什么脚本，非常容易，我选择这个，目前我看到有两个类似的插件：<a href="https://github.com/rozbo/hexo-neat" target="_blank" rel="noopener">hexo-neat</a>、<a href="https://github.com/mamboer/hexo-filter-cleanup" target="_blank" rel="noopener">hexo-filter-cleanup</a>，用法都差不多，我选择前者，其实这些插件也是依赖于其它插件，把多种插件的功能整合在一起而已。</li></ul><h1 id="安装配置"><a href="# 安装配置" class="headerlink" title="安装配置"></a>安装配置 </h1><p><code>hexo-neat</code> 插件其实是使用 <code>HTMLMinifier</code>、<code>clean-css</code>、<code>UglifyJS</code> 插件实现。</p><p> 安装（由于网络不稳定因素，可能不是一次就成功，可以多试几次）<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-neat --save</span><br></pre></td></tr></table></figure><p></p><p>站点配置 <br> 编辑站点的配置文件 <code>_config.yml</code>，开启对应的属性 </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 文件压缩，设置一些需要跳过的文件 </span></span><br><span class="line"><span class="comment"># hexo-neat</span></span><br><span class="line">neat_enable: <span class="literal">true</span></span><br><span class="line"><span class="comment"># 压缩 html</span></span><br><span class="line">neat_html:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  exclude:</span><br><span class="line"><span class="comment"># 压缩 css</span></span><br><span class="line">neat_css:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  exclude:</span><br><span class="line">    - <span class="string">'**/*.min.css'</span></span><br><span class="line"><span class="comment"># 压缩 js</span></span><br><span class="line">neat_js:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  mangle: <span class="literal">true</span></span><br><span class="line">  output:</span><br><span class="line">  compress:</span><br><span class="line">  exclude:</span><br><span class="line">    - <span class="string">'**/*.min.js'</span></span><br><span class="line">    - <span class="string">'**/jquery.fancybox.pack.js'</span></span><br><span class="line">    - <span class="string">'**/index.js'</span></span><br></pre></td></tr></table></figure><h1 id="查看效果"><a href="# 查看效果" class="headerlink" title="查看效果"></a> 查看效果 </h1><p> 在执行 <code>hexo generate</code> 的命令行中就可以看到压缩率输出。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190722232547.png" alt="压缩率输出" title="压缩率输出"></p><p>8 个 html 文件被压缩后，大小只有 206 K，和之前的 314 K 比少了 108 K，虽然只是简单的数字，也可以看到压缩效果不错。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxg6y7u1mej20ro0guq49.jpg" alt="8 个文件压缩后" title="8 个文件压缩后"></p><p>继续打开先前打开的那个 html 文件，可以看到整个 html 文档被合并成为了一行文本内容，不影响浏览器对 html 文件的解析展示，回车换行的空白符内容肯定没有了。但是这样对于 html 文件的可读性变差了，最好还是使用一些回车换行符的，还好这些 html 文件我不会去看，能接受目前的效果。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxg743fu8jj20u00igq3g.jpg" alt="html 文件内容合并为一行" title="html 文件内容合并为一行"></p><h1 id="踩坑记录"><a href="# 踩坑记录" class="headerlink" title="踩坑记录"></a>踩坑记录 </h1><p>1、由于牵涉到压缩文件，所以 <code>hexo</code> 生成静态文件的速度会比以前慢一点，但是可以接受。</p><p>2、不要跳过 .md 文件，也不要跳过 .swig 文件，因为是在 <code>hexo generate</code> 阶段进行压缩的，所以这些文件必须交给 <code>hexo-neat</code> 插件处理，才能保证生成的 html 文件纯净。</p><p>3、参考博客：</p><ul><li><a href="https://www.huangzz.xyz/hexo-optimized-file-compression.html" target="_blank" rel="noopener"> 个人博客 </a></li><li><a href="https://blog.csdn.net/lewky_liu/article/details/82432003" target="_blank" rel="noopener">CSDN 博客</a></li><li><a href="https://www.ecpeng.com/2018/04/02/% E5%85% B3% E4% BA%8Ehexo% E5%8D%9A% E5% AE% A2% E9%9D%99% E6%80%81% E8% B5%84% E6% BA%90% E5%8E%8B% E7% BC% A9% E4% BC%98% E5%8C%96/" target="_blank" rel="noopener"> 个人博客 </a></li><li><a href="https://juejin.im/post/5a93c9385188257a84625aad" target="_blank" rel="noopener"> 掘金博客</a></li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>建站</tag>
        <tag>代码压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA 代理设置伪装激活信息</title>
    <url>/2017101701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>首先声明，此内容并不是教大家破解 <code>IDEA</code>，而仅仅是供学习使用，我在偶然间发现这个方法，觉得很有趣，想探究一下背后的实现原理。因此我选择了一个低版本的 <code>IDEA</code>【<code>v2017.2</code>】进行测试，当然，据说这种方式也只能破解低版本的 <code>IDEA</code>。</p><p>建议读者购买正版 <code>IDEA</code>，或者使用社区版本、校园版本，功能是足够使用的，当然这仅限于个人开源项目开发、学习测试使用，如果是公司的项目开发，为了避免法律风险，还是购买正版 <code>IDEA</code>。</p><p>下文中使用的操作系统为 <code>Windows 10</code>。</p><a id="more"></a><h1 id="准备工作"><a href="# 准备工作" class="headerlink" title="准备工作"></a>准备工作 </h1><p> 首先需要安装好 <code>IDEA v2017.2</code>，其它版本我没有使用过，不知道可行与否，所以还是建议读者使用我指定的版本测试，避免踩坑。</p><p>另外还要准备一个 <code>jar</code> 包文件，里面封装了相关激活逻辑，这个包文件很小，不到 <code>1MB</code>。包文件已经被我上传到 <code>GitHub</code>，读者可以下载使用：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20171017" target="_blank" rel="noopener">JetbrainsCrack.jar</a> 。</p><h1 id="配置"><a href="# 配置" class="headerlink" title="配置"></a>配置 </h1><p> 配置内容很简单，即给 <code>IDEA</code> 设置一个代理，指向前面准备好的 <code>jar</code> 包。</p><p>配置文件在安装目录下的 <code>bin</code> 文件夹中，名称是 <code>idea64.exe.vmoptions</code>，但是要注意，这个是全局配置文件，影响比较大，不建议直接更改它，而且有些 <code>IDEA</code> 版本还不支持【更改了之后没有效果，而且激活时还报错】。</p><p>因此，建议在用户目录下更改，其实用户目录下面有一份 <code>IDEA</code> 的临时目录，会生成一些临时文件，只针对当前用户有效，例如我的 <code>Windows 10</code> 系统，在 <code>C:\Users\Perry\.IntelliJIdea2017.2\config</code> 里面。注意多了一个 <code>config</code> 子文件夹，<code>idea64.exe.vmoptions</code> 配置文件在里面。</p><p>如果读者寻找后发现没有这个配置文件，不要着急，有些时候或者某些版本默认是没有这个配置文件的，需要自己手动生成。注意，不是要自己创建，而是在 <code>IDEA</code> 中创建，依次选择 <code>Help</code>、<code>Edit Costum VM Options</code> 就可以了，会自动创建一份和全局配置文件一样内容的文件，并且保存在用户目录下【就是上面的那个目录】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200304140621.png" alt="手动创建配置文件" title="手动创建配置文件"></p><p>因为 <code>IDEA</code> 是运行在 <code>Java</code> 虚拟机之上的，其实就是更改一些 <code>JVM</code> 参数。</p><p>在文件最后一行加上 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-javaagent:C:\Program Files\JetBrains\JetbrainsCrack.jar</span><br></pre></td></tr></table></figure><p> 表示给 <code>IDEA</code> 设置代理，<code>javaagent</code> 参数后面的值就是 <code>JetbrainsCrack.jar</code> 具体的存放位置。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200304140549.png" alt="配置文件内容" title="配置文件内容"></p><p>注意看一下这个配置文件的位置，就是在用户目录下：<code>C:\Users\Perry\.IntelliJIdea2017.2\config</code>。</p><p>接着就开始填写激活信息，依次选择 <code>Help</code>、<code>Register</code>，在弹出的对话框中先选择 <code>Activation code</code> 方式，然后填写如下格式的内容【也称为激活码】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;licenseId&quot;: &quot;ThisCrackLicenseId&quot;,</span><br><span class="line">	&quot;licenseeName&quot;: &quot;your_name&quot;,</span><br><span class="line">	&quot;assigneeName&quot;: &quot;your_name&quot;,</span><br><span class="line">	&quot;assigneeEmail&quot;: &quot;your_email&quot;,</span><br><span class="line">	&quot;licenseRestriction&quot;: &quot;Thanks Rover12421 Crack&quot;,</span><br><span class="line">	&quot;checkConcurrentUse&quot;: false,</span><br><span class="line">	&quot;products&quot;: [&#123;</span><br><span class="line">			&quot;code&quot;: &quot;II&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;DM&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;AC&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;RS0&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;WS&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;DPN&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;RC&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;PS&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;DC&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;RM&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;CL&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;PC&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;DB&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;GO&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;code&quot;: &quot;RD&quot;,</span><br><span class="line">			&quot;paidUpTo&quot;: &quot;2099-12-31&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	],</span><br><span class="line">	&quot;hash&quot;: &quot;2911276/0&quot;,</span><br><span class="line">	&quot;gracePeriodDays&quot;: 7,</span><br><span class="line">	&quot;autoProlongated&quot;: false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200304135815.png" alt="填写激活信息" title="填写激活信息"></p><p>注意，除了必须满足上面的 <code>JSON</code> 格式，这里面的个人信息可以任意更改，包含过期时间、证书名字、使用人、邮箱等等，更改后的信息会显示在 <code>Help</code>、<code>About</code> 里面【可以装逼使用】。</p><p>最后就是重启 <code>IDEA</code>，注意这个步骤很重要，不然没有效果。想想你如果更改了配置文件，填写了激活信息，然后发现无效，折腾了半天才发现是没有重启，多么折磨人。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 再次提醒读者，本方法仅供学习交流使用，不可用于商业开发，请购买正版，或者使用社区版、教育版。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>JNI 字段描述符基础知识</title>
    <url>/2019041301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>平时在做 Java 开发的时候，难免遇到异常信息中包含一种特殊的表达字符串，例如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">method: createWorker signature: (Ljava/util/concurrent/Executor;) Lorg/jboss/netty/channel/socket/nio/AbstractNioWorker;</span><br></pre></td></tr></table></figure><p>或者 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.NoSuchMethodError: com.fasterxml.jackson.databind.JavaType.isReferenceType () Z</span><br></pre></td></tr></table></figure><p> 可以看到，异常信息中有一种特殊的字符串出现了：<strong>L 后面跟着类名 </strong>、<strong> 方法后面跟了一个 Z</strong>。其实，这就是 <strong>JNI 字段描述符【Java Native Interface FieldDescriptors】</strong>，它是一种对 Java 数据类型、数组、方法的编码。此外，在 Android 逆向分析中，通过反汇编得到的 smali 文件，里面的代码也会遵循这种方式，即 Dalvik 字节码。本文就记录一些数据类型、数组、方法的编码方式以及解释说明，方便以后查阅。</p><a id="more"></a><h1 id="基本概念"><a href="# 基本概念" class="headerlink" title="基本概念"></a>基本概念 </h1><p> 这种编码方式把 Java 中的基本数据类型、数组、对象都使用一种规范来表示：</p><ul><li>八种基本数据类型都使用一个大写字母表示 </li><li>void 使用 V 表示</li><li> 数组使用左方括号表示 </li><li> 方法使用一组圆括号表示，参数在括号里，返回类型在括号右侧 </li><li> 对象使用 L 开头，分号结束，中间是类的完整路径，包名使用正斜杠分隔 </li></ul><h1 id="基本编码"><a href="# 基本编码" class="headerlink" title="基本编码"></a> 基本编码 </h1><p> 基本编码如下表格，并配有解释说明：</p><table><thead><tr><th style="text-align:center">Java 类型 </th><th style="text-align:center">JNI 字段描述符</th></tr></thead><tbody><tr><td style="text-align:center">boolean</td><td style="text-align:center">Z</td></tr><tr><td style="text-align:center">byte</td><td style="text-align:center">B</td></tr><tr><td style="text-align:center">char</td><td style="text-align:center">C</td></tr><tr><td style="text-align:center">short</td><td style="text-align:center">S</td></tr><tr><td style="text-align:center">int</td><td style="text-align:center">I</td></tr><tr><td style="text-align:center">long</td><td style="text-align:center">J</td></tr><tr><td style="text-align:center">float</td><td style="text-align:center">F</td></tr><tr><td style="text-align:center">double</td><td style="text-align:center">D</td></tr><tr><td style="text-align:center">void</td><td style="text-align:center">V</td></tr><tr><td style="text-align:center">Object</td><td style="text-align:center"> 以 L 开头，以；结尾，中间是使用 / 隔开的完整包名、类型。例如：Ljava/lang/String;。如果是内部类，添加 $ 符号分隔，例如：Landroid/os/FileUtils$FileStatus;。</td></tr><tr><td style="text-align:center">数组 </td><td style="text-align:center">[</td></tr><tr><td style="text-align:center"> 方法 </td><td style="text-align:center"> 使用 () 表示，参数在圆括号里，返回类型在圆括号右侧，例如：(II) Z，表示 boolean func (int i,int j)。</td></tr></tbody></table><h1 id="举例说明"><a href="# 举例说明" class="headerlink" title="举例说明"></a>举例说明 </h1><h2 id="数据类型"><a href="# 数据类型" class="headerlink" title="数据类型"></a> 数据类型 </h2><p>1、<strong>[I</strong>：表示 int 一维数组，即 <strong>int []</strong>。<br>2、<strong>Ljava/lang/String;</strong>：表示 String 类型，即 <strong>java.lang.String</strong>。<br>3、<strong>[Ljava/lang/Object;</strong>：表示 Object 一维数组，即 <strong>java.lang.Object []</strong>。<br>4、<strong>Z</strong>：表示 boolean 类型。<br>5、<strong>V</strong>：表示 void 类型。</p><h2 id="方法"><a href="# 方法" class="headerlink" title="方法"></a> 方法</h2><p>1、<strong>() V</strong>：表示参数列表为空，返回类型为 void 的方法，即 <strong>void func ()</strong>。<br>2、<strong>(II) V</strong>：表示参数列表为 int、int，返回类型为 void 的方法，即 <strong>void func (int i,int j)</strong>。<br>3、<strong>(Ljava/lang/String;Ljava/lang/String;) I</strong>：表示参数列表为 String、String，返回类型为 int 的方法，即 <strong>int func (String i,String j)</strong>。<br>4、<strong>([B) V</strong>：表示参数列表为 byte []，返回类型为 void 的方法，即 <strong>void func (byte [] bytes)</strong>。<br>5、<strong>(ILjava/lang/Class;) J</strong>：表示参数列表为 int、Class，返回类型为 long 的方法，即 <strong>long func (int i,Class c)</strong>。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>JNI</tag>
        <tag>字段描述符</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript 中字符串截取方法总结</title>
    <url>/2018121901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近在处理数据的时候，用到了 JavaScript 编程语言，通过绕弯路来解决 ETL 处理的逻辑，其中就用到了字符串的截取方法，查 JavaScript 的文档看到了 3 个方法，被绕的有点晕，本文就总结一下 JavaScript 中字符串截取的方法。</p><a id="more"></a><h1 id="开篇"><a href="# 开篇" class="headerlink" title="开篇"></a>开篇 </h1><p> 首先声明，JavaScript 中对方法名字的大小写是敏感的，该是小写就是小写，该是大写就是大写。</p><h1 id="substring- 方法"><a href="#substring- 方法" class="headerlink" title="substring () 方法"></a>substring () 方法 </h1><h2 id="定义和用法"><a href="# 定义和用法" class="headerlink" title="定义和用法"></a> 定义和用法 </h2><blockquote><p>substring () 方法用于截取字符串中介于两个指定下标之间的字符</p></blockquote><h2 id="语法"><a href="# 语法" class="headerlink" title="语法"></a> 语法 </h2><blockquote><p>stringObject.substring (start, stop)</p></blockquote><p> 上述参数解释：</p><table><thead><tr><th style="text-align:center">参数名 </th><th style="text-align:center"> 解释说明 </th></tr></thead><tbody><tr><td style="text-align:center">start</td><td style="text-align:center"> 必须，一个整数（是负数则被自动置为 0），要截取的子串的第一个字符在 stringObject 中的位置 </td></tr><tr><td style="text-align:center">end</td><td style="text-align:center"> 可选（如果省略该参数，则被默认为字符串长度），一个整数（是负数则被自动置为 0），比要截取的子串的最后一个字符在 stringObject 中的位置多 1</td></tr></tbody></table><h2 id="返回值"><a href="# 返回值" class="headerlink" title="返回值"></a>返回值 </h2><p> 一个全新的字符串，其实就是 stringObject 的一个子字符串，其内容是从 start 到 stop-1 的所有字符，其长度为 stop 减 start。</p><h2 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a>注意事项 </h2><p>1、substring () 方法返回的子字符串包括 start 处的字符，但是不包括 stop 处的字符，这一点可能很多人会迷惑，其实很多编程语言都是这个逻辑；</p><p>2、如果参数 start 与 stop 相等，那么该方法返回的就是一个空串（即长度为 0 的字符串，不是 null，也不是 undefined）；</p><p>3、如果 start 比 stop 大，那么该方法在截取子串之前会先交换这两个参数，这就会导致参数的顺序不影响截取的结果了；</p><p>4、参数理论上不能出现负数（在本方法中无特殊意义，在其它方法中就有特殊意义了），如果有，那么在截取子串之前会被置为 0。</p><h2 id="举例说明"><a href="# 举例说明" class="headerlink" title="举例说明"></a> 举例说明 </h2><p><strong> 例子 1（从下标 3 截取到字符串最后）：</strong><br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substring (<span class="number">3</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>输出（长度为 10 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-world!</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 2（从下标 3 截取到下标 8）：</strong><br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substring (<span class="number">3</span>, <span class="number">8</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>输出（长度为 5 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-wo</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 3（从下标 3 截取到下标 8，但是参数位置反了）：</strong><br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substring (<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>输出（长度为 5 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-wo</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 4（参数为负数，从下标 0 截取到下标 3）：</strong><br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substring (<span class="number">-1</span>, <span class="number">3</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>输出（长度为 3 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">Hel</span><br></pre></td></tr></table></figure><p></p><h1 id="substr- 方法"><a href="#substr- 方法" class="headerlink" title="substr () 方法"></a>substr () 方法 </h1><h2 id="定义和用法 -1"><a href="# 定义和用法 -1" class="headerlink" title="定义和用法"></a> 定义和用法 </h2><blockquote><p>substr () 方法可在字符串中截取从 start 下标开始的指定长度的子串</p></blockquote><h2 id="语法 -1"><a href="# 语法 -1" class="headerlink" title="语法"></a> 语法 </h2><blockquote><p>stringObject.substr (start, length)</p></blockquote><p> 上述参数解释：</p><table><thead><tr><th style="text-align:center">参数名 </th><th style="text-align:center"> 解释说明 </th></tr></thead><tbody><tr><td style="text-align:center">start</td><td style="text-align:center"> 必须，必须是数值（0、正数、负数都可以），表示要截取的子串的起始下标。如果是负数，那么该参数声明的是从字符串的尾部开始计算的位置。也就是说，-1 指字符串中最后一个字符，-2 指倒数第二个字符，以此类推。（参数为负数也可以理解成字符串长度加负数之和即为起始下标）</td></tr><tr><td style="text-align:center">length</td><td style="text-align:center">可选（如果省略该参数，那么默认为从 start 开始一直到 stringObject 的结尾对应的长度），必须是数值（0、正数、负数都可以）。</td></tr></tbody></table><h2 id="返回值 -1"><a href="# 返回值 -1" class="headerlink" title="返回值"></a>返回值 </h2><p> 一个全新的字符串，包含从 stringObject 的 start（包括 start 所指的字符）下标开始的 length 个字符。如果没有指定 length，那么返回的字符串包含从 start 到 stringObject 的结尾的字符。如果 length 指定为负数或者 0，那么返回空串。如果 length 指定为远远大于 stringObject 长度的正数，那么返回的字符串包含从 start 到 stringObject 的结尾的字符。</p><h2 id="注意事项 -1"><a href="# 注意事项 -1" class="headerlink" title="注意事项"></a>注意事项 </h2><p>1、start 参数为负数是有特殊含义的；</p><p>2、如果 length 指定为负数或者 0，那么返回空串（即长度为 0 的字符串，不是 null，也不是 undefined）；</p><p>3、ECMAscript 没有对该方法进行标准化，因此不建议使用它。</p><h2 id="举例说明 -1"><a href="# 举例说明 -1" class="headerlink" title="举例说明"></a> 举例说明 </h2><p><strong> 例子 1（从下标 3 截取到字符串最后）：</strong></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substr (<span class="number">3</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>输出（长度为 9 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-world!</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 2（从下标 3 截取长度为 5 的子串）：</strong></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substr (<span class="number">3</span>, <span class="number">5</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>输出（长度为 5 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-wo</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 3（从下标 3 截取长度为 - 5 的子串，返回空串）：</strong></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substr (<span class="number">3</span>, <span class="number">-5</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>输出（返回空串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><p><strong>例子 4（start 参数为负数，即从字符串倒数第 5 个位置截取长度为 3 的子串）：</strong></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.substr (<span class="number">-5</span>, <span class="number">3</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>输出（长度为 3 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">orl</span><br></pre></td></tr></table></figure><p></p><h1 id="slice- 方法"><a href="#slice- 方法" class="headerlink" title="slice () 方法"></a>slice () 方法 </h1><h2 id="定义和用法 -2"><a href="# 定义和用法 -2" class="headerlink" title="定义和用法"></a> 定义和用法 </h2><blockquote><p>slice () 方法用于截取字符串中介于两个指定下标之间的字符，与 substring () 方法的功能类似</p></blockquote><h2 id="语法 -2"><a href="# 语法 -2" class="headerlink" title="语法"></a> 语法 </h2><blockquote><p>stringObject.slice (start, end)</p></blockquote><p> 上述参数解释：</p><table><thead><tr><th style="text-align:center">参数名 </th><th style="text-align:center"> 解释说明 </th></tr></thead><tbody><tr><td style="text-align:center">start</td><td style="text-align:center"> 必须，一个整数（0、正数、负数，负数有特殊含义），要截取的子串的第一个字符在 stringObject 中的位置。如果是负数，那么该参数声明的是从字符串的尾部开始计算的位置。也就是说，-1 指字符串中最后一个字符，-2 指倒数第二个字符，以此类推。（参数为负数也可以理解成字符串长度加负数之和即为起始下标）</td></tr><tr><td style="text-align:center">end</td><td style="text-align:center">可选（如果省略该参数，则被默认为字符串长度），一个整数（负数含义与 start 相同），比要截取的子串的最后一个字符在 stringObject 中的位置多 1</td></tr></tbody></table><h2 id="返回值 -2"><a href="# 返回值 -2" class="headerlink" title="返回值"></a>返回值 </h2><p> 一个全新的字符串，其实就是 stringObject 的一个子字符串，其内容是从 start 到 stop-1 的所有字符，其长度为 stop 减 start。</p><h2 id="注意事项 -2"><a href="# 注意事项 -2" class="headerlink" title="注意事项"></a>注意事项 </h2><p>1、slice () 方法返回的子字符串包括 start 处的字符，但是不包括 stop 处的字符，这一点可能很多人会迷惑，其实很多编程语言都是这个逻辑；</p><p>2、如果参数 start 与 stop 相等，那么该方法返回的就是一个空串（即长度为 0 的字符串，不是 null，也不是 undefined）；</p><p>3、参数可以出现负数（比 substring () 方法灵活多了）。</p><h2 id="举例说明 -2"><a href="# 举例说明 -2" class="headerlink" title="举例说明"></a> 举例说明 </h2><p><strong> 例子 1（从下标 3 截取到字符串最后）：</strong><br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.slice (<span class="number">3</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>输出（长度为 9 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-world!</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 2（从下标 3 截取到下标 8）：</strong></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.slice (<span class="number">3</span>, <span class="number">8</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>输出（长度为 5 的子串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-wo</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 3（从下标 3 截取到下标 8，但是参数使用负数，从下标 - 9 截取到下标 - 4）：</strong></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.slice (<span class="number">-9</span>, <span class="number">-4</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>输出（长度为 5 的子串，（-4）-（-9）=5）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">lo-wo</span><br></pre></td></tr></table></figure><p></p><p><strong>例子 4（从下标 3 截取到下标 2）：</strong><br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line"><span class="keyword">var</span> str=<span class="string">"Hello-world!"</span></span><br><span class="line"><span class="built_in">document</span>.write (str.slice (<span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>输出返回空串）：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>字符串截取</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown 语法手册</title>
    <url>/2017123101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>首先声明，这份文档可能不完整，因为它是基于我日常的使用来整理的，如果有一些语法我还没有使用到，就不会记录在这份文档上面。但是，我会不定期更新这份文档，把自己使用到的越来越多的语法整理进来，这样就可以不断完善这份文档，从而越来越接近标题中的 <strong>语法手册 </strong>。</p><p>最近更新于：<strong>2019-11-01</strong> 。</p><a id="more"></a><h1 id="语法手册"><a href="# 语法手册" class="headerlink" title="语法手册"></a>语法手册 </h1><h1 id="标题"><a href="# 标题" class="headerlink" title="标题"></a> 标题 </h1><p> 使用井号表示：<code>#</code>，一个代表一级标题，两个代表二级标题，三个代表三级标题，以此类推，最多可以有六级标题。</p><h1 id="换行"><a href="# 换行" class="headerlink" title="换行"></a>换行 </h1><p> 在 <code>GitHub</code> 中写 <code>README.MD</code> 文档，正常的一个换行在被 <code>GitHub</code> 解析后展示出来不是换行，内容仍旧在同一行。如果需要显示出换行，在 <code>README.MD</code> 文件中需要连续 2 个换行，经过 <code>GitHub</code> 解析后才是一个真正的换行。</p><p>如果使用连续的 3 个横杠符号：<code>---</code>，会产生分割线的效果，相当于在普通的换行基础上加了一个标识。</p><h1 id="代码块"><a href="# 代码块" class="headerlink" title="代码块"></a>代码块 </h1><p> 如果是少量的几个单词，可以直接使用两个反斜点表示，即键盘左上角那个波浪号按键。</p><p>如果内容有多行，并且满足某种语言，例如 <code>Java</code>、<code>Python</code>、<code>JSON</code> 等，则可以使用一对 3 个连续的反斜点表示，在前面连续 3 个反斜点后面跟上语言类型：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xxx</span><br></pre></td></tr></table></figure><h1 id="加粗"><a href="# 加粗" class="headerlink" title="加粗"></a>加粗 </h1><p>4 个星号。</p><h1 id="斜体"><a href="# 斜体" class="headerlink" title="斜体"></a> 斜体 </h1><p>xx</p><h1 id="中划线"><a href="# 中划线" class="headerlink" title="中划线"></a> 中划线 </h1><p> 中划线，达到删除的效果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">~~ 这是中划线～～</span><br></pre></td></tr></table></figure><h1 id="链接"><a href="# 链接" class="headerlink" title="链接"></a>链接 </h1><h1 id="列表"><a href="# 列表" class="headerlink" title="列表"></a> 列表 </h1><h2 id="无序列表"><a href="# 无序列表" class="headerlink" title="无序列表"></a> 无序列表 </h2><h2 id="有序列表"><a href="# 有序列表" class="headerlink" title="有序列表"></a> 有序列表 </h2><h1 id="表格"><a href="# 表格" class="headerlink" title="表格"></a> 表格 </h1><p> 表格的使用【居中、加粗、边框线】</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>handbook</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark Kryo 异常</title>
    <url>/2018100801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>本文记录使用 <code>es-hadoop</code>【版本 <code>v5.6.8</code>】组件，运行 <code>Spark</code> 任务时遇到的异常：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Caused by: java.io.EOFException</span><br><span class="line">at org.apache.spark.serializer.KryoDeserializationStream.readObject (KryoSerializer.scala:<span class="number">232</span>)</span><br><span class="line">at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject (TorrentBroadcast.scala:<span class="number">217</span>)</span><br></pre></td></tr></table></figure><p>以及通过 <code>Maven</code> 依赖查找分析问题的方法，最后给出解决此类问题的总结建议。</p><a id="more"></a><h1 id="遇到问题"><a href="# 遇到问题" class="headerlink" title="遇到问题"></a>遇到问题 </h1><p> 由于在业务场景中，最近 <code>elasticsearch</code> 集群升级版本，升到了 <code>v5.6.8</code> 版本，所用的功能代码为了兼容处理高版本的 <code>elasticsearch</code> 集群，需要升级 <code>es-hadoop</code> 相关依赖包到版本 <code>v5.6.8</code>，结果就遇到了问题：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxyn2hnapxj21600cbdhd.jpg" alt="异常信息" title="异常信息"></p><p>业务代码逻辑就是通过 <code>es-spark</code> 直接读取 <code>elasticsearch</code> 里面的数据，并生成 <code>RDD</code>，然后简单处理，直接写入 <code>HDFS</code> 里面。本机在测试平台测试一切正常，或者本机跑 <code>local</code> 模式也正常，没有任何问题，但是在线上 <code>yarn</code> 集群运行就会抛出异常。</p><h1 id="解决方法"><a href="# 解决方法" class="headerlink" title="解决方法"></a>解决方法 </h1><p> 首先分析一下这个问题产生的原因，在代码层面没有任何变动，只是更改了依赖的版本，所以问题在于更改版本之后是不是导致了传递依赖包的缺失，或者版本冲突。所以总体而言，肯定是 <code>Maven</code> 依赖包的问题，这个思路没问题。</p><p>提前说明下面截图中出现的 <code>Maven</code> 中的常量：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">elasticsearch-hadoop.version</span>&gt;</span>5.6.8<span class="tag">&lt;/<span class="name">elasticsearch-hadoop.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">spark-core_2.10.version</span>&gt;</span>1.6.2<span class="tag">&lt;/<span class="name">spark-core_2.10.version</span>&gt;</span></span><br></pre></td></tr></table></figure><p>1、<code>local</code> 模式 </p><p> 通过在本机连接测试平台，运行起来没有问题【或者本机跑 <code>local</code> 模式运行也没有问题】，但是部署到正式环境的 <code>yarn</code> 集群，运行不起来，直接抛出上图所示的异常信息。</p><p>首先去依赖树里面查看与 <code>kryo</code> 相关的依赖信息【使用 <code>mvn dependency:tree</code> 命令】：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxynj70u3ij20ue0kz0uy.jpg" alt="kryo 相关的依赖信息" title="kryo 相关的依赖信息"></p><p>发现两个依赖包【<code>es-hadoop v5.6.8</code>，<code>spark-core_2.10 v1.6.2</code>】里面都有与之相关的传递依赖，而且版本【奇怪的是 <code>groupId</code> 也稍有不同，但是类路径却是相同的，这导致了我后续判断失误】不一致，这必然导致依赖包的版本冲突，通过 <code>exclusions</code> 方式去除其中一个依赖【其实不是随意去除一个，要经过分析去除错误的那个，保留正确的那个】，<code>local</code> 模式可以完美运行。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxyoie8f6wj20mt0dy0tb.jpg" alt="移除 spark-core_2.10 的 kryo 依赖" title="移除 spark-core_2.10 的 kryo 依赖"></p><p>此图是 <code>pom.xml</code> 文件里面的移除信息，是我根据依赖树整理的，可以更加清楚地看到传递依赖的影响。</p><p>2、<code>yarn-client</code> 模式 </p><p> 通过步骤 1 解决了 <code>local</code> 模式运行的问题，但是当使用 <code>yarn-client</code> 模式向 <code>yarn</code> 集群提交 <code>Spark</code> 任务时，如果移除的是 <code>spark-core_2.10</code> 里面的 <code>kryo</code> 依赖，异常信息仍然存在，无法正常运行。</p><p>此时，我想到了前面所说的 2 个 <code>kryo</code> 依赖包的 <code>groupId</code> 有一点不一样，所以这 2 个依赖包虽然是同一种依赖包【类的包路径一致，这是个大坑】，但是可能由于版本不同的原因，导致名称有些不同。我认为使用的 <code>es-hadoop</code> 依赖的版本比较高，可能没有兼容低版本的 <code>spark-core_2.10</code>，所以需要保留 <code>spark-core_2.10</code> 里面的 <code>kryo</code> 依赖，而是把 <code>es-hadoop</code> 里面的 <code>kryo</code> 依赖移除。</p><p>果然，再次完美运行。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxynyr4f4ej20me0h9aas.jpg" alt="移除 es-hadoop 的 kryo 依赖" title="移除 es-hadoop 的 kryo 依赖"></p><p>其实就是 <code>Spark</code> 必须使用自身依赖的 <code>kryo</code> 对应的版本，无法移除，否则提交到 <code>yarn</code> 集群的任务会序列化失败。而 <code>es-hadoop</code> 则可以兼容 <code>Spark</code> 依赖的 <code>kryo</code>。</p><p>因此，使用简单移除的方式可以解决此问题，但是有时候实际场景可能会比这个复杂得多，很折磨人，具体看 <strong>总结说明 </strong>。</p><h1 id="总结说明"><a href="# 总结说明" class="headerlink" title="总结说明"></a>总结说明 </h1><p> 这次通过 <code>Maven</code> 依赖找到了问题，但是版本仅仅限定在我使用的版本，其它的版本之间会有什么冲突我无法得知，但是这种处理问题的思路是正确的，避免走冤枉路，浪费不必要的时间。</p><p>当然，这一次也要庆幸遇到的场景比较简单，所以很快解决了问题。</p><p>另外，提醒一下大家，更新 <code>pom.xm</code> 文件【包括新增依赖和更新依赖版本】一定要谨慎而行，并且对所要引入的依赖有一个全面的了解，知道要去除什么、保留什么，否则会浪费一些不必要的时间去查找依赖引发的一系列问题。</p><p>多说一句，上面的做法纯属是碰运气，刚好解决了问题，根本原因在于依赖 <code>jar</code> 包的冲突。像上面这种情况，一边是 <code>Spark</code> 需要低版本的 <code>Kryo</code> 包，一边是 <code>Elasticsearch</code> 需要高版本的 <code>Kryo</code> 包，但是还好 <code>Elasticsearch</code> 也可以支持低版本的 <code>Kryo</code> 包，它们之间差别不大。</p><p>但是，如果碰到各个组件所需要的依赖高版本、低版本之间差别过大，不能统一使用某一个版本，否则总有一个功能无法运行，这时候就不能使用简单的排除方案了，根本无效，我推荐使用 <code>maven-shade-plugin</code> 插件，可以将 <code>jar</code> 包重定义别名，就可以任意使用了。</p><p>这里还有一种更为复杂的情况，在 <code>Spark</code> 集群模式下，集群本身就已经在 <code>libs</code> 目录下存放了各种版本的 <code>jar</code> 包，如果所需要的 <code>jar</code> 包就在 <code>libs</code> 目录中，但是版本无法匹配，由于 <code>Spark</code> 会优先加载集群中 <code>jar</code> 包，此时你怎么排除怎么变更版本都无效【遇到这种情况可能会折磨人到怀疑人生】，这时候也只能使用 <code>maven-shade-plugin</code> 插件了。</p><p>有时候在本机环境使用 <code>local</code> 模式可以正常运行任务，但是提交到 <code>yarn</code> 集群就不行了，此时只能采用 <code>maven-shade-plugin</code> 插件重定义别名了，比慢慢排除冲突 <code>jar</code> 包方便快捷。哪怕你对依赖的冲突也不是很懂，只需要 <strong>一顿操作猛如虎 </strong>，必能解决依赖冲突、缺失问题。</p><p>这种更为复杂的情况，读者可以参考我以后整理的一篇博文，最后也是使用 <code>maven-shade-plugin</code> 插件才解决问题：<a href="https://www.playpi.org/2019112901.html">Spark 项目依赖冲突问题总结</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Kryo</tag>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark on Yarn 查看日志</title>
    <url>/2018120702.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>一直一来都是直接在 Yarn 的 UI 界面上面查看 Spark 任务的日志的，感觉看少量的内容还勉强可以，但是如果内容很多，浏览器就没法看了，更没法分析。本文讲述如何使用 Yarn 自带的命令在终端查看 Spark 任务的日志，也可以拷贝出日志文件，便于分析。</p><a id="more"></a><p>1、查看某个 Spark 任务的日志，使用 logs 入口：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn logs -applicationId application_1542870632001_26426</span><br></pre></td></tr></table></figure><p></p><p>如果日志非常多，直接看会导致刷屏，看不到有用的信息，所以可以重定向到文件中，再查看文件：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn logs -applicationId application_1542870632001_26426 &gt; ./application.log</span><br></pre></td></tr></table></figure><p></p><p>2、查看某个 Spark 任务的状态，使用 application 入口：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn application -status application_1542870632001_26426</span><br></pre></td></tr></table></figure><p></p><p>同时也可以看到队列、任务类型、日志链接等详细信息 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxxloh9spej20uo0auaas.jpg" alt="查看状态" title="查看状态"></p><p>3、kill 掉某个 Spark 任务，有时候是直接在 Driver 端 kill 掉进程，然后 Yarn 的 Spark 任务也会随之失败，但是这种做法是不妥的。其实 kill 掉 Spark 任务有自己的命令：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn application -<span class="built_in">kill</span> application_1542870632001_26426</span><br></pre></td></tr></table></figure><p></p><p>4、需要注意的是，步骤 1 中去查看日志，要确保当前 HADOOP_USER_NAME 用户是提交 Spark 任务的用户，否则是看不到日志的，因为日志是放在 HDFS 对应的目录中的，其中路径中会有用户名。此外，步骤 1 中的日志要等 Spark 任务运行完了才能看到，否则日志文件不存在（还没收集到 HDFS 中）。</p><p> 在 Linux 环境中可以使用 <strong>export HADOOP_USER_NAME=xxx</strong> 临时伪装用户。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Yarn</tag>
        <tag>日志查看</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 序列化的一些事</title>
    <url>/2017071701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在 <code>Spark</code> 任务中，大家经常遇到的一个异常恐怕就是 <code>Task not serializable: java.io.NotSerializableException</code> 了，只要稍不注意，就会忘记了序列化这件事，当然解决方法也是很简单。</p><p>但是，对于初学者来说，恐怕会有一些疑惑，或者稀里糊涂把问题解决了，但是不知道根本原因。</p><a id="more"></a><h1 id="问题分析"><a href="# 问题分析" class="headerlink" title="问题分析"></a>问题分析 </h1><p> 常见的序列化错误：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; org.apache.spark.SparkException: Task not serializable</span><br><span class="line">at org.apache.spark.util.ClosureCleaner$.ensureSerializable (ClosureCleaner.scala:166)</span><br><span class="line">at org.apache.spark.util.ClosureCleaner$.clean (ClosureCleaner.scala:158)</span><br><span class="line">at org.apache.spark.SparkContext.clean (SparkContext.scala:1242)</span><br><span class="line">at org.apache.spark.rdd.RDD.map (RDD.scala:270)</span><br><span class="line">at org.apache.spark.api.java.JavaRDDLike$class.mapToPair (JavaRDDLike.scala:99)</span><br><span class="line">at org.apache.spark.api.java.JavaRDD.mapToPair (JavaRDD.scala:32)</span><br></pre></td></tr></table></figure><p>由于 <code>Spark</code> 任务在分发的过程中，需要对必要的对象进行序列化传输，在 <code>executor</code> 端接收到数据后再反序列化，如果没有控制好需要序列化的类，可能会出现 <code>NotSerializableException</code> 异常。这种情况还算好的，直接修改对应的类，就可以解决问题。</p><p>有时候如果使用了类成员，不小心使用 <code>static</code> 修饰，而且初始化为 <code>null</code>，再在初始化 <code>Spark</code> 任务时对它进行赋值，实际上在 <code>executor</code> 端执行进程时是接收不到这个变量的值的，因为对 <code>static</code> 变量的修改是归于本地 <code>JVM</code> 管理的，不会序列化传输【传输的只是默认值】。</p><p>对于常见的不会经过序列化的四种场景【注意 <code>static</code> 变量的初始值很重要】：</p><ul><li>加上临时修饰符 <code>transient</code>，不会参与序列化 </li><li><code>static</code> 变量，属于类属性，不会参与序列化</li><li><code>static</code> 方法，属于类属性，不会参与序列化</li><li><code>SparkContext</code> 对象不需要序列化</li></ul><p> 对于常见的需要序列化的三种场景：</p><ul><li>普通的变量，如果在算子中使用到，则这个变量所属的类以及所有成员都需要支持序列化 </li><li> 普通的方法，如果在算子中使用到，则这个变量所属的类以及所有成员都需要支持序列化 </li><li> 类引用，如果在算子中使用到某个类，则这个类需要支持序列化 </li></ul><h1 id="建议"><a href="# 建议" class="headerlink" title="建议"></a> 建议 </h1><p>1、对于需要在算子中使用的方法、变量，全部使用 <code>static</code> 修饰，避免序列化整个类。</p><p>2、对于需要在算子中使用的变量，最好使用 <code>SparkContext</code> 传输，或者使用广播变量。</p><p>3、对于确实需要实例化的类【整个类】，把类定义放在算子内部，也就是内部类，减少序列化的网络传输。</p><p>4、对于需要在算子中使用的方法，可以使用函数式方法，这样就可以避免序列化方法所属的整个类了。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a> 备注 </h1><p> 记录一次踩坑记录：</p><p>业务中需要传输一个集合列表，里面包含十几个字符串元素，在代码中使用 <code>static</code> 修饰集合，并且初始值为 <code>null</code>，而在 <code>driver</code> 端 <code>Spark</code> 任务启动初始化类后，再进行赋值，序列化分发到集群各台 <code>executor</code> 上，集合对象的取值会丢失【<code>static</code> 修饰的变量属于类成员，不属于对象成员，没有序列化流程，<code>static</code> 修饰的对象由本地 <code>jvm</code> 管理，<code>executor</code> 端无法接收，取值为对象的默认值 <code>null</code>。尽管在 <code>driver</code> 端进行初始化为 <code>null</code>，再把它二次更改，但是对 <code>executor</code> 端无效】，而后在 <code>map</code>、<code>foreachPartition</code> 等算子中直接使用此变量时，执行过程中会抛出 <code>NullPointException</code>。</p><p>而如果直接使用的是 <code>local</code> 模式，和 <code>yarn</code> 集群无交互，所以不会有多台节点，全程都在本地单进程执行，这样的测试结果显然是不能作为成功与否的依据。</p><p>修复思路：取消 <code>static</code> 修饰集合变量，这样变量在初始化时就是对象的成员了，并在初始化类后检查配置加载情况，异常时自动退出，保证序列化传输前的配置信息有值。这样操作后，一切配置信息在 <code>driver</code> 端初始化并检查完成，然后才会提交 <code>Spark</code> 任务，而所有的配置信息都会经过序列化分发的过程，不会丢失，可以准确到达 <code>executor</code> 端。</p><p>上述解决方法显然不够优雅，其实对于参数的传递，最好使用 <code>SparkContext</code> 上下文进行传输【小参数】，或者使用广播变量传输【大参数】，比使用序列化的方式更为正式可靠，也符合 <code>Spark</code> 的设计初衷。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>NotSerializableException</tag>
        <tag>serializable</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 异常之 exceeding memory limits</title>
    <url>/2018022501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>业务上使用 <code>elasticsearch-hadoop</code> 框架来处理 <code>Elasticsearch</code> 里面的数据，流程就是读取、中间处理、写入，然后由于数据量级太大的【占用的内存也大】原因，出现异常：<code>Container killed by YARN for exceeding memory limits.</code>，这个异常其实很常见，做大数据开发的工程师基本都遇到过，稍微调整一下内存配置即可。</p><p>本文简单记录一下，给读者参考，开发环境基于 <code>Elasticsearch v1.7.5</code>、<code>Spark v1.6.2</code>、<code>elasticsearch-hadoop v2.1.0</code>、<code>Hadoop v2.7.1</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 使用 <code>elasticsearch-hadoop</code> 处理数据时，借用 <code>Spark</code> 框架，读取大量的数据到内存中【1.8 千万，41 <code>GB</code>】，由于内存参数设置太小，导致报内存错误。</p><p>异常信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 6.0 GB of 6 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.</span><br><span class="line">FetchFailed (BlockManagerId (4, host18, 45026), shuffleId=0, mapId=3, reduceId=27, message=</span><br><span class="line">org.apache.spark.shuffle.FetchFailedException: Failed to connect to host18/192.168.10.188:45026</span><br><span class="line">    at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException (ShuffleBlockFetcherIterator.scala:323)</span><br><span class="line">    at org.apache.spark.storage.ShuffleBlockFetcherIterator.next (ShuffleBlockFetcherIterator.scala:300)</span><br><span class="line">    at org.apache.spark.storage.ShuffleBlockFetcherIterator.next (ShuffleBlockFetcherIterator.scala:51)</span><br><span class="line">    at scala.collection.Iterator$$anon$11.next (Iterator.scala:328)</span><br><span class="line">    at scala.collection.Iterator$$anon$13.hasNext (Iterator.scala:371)</span><br><span class="line">    at scala.collection.Iterator$$anon$11.hasNext (Iterator.scala:327)</span><br><span class="line">    at org.apache.spark.util.CompletionIterator.hasNext (CompletionIterator.scala:32)</span><br><span class="line">    at org.apache.spark.InterruptibleIterator.hasNext (InterruptibleIterator.scala:39)</span><br><span class="line">    at scala.collection.Iterator$$anon$13.hasNext (Iterator.scala:371)</span><br><span class="line">    at scala.collection.Iterator$$anon$11.hasNext (Iterator.scala:327)</span><br><span class="line">    at scala.collection.Iterator$$anon$11.hasNext (Iterator.scala:327)</span><br><span class="line">    at scala.collection.Iterator$$anon$11.hasNext (Iterator.scala:327)</span><br><span class="line">    at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply$mcV$sp (PairRDDFunctions.scala:1195)</span><br><span class="line">    at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply (PairRDDFunctions.scala:1195)</span><br><span class="line">    at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply (PairRDDFunctions.scala:1195)</span><br><span class="line">    at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks (Utils.scala:1277)</span><br><span class="line">    at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply (PairRDDFunctions.scala:1203)</span><br><span class="line">    at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply (PairRDDFunctions.scala:1183)</span><br><span class="line">    at org.apache.spark.scheduler.ResultTask.runTask (ResultTask.scala:66)</span><br><span class="line">    at org.apache.spark.scheduler.Task.run (Task.scala:89)</span><br><span class="line">    at org.apache.spark.executor.Executor$TaskRunner.run (Executor.scala:227)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1145)</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:615)</span><br><span class="line">    at java.lang.Thread.run (Thread.java:745)</span><br><span class="line">Caused by: java.io.IOException: Failed to connect to host18/192.168.10.188:45026</span><br><span class="line">    at org.apache.spark.network.client.TransportClientFactory.createClient (TransportClientFactory.java:216)</span><br><span class="line">    at org.apache.spark.network.client.TransportClientFactory.createClient (TransportClientFactory.java:167)</span><br><span class="line">    at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart (NettyBlockTransferService.scala:90)</span><br><span class="line">    at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding (RetryingBlockFetcher.java:140)</span><br><span class="line">    at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200 (RetryingBlockFetcher.java:43)</span><br><span class="line">    at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run (RetryingBlockFetcher.java:170)</span><br><span class="line">    at java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:471)</span><br><span class="line">    at java.util.concurrent.FutureTask.run (FutureTask.java:262)</span><br><span class="line">    ... 3 more</span><br><span class="line">Caused by: java.net.ConnectException: Connection refused: host18/192.168.10.188:45026</span><br><span class="line">    at sun.nio.ch.SocketChannelImpl.checkConnect (Native Method)</span><br><span class="line">    at sun.nio.ch.SocketChannelImpl.finishConnect (SocketChannelImpl.java:739)</span><br><span class="line">    at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect (NioSocketChannel.java:224)</span><br><span class="line">    at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect (AbstractNioChannel.java:289)</span><br><span class="line">    at io.netty.channel.nio.NioEventLoop.processSelectedKey (NioEventLoop.java:528)</span><br><span class="line">    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized (NioEventLoop.java:468)</span><br><span class="line">    at io.netty.channel.nio.NioEventLoop.processSelectedKeys (NioEventLoop.java:382)</span><br><span class="line">    at io.netty.channel.nio.NioEventLoop.run (NioEventLoop.java:354)</span><br><span class="line">    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run (SingleThreadEventExecutor.java:111)</span><br><span class="line">    ... 1 more</span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>重点看开头的那部分提示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 6.0 GB of 6 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.</span><br></pre></td></tr></table></figure><p>很明显，超过了物理内存 6 <code>GB</code>。</p><h1 id="分析解决"><a href="# 分析解决" class="headerlink" title="分析解决"></a>分析解决 </h1><p> 主要是内存参数设置太小，不够存储数据 1.8 千万，加载到内存的大小大概是 41 <code>GB</code>。</p><p>当然，分散在集群的多个计算 <code>Executor</code> 节点上，每个节点都会处理一些【前提是数据均匀分布，无倾斜的现象】。</p><p>除了计算内存，还要考虑堆外内存，相关参数如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spark.yarn.executor.memoryOverhead=2048</span><br><span class="line">setExecutorMemory (&quot;2g&quot;)</span><br><span class="line">corenum=20</span><br></pre></td></tr></table></figure><p>此外，关于资源分配的定义也要了解，以后才可以更好地设置参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 资源定义分几个：</span><br><span class="line">1、executor memory：  进程内存大小 </span><br><span class="line">2、number of executor：  进程数 </span><br><span class="line">3、executor-cores  ：  进程的线程数，  spark on yarn 模式下 ， 默认一个 core (线程) 会对应占用 yarn 的一个 vcore（ 除非改过类似 resource calculator 类）</span><br></pre></td></tr></table></figure><p>解决办法当然很简单，增大内存配置即可，但是要注意不能盲目地增大，如果太消耗内存资源建议把数据分批处理。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p><a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/2.1/configuration.html" target="_blank" rel="noopener">elasticsearch-hadoop 官网参考</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Spark</tag>
        <tag>elasticsearch-hadoop</tag>
        <tag>yarn</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 异常之 java.net.BindException: 地址已在使用</title>
    <url>/2018122801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天查看日志发现，所有的 Spark 程序提交时会抛出异常：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.net.BindException: 地址已在使用 </span><br></pre></td></tr></table></figure><p>而且不止一次，会连续有多个这种异常，但是 Spark 程序又能正常运行，不会影响到对应的功能。本文就记录发现问题、分析问题的过程。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在 Driver 端查看日志，发现连续多次相同的异常（省略了业务相关类信息）：</p><p>异常截图 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fymxb3zolsj210v0dzabe.jpg" alt="异常截图" title="异常截图"></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 第一次异常 </span></span><br><span class="line"><span class="number">2018</span>-<span class="number">12</span>-<span class="number">28_12</span>:<span class="number">50</span>:<span class="number">56</span> [main] WARN component.AbstractLifeCycle:<span class="number">204</span>: FAILED SelectChannelConnector@<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">4040</span>: java.net.BindException: 地址已在使用 </span><br><span class="line">java.net.BindException: 地址已在使用 </span><br><span class="line">	at sun.nio.ch.Net.bind0 (Native Method)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">433</span>)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">425</span>)</span><br><span class="line">	at sun.nio.ch.ServerSocketChannelImpl.bind (ServerSocketChannelImpl.java:<span class="number">223</span>)</span><br><span class="line">	at sun.nio.ch.ServerSocketAdaptor.bind (ServerSocketAdaptor.java:<span class="number">74</span>)</span><br><span class="line">	at org.spark-project.jetty.server.nio.SelectChannelConnector.open (SelectChannelConnector.java:<span class="number">187</span>)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractConnector.doStart (AbstractConnector.java:<span class="number">316</span>)</span><br><span class="line">	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart (SelectChannelConnector.java:<span class="number">265</span>)</span><br><span class="line">	at org.spark-project.jetty.util.component.AbstractLifeCycle.start (AbstractLifeCycle.java:<span class="number">64</span>)</span><br><span class="line">	at org.spark-project.jetty.server.Server.doStart (Server.java:<span class="number">293</span>)</span><br><span class="line">	at org.spark-project.jetty.util.component.AbstractLifeCycle.start (AbstractLifeCycle.java:<span class="number">64</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$<span class="number">1</span>(JettyUtils.scala:<span class="number">252</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$$anonfun$<span class="number">5</span>.apply (JettyUtils.scala:<span class="number">262</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$$anonfun$<span class="number">5</span>.apply (JettyUtils.scala:<span class="number">262</span>)</span><br><span class="line">	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$<span class="number">1</span>.apply$mcVI$sp (Utils.scala:<span class="number">2024</span>)</span><br><span class="line">	at scala.collection.immutable.Range.foreach$mVc$sp (Range.scala:<span class="number">141</span>)</span><br><span class="line">	at org.apache.spark.util.Utils$.startServiceOnPort (Utils.scala:<span class="number">2015</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$.startJettyServer (JettyUtils.scala:<span class="number">262</span>)</span><br><span class="line">	at org.apache.spark.ui.WebUI.bind (WebUI.scala:<span class="number">136</span>)</span><br><span class="line">	at org.apache.spark.SparkContext$$anonfun$<span class="number">13</span>.apply (SparkContext.scala:<span class="number">481</span>)</span><br><span class="line">	at org.apache.spark.SparkContext$$anonfun$<span class="number">13</span>.apply (SparkContext.scala:<span class="number">481</span>)</span><br><span class="line">	at scala.Option.foreach (Option.scala:<span class="number">236</span>)</span><br><span class="line">	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:<span class="number">481</span>)</span><br><span class="line">	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:<span class="number">59</span>)</span><br><span class="line">......</span><br><span class="line"><span class="number">2018</span>-<span class="number">12</span>-<span class="number">28_12</span>:<span class="number">50</span>:<span class="number">56</span> [main] WARN component.AbstractLifeCycle:<span class="number">204</span>: FAILED org.spark-project.jetty.server.Server@<span class="number">33e434</span>c8: java.net.BindException: 地址已在使用 </span><br><span class="line">java.net.BindException: 地址已在使用 </span><br><span class="line">	at sun.nio.ch.Net.bind0 (Native Method)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">433</span>)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">425</span>)</span><br><span class="line">	at sun.nio.ch.ServerSocketChannelImpl.bind (ServerSocketChannelImpl.java:<span class="number">223</span>)</span><br><span class="line">	at sun.nio.ch.ServerSocketAdaptor.bind (ServerSocketAdaptor.java:<span class="number">74</span>)</span><br><span class="line">	at org.spark-project.jetty.server.nio.SelectChannelConnector.open (SelectChannelConnector.java:<span class="number">187</span>)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractConnector.doStart (AbstractConnector.java:<span class="number">316</span>)</span><br><span class="line">	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart (SelectChannelConnector.java:<span class="number">265</span>)</span><br><span class="line">	at org.spark-project.jetty.util.component.AbstractLifeCycle.start (AbstractLifeCycle.java:<span class="number">64</span>)</span><br><span class="line">	at org.spark-project.jetty.server.Server.doStart (Server.java:<span class="number">293</span>)</span><br><span class="line">	at org.spark-project.jetty.util.component.AbstractLifeCycle.start (AbstractLifeCycle.java:<span class="number">64</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$<span class="number">1</span>(JettyUtils.scala:<span class="number">252</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$$anonfun$<span class="number">5</span>.apply (JettyUtils.scala:<span class="number">262</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$$anonfun$<span class="number">5</span>.apply (JettyUtils.scala:<span class="number">262</span>)</span><br><span class="line">	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$<span class="number">1</span>.apply$mcVI$sp (Utils.scala:<span class="number">2024</span>)</span><br><span class="line">	at scala.collection.immutable.Range.foreach$mVc$sp (Range.scala:<span class="number">141</span>)</span><br><span class="line">	at org.apache.spark.util.Utils$.startServiceOnPort (Utils.scala:<span class="number">2015</span>)</span><br><span class="line">	at org.apache.spark.ui.JettyUtils$.startJettyServer (JettyUtils.scala:<span class="number">262</span>)</span><br><span class="line">	at org.apache.spark.ui.WebUI.bind (WebUI.scala:<span class="number">136</span>)</span><br><span class="line">	at org.apache.spark.SparkContext$$anonfun$<span class="number">13</span>.apply (SparkContext.scala:<span class="number">481</span>)</span><br><span class="line">	at org.apache.spark.SparkContext$$anonfun$<span class="number">13</span>.apply (SparkContext.scala:<span class="number">481</span>)</span><br><span class="line">	at scala.Option.foreach (Option.scala:<span class="number">236</span>)</span><br><span class="line">	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:<span class="number">481</span>)</span><br><span class="line">	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:<span class="number">59</span>)</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第二次异常 </span></span><br><span class="line"><span class="number">2018</span>-<span class="number">12</span>-<span class="number">28_12</span>:<span class="number">50</span>:<span class="number">56</span> [main] WARN component.AbstractLifeCycle:<span class="number">204</span>: FAILED SelectChannelConnector@<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">4041</span>: java.net.BindException: 地址已在使用 </span><br><span class="line">java.net.BindException: 地址已在使用 </span><br><span class="line">	at sun.nio.ch.Net.bind0 (Native Method)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">433</span>)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">425</span>)</span><br><span class="line">...... 其它信息都一样 </span><br><span class="line"></span><br><span class="line"><span class="comment">// 第三次异常 </span></span><br><span class="line"><span class="number">2018</span>-<span class="number">12</span>-<span class="number">28_12</span>:<span class="number">50</span>:<span class="number">56</span> [main] WARN component.AbstractLifeCycle:<span class="number">204</span>: FAILED SelectChannelConnector@<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">4042</span>: java.net.BindException: 地址已在使用 </span><br><span class="line">java.net.BindException: 地址已在使用 </span><br><span class="line">	at sun.nio.ch.Net.bind0 (Native Method)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">433</span>)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">425</span>)</span><br><span class="line">....... 其它信息都一样 </span><br><span class="line"></span><br><span class="line"><span class="comment">// 第一次异常 </span></span><br><span class="line"><span class="number">2018</span>-<span class="number">12</span>-<span class="number">28_12</span>:<span class="number">50</span>:<span class="number">56</span> [main] WARN component.AbstractLifeCycle:<span class="number">204</span>: FAILED SelectChannelConnector@<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">4043</span>: java.net.BindException: 地址已在使用 </span><br><span class="line">java.net.BindException: 地址已在使用 </span><br><span class="line">	at sun.nio.ch.Net.bind0 (Native Method)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">433</span>)</span><br><span class="line">	at sun.nio.ch.Net.bind (Net.java:<span class="number">425</span>)</span><br><span class="line">....... 其它信息都一样 </span><br></pre></td></tr></table></figure><p> 可以轻易发现核心的地方在于：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">FAILED SelectChannelConnector@<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>: 端口号: java.net.BindException: 地址已在使用 </span><br></pre></td></tr></table></figure><p></p><p>端口号在不断变化，从 4040 一直到 4043，才停止了异常的抛出。</p><h1 id="问题分析"><a href="# 问题分析" class="headerlink" title="问题分析"></a>问题分析 </h1><p> 在 Spark 创建 context 的时候，会使用 4040 端口作为默认的 SparkUI 端口，如果遇到 4040 端口被占用，则会抛出异常。接着会尝试下一个可用的端口，采用累加的方式，则使用 4041 端口，很不巧，这个端口也被占用了，也会抛出异常。接着就是重复上面的过程，直到找到空闲的端口。</p><p>这个异常其实没什么问题，是正常的，原因可能就是在一台机器上面有多个进程都在使用 Spark，创建 context，有的 Spark 任务正在运行着，占用了 4040 端口；或者就是单纯的端口被某些应用程序占用了而已。此时是不能简单地把这些进程杀掉的，会影响别人的业务。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 既然找到了问题，解决办法就很简单了：</p><p>1、这本来就不是问题，直接忽略即可，不会影响 Spark 任务的正常运行；</p><p>2、如果非要不想看到异常日志，那么可以检查机器的 4040 端口被什么进程占用了，看看能不能杀掉，当然这种方法不好了；</p><p>3、可以自己指定端口（使用 spark.ui.port 配置项），确保使用空闲的端口即可（不建议，因为要确认空闲的端口，如果端口不空闲，Spark 的 context 会创建失败，更麻烦，还不如让 Spark 自己去重试）。</p><p>参考：<a href="https://community.hortonworks.com/questions/8257/how-can-i-resolve-it.html" target="_blank" rel="noopener">hortonworks</a></p><p>原文：</p><blockquote><p>When a spark context is created, it starts an application UI on port 4040 by default. When the UI starts, it checks to see if the port is in use, if so it should increment to 4041. Looks like you have something running on port 4040 there. The application should show you the warning, then try to start the UI on 4041.<br>This should not stop your application from running. If you really want to get around the WARNING, you can manually specify which port for the UI to start on, but I would strongly advise against doing so.<br>To manually specify the port, add this to your spark-submit:<br>–conf spark.ui.port=your_port</p></blockquote><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>BindException</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 错误之 JavaSparkContext not serializable</title>
    <url>/2018122101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天更新代码，对 Spark 里面的 RDD 随便增加了一个 Function，结果遇到了序列化（Serializable）的问题，这个不是普通的自定义类不能序列化问题，而是 JavaSparkContext 的用法问题，由于小看了这个问题，多花了一点时间解决问题，本文就记录下这一过程。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 针对已有的项目改动了一点点，结果直接出现了这个错误：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fydoetmx57j21gx0hjgph.jpg" alt="日志报错" title="日志报错"></p><p>一开始疏忽大意了，以为像往常一样，是某些需要传递的对象对应的类没有序列化，由于对代码不敢改动太大，就想着用最简单的方法，把几个自定义类都序列化了，以为就应该可以了。结果，还是不行，此时虽然不会有自定义类的序列化问题了，但是却出现了终极错误：JavaSparkContext not serializable，这是什么意思呢，是说 JavaSparkContext 不能序列化，总不能把 JavaSparkContext 序列化吧，Spark 是不允许这么干的。</p><p>那么问题是什么呢？我首先猜测肯定是 Function 里面用到了 JavaSparkContext 对象，导致启动 Spark 任务的时候，需要序列化 Function 用到的所有对象（当然也需要序列化对象所属类里面的所有属性），而这些 Function 所用到的所有对象里面，就有 JavaSparkContext 对象。于是，我耐心看了一下代码，果然，在创建 Function 对象的时候，竟然把 JavaSparkContext 对象作为参数传进去了，还是因为 JavaSparkContext 不能乱用。</p><p>其实，报错日志里面都已经明显指向说明了，除了自定义的类，错误归结于 <br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">at org.apache.spark.api.java.AbstractJavaRDDLike.mapPartitions (JavaRDDLike.scala:<span class="number">46</span>)</span><br></pre></td></tr></table></figure><p></p><p> 而这里的代码，正是我增加的一部分，为了贪图简单方便，直接把 JavaSparkContext 对象传递给了 mapPartitions 对应的 Function。</p><h1 id="解决问题"><a href="# 解决问题" class="headerlink" title="解决问题"></a>解决问题 </h1><p> 既然找到了问题，接下来就好办了。既然 JavaSparkContext 不能乱用，那就不用，把这个传递参数去掉，即可正常运行，但是这样做太简单粗暴，不是解决问题的思路。仔细分析一下，可以有 2 种解决办法（思路就是避免序列化）：</p><p>1、如果在 Function 里面非要用到 JavaSparkContext 对象，那就把 JavaSparkContext 对象设置为全局静态的 Java 属性（使用 static 关键字），那么在哪里都可以调用它了，而无需担心序列化的问题（静态属性可以避免从 Driver 端发送到 Executor 端，从而避免了序列化过程）；</p><p>2、对于 Function 不要使用内部匿名类，这样必然需要序列化 Function 对象，同时也必然需要序列化 Function 对象用到的 JavaSparkContext 对象，其实可以把 Function 类定义为内部静态类，就可以避免序列化了。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p>1、出现这种错误，不要想当然地认为就是某种原因造成的，而要先看详细日志，否则会走弯路，浪费一些时间（虽然最终也能解决问题）；</p><p>2、有时候状态不好，晕乎乎的，找问题又慢又低效，此时应该休息一下，等头脑清醒了再继续找问题，否则可能事倍功半，而且影响心情。</p><p> 参考：<a href="https://stackoverflow.com/questions/27706813/javasparkcontext-not-serializable" target="_blank" rel="noopener">https://stackoverflow.com/questions/27706813/javasparkcontext-not-serializable</a></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>serializable</tag>
        <tag>Spark序列化</tag>
      </tags>
  </entry>
  <entry>
    <title>WPS 关闭广告推送与自动升级</title>
    <url>/2018110301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在工作和生活中，很多人使用金山的 WPS 套件，类似于微软的 Office 套件，而且是免费的。但是很多人会遇到 <strong>广告推送 </strong>或者 <strong>WPS 热点推送 </strong>，每隔几天就会出现，有时候可以点击七天内不再出现，便可以清静几天，而且碍于是免费版本，不想购买会员，于是也就忍了。其实，WPS 自身是有设置可以关闭 <strong>广告推送 </strong>的，当然也可以关闭 <strong>WPS 热点推送 </strong>。</p><a id="more"></a><h1 id="WPS- 的弹框"><a href="#WPS- 的弹框" class="headerlink" title="WPS 的弹框"></a>WPS 的弹框 </h1><p> 以下现象描述与截图均出自版本：WPS 2019，v11.1.0.8013 - Release 正式版。操作系统为：Windows 2007 专业版。</p><p>在使用 WPS 的过程中，经常遇到广告推送与 WPS 热点推送，觉得很受打扰，但是碍于使用的是免费软件，又只能忍受。我一直在想以前是有设置可以关闭的，后来升级了就找不到是在哪里设置的了，后来又查阅了资料，发现果然是有地方可以设置的，只不过隐藏的太深了，不好寻找而已。接下来就一步一步说明具体设置步骤。</p><h1 id="设置关闭"><a href="# 设置关闭" class="headerlink" title="设置关闭"></a>设置关闭 </h1><p> 如果你在互联网上搜索 WPS 广告推送相关话题，可以看到大量的帖子（或者说是方法教程）已经整理出了各种方案，可以帮你解决这个问题，例如：直接更改 WPS 安装目录中的某些文件、利用杀毒软件屏蔽广告推送、直接设置 WPS 等等。显然，前 2 种方案是在走弯路，而最后一种方案才是最简单直接的。</p><p>1、打开 WPS 主页，在右上角找到 <strong>设置 </strong>按钮；<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy4crah9c4j217w0n60u6.jpg" alt="WPS 的设置" title="WPS 的设置"></p><p>2、点击 <strong>设置 </strong>，选择 <strong>配置和修复工具 </strong>；</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy4csqhjngj21ag0md760.jpg" alt="WPS 的配置和修复工具" title="WPS 的配置和修复工具"></p><p>3、在弹出的对话框中选择 <strong>高级 </strong>；<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy4cuavhshj20jt0d80u2.jpg" alt="WPS 的高级配置" title="WPS 的高级配置"></p><p>4、选择对话框的 <strong>其它选项 </strong>标签页，取消截图中的 3 项勾选，即同时关闭 <strong>升级完成后推荐精选软件 </strong>、<strong> 订阅 WPS 热点 </strong>、<strong> 接受广告推送 </strong>；<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy4cw03l87j20lc0l10tw.jpg" alt="WPS 关闭广告推送" title="WPS 关闭广告推送"></p><p>此外，进入步骤 3 也可以直接通过系统的安装程序列表（开始 –&gt; 所有程序 –&gt;WPS Office–&gt;WPS Office 工具 –&gt; 配置工具），步骤如下图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy4d3nem66j20e70qegos.jpg" alt="系统的所有程序" title="系统的所有程序"><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy4d2sadeoj20ec0qjtck.jpg" alt="找到 WPS 的配置工具" title="找到 WPS 的配置工具"></p><p>按照以上步骤设置， WPS 就不再会弹出广告推送和 WPS 热点推送了，亲测有效。</p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a>注意事项 </h1><p>1、说实话，我是没想到这个设置会隐藏的这么深，但至少暴露出来了；</p><p>2、要注意版本区别，可能每个版本的设置步骤有所不同，而且也不排除以后更新的版本会取消这些设置选项，或者隐藏的更深。当然，如果 WPS 找到了其它盈利方式，也可能会取消这些广告推送；</p><p>3、WPS 每次更新后，上述设置会还原，也就是又回到默认开启的状态，此时需要重新设置一次。当然，为了以后不会莫名其妙又弹出广告推送，可以直接关闭自动升级（和前面关闭广告的步骤一致，但是选择的是 <strong> 升级设置 </strong>标签页），以后想升级的时候再手动升级。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy4cflpmajj20lc0l10u0.jpg" alt="关闭自动升级" title="关闭自动升级"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>WPS</tag>
        <tag>关闭广告推送</tag>
        <tag>关闭自动升级</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10 取消 Skype for Business 自动登录</title>
    <url>/2018090701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近在使用 Win10 系统，遇到一个问题，每次开机，Skype for Business 都会自动弹出来，提示登录，每次我都会关掉它。遇到多次之后，我想这个应用我不需要，直接卸载掉算了，但是却找不到这个应用的信息，最后只能通过关闭 <strong>开机自动启动 </strong>的方式来解决问题，本文记录解决问题的过程。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 最近在使用 Win10 的时候，每次开机后，Skype for Business（这个应用不同于 Skype，虽然功能一样）总会弹出来，提示我登录，我每次都会毫不犹豫地关掉它。</p><p>Skype for Business 登录界面 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g09f643hbhj20dq0orwf8.jpg" alt="Skype for Business 登录" title="Skype for Business 登录"></p><p> 正常的 Skype 应用登录界面 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g09f6h7kmtj20xc0pwgqj.jpg" alt="正常的 Skype 应用登录" title="正常的 Skype 应用登录"></p><p> 但是出现多次之后，很麻烦，当我想卸载这个应用的时候，发现从应用列表里面找不到，也就无从卸载。后来就想能不能关闭开机启动，找了一些文档发现可以，那就这么办了（而且还发现 Skype for Business 根本卸载不了）。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p>1、Skype for Business 是属于 Office 套件中的一个软件，所以在安装整个 Office 的同时也会自动安装上 Skype for Business。由于是一次安装整个 Office 套件，所以无法单独删除其中的一个软件（Skype for Business）。如果不需要开机自动启动 Skype for Business（也就不会提示我登录了），可以在 Skype for Business 的 <strong> 设置 </strong>菜单中的 <strong>个人 </strong>选项里将 <strong>当我登录到 Windows 时自动启动应用 </strong>这个设置取消。</p><p>设置（在登录界面的右上角，有一个齿轮按钮）<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g09f7pheokj20dq0orq3b.jpg" alt="设置" title="设置"></p><p>取消当我登录到 Windows 时自动启动应用 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g09f87o24fj20qh09sgmz.jpg" alt="取消" title="取消"></p><p>2、不知道哪一天 Windows 升级到了新的系统后，Skype for Business 不见了（怎么找也找不到），随之而来的是 Skype，尽管它也属于 Office 中的一个应用（还有很多其它一系列应用），但是这个应用可以单独安装卸载，不再与 Office 绑为一个整体。</p><p> 打开我的 Office<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g09f8r9mqgj20i00iu46e.jpg" alt="打开我的 Office" title="打开我的 Office"></p><p>查看应用列表，也可以直接安装显示的应用 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g09f989oipj20rh0go0ti.jpg" alt="查看应用列表" title="查看应用列表"></p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a> 问题总结 </h1><p>1、我是一开始关闭了 Skype for Business 的登录界面，然后再想打开它，就找不到了，不知道在哪（理论上应该隐藏在某个应用列表里面，目前我还没找到，可能是 Windows 系统升级导致的），但是现在却自动有了 Skype 这个应用（可能是 Windows 系统升级替换了以前的 business 版本），其实这 2 个应用应该差不多。</p><p>2、现在 Windows 系统升级到最新版本（最新升级时间是 2019-02-17）后，Skype for Business 已经不存在了，替换它的是 Skype，而这个应用是可以单独卸载的。</p><p>3、参考：<a href="https://answers.microsoft.com/zh-hans/msoffice/forum/msoffice_sfb-mso_win10-mso_o365b/% E6%9C%80% E8% BF%91% E4% B8%80% E5% BC%80% E6%9C% BA/b7ca9aee-76b5-4e7f-a6bc-c94844ed8cdb" target="_blank" rel="noopener"> 官方回复 </a> 、<a href="https://support.office.com/zh-cn/article/% E8% AE% BE% E7% BD% AE-% E4% B8% AA% E4% BA% BA-% E9%80%89% E9% A1% B9-c09b21ac-7334-49cf-a510-d8c432fcaf01" target="_blank" rel="noopener"> 设置方式</a>、<a href="https://support.office.com/zh-cn/article/% E5% AE%89% E8% A3%85% E7%94% B1% E4% B8%96% E7% BA% AA% E4% BA%92% E8%81%94% E8% BF%90% E8%90% A5% E7%9A%84-skype-for-business-93b6e966-120f-493b-955a-365b298ce828" target="_blank" rel="noopener">Skype for Business 应用介绍</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Skype for Business</tag>
        <tag>自动登录</tag>
        <tag>Win10</tag>
        <tag>Skype</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10 输入法简繁体快捷键与 IDEA 冲突</title>
    <url>/2018112301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>用了 2 个月的 Windows 10 系统（教育版），又安装了 IDEA 代码集成工具，开发的时候，发现每一次只要我使用快捷键 Ctrl + Shift + F 格式化代码后（主要作用就是代码对齐），不起作用，而且写中文注释时发现输入法的中文就被切换为了繁体，再来一次就被切换为了简体。到这里，我知道 IDEA 的快捷键与输入法的快捷键冲突了。</p><a id="more"></a><h1 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案 </h1><p>1、如前文描述，在写代码的过程中发现这个问题，并且看出是快捷键冲突的问题，接下来就要解决它。作为一名工程师，IDEA 的快捷键是因为使用习惯设置的，是写代码效率的保证，不可能更改的，任何与它有冲突的快捷键都要让步，那肯定是要更改输入法的快捷键的；</p><p>2、信心满满，打开 <strong> 搜狗输入法 </strong>的 <strong>属性设置 </strong>界面，找到 <strong>高级 </strong>选项，选择，可以看到里面有 <strong>快捷键 </strong>的相关配置；</p><p>配置所有的快捷键 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0oij39bnj20ld0f0dgj.jpg" alt="快捷键配置" title="快捷键配置"></p><p>3、看了半天，也就这么几个快捷键配置，里面根本没有 <strong> 简体 / 繁体 </strong>切换这一个配置选择，去搜索了一下其它资料，发现 <strong>简体 / 繁体 </strong>切换这一个快捷键是 Windows 10 系统内置的，默认就是 Ctrl + Shift + F，默认是给微软输入法使用的，某些版本的 Windows 10 系统有 bug，无法更改，哪怕卸载微软输入法，安装其它输入法也无效；</p><p>4、我看了我的 Windows 10 系统版本，已经是新版本了，不会有那个 bug 出现了，所以要从系统设置入手了，应该有地方设置才对，查看了语言里面的设置信息，没找到，只能又返回到搜狗输入法里面，这时突然看到里面有一个 <strong>系统功能快捷键 </strong>选项；</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0ort48p1j20ld0f03z6.jpg" alt="系统功能快捷键" title="系统功能快捷键"></p><p>5、就是这里了，点进去，把 <strong>简繁切换 </strong>关闭（如果需要保留的话，更改快捷键即可），解决问题。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0oua7u57j20dv09q3ym.jpg" alt="关闭简繁切换" title="关闭简繁切换"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Win10</tag>
        <tag>输入法</tag>
        <tag>快捷键冲突</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10 默认程序设置无效</title>
    <url>/2018120901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>装了 Windows 10 系统（教育版本），用了将近 3 个月了，最近发现一个诡异的现象，我的默认程序设置每次都只是设置后生效一段时间，例如视频播放器、音乐播放器，我分别设置成了迅雷看看、网易云音乐，用了半天之后，发现又变成了 Window 10 系统自带的视频播放器。这个现象也不是重启之后才出现的，而是平时用着用着就会出现，很莫名其妙。后来查阅资料发现这是一个普遍的现象，这个问题的根本原因是 Windows 10 自带的 bug，通常导致这个 bug 出现的原因是开启了系统的自动更新。</p><a id="more"></a><h1 id="现象"><a href="# 现象" class="headerlink" title="现象"></a>现象 </h1><p> 在 Windows 10 系统（没有打对应补丁的）中，如果开启了系统自动更新，就会触发相应的 bug：默认程序会被系统更改回系统自带的程序，例如视频播放器、音乐播放器等等。这个问题的原因用官方标识来指定就是由于 <strong>KB3135173</strong> 所致，同时这个 bug 已经有对应的补丁了。</p><p>按照系统设置，把某些默认程序改为自己需要的，我这里把视频播放器改为迅雷影音，设置特定格式的文件（.mkv，.mp4 等等）使用迅雷影音打开。</p><p>在桌面右下角打开 <strong>所有设置 </strong>选项 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0n2j57csj20bq0ahmz4.jpg" alt="所有设置" title="所有设置"></p><p> 在 Windows 设置中，选择 <strong>应用 </strong>选项 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0nlh83ifj20xc0pwdgf.jpg" alt="选择应用" title="选择应用"></p><p> 选择默认应用，设置视频播放器为 <strong>迅雷影音 </strong><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0nnjkzdcj20xc0pw445.jpg" alt="设置视频播放器为迅雷影音" title="设置视频播放器为迅雷影音"></p><p> 上述的设置步骤实际上还不够，因为视频类型有很多种，还需要进一步指定每种类型的默认播放器，在默认应用下方有一个 <strong>按文件类型指定默认应用 </strong>选项 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0nqc3hdtj20xc0pw43w.jpg" alt="按文件类型指定默认应用" title="按文件类型指定默认应用"></p><p> 我这里特别关注 <strong>.mkv</strong>、<strong>.mp4</strong> 这 2 种格式的文件，默认应用设置为 <strong>迅雷影音 </strong><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0nusxmrxj20md0pw0tu.jpg" alt="单独设置 2 种文件类型" title="单独设置 2 种文件类型"></p><p> 上述内容设置完成，就可以使用了，但是用不了多久，系统时不时就弹出提示框，通知默认程序重置，然后又被设置为系统内置的应用了 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0mr10t67j20bh0h977t.jpg" alt="弹出提示框" title="弹出提示框"></p><h1 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a> 解决方案 </h1><h2 id="不推荐方案"><a href="# 不推荐方案" class="headerlink" title="不推荐方案"></a> 不推荐方案 </h2><p> 更改注册表、使用命令行卸载系统默认程序，这些方案是可行的，但是对于普通用户来说太麻烦了一点，根本不懂得如何操作，而且解决方法太粗暴了，当然喜欢折腾的人是可以选择的。</p><p>以下给出几个命令行示例（需要在管理员模式下执行，打开 Windows PowerShell 的时候选择有管理员的那个）：</p><p>卸载 “电影和电视” 应用（星号表示通配符，下同）<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">get-appxpackage *zunevideo* | remove-appxpackage</span><br></pre></td></tr></table></figure><p></p><p>卸载 “Groove 音乐” 应用 <br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">get-appxpackage *zunemusic* | remove-appxpackage</span><br></pre></td></tr></table></figure><p></p><p> 卸载 “照片” 应用 <br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">get-appxpackage *photos* | remove-appxpackage</span><br></pre></td></tr></table></figure><p></p><p> 如果还想恢复已经卸载的系统自带应用，可以使用以下命令（重装所有系统内置的应用）<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Get-AppxPacKage -allusers | foreach &#123;Add-AppxPacKage -register <span class="string">"<span class="variable">$($_.InstallLocation)</span>appxmanifest.xml"</span> -DisableDevelopmentMode&#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="推荐直接打补丁（更新系统）"><a href="# 推荐直接打补丁（更新系统）" class="headerlink" title="推荐直接打补丁（更新系统）"></a>推荐直接打补丁（更新系统）</h2><p>这个方法很简单，容易操作，直接在系统更新里面更新即可，确保要能更新到 <strong>KB3135173</strong> 这个补丁才行（或者更高版本的补丁）。</p><p>我这里是已经更新完成的，等待重启，补丁标识是 <strong>KB4469342</strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy0n75u4o3j20xc0pw442.jpg" alt="系统更新" title="系统更新"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Win10</tag>
        <tag>默认程序设置</tag>
      </tags>
  </entry>
  <entry>
    <title>git pull 失败：RPC failed;SSL_ERROR_SYSCALL errno 10054</title>
    <url>/2019072301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>众所周知，<code>Git</code> 是一款非常流行的版本控制工具，现在的项目开发基本都离不开它，否则项目的协作开发将寸步难行，甚至会有专门的项目管理职位来规范项目的开发协作。如果不使用 <code>Git</code>，我的博客整理工作也会增加难度与复杂度，不得不说，我已经离不开它了。今天碰到一个关于 <code>Git</code> 的很奇怪的错误，本文记录解决的过程，整理完感觉经验技能又增长了。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 我换了一台电脑，把项目代码下载下来，正常的 <code>clone</code> 后，一直使用，过了几天，突然出现下面的问题。</p><p>在使用 <code>git pull</code> 命令同步最新代码时报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">error: RPC failed; curl 56 OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054</span><br><span class="line">fatal: The remote end hung up unexpectedly</span><br><span class="line">fatal: early EOF</span><br><span class="line">fatal: unpack-objects failed</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190724014935.png" alt="git pull 报错信息" title="git pull 报错信息"></p><p>我仔细观察了整个过程，一开始还是正常的，百分比进度在变化，然后就卡在那里一直不再动，最后就报错，紧接着 <code>pull</code> 流程被终止。</p><p>初步看起来像是网络不好或者文件内容太大导致的网络连接超时失败。</p><p>按照可能是网络问题这个方向，我重试了多次，全部都是 <code>git pull</code> 失败，然后我换成其它项目再做相同的操作就正常，我陷入了沉思：应该和环境无关，只和项目有关，这个 <code>git pull</code> 失败的项目到底有什么特殊之处。</p><p>突然，我一拍脑门，想起来了，这个项目前一天晚上被我 <code>commit</code> 了很多张图片，应该有 100 张以上，总计 <code>200MB</code> 大小，看来这是问题所在。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><p> 循着这个线索，使用报错关键词 <code>RPC failed; curl 56 OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054</code> 去 <code>stackoverflow</code> 搜索一下，发现很多人都遇到过这个问题。原因在于 <code>http</code> 通信缓存设置的值太小，恰好我的项目是使用 <code>http</code> 协议进行 <code>pull</code> 的，而没有使用 <code>ssh</code> 的方式。</p><p>这时候的解决方式就是设置一下缓存大小，参数名为：<code>http.postBuffer</code>，把它的值设置大一点【注意它的单位是 B，字节，进位是 1024 制的】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 500MB, 如果配合使用 --global 参数可以全局生效 </span><br><span class="line">git config http.postBuffer 524288000</span><br><span class="line"># 1GB</span><br><span class="line">git config http.postBuffer 1048576000</span><br></pre></td></tr></table></figure><p>根据官网对 <code>http.postBuffer</code> 这个参数的解释说明：</p><blockquote><p>Maximum size in bytes of the buffer used by smart HTTP transports when POSTing data to the remote system. For requests larger than this buffer size, HTTP/1.1 and Transfer-Encoding: chunked is used to avoid creating a massive pack file locally. Default is 1 MiB, which is sufficient for most requests.</p></blockquote><p>附官网链接：<a href="https://git-scm.com/docs/git-config" target="_blank" rel="noopener">https://git-scm.com/docs/git-config</a> ，参见对参数 <code>http.postBuffer</code> 的解释。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190724015009.png" alt="Git 官网对于缓存参数的解释说明" title="Git 官网对于缓存参数的解释说明"></p><p>可以看到这个参数的默认值为：<code>1 MiB</code>，对大部分项目都是合理的，但是对于我这个一次疯狂 <code>commit</code> 很多张图片的项目就无能为力了。</p><p>配置完成后，也可以在项目的 <code>.git/config</code> 配置文件中查看这个参数的信息【如果设置了全局生效，则需要在家目录中寻找这个配置文件，即 <code>home</code> 目录】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[core]</span><br><span class="line">	repositoryformatversion = 0</span><br><span class="line">	filemode = false</span><br><span class="line">	bare = false</span><br><span class="line">	logallrefupdates = true</span><br><span class="line">	symlinks = false</span><br><span class="line">	ignorecase = true</span><br><span class="line">[remote &quot;origin&quot;]</span><br><span class="line">	url = https://github.com/iplaypi/sources-playpi.git</span><br><span class="line">	fetch = +refs/heads/*:refs/remotes/origin/*</span><br><span class="line">[branch &quot;master&quot;]</span><br><span class="line">	remote = origin</span><br><span class="line">	merge = refs/heads/master</span><br><span class="line">[gui]</span><br><span class="line">	wmstate = normal</span><br><span class="line">	geometry = 1061x563+30+30 233 255</span><br><span class="line">[credential]</span><br><span class="line">	helper = store</span><br><span class="line">[user]</span><br><span class="line">	name = iplaypi</span><br><span class="line">	email = playpi@qq.com</span><br><span class="line">[http]</span><br><span class="line">	postBuffer = 524288000</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190724015105.png" alt="查看 Git 项目的配置信息" title="查看 Git 项目的配置信息"></p><p>好，接下来再进行 <code>pull</code> 操作，可以看到，最终正常了，没有再出问题【一开始我设置的是 500MB，还是不行，接着改为 1GB 就可以了】。由于网络速度问题或者中国大陆访问 <code>GitHub</code> 缓慢的原因，这次正常的 <code>pull</code> 使用了将近四十分钟才完成，等得我着急。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190724015342.png" alt="pull 正常同步更新" title="pull 正常同步更新"></p><p>可见，真的是我这个项目的内容太大了，同步的时候 <code>http</code> 通信缓存不足，导致出错。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p>1、此外，还有一个压缩参数：<code>core.compression</code>，可以用来设置压缩率，有 11 个取值。当然，如果把项目内容压缩了，由于压缩操作本身就会很耗时，会导致下载速度变慢，下载同步过程总的耗时也会随之增加。</p><p> 官网说明：</p><blockquote><p>An integer -1..9, indicating a default compression level. -1 is the zlib default. 0 means no compression, and 1..9 are various speed/size tradeoffs, 9 being slowest. If set, this provides a default to other compression variables, such as core.looseCompression and pack.compression.</p></blockquote><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190724015140.png" alt="Git 官网对于压缩参数的解释说明" title="Git 官网对于压缩参数的解释说明"></p><p>2、我当前使用的是 <code>http</code> 方式，其实还有一种 <code>ssh</code> 方式，更方便，可以试试。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>PRC</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2017102901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>建站</tag>
      </tags>
  </entry>
  <entry>
    <title>jackson 包版本低导致 NoSuchMethodError</title>
    <url>/2018120101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>本文讲述 Java 项目由 Maven 包冲突或者版本不合适导致的运行时错误：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.NoSuchMethodError: com.fasterxml.jackson.databind.JavaType.isReferenceType () Z</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><h1 id="起因"><a href="# 起因" class="headerlink" title="起因"></a>起因 </h1><p> 今天在升级 Web 项目的相关接口，更新了所依赖的 SDk 版本，删除了一些旧代码，测试时发现某个功能不可用，直接抛出异常，异常是在运行时抛出的，编译、打包、部署都没有任何问题。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqmy8sggbj213t0eyq5s.jpg" alt="NoSuchMethodError 异常" title="NoSuchMethodError 异常"></p><p>我看到第一眼，就知道肯定是 Maven 依赖问题，要么是版本冲突（存在不同版本的 2 个相同依赖），要么是依赖版本不对（太高或者太低），但为了保险起见，我还是先检查了一下 Git 的提交记录，看看有没有对 pom.xml 配置文件做相关改动。检查后发现，除了一些业务逻辑的变动，以及无关 jackson 依赖的版本升级，没有其它对 pom.xml 文件的改动，由此可以断定，某个依赖的升级导致了此问题，问题原因找到了，接下来就是解决问题。</p><h1 id="解决办法"><a href="# 解决办法" class="headerlink" title="解决办法"></a>解决办法 </h1><h2 id="查看项目的 -Maven- 依赖树"><a href="# 查看项目的 -Maven- 依赖树" class="headerlink" title="查看项目的 Maven 依赖树"></a> 查看项目的 Maven 依赖树 </h2><p> 由于依赖太多，使用可视化的插件查看太繁杂，所以选择直接使用 maven 的 dependency 构件来生成文本，然后再搜索查看：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mvn dependency:tree &gt; tree.txt</span><br></pre></td></tr></table></figure><p></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqnq28eqmj20nb071jrm.jpg" alt="mvn 命令行脚本" title="mvn 命令行脚本"></p><p>在 tree.txt 文件中搜索 jackson，可以找到 jackson-databind 相关的依赖包，还有 jackson-annotations、jackson-core 这 2 个依赖包。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqob296i5j218a0q2whw.jpg" alt="jackson 依赖搜索" title="jackson 依赖搜索"></p><p>jackson-databind 的版本为 2.9.3<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqovrmijgj20vz0gg0ub.jpg" alt="jackson-databind 的版本" title="jackson-databind 的版本"></p><p>确定了使用的版本，接下来可以在 IDEA 里面搜索一下这个类，然后再找调用的方法，直接去查看源码，看看到底有没有这个方法。搜索 JavaType Java 类，注意包的路径，可能会有很多重名的类出现，我是用 Ctrl + Shift + T 的快捷键搜索，各位根据自己的快捷键设置进行搜索。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqoyomz3nj21ha0ketbp.jpg" alt="搜索 JavaType 类" title="JavaType"></p><p>然后进入类的源代码，搜索方法 isReferenceType，报错信息后面的大写的 Z，是 JNI 字段描述符，表示这个方法的返回值类型，Z 表示 Boolean 类型，我们搜索看看有没有这个方法。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqp3posd9j218h0l2dhd.jpg" alt="搜索方法 isReferenceType" title="搜索方法 isReferenceType"></p><p>我们发现连同名的方法都没有，更不用看返回值类型了，但是注意还是要去父类还有接口里面去搜索一下，保证都没有才是最终的没有。经过查找，没发现这个方法（主要原因是父类 ResolvedType 的版本太低，父类所在的 jackson-core 的版本只有 2.3.3，所以找不到这个方法），到这里就要准备升级 jackson-core 或者降级 jackson-databind 依赖了。</p><h2 id="去除多余依赖"><a href="# 去除多余依赖" class="headerlink" title="去除多余依赖"></a>去除多余依赖 </h2><p> 如果是检查到存在依赖冲突的情况，一般是高低版本之间的冲突（最多的情况是多级传递依赖引起的），然后 Maven 编译打包时会全部打进业务的包。</p><p>1、导致运行时程序不知道选择哪一个，于是抛出 NoSuchMethodError 异常，此时根据需要，移除多余的依赖包即可；</p><p>2、步骤 1 操作后，还是一种可能是虽然只存在一个版本，但是由于版本太新或者太旧，无法兼容所有的调用，导致多处需要调用这个依赖包的地方总会有某个地方出现 NoSuchMethodError 异常。此时就比较麻烦，如果能找到一个合适版本的依赖包，兼容所有的调用，当然是好的；或者升级调用处对应的接口版本；如果还是无法解决，就只能通过 Shade 构件解决问题了，此处就不赘述了。</p><p>经过检查，我这里遇到的就是步骤 2 的情况，虽然只剩下一个依赖包，但是版本太低或者太高，导致调用时找不到 isReferenceType 方法，类其实是存在的，所以要采用升级或者降级的方式。</p><h2 id="升级降级依赖"><a href="# 升级降级依赖" class="headerlink" title="升级降级依赖"></a>升级降级依赖 </h2><p> 如果是检查到只有一个依赖，并没有冲突的情况，就容易了，直接找到最稳定的版本或者适合使用的旧版本，提取依赖的坐标，配置到 pom.xml 文件中即可。</p><p>经过检查，我这里遇到的就是这种情况，去 Maven 私服中搜索 jackson，找到合适的版本（自己根据需要选择，我这里选择 jackson-databind 的 2.9.7 版本，然后 jackson-core 也指定 2.9.7 版本，就可以了，然后又查资料也发现这个方法是 2.6.0 版本之后才开始加上的），配置到 pom.xml 文件中即可。</p><p>私服搜索 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqnn8b0rmj219s0nugn4.jpg" alt="jackson 搜索" title="jackson 搜索"></p><p> 配置到 pom.xml<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqq62vwuvj20mw07kdg4.jpg" alt="jackson 配置" title="jackson 配置"></p><p>我这里使用了常量，在 pom.xml 文件的 properties 属性下面配置即可。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxqq73kgcsj20oo02o746.jpg" alt="Maven 版本常量" title="Maven 版本常量"></p><h1 id="踩坑总结"><a href="# 踩坑总结" class="headerlink" title="踩坑总结"></a>踩坑总结</h1><p>1、其实 jackson 这个依赖我并没有使用，而是引用的一个第三方依赖内部使用的，但是这个第三方依赖并没有一同打进来，也没有说明需要什么版本的，所以导致我自己在实验，最终找到到底哪一个版本合适。</p><p>2、为了统一，jackson-core 的版本要与 jackson-databind 的版本一致，jackson-databind 里面是已经自带了 jackson-annotations 的，由于 jackson-databind 里面的类继承了 jackson-core 里面的，所以才都要升级并且保持版本一致。</p><p>3、搜索类方法时，注意留意父类和接口里面，不一定非要在当前类里面出现。更改版本后同样也去类里面搜索一下，看看有没有需要调用的方法出现，确定版本用对了再继续做测试。</p><p>4、这种错误在编译、打包、部署阶段是检查不出来的，因为代码并没有实际调用到，属于运行时错误，只有跑起来程序，执行到需要使用该方法的时候，才会报错。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>NoSuchMethodError</tag>
        <tag>jackson</tag>
        <tag>Maven</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title>mapreduce 错误之 bin bash-line 0-fg-no job control</title>
    <url>/2019042401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天在开发 mapreduce 程序的过程中，为了快速开发，程序的整体框架是从别的业务复制过来的，自己增加一些数据处理逻辑以及环境的参数配置。接着就遇到问题，在本地本机测试的时候，Job 作业无法启动，总是抛出异常，然后进程退出。本机系统为 Windows 7 X64。</p><p>异常错误信息简略如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exit code: 1</span><br><span class="line">Exception message: /bin/bash: line 0: fg: no job control</span><br></pre></td></tr></table></figure><p>本文记录这个现象以及解决方案。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在本地本机启动 Job 时无法正常运行作业，直接抛出异常后退出进程，完整错误信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Diagnostics: Exception from container-launch.</span><br><span class="line">Container id: container_e18_1550055564059_0152_02_000001</span><br><span class="line">Exit code: 1</span><br><span class="line">Exception message: /bin/bash: line 0: fg: no job control</span><br><span class="line"></span><br><span class="line">Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control</span><br><span class="line"></span><br><span class="line">	at org.apache.hadoop.util.Shell.runCommand (Shell.java:576)</span><br><span class="line">	at org.apache.hadoop.util.Shell.run (Shell.java:487)</span><br><span class="line">	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute (Shell.java:753)</span><br><span class="line">	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer (DefaultContainerExecutor.java:212)</span><br><span class="line">	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call (ContainerLaunch.java:303)</span><br><span class="line">	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call (ContainerLaunch.java:82)</span><br><span class="line">	at java.util.concurrent.FutureTask.run (FutureTask.java:266)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Container exited with a non-zero exit code 1</span><br><span class="line">Failing this attempt. Failing the application.</span><br><span class="line">2019-04-22_22:46:04 [main] INFO mapreduce.Job:1385: Counters: 0</span><br></pre></td></tr></table></figure><p>其中的重点在于：<strong>Exception message: /bin/bash: line 0: fg: no job control</strong>，由于我不了解这种错误，只能靠搜索引擎解决了。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 问题解决很容易，在 Job 的配置中增加一项：mapreduce.app-submission.cross-platform，取值为 true，截取代码片段如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Configuration conf = job.getConfiguration ();</span><br><span class="line">conf.set (&quot;mapreduce.job.running.map.limit&quot;, &quot;50&quot;);</span><br><span class="line">// 本机环境测试加上配置，否则会抛出异常退出：ExitCodeException: /bin/bash: line 0: fg: no job control</span><br><span class="line">conf.set (&quot;mapreduce.app-submission.cross-platform&quot;, &quot;true&quot;);</span><br></pre></td></tr></table></figure><p>这个配置的含义就是跨平台，保障 Job 作业可以在 Windows 平台顺利运行。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 参考：<a href="https://stackoverflow.com/questions/24075669/mapreduce-job-fail-when-submitted-from-windows-machine" target="_blank" rel="noopener">stackoverflow 讨论一例</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>mapreduce</tag>
      </tags>
  </entry>
  <entry>
    <title>一条正则表达式引发的惨案</title>
    <url>/2018120201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>本文讲述由于正则表达式引发的性能惨案，背景就是使用 <code>Java</code> 编程语言进行正则表达式匹配，由于正则表达式很复杂，再加上 <code>Java</code> 使用的是 <code>NFA</code>【非确定型有穷自动机】匹配引擎，导致匹配一条文本内容使用了十几个小时还没完成，一直卡住，同时线上环境的主机 <code>CPU</code> 使用率也居高不下【一开始我是猜的，因为我没有权限看，后来问了运维人员，果然是的】。</p><a id="more"></a><p>整理中。</p><p>就是这个正则表达式把机器打满了，噪音词匹配，血案：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">^(\s|\pP|\pS|#[\u4e00-\u9fa5A-Z0-9a-z._-]+#|(https?|ftp|file)://[-A-Za-z0-9+&amp;@#/%?=~_|!:,.;]+[-A-Za-z0-9+&amp;@#/%=~_|]|\[.&#123;1,4&#125;\]|[0-9a-zA-Z]+| 就是 | 罢了 | 着呢 | 便了 | 已而 | 来着 | 也好 | 着哩 | 不成 | 也罢 | 再说 | 一般 | 而已 | 也 | 不 | 故 | 给 | 的 | 吗 | 家 | 了 | 么 | 呀 | 以 | 吧 | 来 | 哪 | 连 | 而 | 然 | 盖 | 且 | 阿 | 呢 | 啦 | 则 | 哇 | 其 | 哈 | 咧 | 与 | 啊 | 哩 | 乎 | 呗 | 虽 | 惟 | 斯 | 罗 | 价 | 喽 | 维 | 呵 | 般 | 否 | 耶 | 哉 | 罢 | 呕 | 咯 | 嘛 | 噢 | 哟 | 呐 | 焉 | 邪 | 呦 | 啰 | 呸 | 麽 | 嘞 | 矣 | 啵 | 欸 | 唻 | 呃 | 欤 | 噻 | 嘢 | 嚜 |\pP|\pS)*//@([\u4e00-\u9fa5A-Z0-9a-z._-]+).*$</span><br></pre></td></tr></table></figure><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 参考文献：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/38229530" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38229530</a></li><li><a href="http://www.cnblogs.com/study-everyday/p/7426862.html" target="_blank" rel="noopener">http://www.cnblogs.com/study-everyday/p/7426862.html</a></li><li><a href="https://www.jianshu.com/p/5c2e893b8d5d" target="_blank" rel="noopener">https://www.jianshu.com/p/5c2e893b8d5d</a></li><li></li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
        <tag>Java NFA</tag>
        <tag>非确定型有穷自动机</tag>
        <tag>正则无限回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>与微博内容分析相关的正则表达式</title>
    <url>/2018121101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在分析微博内容时，常常需要进行特殊内容去除与抽取，例如抽取微博话题、微博昵称、微博表情、微博短链接、网址长链接等等。本文依据实际使用情况，记录下了与微博内容分析相关的正则表达式，以便查用。</p><a id="more"></a><h1 id="微博表情"><a href="# 微博表情" class="headerlink" title="微博表情"></a>微博表情 </h1><p> 表情是使用左右中括号包含的文本（在实际使用时，显示的是 emoji 表情，不是单纯的字符），例如：[爱心]、[微笑]、[笑哭]，分别表示：:heart:、❤️、:smile:、😊、:joy:、😂</p><p>参考：<a href="https://emojipedia.org" target="_blank" rel="noopener">emoji 百科 </a> 。</p><p> 如果在微博内容中抽取表情，使用正则表达式（1-7 个字符，中文和字母，不排除有的新的表情出现，导致字符更长）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\[[\u4e00-\u9fa5A-Za-z]&#123;1,7&#125;\]</span><br></pre></td></tr></table></figure><p>不同字符长度的表情举例（我用了 10 分钟把微博表情全部浏览了一遍，发现 [小黄人] 系列、[文明遛狗] 是最近刚刚发布出来的）：[耶]、[来]、[跪了]、[ok]、[中国赞]、[紫金草]、[doge]、[文明遛狗]、[给你小心心]、[小黄人微笑]、[弗莱见钱眼开]、[小黄人剪刀手]、[哆啦 A 梦害怕]、[带着微博去旅行]。</p><p>注意，在 2019 年 3 月 21 日，发现微博新增了表情：<strong>[大侦探皮卡丘微笑]</strong>，这个表情有 8 个字符，所以表情的正则表达式也要做相应的更新。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\[[\u4e00-\u9fa5A-Za-z]&#123;1,8&#125;\]</span><br></pre></td></tr></table></figure><h1 id="微博昵称"><a href="# 微博昵称" class="headerlink" title="微博昵称"></a>微博昵称 </h1><p> 微博昵称是用户填写的昵称，并且在转发或者提到时，会增加 @ 前缀，例如有一个 playpi 微博用户，在实际微博内容中，会以 @playpi 的形式出现，当然，微博昵称的可用字符是有限制的，不是任意字符都行，长度也是有限制的，最少 4 个字符，最多 30 个字符。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy6r1bwv0xj20mi082dfy.jpg" alt="微博昵称字符限制" title="微博昵称字符限制"></p><p>以及微博客服的回答：<a href="https://www.weibo.com/2016713117/FCf87jJZt?type=comment#_rnd1544860586591" target="_blank" rel="noopener">微博客服微博 </a> 。</p><p> 但是这个规则是针对修改昵称的限制，如果有些帐号是以前注册的，并且昵称在微博官方限制以前没有修改过，那么就有可能是 2 个字符，3 个字符，例如各个明星、作家、自媒体的个人微博：@阑夕、@王力宏、@韩寒 等等。</p><p>如果在微博内容中抽取昵称，使用正则表达式（中文、数字、字母、横线、下划线的组合，2-30 个字符）：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@[\u4e00-\u9fa5A-Z0-9a-z_-]&#123;2,30&#125;</span><br></pre></td></tr></table></figure><p></p><h1 id="微博话题"><a href="# 微博话题" class="headerlink" title="微博话题"></a>微博话题 </h1><p> 话题是微博定义的一种概念，可以用来标识热门事件、重大新闻、明星、综艺节目等等，发布规则就是使用 2 个 #符号包含话题内容（例如：# 创造 101#），话题即生成，微博还专门有一个实时话题榜单。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy6ro4qztbj20v40q2doc.jpg" alt="微博话题榜" title="微博话题榜"></p><p>如果在微博内容中抽取话题，使用正则表达式（2 个 #号之间，非指定的符号，长度在 1-49 之间）：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#[^@&lt;&gt;#"&amp;'\r\n\t]&#123;1,49&#125;#</span></span><br></pre></td></tr></table></figure><p></p><p>注意，我找到 2014 年的 <a href="https://iask.sina.com.cn/b/wnINuLfme5.html" target="_blank" rel="noopener">一篇旧帖子 </a>，微博小秘书评论说话题不能包含指定的几个特殊字符，还有内容长度限制，但是我在微博页面试了一下，这些特殊字符都可以使用（但是生成的话题页面，&lt; 字符、&gt; 字符被转成了 html 字符实体，换行符后的内容被截断，@符号、’ 单引号、” 双引号被自动替换掉，# 符号根本无法发布，空格符可以正常使用），而且长度限制是 1-49 个字符（中英文、标点都算 1 个字符）。但是为了话题内容的传播，还是使用通俗易懂的中文或者字母比较好。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy6s5061rxj20gv03uwei.jpg" alt="话题测试发布" title="话题测试发布"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy6s42ecfzj20k904l0sq.jpg" alt="话题测试结果" title="话题测试结果"></p><h1 id="微博短链接"><a href="# 微博短链接" class="headerlink" title="微博短链接"></a> 微博短链接 </h1><p> 微博短链接是微博官方提供的网址压缩功能产生的一种只包含少量字符的短网址，例如：<a href="http://finance.sina.com.cn" target="_blank" rel="noopener">http://finance.sina.com.cn</a> ，压缩后为：<a href="http://t.cn/RnM1Uti" target="_blank" rel="noopener">http://t.cn/RnM1Uti</a> 。这样的话，发微博时链接占用更少的字符长度。如果发微博时，内容中带了链接，例如视频地址、淘宝店地址，会被自动压缩为短链接。微博短链接可以直接在浏览器中访问，会被微博的网址解析服务器转换为原来的正常链接再访问。</p><p>如果在微博内容中抽取短链接，使用正则表达式（我这里只是抽取 t.cn 域名的，6-8 个字母、数字）：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#https&#123;0,1&#125;://t.cn/[A-Z0-9a-z]&#123;6,8&#125;[/]&#123;0,1&#125;#</span></span><br></pre></td></tr></table></figure><p></p><p>参考：<br>微博开放平台说明：<a href="http://open.weibo.com/wiki/2/short_url/shorten" target="_blank" rel="noopener">http://open.weibo.com/wiki/2/short_url/shorten</a> ；<br>免费在线短链接转换工具：<a href="http://dwz.wailian.work" target="_blank" rel="noopener">http://dwz.wailian.work</a> 。</p><h1 id="网址长链接"><a href="# 网址长链接" class="headerlink" title="网址长链接"></a>网址长链接 </h1><p> 网址长链接也就是普通的网址，有多种可能性。</p><p>如果在微博内容中抽取网址长链接，使用正则表达式（我这里只考虑 http、https、ftp、file 协议）：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(https?|ftp|file)://[-A-Za-z0-9+&amp;@<span class="comment">#/%?=~_|!:,.;]+[-A-Za-z0-9+&amp;@#/%=~_|]</span></span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
        <tag>微博内容</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Gson 将 = 转为 u003d 的问题</title>
    <url>/2019010601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天遇到一个问题，实现 Web 后台接收 http 请求的一个方法，发现前端传过来的参数值，有一些特殊符号总是使用了 unicode 编码，例如等号 =，后台接收到的就是 \u003d，导致使用这个参数做 JSON 变换的时候就会出错。我看了一下这个参数取值，是前端直接填写的，而填写的人是从其它地方复制过来的，人为没有去改变，前端没有验证转换，导致传入后台的已经是这样了，那么后台只好自己想办法转换。</p><a id="more"></a><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 其实就是字符串还原操作，把 Java 字符串里面的 unicode 编码子串还原为原本的字符，例如把 \u003d 转为 = 这样。</p><p>自己实现一个工具类，做编码字符串和普通字符串的转换，可以解决这个问题。</p><p>单个编码转换，公共方法示例：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * unicode 转字符串 </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> unicode 全为 Unicode 的字符串 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">unicode2String</span><span class="params">(String unicode)</span> </span>&#123;</span><br><span class="line">    StringBuffer string = <span class="keyword">new</span> StringBuffer ();</span><br><span class="line">    String [] hex = unicode.split (<span class="string">"\\\\u"</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; hex.length; i++) &#123;</span><br><span class="line">        <span class="comment">// 转换出每一个代码点 </span></span><br><span class="line">        <span class="keyword">int</span> data = Integer.parseInt (hex [i], <span class="number">16</span>);</span><br><span class="line">        <span class="comment">// 追加成 string</span></span><br><span class="line">        string.append ((<span class="keyword">char</span>) data);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> string.toString ();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>整个字符串转换，公共方法示例：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 含有 unicode 的字符串转一般字符串 </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> unicodeStr 混有 Unicode 的字符串 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">unicodeStr2String</span><span class="params">(String unicodeStr)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> length = unicodeStr.length ();</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 正则匹配条件，可匹配 \\u 1 到 4 位，一般是 4 位可直接使用 String regex = "\\\\u [a-f0-9A-F]&#123;4&#125;";</span></span><br><span class="line">    String regex = <span class="string">"\\\\u [a-f0-9A-F]&#123;1,4&#125;"</span>;</span><br><span class="line">    Pattern pattern = Pattern.compile (regex);</span><br><span class="line">    Matcher matcher = pattern.matcher (unicodeStr);</span><br><span class="line">    StringBuffer sb = <span class="keyword">new</span> StringBuffer ();</span><br><span class="line">    <span class="keyword">while</span> (matcher.find ()) &#123;</span><br><span class="line">        <span class="comment">// 原本的 Unicode 字符 </span></span><br><span class="line">        String oldChar = matcher.group ();</span><br><span class="line">        <span class="comment">// 转换为普通字符 </span></span><br><span class="line">        String newChar = unicode2String (oldChar);</span><br><span class="line">        <span class="keyword">int</span> index = matcher.start ();</span><br><span class="line">        <span class="comment">// 添加前面不是 unicode 的字符 </span></span><br><span class="line">        sb.append (unicodeStr.substring (count, index));</span><br><span class="line">        <span class="comment">// 添加转换后的字符 </span></span><br><span class="line">        sb.append (newChar);</span><br><span class="line">        <span class="comment">// 统计下标移动的位置 </span></span><br><span class="line">        count = index + oldChar.length ();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 添加末尾不是 Unicode 的字符 </span></span><br><span class="line">    sb.append (unicodeStr.substring (count, length));</span><br><span class="line">    <span class="keyword">return</span> sb.toString ();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>调用示例：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str = <span class="string">"ABCDEFG\\u003d"</span>;</span><br><span class="line">System.out.println (<span class="string">"====unicode2String 工具转换:"</span> + unicodeStr2String (str));</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">====unicode2String 工具转换：ABCDEFG=</span><br></pre></td></tr></table></figure><p>截图示例：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyyep0kwtgj20yv0kk0ug.jpg" alt="自己转换" title="自己转换"></p><h1 id="问题后续"><a href="# 问题后续" class="headerlink" title="问题后续"></a>问题后续 </h1><p> 后续我又在想，这个字符串到底是怎么来的，为什么填写的人会复制出来这样一个字符串，一般 unicode 编码不会出现在日常生活中的。我接着发现这个字符串是从另外一个系统导出的，导出的时候是一个类似于 Java 实体类的 JSON 格式字符串，从里面复制出来这个值，就是 \u003d 格式的。</p><p>那我觉得肯定是这个系统有问题，做 JSON 序列化的时候没有控制好序列化的方式，导致对于特殊字符就会自动转为 unicode 编码，给他人带来麻烦，当然，我无法得知系统内部做了什么，但是猜测可能是使用 Gson 工具做序列化的时候没有正确使用 Gson 的对象，只是简单的生成 JSON 字符串而已，例如看我下面的代码示例（等号 = 会被转为 \u003d）。</p><p>使用普通的 </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Gson gson1 = <span class="keyword">new</span> Gson ();</span><br></pre></td></tr></table></figure><p> 会导致后续转换 JSON 字符串的时候出现 unicode 编码子串的情况，而正确生成 Gson 对象 </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Gson gson2 = <span class="keyword">new</span> GsonBuilder ().disableHtmlEscaping ().create ();</span><br></pre></td></tr></table></figure><p> 则不会出现这种情况。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyyeompqqcj20zr0k3jt4.jpg" alt="正确使用 Gson" title="正确使用 Gson"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Gson</tag>
        <tag>等号编码转换</tag>
        <tag>u003d</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 IDEA 自动生成 serialVersionUID</title>
    <url>/2016060801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天在一个 <code>Java Web</code> 项目中，遇到反序列化的问题，在前端生成的参数列表以 <code>JSON</code> 格式保存，然后在后端需要提取参数，并反序列化为指定的实体类使用，结果反序列化失败，失败异常是 <code>InvalidCastException</code>，根本原因还是 <code>serialVersionUID</code> 不一致。本文简述一下这个知识点，也是自己复习使用。</p><a id="more"></a><h1 id="自动生成"><a href="# 自动生成" class="headerlink" title="自动生成"></a>自动生成 </h1><p> 众所周知，<code>InelliJ IDEA</code> 是一款非常优秀的 <code>IDE</code> 工具，其中它包含很多自动检查工具，<code>Serialzable</code> 检查就是其中一项。</p><p>默认的序列化检查项是关闭的，所以不存在自动检查之说，也就无法自动生成。可以去 <code>IDEA</code> 中设置自动检查，依次找到 <code>Settings</code>、<code>Inspections</code>，在里面搜索 <code>Serializable</code> 关键词，就可以发现与之有关的多项设置，其中 <code>Serializable class without serialVersionUID</code> 就是自动检查序列化缺失 <code>serialVersionUID</code> 的场景，在右侧打勾选中即可，以后 <code>IDEA</code> 就会自动检查需要序列化的 <code>Java</code> 类是否缺失 <code>serialVersionUID</code> 了。</p><p>注意右侧还有一个 <code>Severity</code> 选项，用来设置检查的级别，建议设置为 <code>Warning</code>，如果对序列化特别看重的话，可以选择 <code>Error</code> 级别，我在这里使用了 <code>Warning</code> 级别。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200308180911.png" alt="设置自动检查" title="设置自动检查"></p><p>如果设置了 <code>Inspections</code> 的检查项，<code>IDEA</code> 就会自动检查 <code>Java</code> 类是否带有 <code>serialVersionUID</code>，如果没有则会提示，然后可以使用快捷方式来设置。</p><p>具体操作：在已经实现 <code>Serialzable</code> 接口的 <code>Java</code> 类上【即可以序列化的类】，选中类名，使用 <code>ALT + ENTER</code> 快捷键即可弹出选择列表，选择 <code>Add serialVersionUID field</code>，再使用 <code>ENTER</code> 即可生成 <code>serialVersionUID</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200308180956.png" alt="快捷键添加" title="快捷键添加"></p><p>如果在弹出的选择列表中，展开 <code>Add serialVersionUID field</code>，可以看到更多的选择项，此时可以选择 <code>Edit inspection profile setting</code> 进入 <code>Inspections</code> 设置，也可以选择 <code>Disable inspection</code> 关闭自动检查。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200308181011.png" alt="快捷设置选项" title="快捷设置选项"></p><h1 id="作用简介"><a href="# 作用简介" class="headerlink" title="作用简介"></a>作用简介 </h1><p><code>Java</code> 类进行序列化有两个主要目的，分别为：</p><ul><li> 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中 </li><li> 在网络上传输对象的字节序列，发送方、接收方使用的 <code>Java</code> 类版本可能不一致 </li></ul><p><code>serialVersionUID</code> 适用于 <code>Java</code> 的序列化机制，简单来说，<code>Java</code> 的序列化机制是通过判断类的 <code>serialVersionUID</code> 取值来验证版本一致性的。在进行反序列化时，<code>JVM</code> 会把传来的字节流中的 <code>serialVersionUID</code> 与本地相应实体类的 <code>serialVersionUID</code> 进行比较，如果相同就认为版本是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常，即 <code>InvalidCastException</code>，这样也就无法反序列化了。</p><p> 这种做法可以避免 <code>Java</code> 类改动过大引起的未知问题，例如变量类型变了，或者含义变了，如果 <code>Java</code> 类在传输前后的版本差异过大，就会有未知的问题。而只要指定了 <code>serialVersionUID</code> 的不同值，则直接抛出异常，无法进行反序列化，就会直接强制用户升级匹配的版本，从而避免未知的问题。</p><p>具体的序列化过程是这样的：序列化操作的时候系统会把当前类的 <code>serialVersionUID</code> 写入到序列化文件中，当反序列化的时候系统会去检测文件中的 <code>serialVersionUID</code>，判断它是否与当前类的 <code>serialVersionUID</code> 一致，如果一致就说明反序列化类的版本与当前类的版本是一致的，可以反序列化成功，否则反序列化失败。</p><p><code>serialVersionUID</code> 有两种显示的生成方式：</p><ul><li>第一种是设置一个常量值，例如 1L，比如 <code>private static final long serialVersionUID = 1L</code></li><li>第二种是根据类名、接口名、成员方法及属性等来生成一个 64 位的哈希字段，比如：<code>private static final long serialVersionUID = xxxxL</code>【很长的值，可以利用 <code>IDEA</code> 自动生成】</li></ul><p>当一个类实现了 <code>Serializable</code> 接口，如果没有显式定义 <code>serialVersionUID</code>，<code>IDEA</code> 会提供相应的检查，面对这种情况，我们只需要按照上面的步骤，自动生成 <code>serialVersionUID</code> 即可。</p><p>但是如果我们不顾警告，没有手动指定同时也没有使用 <code>IDEA</code> 自动生成，那这个实现 <code>java.io.Serializable</code> 接口的类会有 <code>serialVersionUID</code> 变量吗？当然有，并且是在编译阶段产生的，<code>Java</code> 序列化机制会根据编译的 <code>class</code> 自动生成一个 <code>serialVersionUID</code> 作为序列化版本比较使用。</p><p>在这种情况下，如果 <code>class</code> 文件【类名、方法名等等】没有发生变化【增加空格、换行、增加注释等等】，就算使用同一个版本的 <code>JDK</code> 编译多次，<code>serialVersionUID</code> 也不会变化的。但是只要变更了类，哪怕加一行注释，<code>serialVersionUID</code> 就会变化，所以这种方式是不被建议的。</p><p>因此，如果我们不希望通过编译来强制划分软件版本，即实现 <code>Serializable</code> 接口的实体类能够兼容先前的版本，就需要显式地定义一个名为 <code>serialVersionUID</code>、类型为 <code>long</code> 的变量，不修改这个变量值的实体类都可以相互进行序列化、反序列化。</p><h2 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a>注意事项 </h2><ul><li> 切记对于实现 <code>Serializable</code> 接口的类，要显式地指定 <code>serialVersionUID</code> 的值 </li><li> 如果没有指定 <code>serialVersionUID</code> 的值，并且类的内容不再变化，也可能由于 <code>JDK</code> 版本的不同，导致编译产生的 <code>serialVersionUID</code> 值不一致，所以这也是一个潜在的坑 </li><li><code>serialVersionUID</code> 的修饰符最好是 <code>private</code>，因为 <code>serialVersionUID</code> 不能被继承，所以建议使用 <code>private</code> 修饰</li></ul><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a> 备注 </h1><p>1、<code>IDEA</code> 官网：<a href="https://www.jetbrains.com/idea" target="_blank" rel="noopener">jetbrains</a> 。</p><p>2、在软件开发中，我们一般不希望使用 <code>serialVersionUID</code> 来控制 <code>Java</code> 类的版本，因为这可能会导致未知的异常，而且存在强制兼容的难点【需要让所有的用户强制升级】，所以可以手动指定 <code>serialVersionUID</code> 的值为一个固定值，例如 -1。</p><p> 当然，有时候希望在大版本发布时【变更比较大，<code>Java</code> 类无法兼容，为了避免未知的异常】，把 <code>serialVersionUID</code> 也做升级，这时候可以强制改变 <code>serialVersionUID</code> 的值。例如做第三方的 <code>SDK</code> 工具包，或者一些通用工具类【例如网络传输、格式转换】，涉及到序列化、反序列化，当需要强制把低版本变得不可用时，就可以改变 <code>serialVersionUID</code> 的值【如果用户恰好混合使用高、低版本，就会影响到业务，可以选择一点不做升级，或者所有依赖一同升级】。</p><p>3、关于 <code>Serializable</code> 的官方文档：<a href="https://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html" target="_blank" rel="noopener">Serializable</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>IDEA,Java,serialVersionUID,Serializable,InvalidCastException,Inspections</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 IDEA 调试程序命令过长</title>
    <url>/2019040201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在日常工作学习中，离不开使用 <code>IDEA</code> 调试 <code>Java</code> 程序，这次突然出现异常：<code>Command line is too long.</code>，本文记录分析过程、解决方案，以下内容开发环境基于 <code>Windows10 x64</code>、<code>JDK v1.8</code>、<code>IDEA ULTIMATE 2017.2</code>。</p><a id="more"></a><h1 id="问题出现解决"><a href="# 问题出现解决" class="headerlink" title="问题出现解决"></a>问题出现解决 </h1><p> 在使用 <code>IDEA</code> 调试 <code>Java</code> 程序的时候，启动主程序主类入口后，发现报错，无法继续运行，但并不是代码错误，提示信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Error running TegDataCli: </span><br><span class="line">Command line is too long. In order to reduce its length classpath file can be used. Would you like to enable classpath file mode for all run configurations of your project?</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191107002909.png" alt="提示信息" title="提示信息"></p><p>可以看到，是 <code>IDEA</code> 遇到问题，无法继续执行程序，这应该是触发了什么限制，命令过长，导致无法继续运行。</p><p>可以开启文件模式来避免这个问题，直接在弹出的提示信息中点击 <code>Enable</code> 即可。</p><p>或者，如果弹出的提示信息消失了，没有 <code>Enable</code> 按钮给你点击，也可以直接在 <code>IDEA</code> 的项目配置文件 <code>.idea/workspace.xml</code> 【此文件在项目的根目录下】中更改配置，把参数值改为 <code>false</code>【如果没有这个参数则默认就是 <code>true</code>，想设置为 <code>false</code> 必须手动添加】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property name=&quot;dynamic.classpath&quot; value=&quot;false&quot; /&gt;</span><br></pre></td></tr></table></figure><p>参考网上类似的问题：<a href="https://stackoverflow.com/questions/6381213/idea-10-5-command-line-is-too-long" target="_blank" rel="noopener">stackoverflow</a> 。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 另外，在 <code>Python</code> 中，也会出现路径长度的限制，可以安装后立马取消这个限制，否则后续会带来麻烦。这个限制长度和上面那个 <code>IDEA</code> 限制 <code>Java</code> 命令的长度有类似含义，可以类比参考，如果读者需要安装使用 <code>Python</code> 可以留意一下。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191107003421.png" alt="Python 路径限制" title="Python 路径限制"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>Python</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 JDK 命令行工具分析内存泄漏或内存溢出问题</title>
    <url>/2019040301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近遇到一个棘手的问题，有业务方在调用存储系统封装的 SDK 取数的过程中，遇到了 OOM 问题，但是数据量很小，只有 12000 条。同时进程启动时申请的内存高达 12g，使用 Xmx、Xms 参数控制，实际指定参数取值为：-Xms12g -Xmx12g。但是如果只看报错日志信息，抛出异常的代码位置指向了 SDK 的内部代码。根据这个现象，我猜测可能是业务方的处理逻辑问题、SDK 内部处理逻辑问题、申请的内存过小问题，这些问题归根结底，要么是内存不够【内存溢出】，要么是内存不当使用【内存泄漏】。所以，我要在 Java 虚拟机参数方面或者业务方代码逻辑方面入手，一步一步测试，找出问题的元凶。本文就记录这一过程，以及适当引申一些关于 JVM 的知识。</p><p>解释说明一下，上述中的 SDK 表示存储系统独立封装的取数、查询接口，它屏蔽了 Elasticsearch 自带的接口，并封装成公共组件，提供给各个业务方使用。各个业务方在使用前，需要申请开通 token 验证码，存储系统会根据业务方的使用量分配合适的资源，业务方在调用时需要传入 token 验证。这样做的好处，一是可以监控所有的业务方的取数、查询情况，收集所有的请求日志，统计一些常用的指标，然后反过来指导存储系统的改进，例如根据业务方的调用情况进行资源分配的伸缩、针对常用的数据类型进行索引优化。二是可以保障整个数据库集群的正常运行，由于屏蔽了 Elasticsearch 自带的接口，业务方不能随意操作超大额的数据量，SDK 会做限制，因此不会产生某些不合理的查询、取数请求，从而不对数据库造成巨大的压力。三是限制了一些不需要的查询、取数方式，在保障业务方基本需求的情况下又可以保障数据库集群的稳定，例如多层聚合、日期聚合等操作，这些操作不合理，而且会对数据库集群造成压力【无论数据量大小都可能会出事】。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 简单描述现象，查看日志，猜测可能的原因。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><h2 id="分析现象"><a href="# 分析现象" class="headerlink" title="分析现象"></a> 分析现象 </h2><p> 一开始没有指定 JVM 参数，因为使用的是 JDK1.7 版本的参数，不会生效，这就导致分配的默认堆取值偏小。</p><p>JVM 参数设置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA=$&#123;JAVA_HOME&#125;/bin/java</span><br><span class="line"># 设置 jvm 的参数 </span><br><span class="line">#HEAP_OPTS=&quot;-Xms12g -Xmx12g&quot;</span><br><span class="line">HEAP_OPTS=&quot;-Xms6g -Xmx6g -Xmn2g&quot;</span><br><span class="line"># JDK8 以后取消了 PermSize</span><br><span class="line">#PERM_OPTS=&quot;-XX:PermSize=1024M -XX:MaxPermSize=2048m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC&quot;</span><br><span class="line">#JDK8 的 MetaspaceSize</span><br><span class="line">PERM_OPTS=&quot;-XX:MetaspaceSize=1024m -XX:MaxMetaspaceSize=2048m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+HeapDumpOnOutOfMemoryError&quot;</span><br></pre></td></tr></table></figure><p>待整理，重试，重现现象，确保问题准确复现。</p><h2 id="掌握内存分析工具"><a href="# 掌握内存分析工具" class="headerlink" title="掌握内存分析工具"></a>掌握内存分析工具 </h2><p> 待整理。各种工具介绍，举例，截图。</p><h2 id="对症下药解决问题"><a href="# 对症下药解决问题" class="headerlink" title="对症下药解决问题"></a>对症下药解决问题 </h2><p> 待整理。减小内存，使用普通的 list。<br>重试，使用命令行工具查看现象，截图。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><h2 id="不同版本的参数不一致"><a href="# 不同版本的参数不一致" class="headerlink" title="不同版本的参数不一致"></a> 不同版本的参数不一致 </h2><p> 主要是针对 JDK 来说的，不同的 JDK 版本的参数会有一些不同，例如以下 2 个虚拟机参数，在 JDK1.8 的环境中是 <strong>-XX:MetaspaceSize=1024m -XX:MaxMetaspaceSize=2048m</strong>，已经不是 <strong>-XX:PermSize=1024M -XX:MaxPermSize=2048m</strong> 了【JDK 1.7 以及以前的版本】，在进程启动的时候查看日志会有警告信息的，提示参数设置无效，会被忽略。</p><h2 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h2><p>占用内存，待整理。</p><h2 id="模拟内存溢出"><a href="# 模拟内存溢出" class="headerlink" title="模拟内存溢出"></a>模拟内存溢出 </h2><p> 待整理。</p><h2 id="进程已杀死问题"><a href="# 进程已杀死问题" class="headerlink" title="进程已杀死问题"></a>进程已杀死问题 </h2><p> 加大内存，机器内存不够分配，进程异常退出，待整理。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>JDK</tag>
        <tag>内存泄漏</tag>
        <tag>内存溢出</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>使用海龟绘图绘制一面五星红旗</title>
    <url>/2019100101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天是国庆节，中国正在举行建国七十周年大阅兵，很多人都在观看，我在家里也看了直播片段。在刷微博的过程中，无意中看到有人在介绍 <strong>海龟绘图 </strong>这个 <code>Python</code> 库，可以非常方便地绘制各种图形，其中有人提到可以绘制出一面五星红旗。</p><p>后来我查了一下，的确是可以，难度不大，只要理解基本的绘制流程即可，于是我尝试了一下，并成功绘制出一面五星红旗。本文记录过程，开发环境基于 <code>Python v3.8</code>、<code>Windows 10 x64</code>。</p><a id="more"></a><h1 id="绘制思路"><a href="# 绘制思路" class="headerlink" title="绘制思路"></a>绘制思路 </h1><p> 绘制思路很简单，不过在这里需要先理解坐标轴、画笔的颜色、背景色、角度等基础概念。</p><p>1、先设置弹框大小，也就是五星红旗的长、宽，单位是像素。</p><p>2、设置背景颜色为红色，设置五角星的线条、填充颜色都为黄色。</p><p>3、绘制中心的 1 个大五角星。</p><p>4、绘制边上的 4 个小五角星。</p><h1 id="绘制代码"><a href="# 绘制代码" class="headerlink" title="绘制代码"></a>绘制代码 </h1><p> 需要注意除了 <code>Python</code> 环境，还需要安装海龟绘图库，我使用的 <code>Python v3.8</code> 已经自带了这个库，如果读者有使用这个版本的 <code>Python</code> 则不需要再单独安装。如果是其它版本的 <code>Python</code>，可能缺失这个库，可以使用 <code>pip</code> 工具安装，参考安装命令：<code>pip install turtle</code>。</p><p>当然，可能还会有其它依赖缺失问题，不属于本文讨论的范围，请读者自行解决。</p><p>提醒读者，这里涉及到的代码已经被我上传至 <code>Github</code>，命名为：<code>__main__.py</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypipython/blob/master/iplaypipython/20191001/__main__.py" target="_blank" rel="noopener">main.py</a> 。</p><p>下面给出代码清单，包含注释，读者很容易看懂：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 从海龟绘图模块中导入全部函数 </span><br><span class="line"># 在 Python v3.8 中已经内置此模块，如果其它 Python 版本没有内置，需要使用 pip 安装 </span><br><span class="line">from turtle import *</span><br><span class="line"></span><br><span class="line"># 开始绘制五星红旗 </span><br><span class="line">def daw_flag ():</span><br><span class="line">    # 设置大小，4 个参数：宽度、高度、起始值 x 轴、起始值 y 轴 </span><br><span class="line">    setup (600, 400, 0, 0)</span><br><span class="line">    # 设置背景为红色 </span><br><span class="line">    bgcolor (&apos;red&apos;)</span><br><span class="line">    # 线条、填充颜色设置为黄色 </span><br><span class="line">    fillcolor (&apos;yellow&apos;)</span><br><span class="line">    color (&apos;yellow&apos;)</span><br><span class="line">    # 画笔运行速度 </span><br><span class="line">    speed (10)</span><br><span class="line"></span><br><span class="line">    # 大五角星绘制 </span><br><span class="line">    draw_star (-280, 100, 0, 150, 144, 0)</span><br><span class="line"></span><br><span class="line">    # 4 个小五角星绘制 </span><br><span class="line">    draw_star (-100, 180, 305, 50, 0, 144)</span><br><span class="line">    draw_star (-50, 110, 30, 50, 144, 0)</span><br><span class="line">    draw_star (-40, 50, 5, 50, 144, 0)</span><br><span class="line">    draw_star (-100, 10, 300, 50, 0, 144)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"># 绘制五角星的方法，根据实际情况传入参数 </span><br><span class="line">def draw_star (gotox_val, gotoy_val, heading_val=0, fd_val=50, rt_val=0, lt_val=0):</span><br><span class="line">    # 开始填充 </span><br><span class="line">    begin_fill ()</span><br><span class="line">    # 提起画笔，此时可以任意移动画笔位置 </span><br><span class="line">    up ()</span><br><span class="line">    # 移动至指定坐标 </span><br><span class="line">    goto (gotox_val, gotoy_val)</span><br><span class="line">    # 设置朝向角度 </span><br><span class="line">    if (0 != heading):</span><br><span class="line">        setheading (heading_val)</span><br><span class="line">    # 放下画笔，此时再移动就开始绘制 </span><br><span class="line">    down ()</span><br><span class="line">    # for 循环，绘制 5 条边 </span><br><span class="line">    for i in range (5):</span><br><span class="line">        # forward，向前移动画笔指定单位，像素 </span><br><span class="line">        fd (fd_val)</span><br><span class="line">        if (0 != rt_val):</span><br><span class="line">            # right，向右旋转指定单位，度数 </span><br><span class="line">            rt (rt_val)</span><br><span class="line">        if (0 != lt_val):</span><br><span class="line">            # left，向左旋转指定单位，度数 </span><br><span class="line">            lt (lt_val)</span><br><span class="line">    # 结束填充 </span><br><span class="line">    end_fill ()</span><br><span class="line"></span><br><span class="line"># 程序入口 </span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    print (&apos; 开始绘制五星红旗 & apos;)</span><br><span class="line">    daw_flag ()</span><br><span class="line">    print (&apos; 结束绘制五星红旗 & apos;)</span><br><span class="line">    exitonclick ()</span><br><span class="line">    # input (&apos; 暂停，等待输入（输入任意内容按回车键可退出）：&apos;)</span><br></pre></td></tr></table></figure><p>可以看到，代码中有 3 个函数：主函数 <code>__main__</code>、绘制五星红旗函数 <code>draw_flag</code>、绘制五角星函数 <code>draw_star</code>，这 3 个函数存在调用关系，共同绘制出一面五星红旗。</p><p>我这里故意把绘制速度设置小一点，读者在运行过程中可以清楚地看到绘制的过程，点的移动、线的绘制可以看得很清楚。</p><p>运行结果。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191031005634.png" alt="运行结果" title="运行结果"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>1、<code>Python</code> 官方网站参考：<a href="https://www.python.org" target="_blank" rel="noopener">Python</a> 。</p><p>2、在 <code>Windows</code> 平台安装 <code>Python</code> 需要注意版本的选择，是 32 位还是 64 位要搞清楚，不然后续会引发一系列麻烦，哪怕卸载重装也会有麻烦。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Turtle</tag>
        <tag>national</tag>
      </tags>
  </entry>
  <entry>
    <title>依赖包缺失导致 Spark 任务无法启动</title>
    <url>/2018100701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>本文讲述使用 Spark 的过程中遇到的错误：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">class "javax.servlet.FilterRegistration"'s signer information does not match signer information of other classes in the same package</span><br></pre></td></tr></table></figure><p>最终通过查找分析 Maven 依赖解决问题。</p><a id="more"></a><h1 id="遇到问题"><a href="# 遇到问题" class="headerlink" title="遇到问题"></a>遇到问题 </h1><p> 由于最近的 elasticsearch 集群升级版本，到了 v5.6.8 版本，所用的功能为了兼容处理高版本的 elasticsearch 集群，需要升级相关依赖包，结果就遇到了问题。</p><p>使用 es-hadoop 包（v5.6.8）处理 elasticsearch （v5.6.8）里面的数据，具体点就是通过 es-spark 直接读取 elasticsearch 里面的数据，生成 RDD，然后简单处理，直接写入 HDFS 里面。</p><p>编译、打包的过程正常，运行代码的时候，抛出异常：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">class "javax.servlet.FilterRegistration"'s signer information does not match signer information of other classes in the same package</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxyhhwukskj21g20aumyl.jpg" alt="报错" title="报错"></p><p>一看到这种错误，就知道肯定是 Maven 依赖出现了问题，要么是版本冲突，要么是包缺失，但是从这个错误信息里面来看，无法区分具体是哪一种，因为没有报 ClassNotFound 之类的错误。</p><h1 id="解决方法"><a href="# 解决方法" class="headerlink" title="解决方法"></a>解决方法 </h1><p> 现象已经看到了，问题也找到了，那么第一步就是直接搜索 Maven 项目的依赖，看看有没有 FilterRegistration 这个类，我的 IDEA 直接使用 Ctrl + Shift + T 快捷键，搜索 FilterRegistration，发现有这个类，但是包名对不上，注意包名是：javax.servlet。</p><p>现在就可以断定，是包缺失，通过搜索引擎查找文档，需要引入 javax.servlet-api 相关的包， pom.xml 文件的具体依赖信息是：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>javax.servlet<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>javax.servlet-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>当然，版本信息根据实际的场景需要进行选择，我这里选择 4.0.1 版本。</p><p>需要注意的是，有另外一个包，它的 artifactId 是 servlet-api，可能你会因为没看清而配置了这个依赖包，导致还是包缺失，所以一定要看清楚。</p><p>我这里遇到的问题比较简单，只是包缺失而已，如果遇到的是包版本冲突，需要移除不需要的版本，只保留一个依赖包即可，此时可以借助 Maven 的 dependency 构建来进行分析查找：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mvn dependency:tree</span><br></pre></td></tr></table></figure><p>这个命令会输出项目的所有依赖树，非常清晰，如果内容太多，可以使用：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mvn dependency:tree &gt; ./tree.txt</span><br></pre></td></tr></table></figure><p>重定向到文本文件中，再进行搜索查找。</p><h1 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h1><p>1、还遇到一种情况，在正式环境运行正常【没有单独配置这个依赖，使用的是别的依赖包里面的同名类，org.eclipse.jetty.orbit:javax.servlet】，但是在本机跑，创建 SparkContext 的时候就会报错，无法创建成功。其实还是因为包缺失，确保要使用 javax.servlet-api 这个依赖，其它的都不好使。</p><p>2、在本机连接测试环境的 yarn，创建 SparkContext 的时候无法指定用户名，默认总是当前系统的用户名，导致创建 SparkContext 失败，伪装用户无效，只有打 jar 包执行前使用命令切换用户名：export HADOOP_USER_NAME=xx，而在代码中设置 System.setProperty (“user.name”, “xx”)、System.setProperty (“HADOOP_USER_NAME”, “xx”) 是无效的（这个问题会有一篇文章专门分析，需要查看源代码）；</p><p>3、针对 2 的情况，简单通过 local 模式解决，暂时不使用 yarn-client 模式；</p><p>4、针对 2 的情况，还有一种简单的方法，那就是直接设置 IDEA 的环境变量参数（不是设置操作系统的环境变量，我试了无效），如下图（和设置运行参数类似）；<br> 设置 IEDA 的环境变量：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j8oe0tm5j20li024q2w.jpg" alt="设置 IEDA 的环境变量" title="设置 IEDA 的环境变量"></p><p>5、此外，还有一种情况，当需要操作 HDFS 的时候，发现无论怎么设置环境变量都不可以（配置文件配置、代码设置），总是读取的系统默认用户，就和 2 中讲的一致，其实如果只是单纯地操作 HDFS，还可以在创建文件流的时候指定用户名（不过这种方法要先从 conf 中获取 uri）；</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String uri = conf.get (<span class="string">"fs.defaultFS"</span>);</span><br><span class="line">FileSystem fs = FileSystem.get (<span class="keyword">new</span> URI (uri), CONF, <span class="string">"zeus"</span>);</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Maven</tag>
        <tag>依赖问题</tag>
        <tag>FilterRegistration</tag>
      </tags>
  </entry>
  <entry>
    <title>写入 Elasticsearch 异常：413 Request Entity Too Large</title>
    <url>/2019122901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在一个非常简单的业务场景中，偶尔出现异常：<code>413 Request Entity Too Large</code>，业务场景是写入数据到 <code>Elasticsearch</code> 中，异常日志中还有 <code>Nginx</code> 字样。</p><p>本文记录排查过程，本文环境基于 <code>Elasticsearch v5.6.8</code>，使用的写入客户端是 <code>elasticsearch-rest-high-level-client-5.6.8.jar</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在后台日志中，发现异常信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/12/29 23:06:41 ERROR ESBulkProcessor: bulk [2307 : 1577632001467] 1000 request - 0 response - Unable to parse response body</span><br><span class="line">ElasticsearchStatusException [Unable to parse response body]; nested: ResponseException [POST http://your_ip_address:9200/_bulk?timeout=1m: HTTP/1.1 413 Request Entity Too Large</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;413 Request Entity Too Large&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;413 Request Entity Too Large&lt;/h1&gt;&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx/1.16.1&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">];</span><br><span class="line">	at org.elasticsearch.client.RestHighLevelClient.parseResponseException (RestHighLevelClient.java:506)</span><br><span class="line">	at org.elasticsearch.client.RestHighLevelClient$1.onFailure (RestHighLevelClient.java:477)</span><br><span class="line">	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onDefinitiveFailure (RestClient.java:605)</span><br><span class="line">	at org.elasticsearch.client.RestClient$1.completed (RestClient.java:362)</span><br><span class="line">	at org.elasticsearch.client.RestClient$1.completed (RestClient.java:343)</span><br><span class="line">	at org.apache.http.concurrent.BasicFuture.completed (BasicFuture.java:115)</span><br><span class="line">	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted (DefaultClientExchangeHandlerImpl.java:173)</span><br><span class="line">	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse (HttpAsyncRequestExecutor.java:355)</span><br><span class="line">	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady (HttpAsyncRequestExecutor.java:242)</span><br><span class="line">	at org.apache.http.impl.nio.client.LoggingAsyncRequestExecutor.inputReady (LoggingAsyncRequestExecutor.java:87)</span><br><span class="line">	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput (DefaultNHttpClientConnection.java:264)</span><br><span class="line">	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady (InternalIODispatch.java:73)</span><br><span class="line">	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady (InternalIODispatch.java:37)</span><br><span class="line">	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady (AbstractIODispatch.java:113)</span><br><span class="line">	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable (BaseIOReactor.java:159)</span><br><span class="line">	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent (AbstractIOReactor.java:338)</span><br><span class="line">	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents (AbstractIOReactor.java:316)</span><br><span class="line">	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute (AbstractIOReactor.java:277)</span><br><span class="line">	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute (BaseIOReactor.java:105)</span><br><span class="line">	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run (AbstractMultiworkerIOReactor.java:584)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">	Suppressed: java.lang.IllegalStateException: Unsupported Content-Type: text/html</span><br><span class="line">		at org.elasticsearch.client.RestHighLevelClient.parseEntity (RestHighLevelClient.java:523)</span><br><span class="line">		at org.elasticsearch.client.RestHighLevelClient.parseResponseException (RestHighLevelClient.java:502)</span><br><span class="line">		... 20 more</span><br><span class="line">Caused by: org.elasticsearch.client.ResponseException: POST http://your_ip_address:9200/_bulk?timeout=1m: HTTP/1.1 413 Request Entity Too Large</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;413 Request Entity Too Large&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;413 Request Entity Too Large&lt;/h1&gt;&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx/1.16.1&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"></span><br><span class="line">	at org.elasticsearch.client.RestClient$1.completed (RestClient.java:354)</span><br><span class="line">	... 17 more</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191230002704.jpg" alt="异常信息" title="异常信息"></p><p>留意重点内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;413 Request Entity Too Large&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;413 Request Entity Too Large&lt;/h1&gt;&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx/1.16.1&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>看起来是发送的 <code>HTTP</code> 请求的请求体【<code>body</code>】过大，超过了服务端 <code>Nginx</code> 的配置，导致返回异常。</p><p>这个请求体过大，本质上还是将要写入 <code>Elasticsearch</code> 的文档过大，可见是某个字段的取值过大【这种情况一般都是异常数据导致的，例如采集系统把整个网页的内容全部抓回来作为正文，或者把网站反扒的干扰长文本全部抓回来作为正文】。</p><p>但是我又不禁想，这个配置参数名是什么呢？限制的最大字节数是多少呢？</p><h1 id="问题排查解决"><a href="# 问题排查解决" class="headerlink" title="问题排查解决"></a>问题排查解决 </h1><p> 在 <code>Elasticsearch</code> 官网查看相关配置项，发现有一个参数：<code>http.max_content_length</code>，表示一个 <code>HTTP</code> 请求的内容大小上限，默认为 <code>100MB</code>【对于 <code>v5.6</code> 来说】。</p><p>官网地址：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/modules-http.html" target="_blank" rel="noopener">elasticsearch 关于 HTTP 的配置 </a> ，以下为参数说明：</p><blockquote><p>The max content of an HTTP request. Defaults to 100mb. If set to greater than Integer.MAX_VALUE, it will be reset to 100mb.</p></blockquote><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191230005435.jpg" alt="HTTP 相关配置" title="HTTP 相关配置"></p><p> 这个参数是配置在 <code>elasticsearch.yml</code> 配置文件中的，我查看了我使用的 <code>Elasticsearch</code> 集群中对应的配置，没有发现参数的设置，说明使用了默认配置。</p><p>其实，<code>100MB</code> 对于文本来说很大了，一般正常的文本也不过只有几 <code>KB</code> 大小，对于长一点的文本来说，例如几万个字符，也就是几百 <code>KB</code>。由于写入 <code>Elasticsearch</code> 是批量的，1000 条数据一批，如果一批里面包含的全部是长文本，还是有可能超过 <code>100MB</code> 的，可见调整 <code>HTTP</code> 请求大小的上限是有必要的，或者是降低批次的数据量【会影响写入性能】。</p><p>此外，关于 <code>HTTP</code> 的另外两个参数也值得关注：<code>http.max_initial_line_length</code>、<code>http.max_header_size</code>。</p><p>前者表示 <code>HTTP</code> 请求链接的长度，默认为 <code>4KB</code>：</p><blockquote><p>The max length of an HTTP URL. Defaults to 4kB</p></blockquote><p>后者表示 <code>HTTP</code> 请求头的大小上限，默认为 <code>8KB</code>：</p><blockquote><p>The max size of allowed headers. Defaults to 8kB</p></blockquote><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>HTTP</tag>
        <tag>RestHighLevelClient</tag>
      </tags>
  </entry>
  <entry>
    <title>参加 Elastic 社区第三次线下活动广州站</title>
    <url>/2019033001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在 2019 年 3 月 30 日，我去参加了 Elastic 社区第三次线下活动广州站的分享会，活动简介：<a href="https://meetup.elasticsearch.cn/event/guangzhou/1001.html" target="_blank" rel="noopener">Elastic 社区第三次线下活动广州站 </a> 。看到各位行业顶尖分享者的分享，不能说受益匪浅，至少给我打开了一些思路，拓展了我的知识面，同时我也学到了一些知识，既包括技术方面的，也包括处事方面的。这篇博文就简单记录一下这个过程。</p><a id="more"></a><h1 id="出发"><a href="# 出发" class="headerlink" title="出发"></a> 出发 </h1><p> 先看一下地图指引 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf2ls1z3j214q0u0djy.jpg" alt="地图指引" title="地图指引"></p><p> 到达公交站，上冲南站，天气不错 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf2vj7mlj229s29sb2c.jpg" alt="上冲南站" title="上冲南站"></p><p> 走路路过特斯拉服务站，听说最近交付的特斯拉电动车有很多问题 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf33253ij229s29shdt.jpg" alt="路过特斯拉服务站" title="路过特斯拉服务站"></p><h1 id="到达"><a href="# 到达" class="headerlink" title="到达"></a> 到达 </h1><p> 到达的比较早，因为要帮忙安排桌子凳子，一切准备就绪后，一起吃了个午饭。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf3jejrej229s29s1ky.jpg" alt="吃了个午饭" title="吃了个午饭"></p><p>13:30 开始签到，签到现场 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf3of8qlj229s29sb2a.jpg" alt="签到现场" title="签到现场"></p><p> 我充当了一会儿签到员，坐着的那个是我 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf3sy1ylj20m80cimyt.jpg" alt="坐着的那个是我" title="坐着的那个是我"></p><p> 各种各样的 Elasticsearch 贴纸 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf3ydx4cj229s29s4qq.jpg" alt="各种各样的 Elasticsearch 贴纸" title="各种各样的 Elasticsearch 贴纸"></p><p> 这是一种比较特殊的 Elasticsearch 贴纸 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf427iykj20qo1hcq74.jpg" alt="特殊的 Elasticsearch 贴纸" title="特殊的 Elasticsearch 贴纸"></p><h1 id="静听分享"><a href="# 静听分享" class="headerlink" title="静听分享"></a> 静听分享 </h1><p> 先简单看一下这个分享会的大概流程与分享内容 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf471eb8j21830o9gnw.jpg" alt="分享内容" title="分享内容"></p><h2 id="分享一"><a href="# 分享一" class="headerlink" title="分享一"></a> 分享一 </h2><p>Elasticsearch 在数说全量库的应用实践</p><p> 现场场景一 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf5ceaqtj21kw0w0as5.jpg" alt="场景一" title="场景一"></p><p> 现场场景二 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf58jqs2j20zk0k0ta7.jpg" alt="场景二" title="场景二"></p><p> 现场场景三 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf54mc76j21hc0u0q84.jpg" alt="场景三" title="场景三"></p><h2 id="分享二"><a href="# 分享二" class="headerlink" title="分享二"></a> 分享二 </h2><p>Elasticsearch 在慧算账技术运营中的应用</p><p> 现场场景 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf4yz5k5j20m80ciac7.jpg" alt="现场" title="现场"></p><h2 id="分享三"><a href="# 分享三" class="headerlink" title="分享三"></a> 分享三 </h2><p>Elasticsearch 在大数据可视化分析中的应用</p><p> 现场场景 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf4twfafj20m80cit9r.jpg" alt="现场" title="现场"></p><h2 id="分享四"><a href="# 分享四" class="headerlink" title="分享四"></a> 分享四 </h2><p> 打造云原生的 Elasticsearch 服务 </p><p> 现场场景 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf4p52q6j20m80cit9u.jpg" alt="现场" title="现场"></p><h2 id="分享五"><a href="# 分享五" class="headerlink" title="分享五"></a> 分享五 </h2><p>Elasticsearch 集群在雷达大数据平台的演进</p><p> 现场场景 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf4kjqsjj20m80ciq4f.jpg" alt="现场" title="现场"></p><h2 id="分享者合影留念"><a href="# 分享者合影留念" class="headerlink" title="分享者合影留念"></a> 分享者合影留念 </h2><p> 认真的观众 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf4c5u0oj21400u00x8.jpg" alt="认真的观众" title="认真的观众"></p><p> 分享者合影留念 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tf4ftxkrj20m80cizlx.jpg" alt="分享者合影留念" title="分享者合影留念"></p><h1 id="我的思考以及学到的东西"><a href="# 我的思考以及学到的东西" class="headerlink" title="我的思考以及学到的东西"></a> 我的思考以及学到的东西 </h1><p>0、虽然有一些分享听不懂，例如腾讯云的 Elasticsearch 云服务，做了什么优化、达到了什么效果，或者是数说雷达的架构演进，这些目前对于我来说都太不切实际，因为还没接触到这么高深的知识，平时也使用不到，所以听起来云里雾里。但是，能从中提取 1-2 个重要知识点也是有用的，例如腾讯云的索引碎片化，导致读写速度严重下降，这与我在工作当中遇到的问题一模一样。再例如数说雷达演进过程中遇到的坑，某个字段没有做 doc_values，导致不支持 aggregation 查询，这与我很久之前遇到的问题一模一样，此时又加深了我的认知。</p><p>1、多版本 Elasticsearch 的兼容解决办法，需要设置拦截器，把请求的不兼容参数部分替换掉，可以使用 SpringBoot 整合，需要注意已知版本的种类。</p><p>2、针对 long 类型字段的聚合【即 aggregation】请求根据自己的业务场景，如果判断为实际上没有必要【例如只是对年份、月份、日做聚合，并不考虑时区、毫秒时间戳的问题】，可以换一种思路，转化为字符串存储，针对字符串做聚合操作效率就高多了。</p><p>3、在现场提问时，有的人是带着自己业务实际遇到的问题来提问探讨的，提问时描述问题已经消耗了将近 10 分钟。接下来如果真的探讨起来，估计没有半个小时一个小时搞不定，这显然是在浪费大家的时间。所以分享者也及时打断了提问，并留下联系方式，分享会后线下接着再讨论。这种做法很得体，虽然不能在现场解答【为了节约大家的时间】，但是会后讨论也是一样，有时候根据实际情况就是需要这样的取舍。</p><p>4、在 Elasticsearch 中，字段类型是可以节约存储空间与请求耗时的，例如 integer、long、short 的合理使用，但是切记存储的目的最终都是为了使用。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a> 备注 </h1><p> 如果需要查看分享者的 PPT 文档，可以在 Elastic 社区下载：<a href="https://elasticsearch.cn/slides" target="_blank" rel="noopener">https://elasticsearch.cn/slides</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>游玩</category>
      </categories>
      <tags>
        <tag>Elastic</tag>
        <tag>线下活动</tag>
        <tag>广州</tag>
      </tags>
  </entry>
  <entry>
    <title>可乐鸡翅做法总结</title>
    <url>/2018122501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>可乐鸡翅，是一道做法很简单的菜，很巧妙地将饮料和鸡翅结合在一起，做出来的可乐鸡翅既好看又好吃。本文简单介绍可乐鸡翅的做法总结，这是一种偏甜的做法。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p>3 人份的材料（8-10 个鸡翅），吃多了也不好吃</p><p>1、鸡翅 9 个，最好是鸡中翅（一般 2-3 元一个）；</p><p>2、可乐 1 罐（330 毫升的，如果鸡翅多的话，适当增加可乐）；</p><p> 选择百事可乐 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rg4ht5bj229s29shbr.jpg" alt="百事可乐一罐" title="百事可乐一罐"></p><p>3、姜片、八角、桂皮（也可以不用）；</p><p>4、料酒、生抽、老抽、食用盐；</p><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><p>1、在鸡翅背面划几刀（正面保留完整为了摆盘好看而已），更容易入味，用食用盐、料酒、老抽腌制 10 分钟，备用；</p><p> 划刀腌制 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rh3a3lzj229s29s7wi.jpg" alt="划刀腌制" title="划刀腌制"></p><p>2、锅中加水，放入姜片、少量料酒，鸡翅也下锅（冷水下锅），煮开即可，不用煮透（煮透鸡翅就老了），看到浮沫很多就可以捞出，用温水清洗一下，晾干（晾不干就用厨房纸擦一下，防止煎的时候溅油），此时如果发现有不干净的鸡毛可以拔干净；</p><p> 鸡翅冷水下锅 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rhqcl9lj229s29skjl.jpg" alt="鸡翅冷水下锅" title="鸡翅冷水下锅"></p><p> 鸡翅焯水出浮沫 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0riaxvy9j229s29shdu.jpg" alt="鸡翅焯水出浮沫" title="鸡翅焯水出浮沫"></p><p>3、锅中放入少量油（不放也行，鸡翅会自己出油的），放入姜片，开始煎鸡翅，开小火，煎至两面金黄即可，不可以煎太久，否则鸡翅老了不好吃；</p><p> 小火煎 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0riy1se2j22ao328e81.jpg" alt="小火煎" title="小火煎"></p><p>4、加一罐可乐，适量料酒、生抽、老抽，适量桂皮、八角，开始小火炖煮，炖至可乐还有一小碗水的量的时候，尝尝味道，适量加盐；</p><p> 加入可乐、配料 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rjpt2asj22ao328b29.jpg" alt="加入可乐" title="加入可乐"></p><p> 小火炖煮 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rlapea0j229s29su0y.jpg" alt="小火炖煮" title="小火炖煮"></p><p>5、炖至汤浓收汁，基本所有的汁都覆盖在鸡翅上面了，鸡翅也有味道，装盘，正面朝上，把锅中剩余的汤汁淋入鸡翅中（大概 1-2 饭勺的量），再撒上少许白芝麻，既好看又好吃。</p><p> 可以收汁 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rlzom65j229s29su0y.jpg" alt="可以收汁" title="可以收汁"></p><p> 收汁之前补充食用盐、老抽 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rm8gegzj229s29sqv6.jpg" alt="收汁之前补充食用盐、老抽" title="收汁之前补充食用盐、老抽"></p><p> 收汁完成 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rm3rj6xj229s29se82.jpg" alt="收汁完成" title="收汁完成"></p><p> 装盘 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz0rmcq1luj229s29s7wi.jpg" alt="装盘" title="装盘"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、不要再放糖了，一罐可乐里面含糖大概 35 克；</p><p>2、如果放了那种本身是咸味的生抽，也不用放盐了，或者少量放一点点（放盐之前先尝尝汤水的味道，不容易出差错）；</p><p>3、焯水的时候冷水下锅，防止肉老了，并且放一点姜片和料酒，去腥味；</p><p>4、鸡翅焯水后晾干很有必要，否则下一步骤煎的时候水和热油混合一起会溅出油的；</p><p>5、甜味和咸味的控制依据个人口味调整，此外，可口可乐比百事可乐更甜，即含糖量更高。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>可乐鸡翅</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Elasticsearch 中指定查询返回的字段</title>
    <url>/2020030201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在 <code>Elasticsearch</code> 中，有参数可以指定查询结果返回的字段，这样可以使查询结果更简约，看起来更清晰。如果是大批量 <code>scroll</code> 取数，还可以减少数据在网络中的传输，从而降低网络 <code>IO</code>。本文使用简单的查询来举例，演示环境基于 <code>Elasticsearch v5.6.8</code>。</p><a id="more"></a><h1 id="演示"><a href="# 演示" class="headerlink" title="演示"></a>演示 </h1><p> 我的演示环境里面有一个索引 <code>my-index-user</code>，里面是用户的信息，字段有姓名、年龄、性别、城市等。</p><p>现在我根据用户 <code>id</code> 查询数据，使用 <code>_source</code> 参数指定返回 4 个字段：<code>item_id</code>、<code>gender</code>、<code>city</code>、<code>birthday</code>。</p><p>查询条件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-user/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;terms&quot;: &#123;</span><br><span class="line">      &quot;item_id&quot;: [</span><br><span class="line">        &quot;63639783663&quot;,</span><br><span class="line">        &quot;59956667929&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_source&quot;: [</span><br><span class="line">    &quot;item_id&quot;,</span><br><span class="line">    &quot;gender&quot;,</span><br><span class="line">    &quot;city&quot;,</span><br><span class="line">    &quot;birthday&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 2,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 3,</span><br><span class="line">    &quot;successful&quot;: 3,</span><br><span class="line">    &quot;skipped&quot;: 0,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 2,</span><br><span class="line">    &quot;max_score&quot;: 7.937136,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;user&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;23c659fde1a2c02b3618eaa92fcd7106&quot;,</span><br><span class="line">        &quot;_score&quot;: 7.937136,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;birthday&quot;: &quot;1994-01-01&quot;,</span><br><span class="line">          &quot;city&quot;: &quot; 成都 & quot;,</span><br><span class="line">          &quot;item_id&quot;: &quot;63639783663&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;user&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;75e3db1f4ab288d38de3ab80bfba8ecd&quot;,</span><br><span class="line">        &quot;_score&quot;: 7.937136,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;birthday&quot;: &quot;1982-01-01&quot;,</span><br><span class="line">          &quot;gender&quot;: &quot;1&quot;,</span><br><span class="line">          &quot;city&quot;: &quot; 渭南 & quot;,</span><br><span class="line">          &quot;item_id&quot;: &quot;59956667929&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200302205417.png" alt="查询结果指定字段" title="查询结果指定字段"></p><p>可以看到，查到的数据只返回了 4 个字段。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 除了 <code>_source</code> 参数外，还有其它的参数也可以达到同样的效果，在 <code>v2.4</code> 以及之前的版本，可以使用 <code>fields</code> 参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-user/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;terms&quot;: &#123;</span><br><span class="line">      &quot;item_id&quot;: [</span><br><span class="line">        &quot;63639783663&quot;,</span><br><span class="line">        &quot;59956667929&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;fields&quot;: [</span><br><span class="line">    &quot;user_name&quot;,</span><br><span class="line">    &quot;item_id&quot;,</span><br><span class="line">    &quot;gender&quot;,</span><br><span class="line">    &quot;city&quot;,</span><br><span class="line">    &quot;birthday&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下图是我找了一个低版本 <code>Elasticsearch</code> 集群测试了一下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200302205758.png" alt="fields 参数过滤字段" title="fields 参数过滤字段"></p><p>不过在 <code>v5.x</code> 以及之后的版本不再支持这个参数：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200302205500.png" alt="不支持 fields 参数" title="不支持 fields 参数"></p><p>异常信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The field [fields] is no longer supported, please use [stored_fields] to retrieve stored fields or _source filtering if the field is not stored</span><br></pre></td></tr></table></figure><p>注意这里提及的 <code>stored_fields</code> 参数用处有点鸡肋，还是需要 <code>_source</code> 参数配合。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>fields</tag>
        <tag>source</tag>
        <tag>stored_fields</tag>
      </tags>
  </entry>
  <entry>
    <title>在 IDEA 中管理 Java 项目的文件夹类型</title>
    <url>/2018090101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天在使用 <code>IntelliJ IDEA</code> 时，发现在 <code>Maven</code> 项目中无法创建 <code>Java</code> 类【在 <code>test</code> 目录创建测试用例】，哪怕手动创建了一个 <code>Java</code> 类文件，<code>IDEA</code> 也无法识别，说明项目的设置有问题。后来检查了一下，发现文件夹类型没有设置为项目的 <strong>测试文件夹 </strong>。</p><p>开发环境基于 <code>Windows 10</code>、<code>IntelliJ IDEA 2017.2</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在一个 <code>Maven</code> 项目中，新建测试用例【在 <code>test</code> 文件夹下面】，结果发现 <code>IDEA</code> 的右键 <code>New</code> 列表中没有对应的选项。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200308112906.png" alt="列表无法选择类文件" title="列表无法选择类文件"></p><p>即找不到 <code>Java Class</code>、<code>Kotlin File/Class</code> 等等选择，一开始还以为是 <code>IDEA</code> 的设置哪里有问题，怀疑被隐藏了，但是找了设置项，并没有发现与此有关的问题。</p><p>同时，在 <code>src main java</code> 里面可以正常创建类文件，这就可以怀疑是 <code>Maven</code> 项目的设置有问题。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200308112934.png" alt="列表可以选择类文件" title="列表可以选择类文件"></p><p>注意到 <code>test</code> 文件夹的颜色很普通，这个颜色是 <code>IDEA</code> 用来标记文件夹的类型的，说明这个文件夹不受 <code>IDEA</code> 管理，它只是一个普通的系统目录而已，看来需要找一下在哪里可以设置这个文件夹类型。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 我们打开 <code>Maven</code> 项目的 <code>Project Structure</code>，依次找到 <code>Modules</code>、<code>Sources</code>，可以看到这里对文件夹的类型都做了设置，例如 <code>Sources</code>、<code>Tests</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200308113028.png" alt="打开模块管理" title="打开模块管理"></p><p>它们分别表示不同的作用，下面简单描述一下：</p><ul><li><code>Sources</code>，源码文件夹，里面存放项目的源码，会被编译、打包 </li><li><code>Tests</code>，测试文件夹，里面存放我们写的测试类，编译、打包时可以被移除</li><li><code>Resources</code>，资源文件夹，里面存放配置文件，例如 <code>xml</code>、<code>yaml</code>、<code>json</code> 等等，编译、打包时会被放进 <code>jar</code> 包里面特有的目录</li><li><code>Test Resources</code>，测试资源文件夹，里面存放测试时的配置文件，编译、打包时可以被移除</li><li><code>Excluded</code>，排除文件夹，里面存放临时文件，例如本地编译的 <code>class</code> 文件，本地打包的 <code>jar</code> 文件，这些只是自己测试时临时使用，不算是项目的一部分，编译、打包时会被移除</li></ul><p> 同时，读者可以注意到，这些不同类型的文件夹有不同的颜色，就是为了标记，让用户可以快速分辨。</p><p>好，回到我这里的问题，没法新建类文件就是因为 <code>test</code> 文件夹没有被设置为 <strong>测试文件夹 </strong>，在上面的截图中，可以选中文件夹后直接设置，接着就可以新建类文件了。</p><p>同时，还有一种快捷的设置方法，在主界面中，选择文件夹，右键后会有一个 <code>Mark Directory as</code> 选项【选项中的标识都以 <code>Root</code> 作为结尾】，这就是用来设置文件夹的属性的，直接选择即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200308113115.png" alt="鼠标右键快捷设置" title="鼠标右键快捷设置"></p><p>好，至此我的问题解决，又可以愉快地去写代码了。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>0、注意，如果一个文件夹没有被设置为 <code>Sources Root</code>，它里面的子文件夹【<code>Java</code> 里面的包概念】也是不能被识别为源码目录的，也就是我们无法在里面创建类文件【<code>Java Class</code>、<code>Kotlin File/Class</code>】，即右键 <code>New</code> 里面是没有类文件的选项的，只有普通的文件选项。而且，哪怕我们手动创建一个 <code>Java</code> 类文件放进去，<code>IDEA</code> 也不会识别管理。</p><p>1、在创建 <code>Maven</code> 项目时，初始化之后默认会生成各种类型的文件夹，并且会生成一个默认的类文件，如果一开始觉得不需要文件夹而删除，以后新建时记得要把文件夹的属性更改一下，改为对应的类型，否则 <code>IDEA</code> 无法做对应的类管理。</p><p>2、<code>IDEA</code> 官网：<a href="https://www.jetbrains.com/idea" target="_blank" rel="noopener">jetbrains</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>IDEA,Java,Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Windows 平台遇到 Hadoop 异常：UnsatisfiedLinkError</title>
    <url>/2017052101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在 <code>Windows</code> 平台运行 <code>Spark</code> 程序，<code>Spark</code> 任务的逻辑很简单，从 <code>HBase</code> 中获取数据，然后通过中间 <code>Spark</code> 算子做一些合并、过滤、去重等操作，最后写入 <code>HDFS</code>。</p><p>这个功能在真实线上环境一直运行稳定，由于业务逻辑需要做小部分修改升级，我修改完成后自己在电脑上测试【开发环境】，抛出异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray (II [BI [BIILjava/lang/String;JZ) V</span><br></pre></td></tr></table></figure><p>并且数据写入 <code>HDFS</code> 失败，本文记录排查过程与解决方案。</p><p>本文开发环境基于 <code>Windows 10</code>、<code>HBase v1.1.2</code>、<code>Hadoop v2.7.1</code>、<code>Spark v1.6.2</code> 。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在自己的电脑上使用 <code>IDEA</code> 调试 <code>Spark</code> 程序【开发环境】，使用 <code>local</code> 模式，从 <code>HBase</code> 中读取数据，处理后写入 <code>HDFS</code> 中，以前是运行正常的，但是今天就出现异常，异常信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">20:00:34.116 [Executor task launch worker-0] ERROR org.apache.spark.executor.Executor - Exception in task 0.0 in stage 4.0 (TID 3)</span><br><span class="line">java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray (II [BI [BIILjava/lang/String;JZ) V</span><br><span class="line">	at org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray (Native Method)</span><br><span class="line">	at org.apache.hadoop.util.NativeCrc32.calculateChunkedSumsByteArray (NativeCrc32.java:86)</span><br><span class="line">	at org.apache.hadoop.util.DataChecksum.calculateChunkedSums (DataChecksum.java:430)</span><br><span class="line">	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks (FSOutputSummer.java:202)</span><br><span class="line">	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer (FSOutputSummer.java:163)</span><br><span class="line">	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer (FSOutputSummer.java:144)</span><br><span class="line">	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl (DFSOutputStream.java:2318)</span><br><span class="line">	at org.apache.hadoop.hdfs.DFSOutputStream.close (DFSOutputStream.java:2300)</span><br><span class="line">	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close (FSDataOutputStream.java:72)</span><br><span class="line">	at org.apache.hadoop.fs.FSDataOutputStream.close (FSDataOutputStream.java:106)</span><br><span class="line">	at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.close (TextOutputFormat.java:108)</span><br><span class="line">	at org.apache.spark.SparkHadoopWriter.close (SparkHadoopWriter.scala:103)</span><br><span class="line">	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$8.apply$mcV$sp (PairRDDFunctions.scala:1203)</span><br><span class="line">	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks (Utils.scala:1295)</span><br><span class="line">	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply (PairRDDFunctions.scala:1203)</span><br><span class="line">	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply (PairRDDFunctions.scala:1183)</span><br><span class="line">	at org.apache.spark.scheduler.ResultTask.runTask (ResultTask.scala:66)</span><br><span class="line">	at org.apache.spark.scheduler.Task.run (Task.scala:89)</span><br><span class="line">	at org.apache.spark.executor.Executor$TaskRunner.run (Executor.scala:227)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">20:00:34.128 [Executor task launch worker-0] ERROR o.a.s.u.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread [Executor task launch worker-0,5,main]</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20191015212035.png" alt="Spark 错误日志" title="Spark 错误日志"></p><p>注意这个异常信息里面的类描述信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray (II [BI [BIILjava/lang/String;JZ) V</span><br></pre></td></tr></table></figure><p>除了完整的包名、类名外，可以看到还有一个奇怪的信息，即末尾的：<br><code>(II [BI [BIILjava/lang/String;JZ) V</code>，它其实是 <strong>JNI 字段描述符 </strong>，用简单的符号来表示 <code>Java</code> 的数据类型。</p><p>其中，括号里面的是参数类型，括号外面的 <code>V</code> 表示方法的返回类型是 <code>void</code>，<code>L</code> 表示 <code>Object</code> 类型，<code>[</code> 表示数组类型，更多内容请参考本文末尾的备注，这里不再赘述。</p><p>我查了 <code>Unsatisfied</code> 的含义，表示不满意，我想这里的意思应该是不匹配，也就是这个类有问题，至于是什么问题目前还不清楚。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 通过查询资料，找到这个问题的原因是本机的 <code>Hadoop</code> 版本不对【与服务器上比较、与项目的 <code>Hadoop</code> 依赖版本比较】，或者是本机开发环境缺失正确的 <code>hadoop.dll</code>、<code>winutils.exe</code> 文件。</p><p>我先查看了本机的 <code>Hadoop</code> 版本，并没有问题，并且 <code>HADOOP_HOME</code> 的配置也是正确的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20191015211746.png" alt="HADOOP_HOME 设置" title="HADOOP_HOME 设置"></p><p>在 <code>Windows</code> 中，<code>dll</code> 文件表示动态链接库，全称：<code>Dynamic Link Library</code>，又称应用程序拓展，这种文件并不是一个完整的应用程序，他只是一个扩展库，可以给其它应用程序调用。</p><p>而这里的 <code>hadoop.dll</code> 就是专门给 <code>Hadoop</code> 平台准备的，因为官方发布的 <code>Hadoop</code> 包不能确保开发者开发的 <code>Spark</code>、<code>Mapreduce</code> 等应用在 <code>Windows</code> 平台上面直接运行，或者说不适配，需要加一些 <code>dll</code> 扩展库，才能保证 <code>Hadoop</code> 组件在 <code>Windows</code> 平台提供稳定的服务。</p><p>直接去下载一份对应版本的 <code>hadoop.dll</code>、<code>winutils.exe</code>，放在操作系统的 <code>C:\Windows\System32</code> 目录即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20191015211930.png" alt="dll 文件放入系统目录" title="dll 文件放入系统目录"></p><p>补齐文件后，再次运行，很顺利，问题解决。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>1、互联网上关于 <code>hadoop.dll</code> 的资源很多，但是需要下载时很不友好【积分、广告、过期】，所以推荐大家去 <code>GitHub</code> 上寻找，这里列举一个例子：<a href="https://github.com/steveloughran/winutils" target="_blank" rel="noopener">GitHub winutils</a> ，下载时注意版本的选择，也不是所有的版本都有。</p><p>2、关于上文中简单提到的 <strong>JNI 字段描述符 </strong>，更为完整的信息可以参考我的另外一篇博文：<a href="https://www.playpi.org/2019041301.html">JNI 字段描述符基础知识</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>地锅鸡做法总结（皖北、苏北地区）</title>
    <url>/2018100601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>地锅鸡是流行于皖北、苏北地区的一道传统名菜，并经过改良产生了地锅鱼、地锅豆腐、地锅牛肉、地锅三鲜等一系列菜品，但是配饼始终不变，一般是面饼或者玉米饼。本文用于记录地锅鸡做法总结。</p><a id="more"></a><h1 id="地锅鸡简介"><a href="# 地锅鸡简介" class="headerlink" title="地锅鸡简介"></a>地锅鸡简介 </h1><p> 地锅鸡是一道起源于江苏省的北部、山东省的南部的传统名菜，在安徽北部地区也非常流行，主要食材就是鸡肉、面饼、辣椒，做成菜品后既有主食又包含配菜，口味醇香，饼借菜味，菜借饼香，吃起来回味无穷。另外，经过不断的改进创新，还产生了地锅鱼、地锅豆腐、地锅牛肉、地锅三鲜等一系列菜品，它们的核心都在于使用地锅制作，并配以面饼、玉米饼。</p><h1 id="材料准备"><a href="# 材料准备" class="headerlink" title="材料准备"></a>材料准备 </h1><p>2 人份的材料：</p><ul><li> 面粉 150 克 </li><li> 鸡肉 300 克 </li><li> 鸡蛋 1 个（和面使用，也可以不用）</li><li>花椒 10-15 粒 </li><li> 姜片 4 片 </li><li> 大葱 4 段 </li><li> 干辣椒 5 个 </li><li> 桂皮 1 小块 </li><li> 八角 2 个 </li><li> 大蒜 5 瓣，不用切 </li><li> 青椒、红椒各半个，滚刀切好 </li><li> 酵母菌 </li><li> 各种调味料 </li></ul><h1 id="主要步骤"><a href="# 主要步骤" class="headerlink" title="主要步骤"></a> 主要步骤 </h1><p>1、使用面粉 150 克和面，使用温水，加入 0.5 克酵母菌，也可以加一个鸡蛋一起，和完的面很软但是不粘手，使用保鲜膜包住，注意先撒一点面粉再包（或者直接放碗里用保鲜膜盖住密封，也需要先在碗里撒一层面粉），这样是避免最后粘住。大概需要发 20-30 分钟，等待的过程可以去做其它准备工作了。</p><p>2、取出配料，花椒、姜片、大葱、干辣椒、桂皮、八角、大蒜。锅烧热，放油，多放一点油，先放花椒、桂皮、八角，几秒后再放入葱段、姜片、大蒜、干辣椒，大概 10 秒煸出香味，捞出大蒜备用，其它配料不用捞出。</p><p>3、鸡肉洗干净，放入锅内中火炒 5-10 分钟，放入老抽、生抽、白糖、料酒、豆瓣酱，混合后加入开水，稍微没过鸡肉一点，转为大火，烧开。烧开后中小火焖 15-20 分钟，此时鸡肉已经熟了，要保证还有一些水汤在锅里，因为等一下还需要贴饼、调味、继续焖、收汁等步骤。</p><p>4、在步骤 3 的过程中，面已经发好，均匀分成条状，具体做法是先拉伸，变成长条，然后揪断就行了，大概 20 个左右（如果锅小了一次贴不完，就分 2 次，贴 1 次先吃着，吃完再加一点汤继续贴下一锅），放入清水中，主要不要再动了，就让它们浸泡在水中。</p><p>5、步骤 3 结束后，改为小火，加盐调味，并准备贴饼（如果感觉鸡肉的颜色不够，可以再加一点酱油上色）。步骤 4 的面团在水中浸泡了大概 10 分钟，一个一个取出，是湿漉漉的，用手扯成长条饼状，一半贴在锅沿，用力压一下确保贴紧，一半放入汤中。这样，上半部分会焦脆，下半部分吸收了汤汁很美味。饼贴满后，小火继续焖 10-15 分钟，此时注意如果锅受热不均匀，需要每隔几分钟旋转一下锅。</p><p>6、在步骤 5 中，几分钟后，饼快熟了，就可以加入步骤 2 中捞出来的大蒜，和滚刀切的青椒、红椒，加点香油，稍微搅拌一下，此时汤汁已经基本没了。饼完全熟透了，开锅，大火稍微翻炒几下，就可以吃了，直接在锅里吃。</p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h1><p>1、锅、灶的选择，在农村地区、乡镇地区、城市周边的农家乐，才会有地锅这种设备，所以在家里自己做是很难找到地锅的，只能退而求其次使用普通的炒锅，也是可以的，注意尺寸要大一点的（做 2 人份的地锅鸡就选 3-4 人份的炒锅）；另外最好保证灶的火力能大一点，有用。</p><p>2、面发的时间，和面时可以放鸡蛋也可以不放，最好使用温水，发面的时间不要太久，一般 30 分钟就行了，甚至可以不发，直接使用死面。</p><p>3、贴饼的时候速度一定要快，不然刚刚贴了半圈就已经熟了，丧失了饼的香味；另外饼要贴紧一点，粘在锅上，如果锅受热不均匀，注意每隔几分钟旋转一下锅，保证饼的上半部分能焦脆，这也是需要灶的火力大一点的原因。</p><h1 id="上图"><a href="# 上图" class="headerlink" title="上图"></a> 上图 </h1><h2 id="在安徽合肥吃到的"><a href="# 在安徽合肥吃到的" class="headerlink" title="在安徽合肥吃到的"></a> 在安徽合肥吃到的 </h2><p> 在 2018 年中秋期间，回老家经过合肥，于是在以前的同学的带领下吃了一次地锅鸡，非常满足。这个店的地点在安徽大学（馨苑校区）的西门附近，那条路叫九龙路，一条街都是吃的，又名九龙美食街。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxry66ymf8j229s29se82.jpg" alt="地锅鸡俯视" title="地锅鸡俯视"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxry6uaowkj229s29s1ky.jpg" alt="夹起地锅鸡" title="夹起地锅鸡"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxry7bwy04j229s29shdt.jpg" alt="京酱肉丝" title="京酱肉丝"></p><h2 id="自己做的"><a href="# 自己做的" class="headerlink" title="自己做的"></a>自己做的 </h2><p> 自己在 2018 年国庆期间做了一次，由于没有地锅可以使用，只好选用了普通的炒菜锅，做起来味道还是不错的，只不过饼没有达到香脆的水平，稍有遗憾。此外，家用煤气灶的火力不行，需要更大火的时候不够，导致温度不够高，间接导致了鸡肉的香味和饼的香味没有充分融合，吃的时候感受不到纯正的地锅鸡的香味。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxry84wvalj229s29se82.jpg" alt="真香" title="真香"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>地锅鸡</tag>
      </tags>
  </entry>
  <entry>
    <title>归来</title>
    <url>/2018090501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>好，整理完成后，重新出发。</p><a id="more"></a><h2 id="二级标题，自动创建锚点和目录"><a href="# 二级标题，自动创建锚点和目录" class="headerlink" title="二级标题，自动创建锚点和目录"></a>二级标题，自动创建锚点和目录 </h2><h3 id="三级标题 - 开始"><a href="# 三级标题 - 开始" class="headerlink" title="三级标题 - 开始"></a> 三级标题 - 开始 </h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="三级标题 - 中间"><a href="# 三级标题 - 中间" class="headerlink" title="三级标题 - 中间"></a> 三级标题 - 中间 </h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="三级标题 - 结束"><a href="# 三级标题 - 结束" class="headerlink" title="三级标题 - 结束"></a> 三级标题 - 结束 </h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="三级标题 - 备注"><a href="# 三级标题 - 备注" class="headerlink" title="三级标题 - 备注"></a> 三级标题 - 备注 </h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><h2 id="踩坑记录"><a href="# 踩坑记录" class="headerlink" title="踩坑记录"></a> 踩坑记录 </h2><p> 注意使用 hexo 对 Markdown 文件进行解析时，有一些转义字符是会失败的（使用反斜杠 \ 进行转义的，例如美元符号 &#36;，成对出现有特殊含义，所以需要转义，在 Markdown 中可以使用 \$ 进行转义，但是 hexo 解析完成 html 文件是失败的），所以最好使用编码解决，例如美元符号使用 &amp;#36; 替代。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>建站</tag>
      </tags>
  </entry>
  <entry>
    <title>微博 URL 短网址生成算法 - Java 版本</title>
    <url>/2018101501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>微博短链接是微博官方提供的网址压缩功能产生的一种只包含少量字符的短网址，例如：<a href="https://weibo.com/3086148515/I1IGF4Ud1" target="_blank" rel="noopener">https://weibo.com/3086148515/I1IGF4Ud1</a> ，压缩后为：<a href="http://t.cn/A6vvAcHP" target="_blank" rel="noopener">http://t.cn/A6vvAcHP</a> 。这样的话，发微博时链接占用更少的字符长度。如果发微博时，内容中带了链接，例如视频地址、淘宝店地址，会被自动压缩为短链接。微博短链接可以直接在浏览器中访问，会被微博的网址解析服务器转换为原来的正常链接再访问。</p><p>本文描述微博 <code>URL</code> 短网址生成算法，编程语言是使用 <code>Java</code>。</p><a id="more"></a><h1 id="短网址举例"><a href="# 短网址举例" class="headerlink" title="短网址举例"></a>短网址举例 </h1><p> 各大公司都已经提供短链接服务，例如百度、新浪、谷歌，短链接的优点是字符个数比较少，一般在 10 个以内，例如新浪的短网址可以把字符个数控制在 8 个以内【域名 <code>t.cn</code> 是单字符 <code>t</code>】。</p><p>日常大家见到的应用主要有 2 个地方：一个是微博内容中的网址，例如视频网址、电商商品网址，都会被压缩为 8 个字符以内，这样可以减少微博内容的长度【当然微博内容已经不再限制 140 个字符的长度，但是微博评论还是限制的，使用短网址减少字符的使用，何乐而不为】；另外一个就是邮件中的附件网址、图片网址，一般也都是短链接的形式。</p><h1 id="代码示例"><a href="# 代码示例" class="headerlink" title="代码示例"></a>代码示例 </h1><p> 待整理。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 新浪短链接转换问题 </p><p> 根据新浪短链接，发送 http 请求 </p><p><a href="http://t.cn/RQxjblY" target="_blank" rel="noopener">http://t.cn/RQxjblY</a><br> 可以得到真实链接 (视频 / 官网 / 电商等等)</p><p>在公司真实环境 R 平台，总是请求超时，但是在跳板机及本机浏览器，都可以正常打开，说明链接没有问题 </p><p>R 平台把 t.cn 解析为 180.149.135.224 (北京电信)，无法连接</p><p> 其他环境平台【测试、A 平台】把 t.cn 解析为 121.194.0.133 (北京教育网)，可以正常连接 </p><p> 确定是 R 平台的网络问题，在网络未解决前，只能强制使用旧版短链接了，sinaurl.cn，因为无论是 R 平台还是跳板机服务器，都会把 sinaurl.cn 解析为 121.194.0.133，可以正常使用 </p><p>【打不开】<a href="https://servernotfound.net/weibo-t-cn.html" target="_blank" rel="noopener">https://servernotfound.net/weibo-t-cn.html</a></p><p><a href="https://www.v2ex.com/t/435222" target="_blank" rel="noopener">https://www.v2ex.com/t/435222</a></p><p> 此外，新浪有专门的接口用来转换链接，不需要模拟 http 请求</p><p>【已经下线】<a href="http://open.weibo.com/wiki/2/short_url/expand" target="_blank" rel="noopener">http://open.weibo.com/wiki/2/short_url/expand</a></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>微博URL短网址</tag>
      </tags>
  </entry>
  <entry>
    <title>微博 id mid 相互转换算法实现 - Python 版本</title>
    <url>/2018071801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>对微博数据有了解的人都知道，一条微博内容对应有唯一的微博 <code>url</code>，同时对微博官方来说，又会生成一个 <code>mid</code>，<code>mid</code> 就是一条微博的唯一标识【就像 <code>uid</code> 是微博用户的唯一标识一样】，也类似于人的身份证号。其实，微博 <code>url</code> 里面有一串看起来无意义的字符【称之为 <code>id</code>，由字母、数字组成，6-9 个字符长度，当然以后也可能会变长】，可以和 <code>mid</code> 互相转换，本文就根据理论以及 <code>Python</code> 版本的实现，讲解微博 <code>id</code> 与 <code>mid</code> 的互相转换过程。</p><a id="more"></a><h1 id="数据示例"><a href="# 数据示例" class="headerlink" title="数据示例"></a>数据示例 </h1><p> 下面列举一些微博内容的示例：</p><p>1、通过 <code>id</code>、<code>uid</code> 构造的 <code>url</code>，打开微博内容，示例：<code>https://weibo.com/3086148515/I1IGF4Ud1</code> ，其中，<code>3086148515</code> 是 <code>uid</code>，<code>I1IGF4Ud1</code> 是 <code>id</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200113234603.png" alt="通过微博 url 打开" title="通过微博 url 打开"></p><p>这种格式的 <code>url</code> 可以在网页端通过点击微博的发表时间获取，如下图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200113234623.png" alt="点击发表时间获取 url" title="点击发表时间获取 url"></p><p>2、通过 <code>id</code>、<code>mid</code> 构造的 <code>murl</code> 打开微博内容，示例：<code>https://m.weibo.cn/status/I1IGF4Ud1</code>、<code>https://m.weibo.cn/status/4404101091169383</code>，当然这种内容不适合在 <code>PC</code> 端的浏览器打开，排版不好。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200113235344.png" alt="通过 id 构造 murl" title="通过 id 构造 murl"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200113235336.png" alt="通过 mid 构造 murl" title="通过 mid 构造 murl"></p><h1 id="代码实现"><a href="# 代码实现" class="headerlink" title="代码实现"></a>代码实现 </h1><p> 本文重点讲述 <code>id</code>、<code>mid</code> 的相互转换，其它的概念例如 <code>uid</code>、<code>url</code> 不再赘述，读者可以参考备注中的内容。</p><p>在此提前说明，下文中涉及的代码已经被我上传至 <code>GitHub</code>：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/bin/20180718" target="_blank" rel="noopener">weibo_util.py</a> ，读者可以提前下载查看。</p><p>注意，涉及到的 62 进制表示从 0 到 9、从 a 到 z、从 A 到 Z 一共 62 个字符。</p><p>1、<code>id</code> 转为 <code>mid</code> 的思路，例如：<code>I1IGF4Ud1</code>，有 9 个字符，从后开始以 4 个字符为单位进行拆分，拆分为：<code>I</code>、<code>1IGF</code>、<code>4Ud1</code>，然后再分别把它们转为 62 进制对应的 10 进制数值，得到：<code>44</code>、<code>0410109</code>【不足 7 位在前面补 0】、<code>1169383</code>。紧接着再拼接所有的结果，得到最终的 <code>mid</code>：<code>4404101091169383</code>。</p><p><code>Python</code> 代码逻辑很简洁，主要 <code>Python</code> 代码逻辑如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># id 转换为 mid</span><br><span class="line">def id2mid (id):</span><br><span class="line">    id = str (id)[::-1]</span><br><span class="line">    size = int (len (id) / 4) if len (id) % 4 == 0 else int (len (id) / 4 + 1)</span><br><span class="line">    result = []</span><br><span class="line">    for i in range (size):</span><br><span class="line">        s = id [i * 4: (i + 1) * 4][::-1]</span><br><span class="line">        s = str (base62_decode (str (s)))</span><br><span class="line">        s_len = len (s)</span><br><span class="line">        if i &lt; size - 1 and s_len &lt; 7:</span><br><span class="line">            s = (7 - s_len) * &apos;0&apos; + s</span><br><span class="line">        result.append (s)</span><br><span class="line">    result.reverse ()</span><br><span class="line">    return &apos;&apos;.join (result)</span><br></pre></td></tr></table></figure><p>2、<code>mid</code> 转为 <code>id</code> 的思路，例如：<code>4404101091169383</code>，有 18 个字符，从后开始以 7 个字符为单位进行拆分，拆分为：<code>44</code>、<code>410109</code>【前面有 0 的直接去除】、<code>1169383</code>，然后再分别把它们转为 10 进制数值对应的 62 进制字符串，得到：<code>I</code>、<code>1IGF</code>、<code>4Ud1</code>。紧接着再拼接所有的结果，得到最终的 <code>id</code>：<code>I1IGF4Ud1</code>。</p><p><code>Python</code> 代码逻辑很简洁，主要 <code>Python</code> 代码逻辑如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mid 转换为 id</span><br><span class="line">def mid2id (mid):</span><br><span class="line">    mid = str (mid)[::-1]</span><br><span class="line">    size = int (len (mid) / 7) if len (mid) % 7 == 0 else int (len (mid) / 7 + 1)</span><br><span class="line">    result = []</span><br><span class="line">    for i in range (size):</span><br><span class="line">        s = mid [i * 7: (i + 1) * 7][::-1]</span><br><span class="line">        s = base62_encode (int (s))</span><br><span class="line">        s_len = len (s)</span><br><span class="line">        if i &lt; size - 1 and len (s) &lt; 4:</span><br><span class="line">            s = &apos;0&apos; * (4 - s_len) + s</span><br><span class="line">        result.append (s)</span><br><span class="line">    result.reverse ()</span><br><span class="line">    return &apos;&apos;.join (result)</span><br></pre></td></tr></table></figure><p>3、以上内容运行单元测试后结果截图如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200114000012.png" alt="运行单元测试" title="运行单元测试"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 关于 <code>Java</code> 版本的实现，可以参考我的另外一篇博客：<a href="https://www.playpi.org/2018122001.html">微博 url mid 相互转换算法实现 - Java 版本</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>weibo</tag>
        <tag>mid</tag>
        <tag>id</tag>
      </tags>
  </entry>
  <entry>
    <title>指南页面的自动收集</title>
    <url>/2019050401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近给博客站点增加了一个独立的页面：<strong> 指南 </strong>，用来记录本站点的所有文章，包括发表时间与文章链接，并按照发表时间倒序排列，仅供快速查找以及核对使用。其中，还会有一个文章编号，就是 <code>url</code> 的数字部分，由日期与编号组成，例如 2019050201 表示 2019 年 05 月 02 日发表的第 1 篇文章，这个文章编号对我来说很有用，用来核对查重。但是，为了简化这个页面的整理工作以及后续的自动生成，我需要把这个流程自动化，本文记录实现思路与实现方式。</p><a id="more"></a><h1 id="实现思路"><a href="# 实现思路" class="headerlink" title="实现思路"></a>实现思路 </h1><p> 为了简化难度，我准备使用 <code>Shell</code> 解决这个问题。大概思路：遍历目录的文件、解析 <code>id</code> 与 <code>title</code>、搜索匹配指南 <code>index</code> 文件、替换或者追加。</p><p>1、遍历指定目录【<code>_post</code> 目录】中的所有 <code>markdown</code> 文件，对每个文件执行 2。</p><p>2、对单个文件，使用 <strong>grep</strong> 正则搜索： <strong>^id: [0-9]{10}</strong>，使用 <strong>awk</strong> 获取 <code>id</code> 值，判断 <code>id</code> 值是否在 <code>index</code> 文件中，在则跳过，否则执行 3。</p><p>3、再使用 <strong>grep</strong> 正则搜索： <strong>^title: </strong>，使用 <strong>awk</strong> 获取 <code>title</code> 值，执行 4，把 <code>id</code> 值和 <code>title</code> 值追加到 <code>index</code> 文件中。</p><p>4、先使用 <strong>grep id 值 index 文件 </strong>搜索 3 中的 <code>id</code> 是否已经在 <code>index</code> 文件中，不在才能追加进去。追加 <code>index</code> 文件时，先重命名 <code>index</code> 文件为 <code>index_bak</code>，逐行读取。对每一行数据使用 <strong>grep</strong> 正则搜索：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo $line | grep -E &apos;^- [0-9]&#123;10&#125;，\[&apos; | awk -F&apos;，&apos; &apos;&#123;print $1;&#125;&apos; | awk -F&apos; &apos; &apos;&#123;print $2;&#125;&apos;</span><br></pre></td></tr></table></figure><p>如果搜索无内容的直接将当前行写入新文件，命名为 <code>index</code>。再结合使用 <strong>awk</strong> 获取当前行的 <code>id</code> 值，只要 3 中的 <code>id</code> 值大于此 <code>id</code> 值并且年份一致，则将 3 中的 <code>id</code> 值和 <code>title</code> 值写入新文件【构造特定格式的数据行】，接着再将当前行写入新文件。如果年份一致且 3 中的 <code>id</code> 值最小，则按照 5 写入当年的数据最后一行。</p><p>5、相同年份作一个标记，是否已经写入新文件作一个标记，如果遇到读取的下一行已经不是当年的数据【正则搜索无结果】，则把构造的特定格式的数据行写入新文件，再把当前行写入新文件。</p><p>6、4 中的文件逐行读取完成后，把 4 中一开始重命名的文件 <code>index_bak</code> 删除，只保留新文件 <code>index</code>，此时 <code>index</code> 文件中已经增加了一行新内容。</p><h1 id="具体实现"><a href="# 具体实现" class="headerlink" title="具体实现"></a>具体实现 </h1><p> 以下涉及的 <code>Shell</code> 脚本已经被我上传至 <code>GitHub</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypi.github.io/tree/source" target="_blank" rel="noopener">auto_guide.sh</a> ，脚本命名与下文中描述一致。</p><p><code>Shell</code> 脚本内容参考如下【脚本名称为：<code>auto_guide.sh</code>】，注释都已经标明处理逻辑，通俗易懂：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># index 文件 </span><br><span class="line">index=./source/guide/index.md</span><br><span class="line">index_bak=./source/guide/index_bak.md</span><br><span class="line"># 文本格式 </span><br><span class="line">content_pattern=&apos;- id，[title](https://www.playpi.org/id.html)&apos;</span><br><span class="line"># 遍历文件夹内的所有文件 </span><br><span class="line">for file in ./source/_posts/*.md</span><br><span class="line">do</span><br><span class="line">  if [-f $file]; then</span><br><span class="line">    # 获取单个文件的 id【在第 3 行】 和 title【在第 2 行】</span><br><span class="line">    echo &apos;================================================================&apos;</span><br><span class="line">    # echo &apos;====read file:&apos; $file</span><br><span class="line">    var1=$(grep -nE &apos;^id: [0-9]&#123;10&#125;&apos; $file | grep -E &apos;^3:id: [0-9]&#123;10&#125;&apos; | awk -F&apos;: &apos; &apos;&#123;print $2;&#125;&apos;)</span><br><span class="line">    # echo &apos;====read id:&apos; $var1</span><br><span class="line">    var2=$(grep -n &apos;^title: &apos; $file | grep &apos;^2:title: &apos; | awk -F&apos;: &apos; &apos;&#123;print $2;&#125;&apos;)</span><br><span class="line">    # echo &apos;====read title:&apos; $var2</span><br><span class="line">    # 判断非空必须使用双引号，否则逻辑错误 </span><br><span class="line">    if [-n &quot;$var1&quot;] &amp;&amp; [-n &quot;$var2&quot;]; then</span><br><span class="line">      has=$(grep $var1 $index)</span><br><span class="line">      # 为空，表示 id 不在 index 文件中，has 变量切记使用双引号 </span><br><span class="line">      if [-z &quot;$has&quot;]; then</span><br><span class="line">        # 字符串搜索替换，待搜索字符串是变量，不是字符串本身，// 表示替换所有 </span><br><span class="line">        content=$&#123;content_pattern//id/$var1&#125;</span><br><span class="line">        content=$&#123;content/title/$var2&#125;</span><br><span class="line">        # 追加到 index 文件中 </span><br><span class="line">        echo &apos;====prepare append to index:&apos; $content</span><br><span class="line">        # 重命名 index 文件 </span><br><span class="line">        mv $index $index_bak</span><br><span class="line">        # 标记是否写入 / 是否同一年份 </span><br><span class="line">        has_write=&apos;&apos;</span><br><span class="line">        is_same_year=&apos;&apos;</span><br><span class="line">        while read line</span><br><span class="line">        do</span><br><span class="line">          match_id=$(echo $line | grep -E &apos;^- [0-9]&#123;10&#125;，\[&apos; | awk -F&apos;，&apos; &apos;&#123;print $1;&#125;&apos; | awk -F&apos; &apos; &apos;&#123;print $2;&#125;&apos;)</span><br><span class="line">          # 搜索到匹配内容并且还没写入 </span><br><span class="line">          if [-n &quot;$match_id&quot;] &amp;&amp; [-z &quot;$has_write&quot;]; then</span><br><span class="line">            # echo &apos;====compare,match_id:&apos; $match_id</span><br><span class="line">            # 判断是否相同年份 </span><br><span class="line">            if [$&#123;var1:0:4&#125; == $&#123;match_id:0:4&#125;]; then</span><br><span class="line">              is_same_year=&apos;1&apos;</span><br><span class="line">              # 比较大小 </span><br><span class="line">              if [$var1 -gt $match_id]; then</span><br><span class="line">                echo &apos;====gt match_id append to index:&apos; $content</span><br><span class="line">                echo $content &gt;&gt; $index</span><br><span class="line">                echo $line &gt;&gt; $index</span><br><span class="line">                has_write=&apos;1&apos;</span><br><span class="line">              else</span><br><span class="line">                echo $line &gt;&gt; $index</span><br><span class="line">              fi</span><br><span class="line">            else</span><br><span class="line">              echo $line &gt;&gt; $index</span><br><span class="line">            fi</span><br><span class="line">          elif [-n &quot;$is_same_year&quot;] &amp;&amp; [-z &quot;$has_write&quot;]; then</span><br><span class="line">            # 当前行没有搜索到匹配内容，并且同一年份，并且还没写入，说明已经是当前年份的最后一行了，直接写入即可 </span><br><span class="line">            echo &apos;====last append to index:&apos; $content</span><br><span class="line">            echo $content &gt;&gt; $index</span><br><span class="line">            echo $line &gt;&gt; $index</span><br><span class="line">            has_write=&apos;1&apos;</span><br><span class="line">          else</span><br><span class="line">            # 没有搜索到匹配内容，或者不同年份，或者已经写入，直接写入即可 </span><br><span class="line">            echo $line &gt;&gt; $index</span><br><span class="line">          fi</span><br><span class="line">        done &lt; $index_bak</span><br><span class="line">        # 删除 index_bak 文件，此时只有最新的 index 文件 </span><br><span class="line">        rm $index_bak</span><br><span class="line">      else</span><br><span class="line">      # 在 index 文件中已经存在，无需处理 </span><br><span class="line">      echo &apos;====index has:&apos; $var1</span><br><span class="line">      fi</span><br><span class="line">    else</span><br><span class="line">    echo &apos;!!!!invalid var:&apos; $var1 $var2</span><br><span class="line">    fi</span><br><span class="line">  else</span><br><span class="line">  echo &apos;!!!!invalid file:&apos; $file</span><br><span class="line">  fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>执行脚本时会打印解析出来的每条 <code>id</code> 与 <code>title</code>，以及写入的原因【比较后写入、最后一条写入】，第一次执行脚本耗时久一点，后续执行会自动跳过已经收集过的，耗时可以忽略。</p><p>由于实现思路简化了，所以要求 <code>index</code> 文件在每一年都至少已经有一个完整的记录，否则没法对比写入。</p><p>注意，正则搜索时在必要情况下使用 <strong>-E</strong> 选项开启扩展模式，否则正则无效，仍旧是普通的字符串。</p><p>日期格式的字符串比较大小，由于格式规范，都是十位数字，可以直接转为数字比较，大的就代表日期最新。</p><p>当然，日期格式的字符串比较大小，也可以先转为时间戳数字，再进行比较，示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">date +% s -d &apos;2019010101&apos;</span><br></pre></td></tr></table></figure><p>虽然这种格式得到的结果不是真正的时间戳，但是只要是数字就可以比较了。另外，经过查找帮助手册，没有发现可以指定格式的参数选项，也就是无法把 <strong>YYMMddHH</strong> 格式的日期字符串转为对应的真实时间戳。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>guide</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>武功山两天徒步登山总结</title>
    <url>/2018071601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p> 公司部门组织团建，在 2018-07-13 这天开始，一行二十多人傍晚从公司出发，踏上了去往江西武功山的旅程。本文就详细讲述 2018-07-13 晚上从广州出发，2018-07-16 凌晨到达广州的整个旅程。</p><a id="more"></a><p> 图文并茂，等待整理。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>游玩</category>
      </categories>
      <tags>
        <tag>武功山</tag>
        <tag>徒步</tag>
      </tags>
  </entry>
  <entry>
    <title>微博电影文稿备份 2</title>
    <url>/2019020101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在 2019 年 1 月 1 日整理过一篇，包含 10 部电影，这是第二篇。</p><a id="more"></a><h1 id="武侠"><a href="# 武侠" class="headerlink" title="武侠"></a>武侠 </h1><p>《武侠》是一部 2011 年的动作悬疑片，豆瓣评分 6.6，好于 48% 的动作片，好于 43% 的悬疑片，可见评分不是很好，但是里面的动作戏还是不错的。这部电影由陈可辛导演，甄子丹、金城武、汤唯主演。</p><p>1917 年，中国西南边陲的刘家村，刘金喜（甄子丹 饰演）和妻子阿玉（汤唯 饰演）共同抚养两个儿子方正和晓天，日子平淡且幸福。直到某一天，两个不速之客打破了刘家村的平静，也摧毁着金喜一家的生活，这二人企图洗劫村中的钱柜，被刚好在此的金喜撞见，一阵混乱打斗，二匪稀里糊涂被金喜打死。由于其中一人是政府通缉的要犯，因此县官大喜过望，村里人也将金喜奉为大英雄。但是，这看似普普通通的盲打误杀却引起一个人的怀疑，他名叫徐百九（金城武 饰演），是县衙的捕快。从蛛丝马迹上来看，二匪系死于武功高强人之手，徐百九由此留在村里，对金喜展开了连番的观察、调查与试探。 在这一过程中，金喜神秘的真实身份渐渐浮出水面，而刘家村也面临着一场空前的危机。</p><p> 以下截取的 10 分钟片段（00:05:56 到 00:15:51），是电影开头，刘金喜和两个劫匪的打斗，并稀里糊涂把两个劫匪全部杀死，然后县官带队破案，发现死者之一是通缉犯。在这个片段中，主演悉数出场：汤唯、金城武、甄子丹，而且这一段打斗也是后面剧情发展的主要依据。后面会发现这一段打斗被捕快徐百九解释地合情合理，而刘金喜的身份也因此渐渐浮出水面，为最终的结局埋下了伏笔。</p><h1 id="让子弹飞"><a href="# 让子弹飞" class="headerlink" title="让子弹飞"></a>让子弹飞 </h1><p>《让子弹飞》是一部 2010 年的剧情喜剧片，豆瓣评分 8.7，好于 97% 的喜剧片，好于 95% 的剧情片，又名《让子弹飞一会》、《火烧云》，由姜文导演。</p><p> 民国年间，花钱捐得县长的马邦德（葛优 饰演）携妻子（刘嘉玲 饰演）及随从走马上任。途经南国某地，遭劫匪张麻子（姜文 饰演）一伙伏击，随从尽死，只夫妻二人侥幸活命，马为保命，谎称自己是县长的汤师爷。为汤师爷许下的财富所动，张麻子摇身一变化身县长，带着手下赶赴鹅城上任。有道是天高皇帝远，鹅城地处偏僻，一方霸主黄四郎（周润发 饰演）只手遮天，全然不将这个新来的县长放在眼里。张麻子痛打了黄的武教头（姜武 饰演），黄则设计害死张的义子小六（张默 饰演）。原本只想赚钱的马邦德，怎么也想不到竟会被卷入这场土匪和恶霸的角力之中。鹅城上空愁云密布，血雨腥风在所难免……</p><p>截取的片段一，7 分钟（00:00:32 到 00:07:28），是电影开头的介绍，著名的台词：让子弹飞一会儿。</p><p>截取的片段二，6 分钟（00:25:45 到 00:31:18），是黄四郎陷害小六子的场景，到底吃了几碗粉，小六子切腹致死，陈坤演技无敌。著名的台词：你不是欺负老实人吗。</p><p>截取的片段三，12 分钟（00:34:15 到 00:46:17），是六子死后黄四郎约见县长，县长带着师爷奔赴鸿门宴，本来准备杀死黄四郎替六子报仇，后来计划有变。整个聊天过程真的令人大呼过瘾，经典台词：够硬吗？够硬！</p><h1 id="狼牙"><a href="# 狼牙" class="headerlink" title="狼牙"></a>狼牙 </h1><p>《狼牙》是一部 2008 年的电影，距今已经十年有余，它是一部动作、惊悚电影，又名《狼牙之阿布》，由吴京、李忠志导演，由吴京、卢靖姗主演。</p><p> 截取的片段之一，8 分钟（00:16:39 到 00:24:40），是吴京遭遇台风封岛无法返回内地，在卢靖姗住处附近的小吃店吃面，遇到了一伙贩毒黑社会，进而产生的动作摩擦。</p><p>截取的片段之二，12 分钟（01:09:53 到 01:22:20），卢靖姗被黑社会绑架，威胁吴京前来救援，吴京只好独自一人前往，以一敌百，这场面宏大刺激。</p><h1 id="后会无期"><a href="# 后会无期" class="headerlink" title="后会无期"></a>后会无期 </h1><p>《后会无期》是一部 2014 年的电影，由冯绍峰、陈柏霖、钟汉良、王珞丹、袁泉主演，由韩寒导演，同时也是韩寒的电影处女作。</p><p> 截取的片段之一【00:16:30 到 00:29:00】，12 分钟，是三人刚到旅馆发生的事情。台词：你这种情况，是要加钱的。</p><p>截取的片段之二【00:33:54 到 00:42:26】，9 分钟，是三人遇到苏米的家长。台词：汽油车，不能加柴油。</p><h1 id="失恋 -33- 天"><a href="# 失恋 -33- 天" class="headerlink" title="失恋 33 天"></a>失恋 33 天 </h1><p>《失恋 33 天》是一部 2011 年的爱情、剧情片，由白百何、文章、张嘉译、王耀庆主演，由滕华涛导演，又名《黄了一个来月》。</p><p> 截取的片段，3 分钟【00:55:59 到 00:59:27】，是文章协助白百何咒骂前男友的场景，真的是思路清晰、先下手为强，骂得对方狗血喷头。</p><p>真正失恋要经过三个阶段：第一阶段当然丧尽自尊，痛不欲生，听到他的名字都会跳起来。第二阶段故作忘记，避而不提伤心事，可是内心隐隐作痛。到了最后阶段，他的名字与路人一样，不过是个名字，一点儿特别意义都没有。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>微博电影</tag>
        <tag>文稿备份</tag>
      </tags>
  </entry>
  <entry>
    <title>煮鸡蛋做法总结</title>
    <url>/2018120301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>本文记录水煮鸡蛋的做法总结。</p><a id="more"></a><h1 id="介绍"><a href="# 介绍" class="headerlink" title="介绍"></a>介绍 </h1><p> 水煮鸡蛋是最常见的吃法之一，做法非常简单，直接将鸡蛋放入开水中煮熟即可。煮熟的鸡蛋营养丰富，水煮鸡蛋的营养可以 100% 被保留，是所有的鸡蛋做法中营养被保留的最好的一种。建议每天食用 1-2 个，因为过量的食用可能会导致营养不良，同时鸡蛋的营养并没有被身体吸收，相当于浪费了。</p><p>在生活当中，大家几乎每天早上都会吃煮鸡蛋，或者茶叶蛋，但是有一些人卖的煮鸡蛋不算成功的煮鸡蛋，因为剥皮的时候发现不好剥，蛋壳与蛋白紧紧粘在一起，吃起来可麻烦了，这是因为煮鸡蛋的做法错误，遗漏了重要的步骤。</p><h1 id="做法步骤"><a href="# 做法步骤" class="headerlink" title="做法步骤"></a>做法步骤 </h1><p>1、简单地清洗一下鸡蛋，因为鸡蛋的表面可能会有一些茅草、粪便之类的污垢，这是因为鸡蛋必须是原生的，存储、运输、销售过程都不能清洗，如果非要清洗，水会破坏表面的保护膜，放不了两天鸡蛋就坏了；</p><p>2、放在冷水中浸泡一会儿，1-2 分钟，这样做的目的是防止沸水煮的时候蛋壳破裂；</p><p>3、放入锅中，水的高度稍微没过鸡蛋，使用中火煮开水，不要使用大火，大火煮的速度太快，鸡蛋容易裂开，另外中火使水沸腾的时间会长一些，预热了鸡蛋，味道更香；</p><p>4、水沸腾后，改为小火，煮 7-8 分钟（如果继续使用中火，5 分钟左右即可）；</p><p>5、如果需要溏心蛋（蛋清凝固，蛋黄成稠液状，软嫩滑润），煮 5 分钟即可；</p><p>6、煮熟后不要立即捞出，等 1-2 分钟，然后才捞出，切记此时需要放入冷水中，浸泡 1-3 分钟，这一步骤的目的是保证鸡蛋容易剥开，避免蛋白和蛋壳粘在一起。</p><p> 煮鸡蛋成品 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190503022826.jpg" alt="煮鸡蛋成品" title="煮鸡蛋成品"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、煮鸡蛋前最好放入冷水中浸泡 1-2 分钟，防止煮的过程开裂；</p><p>2、注意控制火力和时间，鸡蛋不能煮太久，超过 10 分钟会有化学反应，导致营养流失；</p><p>3、煮熟后不要立即捞出，捞出后也要放在冷水中浸泡，防止蛋白和蛋壳粘在一起；</p><p>4、每天不要吃太多，1-2 个就够了；</p><p>5、如果想要保持蛋黄在中间，煮鸡蛋的过程中要适当搅拌让鸡蛋旋转。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>煮鸡蛋</tag>
      </tags>
  </entry>
  <entry>
    <title>爬山徒步：竹海丛林 - 广州第二峰鸡枕山</title>
    <url>/2019092201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在 2019 年 9 月 21 日，我们几个小伙伴相约去广州鸡枕山登山徒步，给久坐的身体放松一下。<strong> 鸡枕山 </strong>位于广东省广州市从化区良口镇，海拔 1175 米，为广州市的第二高峰，仅次于天堂顶。另外有一点比较好的地方在于，鸡枕山虽然是广州第二高峰，但是它全程都被树木、竹林遮挡，基本不会被晒到，而且山路比较平缓，除了几处陡一点的路段，整体来说走起来非常舒适。</p><p>因此，这条线路非常适合没有登山经验的人，或者是平时缺少锻炼的人，或者体能差的人，这是一个比较好的入门路线。本文记录这次徒步的过程，给读者一个观察参考。</p><a id="more"></a><h1 id="集合"><a href="# 集合" class="headerlink" title="集合"></a>集合 </h1><p> 我们规定 07:00 在 <strong>客村 </strong>地铁站集合，签到、吃早餐、准备食物水等必需品。这时候有些人没有买够水的去买，没有买够食物的也去买，保证登山过程中能量补给。</p><h1 id="启程"><a href="# 启程" class="headerlink" title="启程"></a>启程 </h1><p>07:40，所有人到齐，准备出发，一个大巴装了 40 多人。</p><h1 id="到达"><a href="# 到达" class="headerlink" title="到达"></a> 到达 </h1><p>08:50 到达服务区，大家下车休息，还可以买水，09:00 继续出发。</p><p> 由于领队的麦克风坏掉了，所以没有进行互动，在过了服务区快要到达的时候，领队讲了一下注意事项。</p><p>在 09:50 到达山脚，做了一下热身，稍微休息几分钟，准备登山。</p><p>为了保留体力，避免运动过量，我们决定慢慢走，全程都是最后一批，其中一个领队就在我们后面。</p><h1 id="登山"><a href="# 登山" class="headerlink" title="登山"></a>登山 </h1><p>10:00 开始登山。</p><p> 在登山入口，我们的小队伍合影。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923005645.jpg" alt="山脚小合照" title="山脚小合照"></p><p>登山路过竹林，有人仰望天空，发现的心形竹林空隙。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923005740.jpg" alt="心形的竹林空隙" title="心形的竹林空隙"></p><p>走过竹林间的小路，看光影婆娑。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923005830.jpg" alt="竹林间的小路" title="竹林间的小路"></p><p>路过小水坝，领队抓拍到的如画风景，我是倒数第二个人。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923005941.jpg" alt="路过小水坝" title="路过小水坝"></p><p>这个小水坝是很小的，看看小水坝的蓄水池就知道了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923010019.jpg" alt="小水坝的蓄水池" title="小水坝的蓄水池"></p><p>总是有人善于观察，看看路边的小花，斑驳的台阶。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923010102.jpg" alt="路边的小花" title="路边的小花"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923010113.jpg" alt="斑驳的台阶" title="斑驳的台阶"></p><p>路上少有的开阔视野，可以看看风景，远处的蓝蓝天空。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923010213.jpg" alt="蓝蓝的天空" title="蓝蓝的天空"></p><h1 id="午餐休息"><a href="# 午餐休息" class="headerlink" title="午餐休息"></a>午餐休息 </h1><p>12:00 到达登顶前的平台，可以休息吃午餐，养好体力准备登顶。</p><p> 领队竟然带了一个西瓜，背上来整整一个大西瓜，切开大家分了，竟然是冰冻的，爽口解渴。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011540.jpg" alt="切西瓜" title="切西瓜"></p><p>吃瓜群众，阳光洒在我全身，像个孩子。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011556.jpg" alt="吃瓜群众" title="吃瓜群众"></p><p>我带的西红柿，都给队友吃了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011609.jpg" alt="吃西红柿" title="吃西红柿"></p><h1 id="登顶"><a href="# 登顶" class="headerlink" title="登顶"></a>登顶 </h1><p>12:40 开始登顶。</p><p> 最后有一段稍微陡峭的登顶路段，全程是暴露在阳光下的，只有灌木丛，慢慢登上去大概需要 20 分钟。</p><p>登顶大合照之一。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011649.jpg" alt="登顶大合照之一" title="登顶大合照之一"></p><p>登顶大合照之二。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011702.jpg" alt="登顶大合照之二" title="登顶大合照之二"></p><p>登顶小合照，我站在最高的石头上，眼睛被阳光照射，只能眯得很小。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011715.jpg" alt="登顶小合照" title="登顶小合照"></p><p>可以看到鸡枕山卫峰。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011731.jpg" alt="鸡枕山卫峰" title="鸡枕山卫峰"></p><p>山顶的平台被阳光直射，还是有点晒的，不过还好有风，感觉不是那么炎热，在上面遥看远方，风景如画，谈笑风生。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011904.jpg" alt="登顶远眺之一" title="登顶远眺之一"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011915.jpg" alt="登顶远眺之二" title="登顶远眺之二"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011924.jpg" alt="登顶远眺之三" title="登顶远眺之三"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923011934.jpg" alt="登顶远眺之四" title="登顶远眺之四"></p><h1 id="下山"><a href="# 下山" class="headerlink" title="下山"></a>下山 </h1><p>13:30 开始下山，一路小树林、竹林、灌木丛、缓坡。</p><p> 下山会有几段灌木丛的路，大概是下图这样，感觉像是玉米地，每次路过时双手挡脸，要防止被叶子刮伤。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923012043.jpg" alt="灌木丛" title="灌木丛"></p><p>下山遇到的竹林，不过此时已经很累，无心观赏。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923012346.jpg" alt="下山遇到的竹林" title="下山遇到的竹林"></p><p>仰望竹林。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923012433.jpg" alt="仰望竹林" title="仰望竹林"></p><p>阳光洒下，一片片翠绿金黄的竹叶；微风袭来，一阵阵扑面而来的凉爽。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923012128.jpg" alt="翠绿金黄的竹林" title="翠绿金黄的竹林"></p><p>竟然在山脚遇到了一群走地鸡，公鸡的羽毛特别漂亮。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190923012211.jpg" alt="走地鸡" title="走地鸡"></p><h1 id="集合返程"><a href="# 集合返程" class="headerlink" title="集合返程"></a>集合返程 </h1><p> 在 16:30 到达山脚。</p><p>返程到山脚，有一些人很早就到了，等了两个多小时。</p><p>大家换衣服、洗脸、去厕所，休息一会，然后喝水、吃东西，聊聊天。</p><p>一切准备就绪后，大家集合，准备返程。</p><h1 id="归来"><a href="# 归来" class="headerlink" title="归来"></a>归来 </h1><p>17:00 开始返程。</p><p> 在下山的路上，由于是曲折蜿蜒的 S 型路线，而且路比较窄，所以堵车很严重，特别在转弯处，还需要下去人去指挥，毕竟安全第一。</p><p>本来 10 分钟可以走完的路花了将近 1 小时。</p><p>最后在 20:00 到达广州。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>游玩</category>
      </categories>
      <tags>
        <tag>Guangzhou</tag>
        <tag>hike</tag>
        <tag>climbing</tag>
      </tags>
  </entry>
  <entry>
    <title>玉米胡萝卜排骨汤做法总结</title>
    <url>/2018053001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>排骨汤，是一道做法非常简单的汤，需要的只是新鲜的食材与足够的耐心而已。除了排骨，还可以增加玉米、胡萝卜这两种配菜，以增加排骨汤的甘甜与鲜美。本文就讲述玉米胡萝卜排骨汤的做法总结。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 用最少的食材做排骨汤，才能做成真正的排骨汤，不需要各种配料，也不需要各种调味料，最终炖出来的排骨汤才能有排骨的鲜美。</p><p>以下的食材分量大约 3 人份：</p><ul><li>排骨 300 克（排骨越好汤越好，我用过各种价格的排骨，12 元 / 斤 - 40 元 / 斤）</li><li>甜玉米 1 根（稍微大一点嫩一点最好，买玉米的时候可以品尝一粒生的）</li><li>姜片 2-3 片（不能太多，或者也可以不放）</li><li>胡萝卜一根 </li><li> 食用盐适量 </li></ul><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><p> 不计算食材的准备，从开火到关火总耗时预计 70 分钟；</p><p>1、清洗排骨，稍微用水冲洗一下，然后在冷水中浸泡 10 分钟 - 20 分钟，目的是去除杂质与血水，但是油脂仍然保留，一般购买排骨的时候会让卖菜的帮忙剁好，否则自己用菜刀处理很麻烦；<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy93ectpkij229s29s1ky.jpg" alt="清洗排骨" title="清洗排骨"></p><p>2、清洗玉米，切片，可以切薄一点，大概每片的厚度是 3 粒玉米的距离，玉米很难切，所以菜刀一定要使用锋利点的，否则会损坏玉米粒的，如果购买的玉米很新鲜，玉米棒里面也是很甜的，有助于增加排骨汤的甘甜；<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy93desywqj229s29s4qr.jpg" alt="玉米切片" title="玉米切片"></p><p>3、清洗胡萝卜，去皮，切片，注意最好去皮，否则最终部分胡萝卜皮会混在汤里，影响汤的品质；<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy93drsw9uj229s29skjl.jpg" alt="胡萝卜切片" title="胡萝卜切片"></p><p>4、姜片，准备 2-3 片即可；</p><p>5、汤锅准备好，加水，加姜片，冷水就下排骨，开大火煮，水开后立马转小火，把水表面的浮沫撇去，小火继续煮 30 分钟；</p><p>6、步骤 5 的 30 分钟后，加玉米片，继续小火煮 20 分钟；</p><p>7、步骤 6 的 20 分钟后，加胡萝卜片，继续小火煮 10 分钟；</p><p>8、加盐调味，关火；</p><p>一锅排骨汤 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy93clglipj229s29sqv5.jpg" alt="一锅排骨汤" title="一锅排骨汤"></p><p> 一碗排骨汤 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy93bgbpevj229s29s1kx.jpg" alt="一碗排骨汤" title="一碗排骨汤"></p><p> 以前做的另外一锅排骨汤，当时买的排骨 38 元 / 斤 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy9467qgw3j21w02ioqv5.jpg" alt="以前做的另外一锅排骨汤" title="以前做的另外一锅排骨汤"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、排骨不能洗的太彻底，比如洗排骨的时候用力搓，不仅洗掉了血水，还把油脂洗没了，这样会导致汤里面丧失了香味；</p><p>2、如果选择了排骨焯水（或者是选择了先在水里煮一下），切记不要焯太久（或者煮太久），10-30 秒即可，目的只是去除血水，否则也会流失油脂；</p><p>3、为了省事，我一般不会对排骨怎么清洗，稍微用水冲一下，确保没有杂质与血水即可，然后直接煮，但是切记煮开后立即用勺子撇掉浮沫（油脂与碎渣），否则最终的汤会浑浊，而且没有香味；</p><p>4、玉米一定要选择甜玉米，嫩的最好；</p><p>5、时间一定要控制好，总计 70 分钟，也要注意火力的控制，除了一开始是大火，后面的 60 分钟全部是小火；</p><p>6、如果只想喝汤，排骨可以用来做红烧排骨、糖醋排骨、酱排骨等等。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>排骨汤</tag>
        <tag>玉米排骨汤</tag>
      </tags>
  </entry>
  <entry>
    <title>番茄鸡蛋面做法总结 - 酸汤口味</title>
    <url>/2019072701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>面食是中国常见的一种传统主食，馒头、饼、包子、馍、面条、面叶，使用面粉做出来的类型多种多样。其中，<strong> 面条 </strong>可谓是最为流行，无论东北、西北、东南、西南、中原、华南，都可以看到 <strong>面条 </strong>身影，形式丰富，口味不一，这更是中华民族劳动人民智慧的结晶。</p><p>其中，<strong> 汤面 </strong>又是一派，汤面最重要的是什么，除了面条本身之外，最重要的是汤。而汤，是非常难做的，耗时长且配料讲究，不仅要选骨头，还要放大料，一般一锅好汤都要熬制两个小时以上，更甚者要熬制四个小时。一般家庭吃面条是不可能这么折腾的，那么我这里有一种更为简单的方法：使用番茄鸡蛋做酸汤，再配合面条，做一碗酸汤面。这种方法操作起来简单，耗时短，又能保留汤的美味，适合自己在家做，本文记录做法总结。</p><a id="more"></a><h1 id="引言"><a href="# 引言" class="headerlink" title="引言"></a>引言 </h1><p> 我在网络上看到全国很多卖的火爆的汤面，看自媒体介绍，看采访报道，都是注重讲究汤的制作，还自夸是祖传，几十年积累改良下来的，无论他们怎么说，这可见汤的重要性。</p><p>在广州的上下九、老西关，也各有一家不错的广式汤面，汤真的很不错，年头也比较久。</p><p>目前市面上为什么很多快餐店的汤面、汤粉都不好吃，就是汤不行。我记得小时候在江南一带生活过一段时间，那里的快餐店的外墙上都会印着 <strong>民以食为天、面以汤为鲜 </strong>作为广告语，而且他们的汤做的真不错，一碗简单的青菜面都很好吃，例如上海清汤面。另外他们的小馄饨也很好吃，也是取决于汤很好，不过现在很难找到这么好吃的了。</p><p>当然，也要考虑到成本，现在如果你舍得消费 40-50 元人民币去吃一碗面，在广州还是能找到比较美味的面的，比如上下九、老西关那两家，此外以前还有一家上海风味的店：<strong> 寻人启示 </strong>【在兆佳业广场，不知道现在还开不开】，味道也很正宗。</p><p>汤固然很重要，但是普通人在家里做面条，不可能耗费那么多精力去熬制一锅汤出来，熬出来只做几碗面也很浪费。此时，可以有两个选择：</p><p>一个是购买 <strong>号称高汤的调料 </strong>，也就是使用一些浓缩骨粉、香料、调料混合制成的面汤专用调料，煮面的时候放在水里，可以把面汤调制成美味鲜香的汤。我小时候用过，当时觉得挺好吃的，但是现在吃起来明显味道不对，而且我担心健康问题。</p><p>二是直接购买 <strong>浓缩高汤液体 </strong>，一般的冷藏的，号称使用原汤制作，买回来尽快使用，不宜旧存，价格比较高，而且我也担心健康问题。</p><p>除了这些有没有其他选择了呢，有，那就是我下面的重点，最简单的番茄鸡蛋汤。这种汤做法简单，汤味鲜美，用来下面最合适。</p><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 以下食材适合 2 人食用，我自己吃是直接吃了一盆：</p><ul><li>番茄 2 个，选择粉的，不要脆的 </li><li> 手工新鲜面条 1 斤，最好是刚做出来的湿面条，实在没有挂面也可以，挂面就用不了 1 斤，半斤足够 </li><li> 鸡蛋 1-2 个 </li><li> 食用盐 </li><li> 其它配菜任选，例如青菜、酱牛肉、榨菜、牛肉丸 </li></ul><p> 番茄 2 个 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810222908.jpg" alt="番茄 2 个" title="番茄 2 个"></p><p> 手工湿面条 1 斤 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810222918.jpg" alt="手工湿面条 1 斤" title="手工湿面条 1 斤"></p><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><p> 从食材准备到出锅装盘，大概需要 20 分钟即可。</p><h2 id="番茄去皮切丁"><a href="# 番茄去皮切丁" class="headerlink" title="番茄去皮切丁"></a>番茄去皮切丁 </h2><p> 番茄切十字花刀，把番茄放在沸水中煮 1 分钟，并使用勺子不断浇番茄上半部分，然后就很容易去皮了。去皮后切丁，放在盘子中备用。</p><p>番茄切丁 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223007.jpg" alt="番茄切丁" title="番茄切丁"></p><h2 id="番茄丁下油锅"><a href="# 番茄丁下油锅" class="headerlink" title="番茄丁下油锅"></a> 番茄丁下油锅 </h2><p> 如果有吃鸡蛋面汤的需求，先把鸡蛋炒好，捣碎备用，番茄炒好后再放进去，一起煮汤。但是我是直接吃煎蛋，所以这里不放鸡蛋了。</p><p>开锅，加花生油，烧热后加入切好的番茄丁，快速翻炒，大概炒 1-2 分钟，番茄丁会产生糊状的酱汁，就可以准备加水了。</p><p>炒制番茄丁 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223120.jpg" alt="炒制番茄丁" title="炒制番茄丁"></p><h2 id="加水煮沸"><a href="# 加水煮沸" class="headerlink" title="加水煮沸"></a> 加水煮沸 </h2><p> 立马加适量水，稍微搅拌一下，接着煮沸。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223144.jpg" alt="加水煮沸" title="加水煮沸"></p><h2 id="下面条"><a href="# 下面条" class="headerlink" title="下面条"></a>下面条 </h2><p> 汤煮沸后开始加面条，注意要一点一点加，并及时搅拌，否则面条很容易粘连，那一锅面条就废了，如果感觉水量不够要及时加水，不要犹豫。</p><p>下面条 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223241.jpg" alt="下面条" title="下面条"></p><p> 适当搅拌防止粘连 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223310.jpg" alt="适当搅拌防止粘连" title="适当搅拌防止粘连"></p><h2 id="煮沸后加冷水"><a href="# 煮沸后加冷水" class="headerlink" title="煮沸后加冷水"></a> 煮沸后加冷水 </h2><p> 接着就是等待煮沸，此时需要反复三次煮沸，第一次煮沸后稍微加一点冷水，防止冒锅，后两次煮沸只要打开锅盖散气即可。<strong> 注意，这时候别忘记加盐。</strong></p><p>第一次煮沸加冷水 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223336.jpg" alt="第一次煮沸加冷水" title="第一次煮沸加冷水"></p><h2 id="出锅装盆"><a href="# 出锅装盆" class="headerlink" title="出锅装盆"></a> 出锅装盆 </h2><p> 最终出锅，装盆，一盆香喷喷的酸汤面就做好了。</p><p>配上煎蛋，再切几个牛肉丸，人间美味。注意，我这不是普通的碗，我这是盆，这一盆吃下去我真的有点撑了。我一开始就不想混鸡蛋在里面，怕汤喝不完浪费了，于是只放了番茄做酸汤，另外煎了一个鸡蛋。</p><p>一大盆被我吃光 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223431.jpg" alt="一大盆被我吃光" title="一大盆被我吃光"></p><h2 id="其它方式"><a href="# 其它方式" class="headerlink" title="其它方式"></a> 其它方式 </h2><p> 如果觉得汤里少了点什么，也可以选择一开始炒鸡蛋捣碎，然后放入汤中。别小看简单的鸡蛋番茄，做出来的汤非常好喝，一口气我可以喝两碗。</p><p>锅里的样子 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223452.jpg" alt="锅里的样子" title="锅里的样子"></p><p> 出锅装盆的样子 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190810223504.jpg" alt="出锅装盆的样子" title="出锅装盆的样子"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h1><p>1、番茄品种一定要选择 <strong> 粉 </strong>的，不要 <strong>脆 </strong>的，这样更容易熬制出美味的酸汤。</p><p>2、面条下锅后一定要迅速搅拌一下，防止面条粘连，特别是挂面，很容易就是一坨，导致里面的煮不熟。</p><p>3、关于面条的选择，我更倾向于选择手工湿面条，更好吃，挂面不好吃。</p><p>4、这种酸汤千万不要浪费，最好全喝了，营养又健康。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>patato</tag>
        <tag>noodles</tag>
        <tag>egg</tag>
        <tag>sugar</tag>
      </tags>
  </entry>
  <entry>
    <title>红烧肉做法总结</title>
    <url>/2018060301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>红烧肉，是一道做法非常简单的传统菜品，而且有多种版本，也有多种口味，同时基于红烧肉再补充其它配菜，又创新出了很多菜品。本文就讲述红烧肉的做法总结，口味偏甜，江南一带的做法。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 以下的食材份量大约 2 人份（实在吃多了也会腻的，要和其它菜配在一起吃）：</p><p>1、五花肉 500 克；</p><p>2、冰糖 30 克；</p><p>3、大葱 3 段、姜片 3 片、香叶 2 片、八角 2 个、桂皮 2 小块、大蒜 2 瓣（可以不用）；</p><p>4、老抽（糖色不够的时候加老抽补充颜色）、料酒、食用盐（看口味，有时候不需要加盐了）；</p><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a>制作步骤 </h1><p>1、配料准备，装盘备用，实际上只需要少量即可，比我想象中的少很多；</p><p> 几种大料准备 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyrlex1dtjj229s29s4qq.jpg" alt="几种大料准备" title="几种大料准备"></p><p>2、五花肉切块，本来应该切大块的，我的炒锅小，同时五花肉的量也少，不方便做，就切小块了（如果买的五花肉质量不好，肥肉肥油比较多的话，不适合直接下锅，最好焯水一下，把肥油过滤掉一些，如果肉的质量好，直接沥干水分就可以）；</p><p> 原始的五花肉 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyrloezvolj229s29sqv5.jpg" alt="原始的五花肉" title="原始的五花肉"></p><p>3、炒糖色，下五花肉，炒糖色其实就是放少量油，把冰糖融化，然后在高温下冰糖渐渐变色，类似棕色或者深红色，此时放进去的五花肉小块就有颜色了（如果炒糖色成功了，后面就不用放老抽了，但是要注意不能炒太久，否则糖会变苦），此步骤同时也可以把五花肉小块定型，防止煮的过久烂掉；</p><p> 给五花肉小块上色 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyrloooyzvj229s29su0x.jpg" alt="给五花肉小块上色" title="给五花肉小块上色"></p><p>4、加水（水量很重要，漫过所有的肉块再多一点，否则最后无法完成收汁操作），放大料，开大火煮开，然后转为小火，煮 50 分钟（中途可以晃一下锅，最好不要打开锅盖，还要注意一下水够不够）；</p><p> 加水，放大料 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyrltbkfs6j229s29se82.jpg" alt="加水，放大料" title="加水，放大料"></p><p> 煮了 30 分钟 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyrlucm7h6j229s29s7wi.jpg" alt="煮了 30 分钟" title="煮了 30 分钟"></p><p>5、50 分钟后，开锅，拣出大料，扔掉，开中火，收汁（一般 10 分钟就够，如果水量少了可能 3 分钟水就干了，看情况根据需要及时放老抽、食用盐等调料），我放的糖不多，于是加了一点食用盐，收汁完成盛出（可以看到我这份颜色还是不够啊），成品看起来虽然有点油腻，但是吃起来绝对肥而不腻，入口即化。</p><p> 拣出大料 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyrlx9fwekj229s29s4qp.jpg" alt="拣出大料" title="拣出大料"></p><p> 收汁完成，成品 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyrlxmebtsj229s29sqv6.jpg" alt="收汁完成，成品" title="收汁完成，成品"></p><p> 附加一份以前做的另外一份红烧肉，当时忘记炒糖色，只好使用老抽上色，并且加了很多盐，味道也是非常棒（由于变成了咸口味，感觉味道和卤肉差不多）<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy94c8f2csj229s29s7wi.jpg" alt="以前做的另外一份红烧肉" title="以前做的另外一份红烧肉"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a>注意事项 </h1><p>1、炒糖色这一步骤是为了替代生抽给红烧肉上色，那种棕色或者深红色是糖遇热产生的颜色，很好看（一开始炒完颜色很好看，然后加水煮的时候可能看不出来了，没关系，等最后收汁的时候颜色会回来的），此外，炒糖色这一步骤也可以不进行，直接在煮的时候放糖（增甜增鲜），然后最后加老抽上色即可；</p><p>2、大火煮开之后一定要转小火，慢慢煮（小火才能把肉煮的又透又软，达到入口即化的地步），就和普通的煲汤的火力一样，煮够 50 分钟；</p><p>3、其实只有在五花肉的质量非常好的情况下，才能免除焯水，一般的五花肉肥油太多，不提前处理一下做出来的红烧肉非常油腻。<br> 而且，很多人看到五花肉那么肥，就不想吃，或者觉得不好吃。其实不是的，正是由于肥肉的存在才能煮出那种香味，如果大部分都是瘦肉，也做不出来红烧肉，那种三肥七瘦的五花肉最好。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>红烧肉</tag>
      </tags>
  </entry>
  <entry>
    <title>腊肠炒饭做法总结</title>
    <url>/2019030901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>蛋炒饭，是一种常见的菜肴，日常生活中听到的最多的就是扬州炒饭、传统炒饭。其实炒饭的做法非常多，口味也非常多，还被改成了很多版本，例如：虾仁炒饭、滑蛋炒蛋、老干妈炒饭。但无论怎么改变，它们的共同点都是做法简单，准备米饭和配菜就行了，炒出来吃起来香喷喷的，口感极好，也不用单独配其它的菜了，很方便。本文就记录腊肠炒饭的家常做法。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 以下准备的是两人份的食材：</p><ul><li>腊肠，我这里选择的皇上皇腊肠，口味偏甜了，不适合炒饭，去买的时候广州酒家的咸香腊肠卖光了，先凑合着用 </li><li> 鸡蛋 2 个 </li><li> 米饭 2 小碗 </li><li> 青菜 1 小棵，普通的青菜即可，或者放绿豌豆也行，主要为了点缀一下 </li><li> 胡萝卜 1 小段 </li></ul><p> 腊肠，我买的这种偏甜了，不适合炒饭，下次还是买广州酒家的咸香腊肠比较好。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wn7ix32qj229s29s7wi.jpg" alt="皇上皇腊肠" title="皇上皇腊肠"></p><p>米饭 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wn80ipw8j229s29skjl.jpg" alt="米饭" title="米饭"></p><p> 全部食材 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wn8yzvcyj229s29shdu.jpg" alt="全部食材" title="全部食材"></p><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><h2 id="1、处理配菜"><a href="#1、处理配菜" class="headerlink" title="1、处理配菜"></a>1、处理配菜</h2><p> 配菜全部都切好备用：青菜切碎，腊肠切斜片，胡萝卜切丁，鸡蛋打入碗里搅拌，米饭捣碎。这里需要注意的有三点：一是胡萝卜要去皮，更能凸显颜色，而且没有胡萝卜皮的影响，炒饭吃起来口感也更好。二是米饭要捣碎，让米粒分开，不要一整块下锅，所以最好选择比较干硬的米饭来做炒饭，炒起来更方便，口感也更好。三是搅拌鸡蛋之前可以稍微放一点点食用盐，这样做为了鸡蛋更入味。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wn9b6cd2j229s29sb2a.jpg" alt="所有配菜处理完成" title="所有配菜处理完成"></p><h2 id="2、炒鸡蛋备用"><a href="#2、炒鸡蛋备用" class="headerlink" title="2、炒鸡蛋备用"></a>2、炒鸡蛋备用 </h2><p> 开火，锅里放油，一定要多放点油，因为鸡蛋非常吃油。放多点没关系，因为后续炒饭可以少放点。油烧热后，把鸡蛋液倒放进去，摇晃炒锅，让鸡蛋在里面呈圆形，防止鸡蛋液堆在一起。如果鸡蛋液太多了，可以在底部的鸡蛋液成型后，用锅铲拨到一边，让上边的鸡蛋液流下来，继续成型。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wn9xwk8jj229s29s1ky.jpg" alt="鸡蛋液入锅成型" title="鸡蛋液入锅成型"></p><p>鸡蛋基本成型后，就可以用锅铲搅拌捣碎。实际上用炒勺做就方便一点，如果是用锅铲就不太方便。这里需要注意，鸡蛋不要炒制太熟，要让它保持嫩嫩的，因为等一下还要和米饭一起重新下锅。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wna3znwnj229s29sb2a.jpg" alt="捣碎嫩鸡蛋" title="捣碎嫩鸡蛋"></p><p>捣碎后盛出备用，如果有时间的话，可以把鸡蛋的蛋清和蛋黄分别炒制，做出来的颜色会更好看。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wna81hkqj229s29sx6p.jpg" alt="盛出备用" title="盛出备用"></p><h2 id="3、炒配菜和饭"><a href="#3、炒配菜和饭" class="headerlink" title="3、炒配菜和饭"></a>3、炒配菜和饭 </h2><p> 鸡蛋盛出后，锅里表面其实还有大量的油，接着再稍微放一点点油就行了。继续加热，放入腊肠片、胡萝卜、碎青菜，大火炒 30 秒。<br>加腊肠片 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wnbf5yncj229s29shdu.jpg" alt="加腊肠片" title="加腊肠片"></p><p> 加胡萝卜青菜【我忘记放碎青菜了，出锅前才补上，看后面的图】<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wnbjhtc3j229s29s4qq.jpg" alt="加胡萝卜青菜" title="加胡萝卜青菜"></p><p>接着就开始加入米饭和刚才的鸡蛋，我这个米饭看起来是一块一块的，其实一碰就散了，开大火不停地翻炒。翻炒 3 分钟左右【如果一开始米饭没有捣碎，或者刚从冰箱拿出来的冷米饭，炒起来会比较慢】，基本就熟了，关小火，准备调味。</p><p>加入米饭和鸡蛋 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wnbopeilj229s29s1ky.jpg" alt="加入米饭和鸡蛋" title="加入米饭和鸡蛋"></p><p> 炒熟了，准备调味 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wnbti2c7j229s29sb2a.jpg" alt="准备调味" title="准备调味"></p><h2 id="4、调味出锅"><a href="#4、调味出锅" class="headerlink" title="4、调味出锅"></a>4、调味出锅</h2><p> 放入盐、鸡精、生抽、老抽，然后继续开大火，翻炒几十秒，出锅装盘，美滋滋。我还放了一点榨菜和辣椒酱。</p><p>放入调味料，因为放了老抽，可以看到颜色有一点点变化 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wnc0a62gj229s29shdu.jpg" alt="调味完成" title="调味完成"></p><p> 前面忘记放青菜了，补回来 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wngewbgvj229s29shdu.jpg" alt="补加青菜" title="补加青菜"></p><p> 出锅装盘，这图片有点糊了 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0wnc81e80j229s29s1ky.jpg" alt="出锅装盘" title="出锅装盘"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、米饭的选择，米饭不是随便都适合做炒饭的，要选择那种稍微干硬一点的，米粒都分开的，炒出来会更香。如果是剩米饭，已经是一整块了，千万不要一整块的下锅，很难分开，要提前捣碎，处理好再下锅炒。</p><p>2、一开始炒鸡蛋的时候，不要炒制太熟，要保持嫩嫩的，因为后面还要和米饭一起下锅。</p><p>3、腊肠的选择，不要选择偏甜的口味，否则最终的炒饭吃起来会有点腻，所以还是选择咸香的口味比较好。广州酒家的那种咸香的腊肠，用来炒饭真的很合适。</p><p>4、关于分量的建议，一般做炒饭至少两人的份量。因为如果只炒一份，各种菜只能放一点，放多了就不是炒饭了。那问题来了，剩下的菜不好办【半个胡萝卜、半棵青菜】，又不能存放太久，只能下次接着炒，甚至连续吃炒饭。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>腊肠炒饭</tag>
        <tag>蛋炒饭</tag>
        <tag>鸡蛋炒饭</tag>
        <tag>炒饭</tag>
      </tags>
  </entry>
  <entry>
    <title>蒸水蛋做法总结</title>
    <url>/2018122901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>蒸水蛋是一道小吃，有时候就简称为水蛋，可以当菜配饭吃，也可以配包子当做早餐，或者晚上蒸一碗当做宵夜，都非常好。吃起来嫩滑爽口，而且营养也丰富，做法非常简单，本文就记录蒸水蛋的过程。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p>2 人份的材料（1 人份减半即可，但是我觉得 1 人份的太少了，做起来浪费，不值当）：</p><ul><li> 鸡蛋 2 只（1 只做成 1 碗）</li><li>葱花少许 </li><li> 生抽少许 </li><li> 食用盐少许 </li><li> 香油少许 </li></ul><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><p>1、准备 2 只小碗（有条件的可以使用带盖子的蒸盅，也就是平时吃快餐盛汤的那种带盖子的小碗），普通的小饭碗即可，一定要是耐热的材料，不要用秸秆环保碗、塑料饭盒、普通玻璃碗等（蒸的时候温度很高，虽然水的沸点是 100 度，但是锅内因为有水蒸气存在，压强变大，同时水蒸气转为液态会放热，锅内实际温度大于 100 度），分别打入 1 只鸡蛋，加少许食用盐，搅拌均匀（下面过程就以 1 份为准，另外 1 份是同样的操作）；</p><p>2、搅拌均匀后开始加温水（最好是温水），温水的量大概是鸡蛋液的 2 倍，即鸡蛋液比温水等于 1:2，注意加温水的量，少了多了都不好（2-3 倍都行，如果碗大一点可能 1 份水蛋就需要放 2 只鸡蛋，不然显得太少了），继续搅拌，此时搅拌完成后表面应该会有一层小泡沫，可以用勺子把小泡沫都盛出去，保证蒸出来的水蛋表面光滑（怕浪费保留也行）；</p><p> 搅拌均匀 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5jgxdp2qj229s29sb29.jpg" alt="搅拌均匀" title="搅拌均匀"></p><p>3、蒸鸡蛋的时候使用保鲜膜封住碗口（有条件的使用整蛊更方便，盖子一盖即可），或者使用小盘子反盖在碗口，这样做是为了保证密封，一方面为了保证蒸出来的水蛋嫩滑，另一方面为了避免液化的水蒸气滴进去，影响水蛋的质量，先大火烧水，等水开后转为小火（火力很重要），再蒸 8 分钟即可出锅（这个时间很重要，太久了鸡蛋就老了）；</p><p> 开始蒸，我为了省事就不撇小泡沫，也不盖保鲜膜了，所以做出来的成品会有点难看 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5jhj31txj229s29skjl.jpg" alt="开始蒸" title="开始蒸"></p><p>4、取出后，滴入少许香油、生抽（不加也行，直接吃），撒入一点点葱花，即可食用，入口即化，滑嫩可口；</p><p> 成品 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5jhyeow6j229s29se81.jpg" alt="成品" title="成品"></p><p> 以下这个我认为是做失败的，加太多水，蒸的过程中不断滴入液化的水蒸气，破坏了美感，也没葱花，但是吃起来绝对美味。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyo56bfejij229s29sx6p.jpg" alt="很勉强的蒸水蛋" title="很勉强的蒸水蛋"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><p>1、食用盐是搅拌鸡蛋的时候就加入的，不是蒸好后再放的，这样才能入味而且分布均匀；</p><p>2、加水时一定要加温水，不是冷水，也不是热水，温水才能让蒸出来的水蛋保持嫩滑；</p><p>3、如果使用保鲜膜，一定要用可以蒸的材料，不是随便能用的。如果是 PVC 材料（聚氯乙烯），坚决不行，含有塑化剂释放有毒物质影响健康，如果是 PE 材料（聚乙烯），无毒，但是耐热温度不够，也不行，如果是 PVDC 材料（聚偏氯乙烯），安全温度在 140 度，可以使用。所以还是使用盘子比较好。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>蒸水蛋</tag>
        <tag>水蛋</tag>
        <tag>蒸鸡蛋</tag>
      </tags>
  </entry>
  <entry>
    <title>西红柿疙瘩汤做法总结</title>
    <url>/2018121601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>西红柿疙瘩汤，是一道做法非常简单的主食与配菜混为一起的菜肴，适合在寒冷的冬天食用，吃一碗热乎乎的，非常暖胃，我知道在中原地区（河南、安徽北部）都有这个做法。本文就讲述西红柿疙瘩汤的做法总结。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 以下的食材份量大约 2 人份：</p><ul><li>黄心乌菜一颗（实在没有使用其它青菜也可以）</li><li>西红柿一颗（粉的最好，与脆的对立）</li><li>鸡蛋 2 颗 </li><li> 面粉 100 克 </li><li> 小葱、香菜各 2 棵 </li><li> 调味料（食用盐、芝麻油）</li></ul><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a>制作步骤 </h1><p> 从开火到关火预计耗时 15-20 分钟。</p><p>0、葱花香菜段。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya5zv7hnmj229s29s4qq.jpg" alt="葱花香菜段" title="葱花香菜段"></p><p>1、西红柿去皮，划十字刀花，放入热水中烫 1 分钟左右，取出直接去皮，不去皮也行，但是会影响口感，去皮后切丁，切小一点，放入碗中备用。</p><p>粉粉的西红柿 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya5kxue8tj229s29se81.jpg" alt="一颗西红柿" title="一颗西红柿"></p><p> 十字花刀 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwaageagj229s29shdt.jpg" alt="十字花刀" title="十字花刀"></p><p> 开水烫 1 分钟（30 秒翻身一次），轻易去皮 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwbgrggsj229s29shdt.jpg" alt="开水烫 1 分钟" title="开水烫 1 分钟"></p><p> 西红柿去皮 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwc37dlbj229s29sb2a.jpg" alt="西红柿去皮" title="西红柿去皮"></p><p> 西红柿切丁 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwcm3w8nj229s29s4qq.jpg" alt="西红柿切丁" title="西红柿切丁"></p><p>2、准备黄心乌菜，洗干净，随便切（手撕也行，无所谓），切成条状或者小块状，别太大就行。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyp2f1kua2j229s29skjl.jpg" alt="黄心乌长这样" title="黄心乌长这样"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya5m1xtc6j229s29su0x.jpg" alt="黄心乌切碎" title="黄心乌切碎"></p><p>3、面粉放入大碗中，放在水龙头下，让水一滴一滴滴下来，迅速搅拌面粉，很快就可以做成面粒。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya5otcr3mj229s29s7wi.jpg" alt="面粒长这样" title="面粒长这样"></p><p>4、鸡蛋打入碗中，搅拌均匀备用。</p><p>5、锅烧热，倒入油，炒制西红柿丁，中小火炒制 3-5 分钟，此时西红柿的状态就是一半是糊状，一半是小颗粒，混合在一起，倒入开水（注意量的控制，比想象的多倒一点，面粒会吸收大量水分的），大火烧开。</p><p> 西红柿丁炒制 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwi298lzj229s29snpe.jpg" alt="西红柿丁炒制" title="西红柿丁炒制"></p><p> 加开水，煮开 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwinvlclj229s29s4qq.jpg" alt="加开水" title="加开水"></p><p>6、烧开后放入面粒，大火煮 5 分钟，面粒基本熟透，汤变得浓稠，放入青菜，中火继续煮 1 分钟左右，鸡蛋液慢慢淋入锅中，搅拌，放入食用盐，中火继续煮 2 分钟。</p><p> 放入面粒，继续煮 5 分钟 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwjke2u4j229s29s7wi.jpg" alt="放入面粒" title="放入面粒"></p><p>7、开锅，放入芝麻油、香菜段，葱花，搅拌十几秒，关火。</p><p> 一锅 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fy94yo4wibj229s29snpd.jpg" alt="一锅" title="一锅"></p><p> 一碗 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya5xkeysqj229s29shdt.jpg" alt="一碗" title="一碗"></p><p> 做完顺便又加了 2 个菜：<br>花菜回锅肉 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya60u5iacj229s29se81.jpg" alt="花菜回锅肉" title="花菜回锅肉"></p><p> 辣椒回锅肉 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya61058ppj229s29su0x.jpg" alt="辣椒回锅肉" title="辣椒回锅肉"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h1><p>1、青菜最好选择黄心乌，因为我一直吃的都是这种，黄心乌这种青菜一般在沿淮地区才播种，因为它比较耐寒，在秋季播种，在冬天收割，一般北方的冬天也看不到其它青菜可以生长了。</p><p>2、条件允许的话，可以放一点酱肉之类的肉粒进去，更能增加食欲。</p><p>3、做面粒的时候切记不要直接倒水搅拌，这样是做不成的一粒一粒的效果的，只能用水滴进去然后迅速搅拌，使水滴周围裹上面粉形成一粒，很快就全部都是面粒了，而且很均匀，另外，做好面粒后要立马使用，不要提前做好放那里，因为放久了（10 分钟都不行）面粒会粘连在一起，实在要放的话再多加点面粉进去，让面粒之间隔开。</p><p>4、西红柿最好选择粉的，就是那种吃起来很柔绵的，更容易做成均匀的汤。</p><p>5、如果在煮的过程中发现有点粘锅，那是因为水少了，面太多了，这时候用汤勺试着加 1-2 勺水进去，再搅拌一下，如果还是粘锅再加 1-2 勺，千万不要一下子加很多水，面汤最好的状态就是不粘锅但是又很浓稠。</p><p>6、做回锅肉，肉要煮到什么程度才能回锅，简单的判断方法就是筷子可以轻易穿透肉，一般要煮 20 分钟以上。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fya63x2errj229s29snpd.jpg" alt="肉回锅之前" title="肉回锅之前"></p><h1 id="补充说明"><a href="# 补充说明" class="headerlink" title="补充说明"></a> 补充说明</h1><p>2018 年 12 月 23 日，广州突然降温，降到 17 度左右（前一天的冬至还 25 度呢，短袖都穿起来了），天气冷了，于是又煮了一锅。可惜这次没买到香菜，没买到黄心乌菜，也没买到酱肉，凑活着吃。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyiauqznd7j229s29sx6p.jpg" alt="2018 年 12 月 23 日又煮了一锅" title="2018 年 12 月 23 日又煮了一锅"></p><p>2018 年 12 月 30 日，广州的温度降到了个位数，最低 5 度，实在是冷。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fypwm9ud6ij229s29shdt.jpg" alt="2018 年 12 月 31 日" title="2018 年 12 月 31 日"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>西红柿疙瘩汤</tag>
        <tag>疙瘩汤</tag>
      </tags>
  </entry>
  <entry>
    <title>爆炒花甲做法总结</title>
    <url>/2019032501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>爆炒花甲是一道做法简单、快速出菜、可口下饭的家常菜，一般晚上去大排档吃夜宵，基本都会有这道菜。本文记录爆炒花甲的家常做法，以及需要注意的地方。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 以下份量为一盘：</p><ul><li>花甲 1.5 斤 - 2 斤，花甲的价格一般在 6-10 块钱之间【广州地区】</li><li>二荆条辣椒 2 个，细长条那种，不是很辣 </li><li> 小米椒 5 个，我用干辣椒和辣椒酱代替了 </li><li> 豆瓣酱、蚝油、食用盐、淀粉 </li><li> 大蒜、香葱，香葱我用青椒代替了 </li></ul><p> 辣椒食材 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5ne1e6kj229s29se81.jpg" alt="辣椒食材" title="辣椒食材"></p><p> 辣椒切碎备用 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5njohsrj229s29se82.jpg" alt="辣椒切碎备用" title="辣椒切碎备用"></p><p> 准备工作中最重要的就是让花甲吐沙，一般买回来的花甲里面都会有大量的沙子，所以要让花甲把沙子吐出来，这样吃起来才不会硌牙，否则会严重影响口感，没法吃。</p><p>花甲吐沙方法主要有两种：</p><ul><li>方法 1【时间长，简单】：放入清水、食用盐、香油，浸泡一个小时，基本可以把沙吐干净。</li><li>方法 2【时间短，麻烦】：放入锅中，加入清水、料酒、姜片、香油，小火煮热【不要很热，保持不烫手的温度，否则会严重影响肉质】，持续 15 分钟，也可以把沙吐干净。</li></ul><p>我一般选择第一种，花甲买回来之后放在盆里，加入盐、香油等着就行了，可以先去处理其它食材了，不用管，很方便。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5oxjyxmj229s29se82.jpg" alt="让花甲吐沙" title="让花甲吐沙"></p><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a>制作步骤 </h1><h2 id="花甲焯水"><a href="# 花甲焯水" class="headerlink" title="花甲焯水"></a> 花甲焯水 </h2><p> 花甲吐沙完成之后，捞出进行焯水，焯水之后花甲基本熟了，然后捞出花甲迅速过冷水，过冷水的目的是保持花甲肉的鲜嫩。注意焯水不要太久，否则花甲肉就老了，影响口感。我把花甲焯水的时候还加了姜片和料酒去腥。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5pebk8cj229s29s4qq.jpg" alt="花甲焯水" title="花甲焯水"></p><h2 id="爆香锅底"><a href="# 爆香锅底" class="headerlink" title="爆香锅底"></a>爆香锅底 </h2><p> 油烧热，一定要比平时炒菜多放一点油，毕竟是爆炒，加入大蒜、辣椒、姜片，十几秒爆香，我这里省略了姜片，因为焯水的时候用的水里面加了姜片和料酒。大蒜也不加了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5qj41y0j229s29skjm.jpg" alt="爆香锅底" title="爆香锅底"></p><h2 id="豆瓣酱或者蚝油调味"><a href="# 豆瓣酱或者蚝油调味" class="headerlink" title="豆瓣酱或者蚝油调味"></a>豆瓣酱或者蚝油调味 </h2><p> 关小火，加入豆瓣酱，调和味道，我没有豆瓣酱，就用蚝油代替了。</p><h2 id="爆炒花甲"><a href="# 爆炒花甲" class="headerlink" title="爆炒花甲"></a>爆炒花甲 </h2><p> 味道调和好后，加入过冷水的花甲，开大火，爆炒。</p><p>爆炒 3 分钟后关小火调味【时间实际依据灶的火力大小，家用灶一般火不够大，要多炒一会】，加入食用盐【如果豆瓣酱或者生抽够味就不用加盐了】、生抽、辣椒酱，大火翻炒十几秒。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5r7ayuaj229s29shdu.jpg" alt="爆炒花甲" title="爆炒花甲"></p><p>我又补了一点辣椒酱 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5y5pj3ej229s29sb2a.jpg" alt="补了一点辣椒酱" title="补了一点辣椒酱"></p><p> 最后一步也很关键，使用淀粉液勾芡，目的是让味道均匀包裹在花甲的表面，否则味道都会遗留在锅里，导致花甲味道偏淡。勾芡可以实现真正入味的效果。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5rkc386j229s29shdu.jpg" alt="淀粉液勾芡" title="淀粉液勾芡"></p><h2 id="出锅装盘"><a href="# 出锅装盘" class="headerlink" title="出锅装盘"></a>出锅装盘 </h2><p> 如果有香葱的话，出锅前再放一点点香葱，更好看，味道也更好。我这里没放香葱，使用青椒代替了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5s40v2jj229s29su0x.jpg" alt="出锅装盘" title="出锅装盘"></p><h2 id="其它配菜"><a href="# 其它配菜" class="headerlink" title="其它配菜"></a>其它配菜 </h2><p> 顺手做了一道红烧肉，加了香菇和 2 个鸡蛋，有点偏卤肉的口味了。</p><p>红烧肉收汁阶段 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5spgpkhj229s29sb2a.jpg" alt="红烧肉收汁阶段" title="红烧肉收汁阶段"></p><p> 红烧肉成品 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1l5su5ddgj229s29sqv5.jpg" alt="红烧肉成品" title="红烧肉成品"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h1><h2 id="花甲吐沙"><a href="# 花甲吐沙" class="headerlink" title="花甲吐沙"></a> 花甲吐沙 </h2><p> 花甲吐沙一定要做好，不可匆匆了事，否则花甲吃起来全部都是沙子就不好了，严重影响口感，另外还要注意在爆炒的时候会有一些花甲壳碎掉，混在花甲肉里面，吃的时候也要注意一下，虽然不是沙子，但是也会硌牙。</p><h2 id="花甲焯水 -1"><a href="# 花甲焯水 -1" class="headerlink" title="花甲焯水"></a>花甲焯水 </h2><p> 花甲焯水，可以适当放一点姜片、料酒，去腥味。当然，如果吐沙的方法采用的是温水慢煮的方式，可以不用再放任何调料了，直接焯水就行了。焯水时要切记水不能太沸腾，或者不要一直放在沸水里面，要适当用漏勺翻一下，否则会导致花甲肉全部脱离花甲壳了，这个和花甲新不新鲜无关，水太沸腾会导致大量的花甲肉脱离花甲壳。</p><h2 id="勾芡"><a href="# 勾芡" class="headerlink" title="勾芡"></a>勾芡 </h2><p> 勾芡，才能保证味道均匀分布在花甲表面，吃起来才有入味的效果，否则调味料大部分都粘在锅的表面了。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>爆炒花甲</tag>
        <tag>麻辣花甲</tag>
        <tag>炒花甲</tag>
      </tags>
  </entry>
  <entry>
    <title>解决 IDEA 无法创建子包的问题</title>
    <url>/2017042201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近在使用 IDEA 的时候，发现一个奇怪的问题，如果新建了一个多层的包，再想新建一个和除第一层包之外的包等级别的子包就不行。说的这么绕口，什么意思呢？举例来说，比如我新建了一个包，完整路径为：a.b.c.d，如果再想新建一个和 d 等级别的子包 e：a.b.c.e，就不行，IDEA 会默认在 d 下面新建一个子包，那整个包就变成了：a.b.c.d.e，这显然是不合常理的，也不是我需要的。本文记录这个问题的解决方案。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 当在 IDEA 中新建一个 Java 项目的包时，完整路径为：org.playpi.blog，再想新建一个和 blog 等级别的包：www，结果发现 www 是建在了 blog 下面，那就变成了 org.playpi.blog.www，这不是我想要的结果。</p><p>新建一个包 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2czihdz8nj20c209wq32.jpg" alt="新建一个包" title="新建一个包"></p><p> 新建一个子包 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2czimvkzsj20cx09zwem.jpg" alt="新建一个子包" title="新建一个子包"></p><p> 注意，上面的现象是在包只有一个的情况下，还没有创建等级别的其它包，如果创建了等级别的其它包就不会有这种现象了。例如如果已经有了 org.playpi.blog、org.playpi.www，再想创建一个 org.playpi.doc，是可以做到的。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 有一种粗暴并且略微繁琐的方法，那就是在新建多层的包时，不要单独创建，而是一层一层创建，并且和类文件【或者其它类型的文件也行，只要不是单纯的包即可】一起创建，这样就可以稳妥地创建多个等级别的包了。但是这种做法显然很傻，而且有时候根本不需要每个包都有等级别的包存在。</p><p>其实，IDEA 有自己的设置方式，可以看到在项目树形结构的右上方，有一个设置按钮【齿轮形状】，点开，可以看到 <strong>Hide Empty Middle Packages</strong>，意思就是 <strong>隐藏空白的中间包 </strong>，这个选项默认是开启的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cziytewrj20iz0in75p.jpg" alt="隐藏空白包设置" title="隐藏空白包设置"></p><p>注意，这里的 <strong>Empty Packages</strong> 并不是严格意义上的空包【对应对操作系统的空文件夹】，而是指包里面只有一个子包，并没有其它的类文件或者任意文件。</p><p>所以，新建的多层的包都会被隐藏，再新建子包时，默认是从最深处的包下面创建，这样也就发生了问题出现的那一幕。</p><p>解决起来就很容易，把这个选项去掉，不要隐藏，全部的包都显示，这样就可以轻松地新建多个子包了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2czj69uxcj20d70co74j.jpg" alt="轻松创建同级别的子包" title="轻松创建同级别的子包"></p><p>这样做有一个缺点，对于那些有多个空白包的情况， 都显示出来很难看，不友好，所以最好还是在需要时临时关闭这个选项，等不需要了再打开，毕竟隐藏空白包的效果看起来还是很清爽的。</p><p>注意，当去掉隐藏选项时，选项的名字会变为 <strong>Compact Empty Middle Packages</strong>，收起空白包，其实意思和隐藏空白包一样。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2czm384wyj20cw05v74b.jpg" alt="Compact 收起空白包设置" title="Compact 收起空白包设置"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>package</tag>
      </tags>
  </entry>
  <entry>
    <title>踩坑特殊字符之硬空格</title>
    <url>/2018090601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近处理数据的过程中，发现一个奇怪的问题，处理数据逻辑如下：有一个短字符串，我需要从一个长字符串寻找这个短字符串是否出现。这个逻辑很简单，使用任何一种编程语言，基本上都会有 <strong>包含 </strong>这种方法，直接就可以判断了，但是我遇到的情况明明就是包含了，子串就是存在，但是判断结果却不包含。另外我又直接把 2 个字符串单独取出来，肉眼去看，也是包含的。愁眉苦展之际，突然灵光闪现：会不会字符串中包含一些奇怪的特殊字符，并且肉眼难以发现。于是立马去验证一下，果然是这样，解决了我的问题，本文记录解决这个小问题的过程。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在使用 <code>Java</code> 编程语言处理数据的时候，有一个字符串包含判断的逻辑，明明是包含关系，判断的结果却是不包含，代码示例如下【看下面截图，由于页面转换问题以下的代码块中丢失了这个字符】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void containsTest () &#123;</span><br><span class="line">    System.out.println (&quot; 每当 #每月 28 日京东企业会员日 #来临，就会有优惠 & quot;.contains (&quot;# 每月 28 日京东企业会员日 # &quot;.trim ()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g07hqpog0vj20x208umxi.jpg" alt="运行结果" title="运行结果"></p><p>尽管加上了 <code>trim ()</code> 方法，但是返回结果仍然是 <code>false</code>，足以说明子串中头尾有某个符号很特殊，并没有被清除掉，所以我觉得很蹊跷。虽然在代码和截图中，那个大大的空格【其实不是空格字符】看起来很显眼，但是在实际运用中是在文本中存放的，而且不止这一个字符串，有很多，所以在检查时使用搜索替换功能【把空格替换为空白】，也是没把这个特殊符号清除掉。同时，也没有料想到文本中会出现这样特殊的符号，所以只是简单地使用 <code>trim ()</code> 方法来清除头尾空白符【还以为生效了，其实遇到这种特殊的符号就没作用了】。</p><p>把内容复制到 <code>Notepad++</code> 文本编辑器中，并且设置文本编辑器的视图显示所有的字符【会用带有颜色的特殊图标来表示文本中的特殊字符，例如肉眼看不到的字符：空格、换行等】，然后可以看到空格【橙色点点】、<code>Tab</code> 符号【橙色箭头】、回车换行【黑块】都会显示出来，但是唯独这个特殊字符没有显示出来，仍然是空白一片。</p><p>使用文本编辑器打开 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g07hrpcs2nj20dr05naa0.jpg" alt="使用文本编辑器打开" title="使用文本编辑器打开"></p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a> 问题解决 </h1><p> 已经知道这是个特殊字符了，下一步只要搞清楚这是个什么字符就行了，问题就会迎刃而解。</p><p>先把特殊字符复制出来，找一个转码器，把字符转为十六进制编码，看看它的编码是什么，在线编码转换工具参考：<a href="http://ctf.ssleye.com/jinzhi.html" target="_blank" rel="noopener">http://ctf.ssleye.com/jinzhi.html</a> 。在 <strong>文本 </strong>这个文本框中输入特殊字符【–&gt; &lt;–】，然后在 <strong>十六进制 </strong>文本框中可以看到编码是 <code>a0</code>。</p><p>可以看到十六进制的结果是 <code>a0</code><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g07hslk62uj216i0k3glx.jpg" alt="转码结果" title="转码结果"></p><p>好，接下来去 <code>Unicode</code> 字符列表，维基百科里面的：<br><a href="https://zh.wikipedia.org/wiki/Unicode% E5% AD%97% E7% AC% A6% E5%88%97% E8% A1% A8" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Unicode% E5% AD%97% E7% AC% A6% E5%88%97% E8% A1% A8</a> 。</p><p>查看这到底是个什么特殊字符。直接搜索 <code>00A0</code>，就可以找到，发现这是 <strong>不换行空格 </strong>，在 <strong>拉丁字符 - 1 辅助 </strong>里面。</p><p>不换行空格 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g07hti5hfcj20pg06vaae.jpg" alt="不换行空格" title="不换行空格"></p><p> 更进一步，我去维基百科查看这一特殊符号的介绍，发现这个符号还是挺有用的，附上链接：<br><a href="https://zh.wikipedia.org/wiki/% E4% B8%8D% E6%8D% A2% E8% A1%8C% E7% A9% BA% E6% A0% BC" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/% E4% B8%8D% E6%8D% A2% E8% A1%8C% E7% A9% BA% E6% A0% BC</a> 。</p><p>不换行空格介绍，一般用在网页排版中 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g07htzx43wj21bb0lhabp.jpg" alt="不换行空格介绍" title="不换行空格介绍"></p><p> 至此，问题原因找到了，我竟然被一个特殊符号坑了【以前也被输入法的全角、半角问题坑过】，那解决办法就很简单了，针对这种符号做替换清除就行了。</p><p>我仍在思考，这个符号是怎么被输进文本文件给我的，因为正常人通过输入法不可能打出这个符号。后来询问相关人，得知他们是从网页上直接复制的内容粘贴到文本文件中，这就可以解释了，因为这个符号就是针对网页的自动压缩空白符问题，量身定做的，怪不得。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p>1、这个特殊字符【–&gt; &lt;–，编码 <code>a0</code>】有些编辑器不一定支持，会产生丢失，例如我把这条字符串内容放在了 <code>Tower</code> 上面的任务回复中，想记录一下，结果再复制下来就变成了空格字符，说明丢失了【并且被转为了空格字符】。但是没关系，我们记住它的 <code>Unicode</code> 编码就行了，找一个工具，例如：<br><a href="http://ctf.ssleye.com/jinzhi.html" target="_blank" rel="noopener">http://ctf.ssleye.com/jinzhi.html</a> 。</p><p> 就可以转换了，<code>Unicode</code> 编码是：<code>U+00A0</code>，把 <code>a0</code> 复制到 <strong>十六进制 </strong>的文本框中，则 <strong>文本 </strong>这个文本框中出现的就是它的字符，当然，直接肉眼看不出来，要选中变为蓝色才会发现有一个字符。</p><p>编码恢复到字符<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g07hvtm04xj216n0l7gm2.jpg" alt="编码恢复到字符" title="编码恢复到字符"></p><p>2、以后处理字符串问题的时候，一定要区分场景，真的是自己知识面之外的情况都可能出现，而且是正常的，自己千万不要怀疑人生，而是要抽丝剥茧，一步一步找问题。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>硬空格</tag>
        <tag>不换行空格</tag>
        <tag>hard-space</tag>
        <tag>fixed-space</tag>
      </tags>
  </entry>
  <entry>
    <title>辣椒炒肉做法总结</title>
    <url>/2018063001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>辣椒炒肉，农家小炒肉，青椒肉片，很多类似的菜品，有的是川菜，有的是湘菜，但是它们有一个共同点，都是食材简单、可口下饭，本文就讲述辣椒炒肉的步骤以及需要注意的地方，本文讲述的做法是湘菜的做法。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 辣椒炒肉的食材比较简单：</p><ul><li>辣椒 4 个（最好是螺丝椒，次之也可以用普通的青椒）</li><li>二刀肉 300 克（或者是普通的后腿肉也行，实在没有用前腿肉也勉强可以，确保肥瘦比例是 2：3 就行了，一定要有肥肉）</li><li>老抽、生抽、料酒（用来腌制瘦肉使用，最后也要使用生抽提鲜）</li><li>食用盐 </li><li> 大蒜 5 瓣 </li></ul><h1 id="炒制步骤"><a href="# 炒制步骤" class="headerlink" title="炒制步骤"></a> 炒制步骤 </h1><p>1、螺丝椒 4 个，脆嫩皮薄，买的时候一定要挑选颜色比较鲜亮的（颜色发暗的不能要，不新鲜了），同时捏起来比较脆硬（软的不能要），说明新鲜。此外尽量挑大个的，比较容易去籽、容易滚刀切。买回来后去除头部，去除籽粒（一定要去除干净，否则炒制的时候辣椒籽容易变黑变苦，影响颜色与口感，当然稍微有个别的辣椒籽可以忽略），滚刀切成小块，沥干水分（尽量让它保持干燥）。</p><p> 认准螺丝椒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy2vu2axj229s29sqv5.jpg" alt="买这样的螺丝椒" title="买这样的螺丝椒"></p><p> 螺丝椒去籽洗干净 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy4y0iglj229s29su0x.jpg" alt="去籽洗干净" title="去籽洗干净"></p><p> 滚刀切螺丝椒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy5bbuz8j229s29s7wi.jpg" alt="滚刀切" title="滚刀切"></p><p>2、将二刀肉去皮，肥瘦分离（这个步骤自己处理比较麻烦，最好让卖肉的大叔大姐帮忙处理了），肥肉切片，稍微切大一点，方便后续炼油，沥干水分，不做任何处理，直接放入碗中备用。瘦肉也是切片，放入碗中，接着放入生抽、老抽、食用盐、料酒，用手搅拌 1 分钟，再腌制 10 分钟。</p><p> 肥肉沥干水分装碗备用 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy5rzay8j229s29s7wh.jpg" alt="肥肉" title="肥肉"></p><p> 腌制瘦肉 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy6pantsj229s29sb29.jpg" alt="瘦肉" title="瘦肉"></p><p>3、大蒜切片，每一瓣切 3-5 片，尽量厚一点，备用。</p><p> 忽略掉旁边的葱花和蒜粒，那是炒其它菜使用的 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy8gu12sj229s29snpd.jpg" alt="大蒜切片" title="大蒜切片"></p><p>4、干锅煸炒辣椒（这个过程大概 3 分钟），先将炒锅烧干烧热，不放油、不放水，直接将步骤 1 中切好的辣椒片扔进去（这也是辣椒切好后必须沥干水分的原因），就是干煸，这是决定这道菜口感的第一步。控制中小火（大火容易糊），让辣椒块水分逐渐挥发，表皮起皱，即俗称起虎皮，这时候会有少量烟冒出，并伴随着独特的呛香辣味（像我这样家里没有抽油烟机的，只能在旁边准备好湿毛巾，不时去捂一下口鼻）。此时可以稍微放一点食用盐，这样辣椒才能入味，看到辣椒表皮起皱了，就可以了，切记不能熟透（熟透严重影响口感，因为最后还要回锅调味）。此时大概七八分熟，俗称断生，盛出放入碗中备用。</p><p>5、炒制肥肉（这个过程大概 6 分钟），大火将炒锅烧热，放入少量花生油（少量就可以，只是为了防止肥肉下锅时粘锅，不是为了炒菜），下肥肉，先煸炒 1 分钟，待煸炒出少量猪油，火力转中小火，开始炼油。这里耗费时间长一点，大概 5 分钟，肥肉慢慢消失，本来的肥肉块越来越小，越来越干，炼出了很多猪油，很香。</p><p> 肥肉炼油，很香 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy9gtgaqj229s29su0z.jpg" alt="肥肉炼油" title="肥肉炼油"></p><p>6、炒制瘦肉（这个过程大概 1 分钟），等步骤 5 中的肥肉炼成了肉干（这里自己把握，也可以炼油时间短一点，保留多一点肥肉，吃起来更香），火力转大火，将步骤 2 中腌制的瘦肉倒进来翻炒，大概 1 分钟，炒到瘦肉变色，基本熟了。</p><p>7、调味翻炒，辣椒回锅（这个过程大概 2 分钟，根据放调味料和辣椒的速度而定），等瘦肉基本熟了，放入大蒜片（不是一开始和瘦肉一起放，否则大蒜片都炒烂了），此时按照湖南的做法，还要放点豆豉进来（注意这是几秒内就要完成的动作，如果大蒜片和豆豉没放在边上，记得先关小火，等放完了再开大火）。接着把步骤 4 中的干煸后的辣椒倒进来，先翻炒几下，然后不停地用锅铲戳，戳 1 分钟左右，倒点生抽提鲜，放点食用盐，再翻炒 10 秒，关火。</p><p> 辣椒炒肉成品，不过辣椒有点炒过头，老抽放的少了 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxzy7by7zej229s29skjl.jpg" alt="辣椒炒肉成品" title="辣椒炒肉成品"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h1><p>1、所谓 <strong> 二刀肉 </strong>，是指屠户旋掉猪尾巴那圈肉以后，靠近后腿的那块肉，因为它是第二刀，顾名思义，就称为二刀肉。那地方的肉有肥有瘦，肥瘦搭配，一刀肉肥的多，二刀肉是 <strong>肥四瘦六 </strong>，比较适合做这道菜，同时也适合做 <strong>回锅肉 </strong>这道菜。</p><p>2、腌制瘦肉，煸炒辣椒块，都已经放过少量的盐了，所以最后千万不要又放了很多盐，根据个人口味添加。</p><p>3、购买辣椒时，一定要选择新鲜的，否则口感不好。</p><p>4、步骤 4 中的干煸辣椒千万不要把辣椒炒熟了，否则最后的成品辣椒不够脆嫩，而且辣味会全部丢失。</p><p>5、这道菜看起来注定非常油腻，因为肥肉炼出了大量的猪油，但是吃起来不会腻，而且菜底的这个油非常香，甚至可以用来拌饭吃。但是要注意，如果炼油的时候发现炼出来的油过多，还是要倒出来一些的，否则真的很油腻。</p><p>6、为了让成品的颜色好看一点，腌制瘦肉时需要老抽，如果在炒制瘦肉的最后发现颜色不够，可以再补加一点老抽。当然，如果有豆瓣酱，基本不用放老抽了。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>辣椒炒肉</tag>
        <tag>川菜</tag>
        <tag>湘菜</tag>
      </tags>
  </entry>
  <entry>
    <title>重装系统后软件环境清单</title>
    <url>/2019102401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近又重装电脑系统了，<code>Windows 10</code>，需要搞很多开发工具的初始化，整个流程操作下来感觉挺麻烦的，而且显得很混乱。因此，我整理这一份文档，把基础环境的安装过程记录下来，需要安装哪些工具、配置哪些参数，都一一列举，为以后的重装系统做指导，同时也给部分读者参考。</p><p>以后如果有新增内容会持续补充。</p><a id="more"></a><h1 id="基础环境"><a href="# 基础环境" class="headerlink" title="基础环境"></a>基础环境 </h1><ol><li><p><code>JDK</code>，<code>Java</code> 开发基础工具，包含虚拟机、依赖包等。</p></li><li><p><code>Maven</code>，项目管理工具，非常流行。</p></li><li><p><code>Git</code>，版本控制系统，非常流行。</p></li><li><p><code>Nodejs</code>，一个流行的 <code>js</code> 库。</p></li><li><p><code>Python</code>，<code>Python</code> 开发基础工具。</p></li><li><p><code>Shadiwsocks</code>，一款代理客户端。</p></li><li><p><code>Chrome</code> 浏览器，一款流行全球的浏览器。</p></li><li><p><code>Gradle</code>，项目管理工具。</p></li><li><p><code>Scala</code>，<code>Scala</code> 开发基础工具。</p></li><li><p><code>Memory Analyzer</code>，一款内存诊断分析工具。</p></li></ol><h1 id="开发工具"><a href="# 开发工具" class="headerlink" title="开发工具"></a> 开发工具 </h1><ol><li><p><code>IDEA</code>，<code>IntelliJ</code> 系列的 <code>Java</code> 开发工具，非常流行。</p></li><li><p><code>PyCharm</code>，<code>IntelliJ</code> 系列的 <code>Python</code> 开发工具，非常流行。</p></li><li><p><code>Notepad++</code>，文本编辑器，小巧好用【但是作者是 <code>td</code>，可以废弃】。</p></li><li><p><code>Sublime</code>，文本编辑器，好用。</p></li><li><p><code>Navicat</code>，一款 <code>MySQL</code> 可视化管理工具，好用。</p></li></ol><p> 曾经在某个论坛发现有人贡献了一枚注册码：<code>NAVN-LNXG-XHHX-5NOO</code>，用户名可以任意指定。</p><ol start="6"><li><p><code>Aria2</code>，一款下载工具，支持多种协议，线程数可以自定义。</p></li><li><p><code>Typora</code>，一款 <code>Markdown</code> 编辑器，简洁好用。</p></li><li><p><code>Xshell</code>，一款 <code>ssh</code> 工具。</p></li><li><p><code>Xftp</code>，一款 <code>ftp</code> 工具，用来传输文件。</p></li><li><p><code>Everything</code>，文件快速搜索工具，索引创建成功后，基本秒出，比 <code>Windows</code> 自带的文件浏览器快得多。</p></li><li><p><code>Android Studio</code>，一款安卓开发工具，非常流行。</p></li><li><p><code>AndroidKiller</code>，一款安卓逆向工具。</p></li><li><p><code>IDAPro</code>，一款逆向开发工具。</p></li><li><p><code>Wireshark</code>，一款网络抓包工具。</p></li><li><p><code>PostMan</code>，一款 <code>HTTP</code> 调试工具，非常好用。</p></li><li><p><code>xMind</code>，一款脑图工具。</p></li><li><p><code>RedisDesktop</code>，一款 <code>Redis</code> 可视化管理工具。</p></li><li><p><code>picGo</code>，图床上传工具。</p></li><li><p><code>ProcessExplorer</code>，<code>Windows</code> 进程查看工具。</p></li><li><p><code>Imagine</code>，一款图片压缩工具，压缩大小而不失真。</p></li><li><p><code>EditPlus</code>，文本编辑器。</p></li></ol><h1 id="附加工具"><a href="# 附加工具" class="headerlink" title="附加工具"></a>附加工具 </h1><ol><li><p> 迅雷下载，一款下载工具。</p></li><li><p>迅雷看看，一款视频播放工具。</p></li><li><p><code>PhotoShop</code>，即大家所说的 <code>PS</code>，用来修图。</p></li><li><p><code>Premiere</code>，即大家所说的 <code>PR</code>，用来剪辑视频。</p></li><li><p><code>ffmpeg</code>，视频剪辑命令行工具，小巧好用，例如截取、拼接、格式转换。</p></li><li><p><code>EmEditor</code>，专为 <code>csv</code> 文件开发，可以打开超大文件，例如几 <code>GB</code>、几十万行的文件可以被轻松打开【当然，操作系统的内存要大一点，例如 <code>8GB</code>、<code>16GB</code>】。</p></li></ol><p>曾经逛相关论坛，发现有人贡献了几个注册码，有效期到 2021 年 6 月份，可以试用一下【注册码可以开启一些高级功能】：</p><ul><li>DEAZV-27TFM-BL52D-PVN9L-ADULD，2021-06-11 到期 </li><li>DEAZW-38TGM-HH52D-XG5WR-FX4QW，2021-06-11 到期</li><li>DMAZW-48TGM-LQ52C-G82V6-2JJUC，2021-06-10 到期</li><li>DMAZW-4ATGM-QL52D-M6XEM-TCFCS，2021-06-11 到期</li></ul><ol start="7"><li><p><code>IDM</code>，即 <code>Internet Download Manager</code>，网络下载工具，支持多种协议，例如可以下载 <code>Youtube</code> 的视频</p></li><li><p><code>Tomcat</code>，一款服务器。</p></li><li><p><code>Nginx</code>，一款服务器。</p></li><li><p><code>Ditto</code>，好用的粘贴板工具，高效便捷。</p></li><li><p><code>HandShaker</code>，锤子科技的手机文件管理器，可以方便把手机连接至电脑。</p></li><li><p><code>Office</code>，微软系列的办公软件，例如 <code>Word</code>、<code>Excel</code>、<code>PPT</code> 等。</p></li><li><p><code>openVPN</code>，<code>VPN</code> 连接工具。</p></li><li><p><code>UItraCompare</code>，一款文件比较器，<code>UItra</code> 系列，另外还有一个 <code>UItraEdit</code>，文本编辑器。</p></li><li><p><code>WinRAR</code>，一款解压、压缩工具。</p></li><li><p> 易我数据恢复，一款数据恢复工具。</p></li><li><p><code>WPS</code>，金山系列的办公软件，例如 <code>Word</code>、<code>Excel</code>、<code>PPT</code> 等。</p></li><li><p><code>youtubu-dl</code>，一款下载工具，使用命令行操作，需要搭配 <code>Aria2</code> 使用</p></li></ol><!-- rebuild by neat -->]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>init</tag>
      </tags>
  </entry>
  <entry>
    <title>青椒炒蛋做法总结</title>
    <url>/2019033101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>青椒炒蛋，是一道非常普通的家常菜，基本家家户户都会做。有的家庭喜欢吃辣，放的是稍微辣一点的辣椒，有的家庭不喜欢吃辣，就放菜椒或者甜椒，总之，对于辣椒的选择非常多。对于辣椒的处理方式，有的人喜欢切小块，有的人喜欢斜切小段，还有的人直接剁碎，做法也多种多样。本文记录青椒炒蛋的做法总结，使用的是菜椒【不辣微甜】，由于故意多放了生抽，做出来的口味是咸香的。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 以下食材的份量为一大盘，足够 2 人吃，食材非常简单：</p><ul><li>鸡蛋 3 个 </li><li> 青椒 2 棵 </li><li> 大蒜 6 粒 </li><li> 食用盐、生抽酱油 </li></ul><p> 全部的食材 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb59lzf0j229s29sx6p.jpg" alt="全部的食材" title="全部的食材"></p><h1 id="制作过程"><a href="# 制作过程" class="headerlink" title="制作过程"></a> 制作过程 </h1><p> 这是一道快菜，制作过程根据家庭灶的火力大小，2-5 分钟即完成。</p><h2 id="处理食材备用"><a href="# 处理食材备用" class="headerlink" title="处理食材备用"></a>处理食材备用 </h2><p> 青椒洗净去籽切小快，鸡蛋液加少量食用盐搅拌均匀，大蒜切片。</p><p>青椒切块，大蒜切片 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb5ifv55j229s29sb2a.jpg" alt="青椒切块，大蒜切片" title="青椒切块，大蒜切片"></p><p> 鸡蛋液 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb5mnskjj229s29sb29.jpg" alt="鸡蛋液" title="鸡蛋液"></p><h2 id="炒鸡蛋备用"><a href="# 炒鸡蛋备用" class="headerlink" title="炒鸡蛋备用"></a> 炒鸡蛋备用 </h2><p> 锅里加油，要多加一点，鸡蛋液很吸油，烧热后下鸡蛋液，定型后炒散，炒散后盛出备用。由于鸡蛋液里面已经加了食用盐，就不用再加盐调味了。</p><p>鸡蛋液下锅 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb5rk896j229s29s4qq.jpg" alt="鸡蛋液下锅" title="鸡蛋液下锅"></p><p> 定型炒散 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb5x5pt6j229s29skjl.jpg" alt="定型炒散" title="定型炒散"></p><p> 鸡蛋盛出备用 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb62uunrj229s29sqv5.jpg" alt="鸡蛋盛出备用" title="鸡蛋盛出备用"></p><h2 id="炒青椒大蒜"><a href="# 炒青椒大蒜" class="headerlink" title="炒青椒大蒜"></a> 炒青椒大蒜 </h2><p> 锅里留底油，如果炒完鸡蛋后不够再适当加点油，烧热，大蒜片和青椒同时下锅翻炒【注意是同时下锅】，翻炒至青椒 5 成熟，关小火准备加生抽调味。</p><p>青椒大蒜同时下锅 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb6hcvv2j229s29snpe.jpg" alt="青椒大蒜同时下锅" title="青椒大蒜同时下锅"></p><p> 翻炒至青椒 5 成熟 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb6n92i2j229s29snpe.jpg" alt="翻炒至青椒 5 成熟" title="翻炒至青椒 5 成熟"></p><h2 id="加生抽调味后下鸡蛋"><a href="# 加生抽调味后下鸡蛋" class="headerlink" title="加生抽调味后下鸡蛋"></a> 加生抽调味后下鸡蛋 </h2><p> 青椒翻炒至 5 成熟时，关小火，加生抽调味。注意一定要加多一点生抽，那种大的汤勺可以加将近一汤勺，然后开大火翻炒，把青椒炒至 8 成熟，生抽遇到大火热量时会散发独特的香味。</p><p>加生抽炒至青椒 8 成熟 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb72tpblj229s29snpe.jpg" alt="加生抽炒至青椒 8 成熟" title="加生抽炒至青椒 8 成熟"></p><p> 此时倒入前面炒过的鸡蛋，混合翻炒，如果觉得不够味再加一点食用盐，我加的生抽已经够味，不再加食用盐了。</p><p>倒入鸡蛋 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb7dw5nvj229s29se82.jpg" alt="倒入鸡蛋" title="倒入鸡蛋"></p><p> 翻炒均匀 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb7i7j4wj229s29skjm.jpg" alt="翻炒均匀" title="翻炒均匀"></p><h2 id="出锅装盘"><a href="# 出锅装盘" class="headerlink" title="出锅装盘"></a> 出锅装盘 </h2><p> 翻炒均匀后可以出锅装盘了。</p><p>装盘侧视图 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb7odz35j229s29sqv5.jpg" alt="装盘侧视图" title="装盘侧视图"></p><p> 装盘俯视图 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb7s48a3j229s29snpd.jpg" alt="装盘俯视图" title="装盘俯视图"></p><p> 配上剩下的几块红烧肉，美滋滋。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1mb7ww16ej229s29sqv5.jpg" alt="配上剩下的几块红烧肉，美滋滋" title="配上剩下的几块红烧肉，美滋滋"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a>注意事项 </h1><p>1、炒青椒时和大蒜片一起下锅，不需要先下大蒜片爆香，这很关键。</p><p>2、油量，炒鸡蛋的时候一定要多放一点油，才能保持鸡蛋的嫩滑，因为鸡蛋液吸油很厉害。如果油加的少，会导致鸡蛋炒的有点干有点糊，影响口感。</p><p>3、炒青椒的时候为什么要多加一点生抽呢，毕竟会影响这道菜的颜色，一般炒菜都只会在最后调味时加一点点。因为使用青椒来炒鸡蛋，这种青椒是没有什么味道的，那样只会有鸡蛋的香味，显得太单调，而生抽遇到热量会散发出独特的香味，同时生抽里面又有盐分，从而达到了咸香的效果。就如北方有些地方做番茄炒蛋的时候，是做成咸味的，也会加入大量的生抽，味道也非常好，特别是拌面吃，既是菜又能调味。</p><h1 id="致谢"><a href="# 致谢" class="headerlink" title="致谢"></a> 致谢 </h1><p> 感谢微博用户 <strong>@开心的柠檬日记 </strong>，在微博上放了很多做菜的方子，微博主页为：<a href="https://weibo.com/u/2232990523" target="_blank" rel="noopener">开心的柠檬日记的微博</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>青椒炒蛋</tag>
        <tag>辣椒炒蛋</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次愚蠢的 HBase 错误</title>
    <url>/2019061701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近在整理一个单独的 Maven 项目，是从其它项目迁移过来的，主要存放的是和业务强相关的代码，略显混乱的代码是必不可少的，我的职责就是把现存的代码抽象出来，尽量删除一些无用的代码，只保留少量的可复用的代码。在整理的过程中，我几乎把所有的代码全部删除了，只保留一些高复用性的 <code>util</code>、<code>constant</code> 之类的代码，但是在整理和 HBase 相关的代码时，遇到了一个诡异的问题，报错信息截取片段：<code>Cannot get replica 0 location for</code>，后来经过排查发现不是现象诡异，而是自己太愚蠢，本文记录这个过程。</p><a id="more"></a><h1 id="代码问题"><a href="# 代码问题" class="headerlink" title="代码问题"></a>代码问题 </h1><p> 代码逻辑很简单，根据批量的 <code>pk 值 </code> 去 <code>HBase</code> 表中查询数据，只需要查询指定的 <strong> 列簇 </strong>，然后对返回结果进行解析，按行输出为文本文件。</p><p>具体的代码逻辑：</p><ol><li>根据 <code>pk</code> 构造 <code>Get</code> 对象，并指定 <strong>列簇 </strong></li><li> 根据 <code>HBase</code> 表名称以及环境配置参数构造 <code>HTable</code> 对象 </li><li> 调用 <code>HTbale</code> 对象的 <code>get</code> 方法获取结果 </li><li> 解析 3 中返回的结果 </li></ol><p> 在测试的时候，发现总是在第 3 个步骤出现大量的异常信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-06-17_23:09:40 [Executor task launch worker-11] ERROR client.AsyncProcess:927: Cannot get replica 0 location for &#123;&quot;cacheBlocks&quot;:true,&quot;totalColumns&quot;:1,&quot;row&quot;:&quot;ef7e0077a525929788b387dda294b9bb&quot;,&quot;families&quot;:&#123;&quot;r&quot;:[&quot;publish_date&quot;]&#125;,&quot;maxVersions&quot;:1,&quot;timeRange&quot;:[0,9223372036854775807]&#125;</span><br></pre></td></tr></table></figure><p>此外我还看到一些 <code>HBase</code> 查询时的错误，只列出了 <code>HBase</code> 相关的片段：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1007 actions: IOException: 1007 times, </span><br><span class="line">	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException (AsyncProcess.java:228)</span><br><span class="line">	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$1700 (AsyncProcess.java:208)</span><br><span class="line">	at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.getErrors (AsyncProcess.java:1605)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.batch (HTable.java:936)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.batch (HTable.java:950)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:911)</span><br></pre></td></tr></table></figure><p>而且是所有的查询请求全部都是这种错误，看起来像是查询不到数据，但是不知道为何如此。我一开始猜测是环境的原因，可能是哪里把环境参数的配置文件搞错了，于是检查了一遍配置文件，没有发现任何问题。后来猜测可能是集群的问题，但是检查了一遍，集群一直正常运行。</p><p>折腾了一个多小时，最终实在没有办法，只好把这段查询数据的逻辑代码单独拆出来，重新手写一遍，查询 2 条测试数据的发表时间：<code>publish_date</code>，并单步调试，看看究竟发生了什么。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Test</span><br><span class="line">    public void TestHBase () &#123;</span><br><span class="line">	String string = &quot;XX_POST_TABLE_NAME&quot;;</span><br><span class="line">	try &#123;</span><br><span class="line">		HTable hTable = new HTable (XxxConfig.getInstance (), TableName.valueOf (string));</span><br><span class="line">		List&lt;Get&gt; getList = Lists.newArrayList ();</span><br><span class="line">		Get get = new Get (Bytes.toBytes (&quot;0000135807e05492e830ade76a8a0c38x&quot;));</span><br><span class="line">		get.addColumn (XxxConsts.R, &quot;publish_date&quot;.getBytes ());</span><br><span class="line">		getList.add (get);</span><br><span class="line">		Get get2 = new Get (Bytes.toBytes (&quot;0000135807e05492e830ade76a8a0c38&quot;));</span><br><span class="line">		get.addColumn (XxxConsts.R, &quot;publish_date&quot;.getBytes ());</span><br><span class="line">		getList.add (get2);</span><br><span class="line">		Result [] resultArr = hTable.get (getList);</span><br><span class="line">		for (Result result : resultArr) &#123;</span><br><span class="line">			Cell cell = result.getColumnLatestCell (RhinoETLConsts.R, &quot;publish_date&quot;.getBytes ());</span><br><span class="line">			if (null != cell) &#123;</span><br><span class="line">				System.out.println (&quot;====&quot; + Bytes.toString (cell.getValueArray (), cell.getValueOffset (), cell.getValueLength ()));</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				System.out.println (&quot;====null&quot;);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	catch (IOException e) &#123;</span><br><span class="line">		e.printStackTrace ();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619000313.png" alt="手写代码单元测试" title="手写代码单元测试"></p><p>经过运行测试，发现是正常的，没有任何错误信息出现，需要的 <strong>发表时间 </strong>字段可以正常查询出来，我立即懵了，这可怎么办。懵了 3 秒，我立刻缓过神来，作为一个有三年工作经验的工程师，我觉得这都是小场面。</p><p>而且，此刻我的内心已经有了答案：<strong> 没出问题就说明有问题 </strong>，至于哪里有问题则很容易确认，要么是旧代码有问题，要么是我手写的新代码有问题，只要仔细对比一下真相就出来了。</p><p>接着我仔细对比了一下两份代码的不同之处，没用 3 分钟就发现了蹊跷之处，而且是很低级的错误，且看下一小节的分析。</p><h1 id="错误代码片段"><a href="# 错误代码片段" class="headerlink" title="错误代码片段"></a>错误代码片段 </h1><p> 在上面的开头我已经列出来了代码逻辑的 4 个步骤，本以为出错原因在第 3 个步骤，没想到真实原因在第 2 个步骤：根据 <code>HBase</code> 表名称以及环境配置参数构造 <code>HTable</code> 对象，代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 获取 HBase 连接 </span><br><span class="line">     *</span><br><span class="line">     * @param htableStr</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">public static HTable getHTable (String htableStr) &#123;</span><br><span class="line">	HTable hTable = null;</span><br><span class="line">	try &#123;</span><br><span class="line">		hTable = new HTable (XxxConfig.getInstance (), TableName.valueOf (htableStr));</span><br><span class="line">	&#125;</span><br><span class="line">	catch (Exception e) &#123;</span><br><span class="line">		LOG.error (e.getMessage (), e);</span><br><span class="line">	&#125;</span><br><span class="line">	finally &#123;</span><br><span class="line">		if (null != hTable) &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				hTable.close ();</span><br><span class="line">			&#125;</span><br><span class="line">			catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace ();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return hTable;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619000540.png" alt="获取 HBase 表连接的代码片段" title="获取 HBase 表连接的代码片段"></p><p>代码乍一看好像没有问题，就那么几行，但是千万要留意 <code>finally</code> 代码块中的代码，它是在做什么？它把刚刚创建好的 <code>HTable</code> 链接关了，关闭之前还友好地判断了一下是不是为 <code>null</code>，我真是一口老血喷出来。</p><p>注意，这里的关闭操作完全不影响后续的查询请求，在代码层面是判断不出来有什么问题的，即不会产生 <strong>编译错误 </strong>，直到运行起来真正去查询的时候才发现报错，但是报错信息又很模糊，没有表明具体的原因。</p><h1 id="个人思考"><a href="# 个人思考" class="headerlink" title="个人思考"></a>个人思考 </h1><p> 我回顾了一下，这个问题明显是一个很低级的错误，但是为什么出现在我身上呢，总结原因有二：一是直接复制了别处的代码，稍做改动，结果改错了；二是在晚上整理的代码，已经工作了一天，状态不够好，容易犯小错误。</p><p>从小事中吸取教训，总结如下：</p><p>1、在状态不好的时候，还是先休息好最重要，否则坚持写出来的代码会有一些低级错误，而且还自信地认为没有问题，给后续的排查留下坑。同理，做其它事情也是一样，对于一些要求严格的事情，为了保证质量，一定要在一天中状态最好的时间段去处理，才能最大程度地避免出问题。</p><p>2、对自己写出的代码不要过于自信，特别是一些简单的代码，自己想当然地认为不可能有问题，不舍得花费几分钟检查一下，或者测试一下，这会为自己带来浪费时间的风险，就像现在这样，早晚要为自己的失误买单。做其它事情也是一样，一定要反复检查自己负责的部分，如果有时候局限于时间排期，没有充足的时间检查，无法保证可靠性的话，宁愿延期解决，也不要坑自己和别人。当然，也不要因此自卑或者退缩，该是自己负责的时候一定要积极，按时保质保量完成。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>青椒肉丝做法总结</title>
    <url>/2019031101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>青椒肉丝，本来是一道做法非常简单的菜肴，但是想做好却不容易，为什么呢？一是因为肉丝和青椒丝很多人切不出来，可能切出来的是条状的，那就做不出来青椒肉丝；二是因为腌制肉的时候没有进行裹淀粉的步骤【有条件裹鸡蛋清当然更好】，导致肉刚下锅就老，炒不出鲜嫩滑爽的效果；三是因为炒的时候油量和油温没有控制好，导致肉炒老了，不好吃。本文则记录青椒肉丝的炒制过程以及需要注意的地方，请观察一下我是怎么做出来一道家常的青椒肉丝的。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 食材就很简单了，以下是一盘的份量：</p><ul><li>纯瘦肉 200 克 </li><li> 大青椒一棵 </li><li> 大红椒一棵【为了好看，搭配一棵红椒】</li><li>淀粉少量、花生油少量 </li></ul><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><h2 id="食材处理"><a href="# 食材处理" class="headerlink" title="食材处理"></a> 食材处理 </h2><p> 主要就是切肉丝，切青椒丝，腌制肉丝，注意肉丝要切细一点。切肉丝的时候先把肉切片【一只手掌按着肉，刀躺着从手掌下划过】，最后用肉片去切肉丝，可以保证肉丝的质量。腌制肉丝的时候除了调味料，还需要加一点点水和淀粉【淀粉不要多放，否则菜炒出来会偏甜】，用手抓均匀，让淀粉液充分裹在肉丝表面【有条件就用鸡蛋清替代更好，但是肉丝少的时候就没必要了，用不完一个鸡蛋】。最后还要加一点点花生油，防止肉丝下锅的时候粘锅。肉丝腌制 10 分钟。</p><p>青红椒切丝 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fw75eifj229s29shdt.jpg" alt="青红椒切丝" title="青红椒切丝"></p><p> 腌制肉丝加调料 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10funjj97j229s29se81.jpg" alt="腌制肉丝加调料" title="腌制肉丝加调料"></p><p> 腌制肉丝加水和淀粉 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fvj4muxj229s29s1ky.jpg" alt="腌制肉丝加水和淀粉" title="腌制肉丝加水和淀粉"></p><p> 抓均匀后放一点花生油 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fvxca54j229s29sx6p.jpg" alt="抓均匀后放一点花生油" title="抓均匀后放一点花生油"></p><h2 id="肉丝炒制，盛出备用"><a href="# 肉丝炒制，盛出备用" class="headerlink" title="肉丝炒制，盛出备用"></a> 肉丝炒制，盛出备用 </h2><p> 锅里加油，多加一点，先烧热，然后关火让油冷却一下。冷却到 3 成热再倒入肉丝，然后开大火开始翻炒，基本 30 秒就可以把肉丝炒熟了【取决于肉丝切得好不好】。然后盛出备用。</p><p>油加热后冷却 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fwionwoj229s29shdu.jpg" alt="油加热后冷却" title="油加热后冷却"></p><p> 倒入腌制好的肉丝 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fwrw22wj229s29s7wi.jpg" alt="倒入腌制好的肉丝" title="倒入腌制好的肉丝"></p><p> 不停地翻炒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fx1x7c8j229s29sb2a.jpg" alt="不停地翻炒" title="不停地翻炒"></p><p> 盛出备用 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fxc44nlj229s29s4qq.jpg" alt="盛出备用" title="盛出备用"></p><h2 id="青椒炒制，混合翻炒"><a href="# 青椒炒制，混合翻炒" class="headerlink" title="青椒炒制，混合翻炒"></a> 青椒炒制，混合翻炒 </h2><p> 由于一开始加了偏多的油，此时不需要再放油，或者根据实际情况放一点点也行。油烧热后放入青红椒丝，大火快速翻炒，基本 1 分钟以内就可以把青红椒丝炒至断生。关小火，放入备用的肉丝，翻炒几下，开始调味，放入食用盐、鸡精、耗油，接着大火快速翻炒几下，放几滴香醋，准备出锅。</p><p>放入青红椒丝翻炒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fxn3q87j229s29s1ky.jpg" alt="放入青红椒丝翻炒" title="放入青红椒丝翻炒"></p><p> 翻炒至断生【为了拍图青红椒丝炒太熟了】<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fxw4b92j229s29s4qq.jpg" alt="翻炒至断生" title="翻炒至断生"></p><p>放入肉丝调味翻炒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fyjb9j8j229s29s1ky.jpg" alt="放入肉丝调味翻炒" title="放入肉丝调味翻炒"></p><h2 id="出锅装盘"><a href="# 出锅装盘" class="headerlink" title="出锅装盘"></a> 出锅装盘 </h2><p> 盛出装盘 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fyubmo8j229s29s7wi.jpg" alt="盛出装盘" title="盛出装盘"></p><p> 还配了一道麻婆豆腐 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g10fyyqu9wj229s29se82.jpg" alt="麻婆豆腐" title="麻婆豆腐"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、买肉一定要买纯瘦肉，最好不要带一丝肉筋，并且形状要规整，薄厚均匀，这样才容易切片进而切肉丝。买肉的时候肯定不需要店方帮忙切肉了，因为他们不可能有时间给你切肉丝出来。此外一定要保证刀比较锋利，锋利的刀更容易处理，如果刀用了很久都没磨过，恰好找这个机会磨磨刀。</p><p>2、腌制肉丝的时候可以适当加一点水【用来溶解淀粉】，然后加一点淀粉，抓均匀，让淀粉充分裹上肉丝。当然，有条件的直接使用鸡蛋清最好，不需要水和淀粉了，味道还更香。抓均匀后再加一点花生油，防止下锅的时候粘锅。</p><p>3、肉丝下锅之前要确保油温不高，如果油温过高要开小火让油冷却一下，否则裹着淀粉的肉丝一下锅表面就会糊掉。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>青椒肉丝</tag>
        <tag>青红椒</tag>
        <tag>炒肉丝</tag>
      </tags>
  </entry>
  <entry>
    <title>预估 Mysql 数据表的数据大小和索引大小</title>
    <url>/2019041001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>最近接到一个小的新需求，需求很容易实现，就是定时把一些分析得出的指标从 Elasticsearch 中离线存储到 Mysql 数据库中，方便以后查询。离线存储的原因是因为资源不足，Elasticsearch 会自动删除 15 天以前的原始数据，而且 Elasticsearch 每天都会新产生数十万到数百万的数据，依据这些原始数据只会产生几十条分析结果，显然离线存储到 Mysql 中更为合理。在处理这个需求时，接着就遇到了一个小问题，当前业务组没有数据库资源，需要申请，而且由于资源不足，不能随便申请，要给出合理的预估值。这样，就涉及到数据库占用空间大小的预估了，本文记录一种简单的方法。</p><a id="more"></a><h1 id="数据大小和索引大小预估"><a href="# 数据大小和索引大小预估" class="headerlink" title="数据大小和索引大小预估"></a>数据大小和索引大小预估 </h1><p> 我当前使用的是 Mysql 数据库，其它数据库产品查询方式可能会有所不同，请根据实际情况操作。</p><p>在数据库中，使用系统数据库的表 <strong>TABLES</strong> 进行查询：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT data_length,index_length</span><br><span class="line">FROM information_schema.TABLES t</span><br><span class="line">WHERE table_schema=&apos;your_db_name&apos;</span><br><span class="line">AND table_name = &apos;your_table_name&apos;;</span><br></pre></td></tr></table></figure><p>其中，系统数据库是 <strong>information_schema</strong>，存储表信息的表是 <strong>TABLES</strong>，<strong>data_length</strong>、<strong>index_length</strong> 这 2 个字段表示数据大小、索引大小，单位是字节 B。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g228n8cy91j20cd06gq2x.jpg" alt="SQL 查询数据空间大小" title="SQL 查询数据空间大小"></p><p>当然，如果使用可视化的数据库连接管理工具，也可以通过管理工具直接鼠标点击查看，其实背后的逻辑仍旧是查询 <strong>TABLES</strong> 表，例如我通过 <strong>Navicat</strong> 工具查看。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g228nw2hx5j20er0c1t8y.jpg" alt="Navicat 查看表信息" title="Navicat 查看表信息"></p><p>可见，无论使用哪种方式，都可以把需要的信息查询出来，然后就可以预估数据大小了。我截图的信息显示，数据大小 <strong>8.5MB</strong>，索引大小 <strong>0MB</strong>，还要结合数据条数，我查了一下有 10000 条数据，因此可以粗略估计每条数据的大小为 <strong>0.85KB</strong>。这里需要注意一下，预估数据大小之前要保证数据的字段取值接近真实情况，最好能有数据示例可以参考，而且数据量要尽量大一些，例如几万条，不能只有几十条、几百条。</p><p>如果确实没有数据示例参考，需要自己模拟生成，尽量把字段的取值多生成一些实际中可能出现的值。例如字符串类型如果是 <strong>vachar</strong>，要把每种长度的取值都生成一些，或者根据实际场景，某些长度的字符串出现的可能性大一点，那就多生成一些。</p><p>如果觉得这样计算比较麻烦的话，其实还有一种更简单的方法，直接查询 <strong>avg_row_length</strong> 字段，这个字段表示数据表的平均行大小，和上面自己计算的结果类似。</p><p>总之，就是为了接近真实，才能更为准确地预估出数据占用的空间大小，实际去申请资源时才能有理有据。</p><p>此外，这个 <strong>TABLES</strong> 表里面的内容很丰富的，有需要的可以查询一下，查看数据表的字段信息 SQL 语句：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SHOW COLUMNS FROM TABLES;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>数据库</tag>
        <tag>database</tag>
        <tag>space</tag>
      </tags>
  </entry>
  <entry>
    <title>鸡蛋饼做法总结</title>
    <url>/2019021001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>鸡蛋饼算是一种小吃，做法多种多样，可以煎，可以烙，可以蒸；吃法也多种多样，有的地方会卷配菜吃，有的地方会配粥吃，有的地方会直接吃。总而言之，鸡蛋饼算是一种万能美食，全国各地都有，大家也都喜欢吃，本文就记录鸡蛋煎饼的做法总结，本文记录的做法是采用煎的方式，另外还会额外放点葱花。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 以下准备的食材可以煎 15 个鸡蛋饼左右：</p><p>1、鸡蛋 4 个（喜欢的话多放点也可以）；</p><p>2、200-300 克面粉（可以煎 15 个左右，面粉不能确定量，是因为如果面糊没有配好，就适量加水或者加面，调整好为止，具体会用到多少看情况了）；</p><p>3、小葱 5 根（根据个人口味添加，多点少点都行）；</p><p>适量的食材 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zsjak5uj229s29sb2a.jpg" alt="适量的食材" title="适量的食材"></p><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><p> 制作步骤很简单，只要能煎好一张饼，重复进行就行了，煎好一张饼大概需要 3 分钟。当然，如果是第一次煎饼，可能煎前面几张饼的时候需要练习一下，也可能需要重新调制面糊，所以时间会长一点，但是为了煎饼成功，麻烦一点也值了。</p><p>调制面糊的过程就不记录了，就是加盐（4 勺）、葱花、面粉、鸡蛋、水（最好可以用凉白开，别直接使用自来水）搅拌即可，如果里面有很多面疙瘩，不用担心，静置 10 分钟搅拌一次，重复 3 次左右面疙瘩即全部溶于水。</p><p>面糊调制初步，还有很多面疙瘩 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zsyhqz9j229s29sx6p.jpg" alt="面糊调制初步" title="面糊调制初步"></p><p> 面糊调制完成 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zt8lieaj229s29s1ky.jpg" alt="面糊调制完成" title="面糊调制完成"></p><p> 粘稠度大概这样，不会很粘稠，和液体差不多 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02ztjniz7j229s29s1ky.jpg" alt="粘稠度大概这样" title="粘稠度大概这样"></p><p>1，锅里加油烧热，只要半勺即可（吃饭的那种小汤勺），多了会腻，然后火力转小火，并一直持续小火。</p><p> 半勺油的量 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zttlh5dj229s29su0x.jpg" alt="半勺油的量" title="半勺油的量"></p><p>2，放入一汤勺面糊（烧汤那种大汤勺，或者电饭煲自带的那种粥勺），如果发现煎出来的饼太厚了或者太大了，可以适当少放一点点面糊，具体放多少自己把握。然后适当转动煎锅，让面糊呈圆形（一定要快，10 秒内完成，否则因为受热不均匀，饼可能会散开变成多块，或者是一个圆环饼套着一个小圆饼），等逐渐凝固后就成了圆饼，然后接触锅的那一面就变得金黄，这个过程大概 1 分钟。</p><p> 一大汤勺面糊 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zu5p94aj229s29s7wi.jpg" alt="一大汤勺面糊" title="一大汤勺面糊"></p><p> 加面糊到锅里 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zuex8yfj229s29sqv5.jpg" alt="加面糊到锅里" title="加面糊到锅里"></p><p> 转动成型 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zuu7r6ej229s29su0x.jpg" alt="转动成型" title="转动成型"></p><p>3，等凝固后就可以翻身了，这个步骤说简单也简单，说难也难，如果直接用锅不方便翻身的话，可以借助铲子，翻身后，可以看到饼的上一面已经煎好了，金黄的。这个时候注意要适当把饼转动一下，吸收一下油，避免粘锅。</p><p> 给饼翻身 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zv4hgxoj229s29s7wi.jpg" alt="给饼翻身" title="给饼翻身"></p><p>4，翻身后再煎 1 分钟左右，就可以出锅了，如果看到饼上面哪里煎的不均匀，还没熟，可以再着重煎几十秒。切记不能煎太久，要不然饼就糊了。</p><p> 翻身后继续煎 1 分钟，再根据实际情况着重煎一下，准备出锅 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zvduw1jj229s29su0x.jpg" alt="准备出锅" title="准备出锅"></p><p>5，出锅装盘，继续下一张鸡蛋饼。</p><p> 全部出锅装盘 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g02zvpluirj229s29sb2a.jpg" alt="全部出锅装盘" title="全部出锅装盘"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、特别注意，如果调制面糊不是特别熟练的话，可能面糊的粘稠度不适合，或者调味偏淡偏咸，这样都不好，所以最好尝试着煎一个，然后品尝一下，如果味道不对再加调料，如果煎出来的饼不对，再加水或者面粉。多试几次，确保煎出来的饼自己满意。如果一味地煎饼，最后发现不好吃，那就浪费了；</p><p>2、如果有两个锅可以用，为了节省时间，最好两个锅同时煎，要不然整个过程很枯燥，因为有一半的时间都在等待；</p><p>3、有时候可能看着好像煎糊了，不用担心，不影响吃，因为出锅后等一会儿，褐色就会变成金黄色，非常好看；</p><p>4、整个过程一定要确保是小火，否则饼很快就糊了；</p><p>5、难点在于翻身，只要一出错一张饼就废了（或者变成了一堆碎饼）。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>鸡蛋饼</tag>
        <tag>鸡蛋葱饼</tag>
        <tag>鸡蛋煎饼</tag>
      </tags>
  </entry>
  <entry>
    <title>麻婆豆腐做法总结</title>
    <url>/2019031601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>麻婆豆腐是一道川菜，口味特色就是麻、辣、鲜，而且非常下饭。我常听说正宗的麻婆豆腐要用郫县豆瓣酱【回锅肉也是这样】，才能做出来正宗的味道，但是我身边没有那么多材料，只能做一道简单版的麻婆豆腐。本文就记录麻婆豆腐的做法总结。</p><a id="more"></a><h1 id="食材准备"><a href="# 食材准备" class="headerlink" title="食材准备"></a>食材准备 </h1><p> 食材就很简单了，以下的量为一盘：</p><ul><li>嫩豆腐一块，一般 2 块钱左右 </li><li> 瘦肉 50 克，剁成肉沫 </li><li> 豆瓣酱，我没有豆瓣酱就用一种混合调味酱【辣椒酱、豆瓣酱、胡椒粉】替代了 </li><li> 辣椒粉，或者辣椒酱 </li><li> 青花椒，最好用青花椒，才够麻的味道【买的散装青花椒里面会有一些其它植物的种子，要细心挑拣出去】</li></ul><p>一块嫩豆腐 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mdpgmo7j229s29snpd.jpg" alt="一块嫩豆腐" title="一块嫩豆腐"></p><p> 青花椒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15me1xf07j229s29snpd.jpg" alt="青花椒" title="青花椒"></p><h1 id="制作步骤"><a href="# 制作步骤" class="headerlink" title="制作步骤"></a> 制作步骤 </h1><h2 id="初步处理食材"><a href="# 初步处理食材" class="headerlink" title="初步处理食材"></a> 初步处理食材 </h2><p> 豆腐切小块，稍微焯水，备用。如果豆腐质量比较好的话，可以一整块冲一下水就行，不用再焯水了。我买的这个豆腐有点碱的味道【类似魔芋一样】，所以稍微焯一下水为好。焯水时不能用大火，否则豆腐会碎掉的，也可以在焯水时稍微放一点点盐进去。</p><p>豆腐切小块 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15meleoz3j229s29skjl.jpg" alt="豆腐切小块" title="豆腐切小块"></p><p> 豆腐简单焯水 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15meu18t2j229s29s4qq.jpg" alt="豆腐简单焯水" title="豆腐简单焯水"></p><p> 瘦肉剁成肉沫，稍微腌制一下，备用。我为了保持肉沫的鲜嫩，还裹了一层淀粉液。<br>瘦肉剁成肉沫 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mf2x2shj229s29shdu.jpg" alt="瘦肉剁成肉沫" title="瘦肉剁成肉沫"></p><p> 肉沫腌制 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mf7k4lij229s29sb29.jpg" alt="肉沫腌制" title="肉沫腌制"></p><p> 肉沫裹淀粉液 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mfc810oj229s29s7wh.jpg" alt="肉沫裹淀粉液" title="肉沫裹淀粉液"></p><h2 id="炒肉沫"><a href="# 炒肉沫" class="headerlink" title="炒肉沫"></a> 炒肉沫 </h2><p> 锅里放油烧热，稍微多放一点油，然后倒入肉沫翻炒，基本 30 秒就可以了。<br>肉沫下锅 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mgbgss2j229s29s7wi.jpg" alt="肉沫下锅" title="肉沫下锅"></p><p> 肉沫翻炒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mgghk4kj229s29s7wi.jpg" alt="肉沫翻炒" title="肉沫翻炒"></p><h2 id="炒豆腐"><a href="# 炒豆腐" class="headerlink" title="炒豆腐"></a> 炒豆腐 </h2><p> 一般的做法应该是接着放豆瓣酱，炒出红油，然后加青花椒、辣椒粉，加水煮了一段时间后，再下豆腐。但是我就不搞这么复杂的过程了，直接炒一下豆腐，把豆腐和肉沫混合在一起。<br>豆腐下锅炒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mh0jf5jj229s29sx6p.jpg" alt="豆腐下锅炒" title="豆腐下锅炒"></p><p> 豆腐肉沫混合 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mh4vb6jj229s29s1ky.jpg" alt="豆腐肉沫混合" title="豆腐肉沫混合"></p><p> 加混合调味酱、辣椒酱、调味料、青花椒 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mhb1f5bj229s29se82.jpg" alt="加酱料" title="加酱料"></p><h2 id="加水开煮"><a href="# 加水开煮" class="headerlink" title="加水开煮"></a> 加水开煮 </h2><p> 因为我的豆腐已经焯水了，所以很容易就熟了，接着再加热水煮开，转为小火再煮 5 分钟就行了。切记别加太多热水，否则变汤了，我这个加的有点多，要多煮一会儿水才能蒸发。<br>加热水，刚刚淹没豆腐 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mi8u826j229s29s1ky.jpg" alt="加热水，刚刚淹没豆腐" title="加热水，刚刚淹没豆腐"></p><p> 煮开后转为小火 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mignd6yj229s29sb2a.jpg" alt="煮开后转为小火" title="煮开后转为小火"></p><p> 小火慢煮 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mindngjj229s29sb2a.jpg" alt="小火慢煮" title="小火慢煮"></p><h2 id="收汁出锅装盘"><a href="# 收汁出锅装盘" class="headerlink" title="收汁出锅装盘"></a> 收汁出锅装盘 </h2><p> 煮了 5 分钟就可以准备收汁了，接着还要进行勾芡，我使用淀粉液进行勾芡。勾芡完成稍微再煮 30 秒就可以关火，出锅装盘。</p><p>收汁 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mirmvljj229s29s4qq.jpg" alt="收汁" title="收汁"></p><p> 调淀粉液，少量淀粉加水 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mixp0uzj229s29shdt.jpg" alt="调淀粉液，少量淀粉加水" title="调淀粉液，少量淀粉加水"></p><p> 调淀粉液成品 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mj2h97cj229s29sqv5.jpg" alt="调淀粉液成品" title="调淀粉液成品"></p><p> 勾芡完成，可以看到有点浓稠 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mnev10jj229s29se82.jpg" alt="勾芡完成，可以看到有点浓稠" title="勾芡完成，可以看到有点浓稠"></p><p> 出锅装盘 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mjau8njj229s29skjm.jpg" alt="出锅装盘" title="出锅装盘"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、为了保证肉沫的鲜嫩，千万不要炒太久，下锅后稍微炒一下就行了，因为后续还要加水煮很久呢。我这里没有采用炒豆瓣酱出红油的做法，所以就用淀粉液裹了一下，肉沫炒熟后直接下豆腐。</p><p>2、切豆腐时豆腐一般都会粘在刀上，所以有一个技巧就是从手心往手指的方向反着切，切完一刀就可以用手压住，这样豆腐就不会粘在刀上了。参考如下图【我是左手持刀，右手压豆腐】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g15mjlrsb8j229s29s4qq.jpg" alt="反向切豆腐" title="反向切豆腐"></p><p>3、收汁时最好使用淀粉液勾芡一下，这样才能保证调味料都裹在豆腐上，达到入味的效果。否则味道可能都遗落在汤汁里面了，导致豆腐没有什么味道。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>菜谱</category>
      </categories>
      <tags>
        <tag>麻婆豆腐</tag>
        <tag>豆腐</tag>
        <tag>麻辣豆腐</tag>
      </tags>
  </entry>
  <entry>
    <title>Aria2 Web 管理面板使用</title>
    <url>/2018110902.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>如果使用浏览器默认的下载器，下载百度云的文件速度大多数情况下不理想，而且大文件不能下载，同时非客户端下载文件又会严重限速。如果使用插件和脚本配合，突破了百度云的限制，可以下载大文件，但是遇到下载中途失败的情况，有时候不能继续下载，还要重头来，会让人崩溃，体验非常不友好。那么我前面一篇文章描述了这个过程，同时给出了几个解决方案，本文就记录一下其中涉及到 Aria2 的使用以及其中一种管理面板【YAAW for Chrome】的使用。</p><a id="more"></a><h1 id="插件的安装"><a href="# 插件的安装" class="headerlink" title="插件的安装"></a>插件的安装 </h1><p> 这款插件的全名是 Yet Another Aria2 Web Frontend，简称 YAAW，可以去谷歌的插件商店获取：<a href="https://chrome.google.com/webstore/detail/yaaw-for-chrome/dennnbdlpgjgbcjfgaohdahloollfgoc?hl=zh-CN" target="_blank" rel="noopener">YAAW</a> 。当然，如果你没有翻墙，是打不开这个链接的，你可以选择去国内的镜像站点下载，例如：<a href="https://chrome-extension-downloader.com" target="_blank" rel="noopener">chrome-extension-downloader</a> ，或者 <a href="http://getcrx.cn/#" target="_blank" rel="noopener">getcrx</a> ，至于怎么使用可以参考本博客的 <a href="https://www.playpi.org/about/">关于页面 </a> 。为了方便你们，我把这款插件的插件 id 也放出来：dennnbdlpgjgbcjfgaohdahloollfgoc。</p><p> 详细的安装过程就不赘述了，不是重点，一般也就是在线安装或者下载 crx 离线文件安装，都不是困难的事情。</p><h1 id="插件的使用"><a href="# 插件的使用" class="headerlink" title="插件的使用"></a>插件的使用 </h1><p> 为了使用这款插件，还需要 Aria2 、baiduexporter 这 2 款工具的协助。Aria2 在前文已经描述过了，是用来下载文件的后台程序，本来直接使用它下载文件就可以了，但是奈何不方便批量下载以及任务管理，所以需要搭配 YAAW 来使用。baiduexporter 这款插件是用来转换百度云盘文件的链接的，转为 Aria2 可以直接使用的方式。</p><p>这 2 款工具的安装可以参考上一篇博客，在这里仅给出对应的链接和插件 id：<a href="https://github.com/aria2/aria2/releases" target="_blank" rel="noopener">Aria2 安装包 </a> 、<a href="https://aria2.github.io/" target="_blank" rel="noopener">Aria2 介绍</a> 、<a href="https://chrome.google.com/webstore/detail/baiduexporter/jgebcefbdjhkhapijgbhkidaegoocbjj?hl=zh-CN" target="_blank" rel="noopener">baiduexporter 插件</a> 、baiduexporter 插件的 id【jgebcefbdjhkhapijgbhkidaegoocbjj】。</p><h2 id="Aria2"><a href="#Aria2" class="headerlink" title="Aria2"></a>Aria2</h2><p> 一切准备就绪后，我先在后台启动 Aria2 进程。切记要开启 RPC 模式，否则 YAAW 插件无法监控后台的下载任务，也就无法进行管理了。还要开启断点续传，这样才能在下载出现异常中断之后，还能接着上次的进度继续下载，节约时间。</p><p>启动 Aria2 进程 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rdtxd1mj20nf0fbq47.jpg" alt="启动 Aria2 进程" title="启动 Aria2 进程"></p><h2 id="YAAW"><a href="#YAAW" class="headerlink" title="YAAW"></a>YAAW</h2><p> 如果一开始直接打开 YAAW 插件，会显示错误：<strong>Error: Internal server error</strong>，其实就是没有找到 Aria2 进程。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rfb5jz5j21hc0rhmyg.jpg" alt="直接打开 YAAW 插件" title="直接打开 YAAW 插件"></p><p>那它们是怎么通信的呢，其实就是依靠一个端口，这个端口我们使用默认的就行了【默认就是 6800】，否则要在 YAAW 和 Aria2 两边都要设置，并且保持一致。</p><p>YAAW 插件设置端口 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rfu7534j21hc0rfjt6.jpg" alt="YAAW 插件设置端口" title="YAAW 插件设置端口"></p><p>Aria2 设置端口<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rfzt0nnj20j4036glo.jpg" alt="Aria2 设置端口" title="Aria2 设置端口"></p><p> 当然，从上面的截图中我们可以看到，还可以设置一些其它参数，例如：自动刷新时间、限速大小、用户代理、基础目录。然而，这些参数都是全局性的，我们没有必要设置，因为等到真正需要下载文件的时候，还可以重新设置，实际应用中不一定每次下载的设置都一致，所以放在每次下载文件的时候重新设置显得更灵活。</p><h2 id="baiduexporter"><a href="#baiduexporter" class="headerlink" title="baiduexporter"></a>baiduexporter</h2><p>baiduexporter 的安装就比较简单了，就是一个浏览器插件而已，安装后打开即可。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rgfsynwj20ge0craah.jpg" alt="baiduexporter 插件" title="baiduexporter 插件"></p><h2 id="三者结合协同工作"><a href="# 三者结合协同工作" class="headerlink" title="三者结合协同工作"></a>三者结合协同工作 </h2><p> 打开我的百度云网盘，随意找一个文件测试 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rgzfh7oj21hc0q90uf.jpg" alt="打开百度网盘" title="打开百度网盘"></p><p> 细心的人可以发现，在选中一个文件后，在本来的 <strong>下载 </strong>旁边多了一个选择项 <strong>导出下载 </strong>，如果移动鼠标到上面，<strong> 导出下载 </strong>会展开下拉列表，出来 3 个选项：Aria2 RPC、文本导出、设置。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rhn2uy2j21hc0q9q4p.jpg" alt="导出下载" title="导出下载"></p><p>如果我选择第一个 Aria2 RPC，则会直接调用后台的 Aria2 进程，直接帮我下载文件了，不需要我使用 Aria2 的原生命令加上必要的参数去启动一个下载任务了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12ric7fwqj21hc0q9taf.jpg" alt="Aria2 RPC 下载文件" title="Aria2 RPC 下载文件"></p><p>而第二个文本导出，其实就是导出这个百度云文件的 Aria2 完整的命令，这样我们就可以复制使用，在后台起一个 Aria2 的下载任务了【有了第一种的 RPC 方式，更为方便快捷，肯定不用这种方式】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rixl1p1j21hc0q9ac0.jpg" alt="文本导出" title="文本导出"></p><p>而设置则是导出的参数设置，这个没什么好说的，一般使用默认的就行了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rj8h9n9j21hc0q9410.jpg" alt="导出的设置" title="导出的设置"></p><p>好，接下来重点来了，必将能让你感受到什么叫做方便快捷。前面说那么多操作步骤，是不是发现还没 YAAW 插件什么事情，别着急，接下来的描述都是它的。直接打开插件：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rjw0jgyj21hc0q9t9j.jpg" alt="YAAW 任务列表" title="YAAW 任务列表"></p><p>有没有发现什么，刚才下载的任务已经在这里可以看到了。不仅如此，还可以在这个控制面板中随意操管理任务：暂定、开始、删除，还可以看到下载的网速和进度百分比，多方便，这已经近似于一个下载管理软件了【虽然很简陋，但是比直接操作 Aria2 后台方便多了】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rk0wdhej21hc0q9t9k.jpg" alt="YAAW 任务管理" title="YAAW 任务管理"></p><p>刚才使用百度云下载文件的时候，是直接在 <strong>导出下载 </strong>中一键勾选的，很方便，但是如果是别人发给你一个 Aria2 能下载的链接，你该怎么办呢？是使用 Aria2 后台起一个下载任务，还是怎么样，因为此时没有像下载百度云盘文件那么方便的按钮给你选择。别担心，此时又要使用 YAAW 的另外一个功能了：创建任务，也就是相当于在迅雷中创建一个下载任务一样。在 YAAW 插件中有一个 <strong>ADD</strong> 按钮。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rk5z1fhj21hc0q9ab6.jpg" alt="YAAW 任务创建" title="YAAW 任务创建"></p><p>点击后弹出一个配置的对话框，在里面填上对应的参数就行了。不知道大家有没有发现，这里面的参数和使用 baiduexporter 插件的 <strong>导出下载 </strong>里面的 <strong>文本导出 </strong>导出的文本里面的一些内容很是相似，另外需要自己设置一下文件名字、文件下载目录、用户代理等信息就行了。这里就不再具体演示了。</p><p>当然，以上只是使用百度云网盘作为示例，大家比较容易理解，演示给大家，纯粹是为了抛砖引玉，其实 Aria2 还支持更多的协议，大家可以自行参考 Aria2 的官方网站。如果下载磁力链接的东西，有时候迅雷更快，因为毕竟它是 p2p 的，可以加速，大家还是要看情况使用。</p><h1 id="温馨提示"><a href="# 温馨提示" class="headerlink" title="温馨提示"></a>温馨提示 </h1><p> 除了突破限速的场景，我还发现一个场景，那就是资源文件被禁用的时候，也可以突破禁用，自由下载资源文件，例如盗版电影的下载。在不久后的 2019 春节档，竟然出现了史无前例的电影高清资源泄漏的事件。重点包括《新喜剧之王》、《疯狂的外星人》、《流浪地球》、《飞驰人生》这几部，电影刚上映 3 天，就有高清资源【画质比较好，不是一般的枪版】流出来了，大家可以下载。接着电影官网就鼓励大家进行举报封禁，导致各大下载软件都屏蔽了资源，显示由于版权问题而禁止下载。</p><p>这时候各种开源的下载器就派上用场了，例如 Aria2 就是一个，但是缺点就是网速可能没有那么快，因为没有 p2p 加速机制。但是我仅仅是为了学习，测试一下也无妨。</p><p>可以看到，使用迅雷下载是被禁止的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rl6jyahj209y0k6diy.jpg" alt="迅雷下载被禁" title="迅雷下载被禁"></p><p>把 torrent 文件保存下来，转而使用 Aria2 下载，为了方便直接在 YAAW 插件上面建任务，直接上传 torrent 文件即可，其它参数则使用默认的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rlh3exej217i0ndq4h.jpg" alt="保存 torrent 文件" title="保存 torrent 文件"></p><p>可以看到，下载速度可以达到 2M 以上。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12rlbkjcpj216q0ekq43.jpg" alt="下载顺利" title="下载顺利"></p><p>以上下载电影实践中，当然目的只是为了学习使用，给你们演示一下而已，不是提倡下载盗版电影，在下载一些被屏蔽的资源或者被限速的情况下，可以使用这种方式试试。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>aria2</tag>
        <tag>百度云下载</tag>
        <tag>百度云限速</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 中的 429 错误 es_rejected_execution_exception</title>
    <url>/2017042601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>今天在处理数据，处理逻辑是从 HBase 中扫描读取数据，经过转换后写入 Elasticsearch 中，程序的整体方案使用的是 mapreduce 结构。map 负责扫描 HBase 数据，并转换为 Map 结构，reduce 负责把 Map 结构的数据转为 JSON 格式，并验证合法性、补充缺失的字段、过滤非法数据等，最后使用 elasticsearch 官方发布的 BulkProcessor 把数据批量写入 elasticsearch。</p><p>在处理数据的过程中，遇到了一个诡异的问题，说它诡异是因为一开始不知道 BulkProcessor 存在的坑。关于这个问题，表面现象就是漏数，写入 elasticsearch 中的数据总是少于 HBase 中的数据，而且差距巨大。当然，如果是有经验的工程师，可以猜测好几个原因：扫描读取 HBase 的数据时设置过滤器过滤掉了不该过滤的数据、ETL 的处理逻辑中有误过滤数据的 bug、写入 elasticsearch 时数据不合法导致写入失败、由于 BulkProcessor 潜在的问题导致写入漏数。本文就记录解决这个问题的过程。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 问题其实就是漏数，HBase 里面的数据写入到 Elasticsearch 后发现数据量对不上，而且重跑了几次作业，每次重跑都会有多一点点的数据写入 Elasticsearch，这就很诡异了，不像普通的漏数。这个漏数现象复现不了，虽然每次重跑作业都会漏数，但是数据量对不上，说明背后有一只无形的手在操控着这一切，而且操控过程随心所欲，让人疑惑不解。</p><p>漏数现象出现后，作为一个有经验的工程师，我先初步怀疑了几个关键点，然后逐步分析，抽丝剥茧，找到了问题所在。</p><p>Elasticsearch 版本为 v5.6.8。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><h2 id="怀疑点排查"><a href="# 怀疑点排查" class="headerlink" title="怀疑点排查"></a> 怀疑点排查 </h2><p>1、扫描读取 HBase 的数据时设置过滤器过滤掉了不该过滤的数据，经过查看，扫描过滤器只是设置了某个时间字段的范围，并且提交作业时设置的参数属于正常范围，不会影响数据量，排除此种可能。</p><p>2、ETL 的处理逻辑中有误过滤数据的 bug，仔细查看了 ETL 的处理逻辑，里面有多处过滤数据的处理逻辑，例如发表时间、id 等必要的字段必须存在，但是不会过滤掉正常的数据，而且给对应的过滤指标设置了累加器。一旦有数据被正常过滤掉，累加器会记录数据量的，在作业的日志中可以查看，排除此种可能。</p><p>3、写入 elasticsearch 时数据不合法导致写入失败，在作业运行中，如果出现这种情况，一定会抛出异常【使用 BulkProcessor 不会抛出异常，但是有回调方法可以使用，从而检测异常情况】，所以在业务代码中，考虑了异常情况的发生，把对应的数据格式输出到日志中，方便查看。我仔细搜索检查了日志文件，没有发现数据不合法的异常日志内容，排除此种可能。</p><p>4、由于 BulkProcessor 潜在的问题导致写入漏数，这个怀疑点就比较有意思了，使用 BulkProcessor 来批量把数据写入 elasticsearch 时，会有两个隐藏的坑：一是写入失败不会抛出异常，注意，批量的内容全部失败或者部分失败都不会抛出异常，只能在它提供的回调方法【afterBulk ()】中捕捉异常信息，二是资源紧张会导致 elasticsearch 拒绝请求，导致写入数据失败，注意，此时也不会抛出异常，只能通过回调方法捕捉错误信息。所以有可能是这个原因。</p><h2 id="重点排查"><a href="# 重点排查" class="headerlink" title="重点排查"></a> 重点排查 </h2><p> 好了，已经逐条分析了可能的原因，并初步定位了最有可能的原因，接下来就是利用 BulkProcessor 提供的回调方法，把异常信息捕捉，并在日志中输出所有必要的信息，以方便发现问题后排查具体原因。</p><p>代码更新完成后重跑作业，为了速度快一点，先筛选少量的数据进行重跑，然后观察日志。</p><p>查看日志，发现有大量的错误信息，就是从 <strong>BulkProcessor</strong> 的回调方法 <strong>afterBulk ()</strong> 里面捕捉打印的【以下日志片段本来是一行，为了友好地显示，我把它格式化多行了】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...... 省略 </span><br><span class="line">2019-04-23 17:37:22,738 ERROR [I/O dispatcher 68] org.playpi.blog.client.es.ESBulkProcessor: bulk [43 : 1556012242738] - </span><br><span class="line">&#123;</span><br><span class="line">    &quot;cause&quot;: &#123;</span><br><span class="line">        &quot;reason&quot;: &quot;Elasticsearch exception [type=es_rejected_execution_exception, reason=rejected execution of org.elasticsearch.transport.TransportService$7@45c00a5f on EsThreadPoolExecutor [bulk, queue capacity = 1500, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@53ffdb18 [Running, pool size = 32, active threads = 32, queued tasks = 4527, completed tasks = 26531491]]]&quot;,</span><br><span class="line">        &quot;type&quot;: &quot;exception&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;id&quot;: &quot;f176fd6b68d22ad357a61714313d2748&quot;,</span><br><span class="line">    &quot;index&quot;: &quot;org-playpi-datatype-post-year-2018-v1&quot;,</span><br><span class="line">    &quot;status&quot;: 429,</span><br><span class="line">    &quot;type&quot;: &quot;post&quot;</span><br><span class="line">&#125;</span><br><span class="line">...... 省略 </span><br></pre></td></tr></table></figure><p>更多错误内容如截图所示 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cy72abpej20xt0bxq54.jpg" alt="某个 reduce 任务的日志" title="某个 reduce 任务的日志"></p><p> 找到里面的关键信息：<strong>es_rejected_execution_exception</strong>、<strong>“status”: 429</strong>，到这里，可以确定这个错误不是由于数据格式不合法导致写入 Elasticsearch 失败，否则错误信息应该携带 <strong>source invalid </strong>字样。可惜，进一步，我看不懂这个异常错误，只能借助搜索引擎了。</p><p>经过搜索，发现这个问题的原因在于 Elasticsearch 集群的资源不足，处理请求的线程池队列全部被占用，无法接收新的请求，于是拒绝，这也就导致了数据漏掉。</p><p>在这里先提前说明一下，以下内容的配置信息是基于 <strong>数据索引所在的集群、节点 </strong>，例如索引 A 在某个集群，分配了 3 个节点，那就只看这个集群的这 3 个节点，可能还有其它几百个节点存放的是其它的数据索引，不用关心。这样才能准确找到问题所在，否则如果看到配置信息对不上，就会感到疑惑。另外在使用 API 接口时，可以在 url 结尾增加 <strong>?pretty</strong> 协助格式化结果数据，查看更容易，<strong>?v</strong> 参数可以协助返回结果增加表头，显示更为友好。</p><p>其实，Elasticsearch 分别对不同的操作【例如：index、bulk、get 等】提供不同的线程池，并设置线程池的线程个数与排队任务上限。可以在数据索引所在节点的 <strong>settings</strong> 中查看，如果有 head 插件【或者 kopf 插件】，在 <strong>概览 -&gt; 选择节点 -&gt; 集群节点信息 </strong>中查看详细配置。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cy83tslkj20iq0k5t93.jpg" alt="使用 head 插件查看节点信息" title="使用 head 插件查看节点信息"></p><p>其中在 <strong>settings -&gt; thread_pool</strong> 里面有各个操作的线程池配置。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cy8baeesj20ek0f7zki.jpg" alt="使用 head 插件查看 thread_pool 信息" title="使用 head 插件查看 thread_pool 信息"></p><p>这里面，有两种类型的线程池，一种是 fixing，一种是 scaling，其中 fixing 是固定大小的线程池，默认是 core 个数的 5 倍，也可以指定大小，scaling 是动态变化的线程池，可以设置最大值、最小值。</p><p>如果不使用 head 插件，直接通过 Elasticsearch 集群的 http 接口【前提是开放 http 端口或者设置了转发端口，否则无法访问】也可以获取这个数据，例如通过 <strong>/_nodes / 节点唯一标识 /settings/</strong> 查看某个节点的配置信息。这个节点唯一标识【uuid】可以通过 head 插件获取，我这里使用 <strong>q6GpFsnCSOOfLoLl72MVAg</strong> 演示。</p><p>使用 head 插件获取节点的唯一标识。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cy972bq0j20md07p3yj.jpg" alt="查看节点的唯一标识" title="查看节点的唯一标识"></p><p>使用 API 接口查看节点的配置信息 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cy9knbhej20ra0mm3z0.jpg" alt="使用 API 查看节点的配置信息" title="使用 API 查看节点的配置信息"></p><p> 可以看到数据所在节点的线程池配置，对于 <strong>bulk</strong> 类型的操作，线程池的大小为 32【由于 min 和 max 都设置为了 32，并且线程池类型为 fixing，所以是 32】，队列上限为 1500。好，至此，再结合上面错误日志中的信息：<strong>bulk, queue capacity = 1500</strong>、<strong>Running, pool size = 32, active threads = 32, queued tasks = 4527</strong>，可以发现，当前节点【某个 node，不能说整个集群】处理数据时线程的队列已经超过了上限 1500，而且我惊讶地发现已经到达了 4527，这种情况下 Elasticsearch 显然是要拒绝请求的。</p><p>此外，使用集群的 API 接口也可以看到节点的线程池使用情况，包括拒绝请求量，<strong>/_cat/thread_pool?v</strong>，查看详情如下图所示。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cyav2c1rj20ke097aa9.jpg" alt="使用 API 查看节点的线程池使用情况" title="使用 API 查看节点的线程池使用情况"></p><p>不妨再次探索一下 mapreduce 的日志，搜索关于 bulk 的错误，可以看到大量的错误都是这种，超过队列上限而被拒绝请求。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cyb09mggj21dq0mcn28.jpg" alt="大量的线程池超过最大限制错误" title="大量的线程池超过最大限制错误"></p><h2 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案 </h2><p> 原因找到了，解决方案也可以定下来了。</p><p>1、给 Elasticsearch 的索引增加更多的节点，这样就可以把线程池扩大了，但是需要消耗资源，一般无法实现。</p><p>2、优化批量的请求，尽量不要发送多个小批量的请求，而是发送少量的大批量请求。这个方法还是适合的，把 bulk 请求的数据量增大一点，收集多一点数据再发送请求。</p><p>3、改善索引性能，让文档编制索引速度更快，这样处理请求就更快，批量队列就不太容易阻塞了。这个方法说起来容易，做起来有点难，需要优化整个索引设计，例如取消某些字段的索引、删除冗余的字段等。</p><p>4、在不增加节点的情况下，把节点的线程池设置大一点、队列上限设置大一点，就可以处理更多的请求了。这个方法需要改变 Elasticsearch 集群的配置，然后重启集群，但是一般情况下会有风险，因为节点的硬件配置【内存、CPU】没有变化，单纯增加线程池，会给节点带来压力，可能会宕机，谨慎采用。配置信息参考如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 修改 elasticsearch.yml 配置文件 </span><br><span class="line">threadpool.bulk.type: fixed</span><br><span class="line">threadpool.bulk.size: 64</span><br><span class="line">threadpool.bulk.queue_size: 1500</span><br></pre></td></tr></table></figure><p>5、如果确实在硬件、集群方面都无法改变，那就直接在使用方式上优化吧，例如把并发设置的小一点，请求一批后休眠一段时间，保障 Elasticsearch 可以把请求处理完，接着再进行下一批数据的请求。这种做法立竿见影，不会再影响到 Elasticsearch 的线程池，但是缺点就是牺牲了时间，运行作业的时间会大大增加。</p><p>迫于资源紧张，我只能选择第 5 种方式了，减小并发数，数据慢慢写入 Elasticsearch，只要不再漏数，时间可以接受。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p> 除了上面的排查总结，再描述一下一开始针对业务逻辑的具体的思路。</p><p>拿到错误日志后，简单搜索统计了一下，一个 reduce 任务的错误信息有 16 万次，也就是有 16 万条数据没有成功写入 Elasticsearch。而整个 mapreduce 作业的 reduce 个数为 43，可以预估一下有 688 万次错误信息，也就是有 688 万条数据没有成功写入 Elasticsearch，这可是个大数目。</p><p>再查看作业日志的统计值，累加器统计结果，在 driver 端的日志中，发现一共处理了 1413 万数据，这样一计算，漏掉了接近 49% 的数据，太严重了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2cyb6wscxj20gv0kcgme.jpg" alt="查看累加器的取值" title="查看累加器的取值"></p><p>再对比一下我文章开头的描述，每次重跑作业，总是有一部分数据可以重新写入 Elasticsearch，但是成功的数据量仅仅限于几十条、几条。最终还差 500 多条数据的时候，已经重跑了 5 次以上了，所以我才会更加怀疑是程序写入 Elasticsearch 方式的问题。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>mapreduce</tag>
        <tag>HBase</tag>
        <tag>BulkProcessor</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 异常之 too many open files</title>
    <url>/2018070901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>目前在 <code>Java</code> 项目中普遍使用 <code>Elasticsearch</code> 的 <code>Java API</code> 进行连接集群、发送请求、解析结果，方便快捷。在某一次运行时发生了异常，异常信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.net.SocketException: Too many open files</span><br><span class="line">  at java.net.Socket.createImpl (Socket.java:460)</span><br><span class="line">  at java.net.Socket.connect (Socket.java 587)</span><br><span class="line">  at sun.net.NetworkClient.doConnect (NetworkClient.java 175)</span><br><span class="line">  at sun.net.www.http.HttpClient.openServer (HttpClient.java 463)</span><br><span class="line">  at sun.net.www.http.HttpClient.openServer (HttpClient.java 558)</span><br><span class="line">  at sun.net.www.http.HttpClient.&lt;init&gt;(HttpClient.java 242)</span><br><span class="line">  at sun.net.www.http.HttpClient.New (HttpClient.java 339)</span><br><span class="line">  at sun.net.www.http.HttpClient.New (HttpClient.java 357)</span><br><span class="line">  at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient (HttpURLConnection.java 1220)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.plainConnect0 (HttpURLConnection.java 1156)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.plainConnect (HttpURLConnection.java 1050)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.connect (HttpURLConnection.java 984)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.getOutputStream0 (HttpURLConnection.java 1334)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.getOutputStream (HttpURLConnection.java 1309)</span><br><span class="line">  ...(省略更多业务代码)</span><br><span class="line">  </span><br><span class="line">  备注：以上异常信息实际是因为创建 HTTP 链接过多，超过了操作系统设置的最大值，这个异常与创建 TransportClient 过多类似，所以拿它举例，实际排查思路还是以 TransportClient 为准。</span><br></pre></td></tr></table></figure><p>查看异常信息里面的重点内容：<code>java.net.SocketException: Too many open files</code>，有时候在中文运行系统环境中会显示：<code>打开的文件过多 </code>，其实是一个意思。</p><p> 本文介绍遇到此问题后分析、解决的方法，开发环境基于 <code>Elasticsearch v1.7.5</code>【这是一个很古老的版本了】、<code>JDK v1.8</code>，其它版本的报错详细信息可能会大同小异，但是主要异常信息以及原因是一致的。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 首先说明一下业务代码中的相关逻辑，使用 <code>Elasticsearch</code> 中的 <code>TransportClient</code> 接口连接集群，进行查询操作，<code>TransportClient</code> 接口的使用方式可以参考我的另外一篇博文：<a href="https://blog.playpi.org/2018022401.html" target="_blank" rel="noopener">Elasticsearch 根据查询条件删除数据的 API</a> 。</p><p>今天启动程序正常运行一段时间后，抛出异常，持续多次，日志内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.net.SocketException: Too many open files</span><br><span class="line">  at java.net.Socket.createImpl (Socket.java:460)</span><br><span class="line">  at java.net.Socket.connect (Socket.java 587)</span><br><span class="line">  at sun.net.NetworkClient.doConnect (NetworkClient.java 175)</span><br><span class="line">  at sun.net.www.http.HttpClient.openServer (HttpClient.java 463)</span><br><span class="line">  at sun.net.www.http.HttpClient.openServer (HttpClient.java 558)</span><br><span class="line">  at sun.net.www.http.HttpClient.&lt;init&gt;(HttpClient.java 242)</span><br><span class="line">  at sun.net.www.http.HttpClient.New (HttpClient.java 339)</span><br><span class="line">  at sun.net.www.http.HttpClient.New (HttpClient.java 357)</span><br><span class="line">  at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient (HttpURLConnection.java 1220)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.plainConnect0 (HttpURLConnection.java 1156)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.plainConnect (HttpURLConnection.java 1050)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.connect (HttpURLConnection.java 984)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.getOutputStream0 (HttpURLConnection.java 1334)</span><br><span class="line">  sun.net.www.protocol.http.HttpURLConnection.getOutputStream (HttpURLConnection.java 1309)</span><br><span class="line">  ...(省略更多业务代码)</span><br><span class="line">  </span><br><span class="line">  备注：以上异常信息实际是因为创建 HTTP 链接过多，超过了操作系统设置的最大值，这个异常与创建 TransportClient 过多类似，所以拿它举例，实际排查思路还是以 TransportClient 为准。</span><br></pre></td></tr></table></figure><p><strong>备注 </strong>：以上异常信息实际是因为创建 <code>HTTP</code> 链接过多，超过了操作系统设置的最大值，这个异常与创建 <code>TransportClient</code> 过多类似，所以拿它举例，实际排查思路还是以 <code>TransportClient</code> 为准。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191117154740.png" alt="异常日志" title="异常日志"></p><p>在这里看不到具体的代码出错位置，首先需要跟踪找到业务代码。经过排查，发现是在一个关于 <code>Elasticsearch</code> 的工具类中，在创建 <code>TransportClient</code> 连接实例的时候，抛出这个异常。</p><p>代码已经被我上传至 <code>GitHub</code>，详见：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-elasticsearch/src/main/java/org/playpi/study/util" target="_blank" rel="noopener">EsClusterUtil.initTransportClient</a> ，搜索类名 <code>EsClusterUtil</code> 即可，仅供参考【此代码的书写基于 <code>Elasticsearch v5.6.8</code>，与 <code>v.1.7.5</code> 略有不同】。</p><p>方法代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 根据主机端口列表 / 集群名称，创建 es 连接 </span><br><span class="line">     * 由于开启连接需要占用资源，不要开启过多，并在使用完毕后及时关闭 </span><br><span class="line">     *</span><br><span class="line">     * @param hostArr</span><br><span class="line">     * @param clusterName</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">public static TransportClient initTransportClient (String [] hostArr, String clusterName) &#123;</span><br><span class="line">	TransportClient client = null;</span><br><span class="line">	Settings settings = Settings.builder ()</span><br><span class="line">	                .put (&quot;cluster.name&quot;, clusterName)</span><br><span class="line">	                .put (&quot;client.transport.ping_timeout&quot;, &quot;60s&quot;)</span><br><span class="line">	                .put (&quot;client.transport.sniff&quot;, true)// 开启嗅探特性 </span><br><span class="line">	.build ();</span><br><span class="line">	/**</span><br><span class="line">         * String [] hostArr = new String []&#123;&quot;hostname1:port&quot;, &quot;hostname2:port&quot;, &quot;hostname3:port&quot;&#125;;</span><br><span class="line">         */</span><br><span class="line">	TransportAddress [] transportAddresses = new InetSocketTransportAddress [hostArr.length];</span><br><span class="line">	for (int i = 0; i &lt; hostArr.length; i++) &#123;</span><br><span class="line">		String [] parts = hostArr [i].split (&quot;:&quot;);</span><br><span class="line">		try &#123;</span><br><span class="line">			InetAddress inetAddress = InetAddress.getByName (parts [0]);</span><br><span class="line">			transportAddresses [i] = new InetSocketTransportAddress (inetAddress, Integer.parseint (parts [1]));</span><br><span class="line">		&#125;</span><br><span class="line">		catch (UnknownHostException e) &#123;</span><br><span class="line">			log.error (&quot;!!!!es 连接初始化出错: &quot; + e.getMessage (), e);</span><br><span class="line">			return client;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	client = new PreBuiltTransportClient (settings)</span><br><span class="line">	                .addTransportAddresses (transportAddresses);</span><br><span class="line">	return client;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，这里的方法不是单例模式，仅仅是创建一个 <code>TransportClient</code> 实例。</p><p>如果在业务代码中频繁调用这个方法，可能会创建大量的连接，而如果又没有及时关闭，有潜在的危险。</p><p>顺着这个思路继续找下去，的确，在业务代码中会创建大量的连接，然后请求 <code>Elasticsearch</code> 集群，更为奇葩的是，在使用完成后也没有关闭 <code>TransportClient</code> 连接，而是不管不问，让它自生自灭。</p><p>这样怎么能行，肯定会有大量连接没有关闭，占用着 <code>Elasticsearch</code> 集群的资源。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><p> 上面对于问题的分析、排查基本完成，下面就要仔细分析集群的设置以及给出可行的解决思路。</p><p>先使用 <code>Elasticsearch</code> 官方的 <code>api</code> 查看集群的文件句柄使用情况：<code>GET /_nodes/stats?pretty</code>，找到 <code>process</code> 下面的配置 <code>open_file_descriptors</code>、<code>max_file_descriptors</code> 。</p><p><code>v5.6.8</code> 的查看结果 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191117184201.png" alt="v5.6.8 查看 open_file_descriptors" title="v5.6.8 查看 open_file_descriptors"></p><p><code>v1.7.5</code> 的查看结果，没有 <code>max_file_descriptors</code> 显示</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191117184244.png" alt="v1.7.5 查看 open_file_descriptors" title="v1.7.5 查看 open_file_descriptors"></p><p> 使用 <code>GET _nodes/stats/process?filter_path=**.max_file_descriptors</code> 查看集群的最大限制，和上面的结果一致，可以看到是数十万，已经是很大的数值了【<code>v5.6.8</code> 可以查看，<code>v1.7.5</code> 不可查看】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191117184253.png" alt="v5.6.8 查看 max_file_descriptors" title="v5.6.8 查看 max_file_descriptors"></p><p>根据 <code>open_file_descriptors</code> 的结果，仅仅使用了数千个，而集群允许使用数十万个【<code>max_file_descriptors</code> 参数】，所以业务中不可能使用这么多连接，真的使用这么多集群恐怕无法正常运行了。</p><p>由此进一步猜测，业务中的报错可能和执行进程的操作系统、用户有关，根据官网的介绍：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/file-descriptors.html" target="_blank" rel="noopener">file-descriptors</a> ，不妨查看系统的配置，打开系统的 <code>cat /etc/security/limits.conf</code> 文件，可以看到限制的最大文件句柄数为 65535【星号表示针对所有的用户生效】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191117184050.png" alt="查看系统的 limits" title="查看系统的 limits"></p><p>还可以继续使用 <code>ulimit -a</code> 验证操作系统对当前用户的限制是不是这么大，如下图所示，根据 <code>open files</code> 配置，的确是的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191117184018.png" alt="查看用户的 ulimit" title="查看用户的 ulimit"></p><p>这么一来，程序运行时如果创建的连接数超过 65535 个，就会被操作系统限制，而这个数万级别的数量还是有可能的。</p><p>至此，问题基本分析出来了，主要就是业务代码中创建的 <code>Elasticsearch</code> 连接数过多，被操作系统拒绝了，才会导致本文开头的异常。那么解决方案就很简单了，在业务代码中限制创建的连接数即可【使用单例模式创建连接或者使用完成后及时关闭连接】。</p><p>最后总结一下：</p><p>这种创建连接的操作，最好使用单例模式进行设计，这样无论业务代码怎么调用，都不会创建过多的实例，从根本上杜绝滥用的情况。</p><p>在使用这种占用资源的场景下，例如：<code>Elasticsearch</code> 的 <code>TransportClient</code> 对象，使用完成后要及时关闭，不能占用着连接不使用但是又不关闭，这样肯定是给 <code>Elasticsearch</code> 集群造成压力，其它文件流也是类似。等到连接数达到最大时，<code>Elasticsearch</code> 集群也就会一直报错：打开的文件过多。</p><p>但是，还要注意一点，在不使用单例模式的情况下，合理地关闭连接也可能会有问题，因为 <code>Elasticsearch</code> 会维护一个连接池，代码显示 <code>close</code> 后连接并不一定真的被关闭，因此使用单例模式是最好的选择。</p><p>加大系统的文件句柄数【或者是用户的文件句柄数】不是根本解决办法，只是滋养了烂代码的生存空间，最终还是会重现问题。最好的方式当然是把生成 <code>TransportClient</code> 的方法改成单例模式，或者使用完成后及时关闭连接，简单正确，可以永久解决此问题。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 以上排查思路以客户端连接数为切入点，因为一开始查到 <code>Elasticsearch</code> 集群的 <code>max_file_descriptors</code> 参数设置的足够大，所以不太可能是 <code>Elasticsearch</code> 集群的问题，转而把关注点放到客户端的使用上。其实，无论是使用 <code>HTTP</code> 连接还是官方的 <code>TransportClient</code> 连接，如果连接数超过了操作系统的设置，就会出现 <code>Too many open files</code> 这个异常。</p><p>关于文件描述符的官网介绍：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/file-descriptors.html" target="_blank" rel="noopener">file-descriptors</a> 。</p><p>使用单例模式，解决问题，<a href="https://www.cnblogs.com/GoQC/p/6803341.html" target="_blank" rel="noopener">博客园 </a> 。</p><p> 关于用户、系统的文件句柄数上限，<a href="https://elasticsearch.cn/question/4702" target="_blank" rel="noopener">elastic 中文社区 </a> 。如果是启动 <code>Elasticsearch</code> 进程时出现这个问题，导致启动失败，可以查看对应的进程占用了多少个文件句柄，使用命令：<code>losf -p pid |wc -l</code>。如果是 <code>Elasticsearch</code> 本身占用了过多的文件句柄，可以考虑是不是索引的段个数设置不合理，参考：<a href="https://www.jianshu.com/p/0ceb59025521" target="_blank" rel="noopener"> 索引段个数的问题 </a> ，可以使用 <code>GET your_index_name/_segments</code> 查看段信息。</p><p> 关于系统配置生效问题：<a href="http://imsilence.github.io/2015/09/16/elasticsearch/elasticsearch_max_open_files" target="_blank" rel="noopener">记一次修改 elasticsearch 文件描述符数量</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 根据查询条件删除数据的 API</title>
    <url>/2018022401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>在使用 Elasticsearch 的时候，有时候免不了存入了一些脏数据，或者多余的数据，此时如果想把这部分数据删除，第一时间想到的就是删除接口，类似于关系型数据库中的 <strong>delete</strong> 操作。尽管 <strong>删除 </strong>这个操作在 IT 的世界里是大忌，甚至 <strong>从删库到跑路 </strong>这句话早已经成为了段子，但是只要控制好流程，经过多人审核，并做好备份，必要的时候删除这个操作还是要出场的。好，言归正传，本文记录 Elasticsearch 中的删除接口的使用，以及不同版本之间的差异。</p><a id="more"></a><h1 id="网络接口"><a href="# 网络接口" class="headerlink" title="网络接口"></a>网络接口 </h1><p> 这里的网络接口其实就是指 HTTP 的 RESTful 接口，优点就是接口稳定，各版本不会有差别，兼容多种编程语言的调用，只要能发送 HTTP 请求即可，缺点就是返回的数据结果是原生的 Elasticsearch 数据，需要调用方自己解析处理。</p><p>好，关于接口的情况不再多做解释，直接进入正题，怎么删除数据。不得不再多解释一点，关于 Elasticsearch 的删除数据接口在不同版本之间有变化。</p><ul><li>在 1.x 的版本中，可以直接使用 <strong>DELETE</strong> 请求加上 <strong>_query</strong> 查询语句来删除数据 </li><li> 在 2.x 的版本中，此功能被从 core 中移除，单独作为插件使用，因为官方认为可能会引发一些错误，如果需要使用，安装插件即可：<strong>bin/plugin install delete-by-query</strong>，使用方式与上述一致 </li><li> 在 5.x 的版本中，此功能又回归到 core，无需安装插件，但是使用方式变化了，是使用 <strong>POST</strong> 请求加上 <strong>_delete_by_query</strong> 查询语句来删除数据 </li></ul><p> 下面直接举例说明：</p><p>1、在 1.x、2.x 的版本中，发送的是 <strong>DELETE</strong> 请求，并且使用 <strong>_query</strong> 关键字。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DELETE 主机地址 / 删除数据的索引名 / 删除数据的索引 type/_query</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、在 5.x 的版本中，发送的是 <strong>POST</strong> 请求，并且使用 <strong>_delete_by_query</strong> 关键字。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST 主机地址 / 删除数据的索引名 / 删除数据的索引 type/_delete_by_query</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我这里为了代码简洁，查询条件设置的为 <strong>match_all</strong>，会命中所有数据，因此会删除指定索引 type 下的所有数据。如果只是删除部分数据，只要指定自己的查询条件即可，例如删除用户索引下 uid 为特定值的数据【以 5.2 版本语法演示】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST 主机地址 / 用户的索引名 / 用户的索引 type/_delete_by_query</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;uid&quot;: [</span><br><span class="line">                &quot;uid1&quot;,</span><br><span class="line">                &quot;uid2&quot;,</span><br><span class="line">                &quot;uid2&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回的数据格式如下，包含删除记录条数、消耗时间等信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 147,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;deleted&quot;: 119,</span><br><span class="line">  &quot;batches&quot;: 1,</span><br><span class="line">  &quot;version_conflicts&quot;: 0,</span><br><span class="line">  &quot;noops&quot;: 0,</span><br><span class="line">  &quot;retries&quot;: &#123;</span><br><span class="line">    &quot;bulk&quot;: 0,</span><br><span class="line">    &quot;search&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;throttled_millis&quot;: 0,</span><br><span class="line">  &quot;requests_per_second&quot;: -1.0,</span><br><span class="line">  &quot;throttled_until_millis&quot;: 0,</span><br><span class="line">  &quot;total&quot;: 119,</span><br><span class="line">  &quot;failures&quot; : []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="客户端接口"><a href="# 客户端接口" class="headerlink" title="客户端接口"></a>客户端接口 </h1><p> 这里的客户端接口就是官方或者社区开发的适配各个编程语言的接口，它和 RESTful 接口相匹配，但是必须写代码实现查询或者取数的操作，例如：Java、Python、Go 等。这种接口的优点是不用担心使用出错【例如在 HTTP 中，参数构造错误导致请求失败】，只要按照接口写代码，请求的构造过程按照官方提供的接口来就行，而且，请求的数据结果是被封装为实体的，不需要额外解析数据结构，直接使用即可。但是，有时候优点也是缺点，由于接口过于死板，导致多版本之间不兼容，例如 1.x 和 2.x 之间的 TransportClient 生成方式就不兼容，导致一份代码只能请求一个版本的 Elasticsearch 集群，此时对于多版本 Elasticsearch 集群之间的请求则无能为力。</p><p>好，直接进入正题，给出删除数据的示例，直接使用 5.1.1 版本的示例，其它的请参考文末的官方文档【此外还可以根据 client 指定 id 进行单条删除，不属于根据查询条件删除的范畴，不再赘述】，这个操作如果耗时很长，还会有异步的问题，也可以参考官方文档。此处需要特别注意 5.1、5.6 之间的使用方式也略有不同，具体以官方文档为准，我就被坑了，例如 BulkIndexByScrollResponse、BulkByScrollResponse。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BulkIndexByScrollResponse response =</span><br><span class="line">                DeleteByQueryAction.INSTANCE.newRequestBuilder (client)</span><br><span class="line">                        .filter (QueryBuilders.matchQuery (&quot;uid&quot;, &quot;uid1&quot;))</span><br><span class="line">                        .filter (QueryBuilders.typeQuery (&quot; 需要删除的索引类型 & quot;))</span><br><span class="line">                        .source (&quot; 需要删除的索引名称 & quot;)</span><br><span class="line">                        .get ();</span><br><span class="line">// 返回删除的行数 </span><br><span class="line">long deleted = response.getDeleted ();</span><br></pre></td></tr></table></figure><p>注意如果是 2.x 版本是不支持删除的，但是可以更新，如果更新还需要增加相关依赖：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch.module&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;reindex&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.3.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>上面的删除代码示例中用到了 client 变量，其实就是 TransportClient 的实例，下面再给出不同版本 Elasticsearch 的 TransportClient 初始化方式【需要注意，访问不同版本的 Elasticsearch 集群，需要依赖不同版本的 org.elasticsearch 官方包，而且特别要注意 5.x 版本的还需要额外的 transport 依赖包】。</p><p>1、1.7.5 版本，需要集群名字、主机名、tcp 端口等信息。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Settings settings = ImmutableSettings.settingsBuilder ()</span><br><span class="line">                .put (&quot;cluster.name&quot;, &quot;your_cluster_name&quot;)</span><br><span class="line">                .put (&quot;client.transport.ping_timeout&quot;, &quot;60s&quot;)</span><br><span class="line">                .put (&quot;client.transport.sniff&quot;, true)</span><br><span class="line">                .put (&quot;discovery.zen.fd.ping_retries&quot;, 5)</span><br><span class="line">                .build ();</span><br><span class="line">String [] hostArr = new String []&#123;&quot;hostname1:port&quot;, &quot;hostname2:port&quot;, &quot;hostname3:port&quot;&#125;;</span><br><span class="line">TransportAddress [] transportAddresses = new InetSocketTransportAddress [hostArr.length];</span><br><span class="line">TransportClient client = new TransportClient (settings);</span><br><span class="line">for (int i = 0; i &lt; hostArr.length; i++) &#123;</span><br><span class="line">	String [] parts = hostArr [i].split (&quot;:&quot;);</span><br><span class="line">	try &#123;</span><br><span class="line">		InetAddress inetAddress = InetAddress.getByName (parts [0]);</span><br><span class="line">		transportAddresses [i] = new InetSocketTransportAddress (inetAddress, Integer.parseint (parts [1]));</span><br><span class="line">	&#125;</span><br><span class="line">	catch (UnknownHostException e) &#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">client = client.addTransportAddresses (transportAddresses);</span><br></pre></td></tr></table></figure><p>2、2.3.2 版本，需要集群名字、主机名、tcp 端口等信息，生成方式与 1.7.5 版本的略有不同。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Settings settings = Settings.settingsBuilder ()</span><br><span class="line">                .put (&quot;cluster.name&quot;, &quot;your_cluster_name&quot;)</span><br><span class="line">                .put (&quot;client.transport.ping_timeout&quot;, &quot;60s&quot;)</span><br><span class="line">                .put (&quot;client.transport.sniff&quot;, true)</span><br><span class="line">                .build ();</span><br><span class="line">String [] hostArr = new String []&#123;&quot;hostname1:port&quot;, &quot;hostname2:port&quot;, &quot;hostname3:port&quot;&#125;;</span><br><span class="line">TransportAddress [] transportAddresses = new InetSocketTransportAddress [hostArr.length];</span><br><span class="line">for (int i = 0; i &lt; hostArr.length; i++) &#123;</span><br><span class="line">	String [] parts = hostArr [i].split (&quot;:&quot;);</span><br><span class="line">	try &#123;</span><br><span class="line">		InetAddress inetAddress = InetAddress.getByName (parts [0]);</span><br><span class="line">		transportAddresses [i] = new InetSocketTransportAddress (inetAddress, Integer.parseInt (parts [1]));</span><br><span class="line">	&#125;</span><br><span class="line">	catch (UnknownHostException e) &#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">TransportClient client = TransportClient.builder ()</span><br><span class="line">                .settings (settings)</span><br><span class="line">                .build ()</span><br><span class="line">                .addTransportAddresses (transportAddresses);</span><br></pre></td></tr></table></figure><p>3、5.1.1 版本，需要集群名字、主机名、tcp 端口等信息，生成方式与 2.3.2 版本的略有不同，特别要注意 5.1.1 版本的还需要额外的 transport 依赖包，否则找不到 PreBuiltTransportClient 类。</p><p>额外的依赖包信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;5.1.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;transport&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;5.1.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>代码信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Settings settings = Settings.builder ()</span><br><span class="line">                .put (&quot;cluster.name&quot;, &quot;your_cluster_name&quot;)</span><br><span class="line">                .put (&quot;client.transport.ping_timeout&quot;, &quot;60s&quot;)</span><br><span class="line">                .put (&quot;client.transport.sniff&quot;, true)</span><br><span class="line">                .build ();</span><br><span class="line">String [] hostArr = new String []&#123;&quot;hostname1:port&quot;, &quot;hostname2:port&quot;, &quot;hostname3:port&quot;&#125;;</span><br><span class="line">TransportAddress [] transportAddresses = new InetSocketTransportAddress [hostArr.length];</span><br><span class="line">for (int i = 0; i &lt; hostArr.length; i++) &#123;</span><br><span class="line">	String [] parts = hostArr [i].split (&quot;:&quot;);</span><br><span class="line">	try &#123;</span><br><span class="line">		InetAddress inetAddress = InetAddress.getByName (parts [0]);</span><br><span class="line">		transportAddresses [i] = new InetSocketTransportAddress (inetAddress, Integer.parseint (parts [1]));</span><br><span class="line">	&#125;</span><br><span class="line">	catch (UnknownHostException e) &#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">TransportClient client = new PreBuiltTransportClient (settings)</span><br><span class="line">                .addTransportAddresses (transportAddresses);</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="# 参考" class="headerlink" title="参考"></a>参考 </h1><p> 参考内容来自于官方文档，注意不同版本有不同的文档，某些内容稍有不同：</p><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.2/java-docs-delete-by-query.html" target="_blank" rel="noopener">5.2 版本的 Java 接口</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.2/docs-delete-by-query.html" target="_blank" rel="noopener">5.2 版本的 HTTP 接口</a></li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>API</tag>
        <tag>delete</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 的 fielddata 入门指引</title>
    <url>/2020050101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>昨天查看 <code>Elasticsearch</code> 集群监控，发现有几个 <code>Elasticsearch</code> 节点的 <code>JVM Heap</code> 异常，上下波动非常频繁，进一步查看 <code>GC</code>，发现 <code>Full GC</code> 非常频繁，每分钟达到 5-10 次，而累加耗时有 10-20 秒，也就是说有 17%-33% 的时间都在做 <code>Full GC</code>，这显然是不健康的。</p><p>进一步查看 <code>CPU</code> 使用情况，发现 <code>CPU</code> 使用率由正常的 20% 左右，达到现在的 50%-70%，这也是不正常的。</p><p>排查方向是看是否有大量的 <code>aggregations</code> 请求或者排序 <code>sort</code> 操作，这种情况才会造成大量的内存占用【<code>fielddata</code> 缓存】。当然其它情况也有可能，但概率低【例如大查询，<code>query</code> 语句复杂，数据量大】，具体情况需要具体对待。排查的过程就不说了，由此做引子，先简单对 <code>fielddata</code> 缓存做入门指引。</p><p>首先声明，本文记录的内容是 <code>fielddata</code> 缓存数据、熔断器，不是 <code>text</code> 开启 <code>fielddata</code> 属性那种含义，给出 3 个链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/modules-fielddata.html" target="_blank" rel="noopener">modules-fielddata</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/circuit-breaker.html" target="_blank" rel="noopener">circuit-breaker</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/cluster-nodes-stats.html" target="_blank" rel="noopener">cluster-nodes-stats</a> 。</p><a id="more"></a><h1 id="问题引入"><a href="# 问题引入" class="headerlink" title="问题引入"></a>问题引入 </h1><p> 昨天将要迎来小长假，仔细看了一眼 <code>Elasticsearch</code> 集群的监控，发现某几个 <code>Elasticsearch</code> 节点的 <code>CPU</code> 使用率、<code>JVM</code> 内存的指标都有异常，初步排查下来和 <code>aggregations</code> 请求有关，而根本原因和 <code>fielddata</code> 缓存有关。</p><p>异常的监控 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200506014112.png" alt="CPU 使用率" title="CPU 使用率"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200506014105.png" alt="Full GC 次数" title="Full GC 次数"></p><p> 观察服务端集群的日志，发现有频繁的 <code>Full GC</code> 流程：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2020-05-01T17:01:03,243][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206644 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:03,296][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778952590 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:03,333][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206644 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:03,373][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778442411 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:03,411][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206644 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:03,526][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206644 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:03,665][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206644 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:03,963][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778442411 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:04,037][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206644 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:04,518][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206644 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:04,713][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778372453 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:04,715][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12777862273 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:04,821][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12777862273 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:05,059][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12777626506 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:05,470][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206751 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:05,530][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206751 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:05,693][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778442518 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:09,173][WARN][o.e.m.j.JvmGcMonitorService] [es1] [gc][1567372] overhead, spent [665ms] collecting in the last [1s]</span><br><span class="line">[2020-05-01T17:01:12,000][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778442518 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:12,410][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206751 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:12,652][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206751 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:17,947][WARN][o.e.m.j.JvmGcMonitorService] [es1] [gc][1567379] overhead, spent [2.4s] collecting in the last [2.7s]</span><br><span class="line">[2020-05-01T17:01:20,295][WARN][o.e.i.b.fielddata] [fielddata] New used memory 12778206751 [11.9gb] for data of [_uid] would be larger than configured breaker: 12759701913 [11.8gb], breaking</span><br><span class="line">[2020-05-01T17:01:34,847][WARN][o.e.m.j.JvmGcMonitorService] [es1] [gc][1567395] overhead, spent [1.6s] collecting in the last [1.8s]</span><br><span class="line">[2020-05-01T17:01:41,989][WARN][o.e.m.j.JvmGcMonitorService] [es1] [gc][1567402] overhead, spent [638ms] collecting in the last [1.1s]</span><br><span class="line">[2020-05-01T17:01:51,991][WARN][o.e.m.j.JvmGcMonitorService] [es1] [gc][1567412] overhead, spent [563ms] collecting in the last [1s]</span><br><span class="line">[2020-05-01T17:02:04,601][WARN][o.e.m.j.JvmGcMonitorService] [es1] [gc][1567422] overhead, spent [2.8s] collecting in the last [3.6s]</span><br><span class="line">[2020-05-01T17:02:16,809][WARN][o.e.m.j.JvmGcMonitorService] [es1] [gc][1567433] overhead, spent [1.7s] collecting in the last [2.2s]</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200506014039.png" alt="频繁 Full GC" title="频繁 Full GC"></p><p>日志中显示的 <code>breaking</code>，即熔断，和 <code>fielddata</code> 缓存有关，而根源是 <code>_uid</code> 字段。</p><p>下面简单介绍 <code>fielddata</code> 缓存的内容。</p><h1 id="入门指引"><a href="# 入门指引" class="headerlink" title="入门指引"></a>入门指引 </h1><h2 id="含义"><a href="# 含义" class="headerlink" title="含义"></a> 含义 </h2><p><code>feilddata</code> 缓存的含义：<code>Elasticsearch</code> 节点在处理 <code>aggregations</code>、<code>sort</code>、自定义脚本等请求时，为了快速计算，需要把相关的值全部加载到 <code>JVM</code> 的内存中，而且一般情况下不会释放。</p><p> 原文：</p><blockquote><p>The field data cache is used mainly when sorting on or computing aggregations on a field. It loads all the field values to memory in order to provide fast document based access to those values. The field data cache can be expensive to build for a field, so its recommended to have enough memory to allocate it, and to keep it loaded.</p></blockquote><p>如果对一个多值的字段做此操作，必然需要很大的内存，例如极端一点的 <code>id</code> 字段【值唯一，多少条数据也就有多少个值】、时间戳字段【值的可能性很多】。</p><p>其实，这种数据就是正排索引，刚好与 <code>Elasticsearch</code> 的倒排索引相反，它不是为了快速检索，而是为了计算值的分布、排序。</p><h2 id="相关配置"><a href="# 相关配置" class="headerlink" title="相关配置"></a>相关配置 </h2><p> 提示：这些配置大部分可以通过 <code>put</code> 的方式更新到 <code>Elasticsearch</code> 集群，立即生效。</p><p>1、<code>indices.fielddata.cache.size</code>，字段可以占用缓存的最大值，默认无边界。如果这里不手动设置，建议把熔断器设置好，否则集群在大量的 <code>aggregations</code> 请求下很容易挂掉。</p><p>官方解释：</p><blockquote><p>The max size of the field data cache, eg 30% of node heap space, or an absolute value, eg 12GB. Defaults to unbounded.</p></blockquote><p>注意：这个是静态设置，必须在 <code>Elasticsearch</code> 群集中的每个数据节点上进行配置，所以无法实时更新。建议设置时取值比 <code>indices.breaker.fielddata.limit</code> 稍小，否则这个参数也就没有意义了【到达 <code>indices.breaker.fielddata.limit</code> 已经被熔断了】。</p><p>2、<code>indices.breaker.fielddata.limit</code>，<code>fielddata</code> 占用内存的熔断器，超过后出发垃圾回收机制，回收内存。</p><blockquote><p>Limit for fielddata breaker, defaults to 60% of JVM heap</p></blockquote><p><code>indices.breaker.fielddata.overhead</code>，一个系数【我也没搞明白，大概是内存占用估算时需要乘以它】。</p><blockquote><p>A constant that all field data estimations are multiplied with to determine a final estimation. Defaults to 1.03</p></blockquote><p>3、<code>indices.breaker.total.limit</code>，总的内存限制，它可以保护所有的请求、处理过程。</p><blockquote><p>Starting limit for overall parent breaker, defaults to 70% of JVM heap.</p></blockquote><p>4、其它几个相关参数。</p><ul><li><code>indices.breaker.request.limit</code>，请求的内存占用限制 </li><li><code>indices.breaker.request.overhead</code>，与上面那个参数相关的系数</li><li><code>network.breaker.inflight_requests.limit</code>，处理请求的内存占用限制</li><li><code>network.breaker.inflight_requests.overhead</code>，与上面那个参数相关的系数</li></ul><h2 id="接口查看示例"><a href="# 接口查看示例" class="headerlink" title="接口查看示例"></a> 接口查看示例 </h2><p> 可以从不同的角度查看。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 查看所有的 </span><br><span class="line">GET /_cat/fielddata</span><br><span class="line"> 过滤字段的 </span><br><span class="line">GET /_cat/fielddata?v&amp;fields=uid&amp;pretty</span><br><span class="line"></span><br><span class="line"># Fielddata summarised by node</span><br><span class="line">GET /_nodes/stats/indices/fielddata?fields=field1,field2</span><br><span class="line"></span><br><span class="line"># Fielddata summarised by node and index</span><br><span class="line">GET /_nodes/stats/indices/fielddata?level=indices&amp;fields=field1,field2</span><br><span class="line"></span><br><span class="line"># Fielddata summarised by node, index, and shard</span><br><span class="line">GET /_nodes/stats/indices/fielddata?level=shards&amp;fields=field1,field2</span><br><span class="line"></span><br><span class="line"># You can use wildcards for field names</span><br><span class="line">GET /_nodes/stats/indices/fielddata?fields=field*</span><br></pre></td></tr></table></figure><p>下面给出 2 种查询示例 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200506013927.png" alt="stats 查看" title="stats 查看"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200506013952.png" alt="cat 查看" title="cat 查看"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a> 备注 </h1><p>1、关于熔断的异常。</p><p> 如果执行的查询刚好遇到熔断，会返回到客户端异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;error&quot;: &quot;... CircuitBreakingException [[FIELDDATA] Data too large, data for [proccessDate] would be larger than limit of [12759701913/11.8gb]]; &#125;]&quot;,</span><br><span class="line">    &quot;status&quot;: 500</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、对于一般的字段，很难达到大量的内存占用，而多值的字段则很容易，例如 <code>id</code>、时间戳等字段，取值范围太广了，无论是聚合还是排序，都需要大内存【而且对于这种字段做聚合、排序显然是无意义的】。</p><p>此外还有一种内置元字段，可能也会被误操作加载到内存中去了【上述现象就是这种】，关于 <code>_uid</code> 元字段的内容请参考官网【<code>v7.x</code> 之后不再有这个字段，因为取消了 <code>type</code>】：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/mapping-uid-field.html" target="_blank" rel="noopener">mapping-uid-field</a> 。</p><p>由于 <code>fielddata</code> 缓存优先级非常高，<code>JVM</code> 做 <code>Full GC</code> 时很难把它清理掉，所以会永远占用着内存，如果内存使用已经达到了上限，则就会引发频繁的 <code>Full GC</code>，严重点 <code>Elasticsearch</code> 节点可能会挂掉。</p><p>所以，手动清除缓存也是有必要的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl localhost:9200/index/_cache/clear?pretty&amp;filter=false&amp;field_data=true&amp;fields=_uid,site_name</span><br><span class="line"></span><br><span class="line"> 关于 `&amp;bloom=false` 参数的问题，要看当前 `Elasticsearch` 版本是否支持，`v5.6.x` 是不支持了。</span><br></pre></td></tr></table></figure><p>3、关于 <code>fielddata</code> 属性【不是本文描述的 <code>fielddata</code> 缓存】。</p><p>关于 <code>text</code> 类型字段的 <code>fielddata</code> 解释，官网链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/fielddata.html" target="_blank" rel="noopener">fielddata</a> 。</p><p>如果对没有开启 <code>fielddata</code> 属性的 <code>text</code> 字段执行聚合、排序等操作，会抛出异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Fielddata is disabled on text fields by default. Set fielddata=true on [your_field_name] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory.</span><br></pre></td></tr></table></figure><p>类型有 <code>paged_bytes</code>【默认的】、<code>fst</code>、<code>doc_values</code> 等几种。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>fielddata</tag>
        <tag>aggregations</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 的 terms lookup 查询</title>
    <url>/2019060601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:48 GMT+0800 (China Standard Time) --><p>对分析工作熟练的人，想必都用过 <code>Excel</code> 中的 <code>VLOOKUP</code> 函数，参考我的另一篇博客：<a href="https://www.playpi.org/2017051401.html">VLOOKUP 函数跨工作表跨文件使用方式 </a> ，但是目前已经被官方取消【2019 年末宣布】，转而使用 <code>XLOOKUP</code>。此外，可能很少有人知道，在 <code>Elasticsearch</code> 中也存在这样一个类似的查询接口：<code>terms lookup</code>，可以跨索引查询数据，看起来很是方便，本文简单介绍一下。开发环境基于 <code>Elasticsearch v5.6.8</code>。</p><a id="more"></a><h1 id="接口介绍"><a href="# 接口介绍" class="headerlink" title="接口介绍"></a> 接口介绍 </h1><p> 在 <code>Elasticsearch</code> 中，是存在父子文档这种设置的，即在父索引中嵌套一个子索引，例如在主帖中嵌套用户的信息。这样查询主帖时，不仅可以同时指定用户的筛选条件，而且返回数据时可以连同用户信息一起返回，在使用层面很方便。</p><p>但是，这种存储方式显然冗余了大量的用户信息，如果数据量级很大，浪费了大量的存储空间，不可取。随着业务的数据增长，这种设计方式肯定要被淘汰掉，转而选择把父子文档拆分，此时如果还想使用类似父子文档的查询特性，可以选择跨索引查询，即 <code>terms lookup</code>。</p><p>例如查询某个用户关注列表中所有用户发表的主帖，如果是拆开查询，需要两步：先查出关注列表，再查询发表的主帖，而使用 <code>terms lookup</code> 查询只需要一步即可。但是这种方式有诸多的限制，下面会举例说明，我想这也是为了性能考虑。</p><p>其实，<code>terms lookup</code> 是一个查询过滤器【<code>filter</code>，从 <code>v0.90</code> 开始引进】，只不过不需要用户指定 <code>filter</code>、<code>filtered</code> 等关键字，所以用户使用起来也无感知。</p><p>参考官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/query-dsl-terms-query.html" target="_blank" rel="noopener">query-dsl-terms-query</a> 。</p><p>读者在继续往下阅读之前可以先去了解一下与 <strong>缓存 </strong>相关的知识点，例如：如何开启、如何关闭、删除缓存、自定义命名、什么场景应该使用、哪些查询不会被缓存。</p><h1 id="演示示例"><a href="# 演示示例" class="headerlink" title="演示示例"></a>演示示例 </h1><p> 我在这里使用两个典型的场景进行演示，一个可以支持，另一个不能支持。假如有 2 个索引：用户 <code>my-index-user</code>、主帖 <code>my-index-post</code>，它们之间是通过用户的 <code>id</code> 来进行关联的【在用户索引中字段为 <code>item_id</code>，在主帖索引中字段为 <code>user_item_id</code>】，即用户可以任意发表主帖。</p><h2 id="场景一"><a href="# 场景一" class="headerlink" title="场景一"></a>场景一 </h2><p> 查询某个用户的关注列表中所有用户发表的主帖。【可以支持】</p><p>查询思路分两个步骤，一是利用 <code>item_id</code> 查询用户索引，返回关注列表 <code>friends</code> 中的所有 <code>item_id</code>；二是利用一步骤中返回的 <code>itemt_id</code> 列表，去匹配主帖的 <code>user_item_id</code> 字段，从而查询所有的主帖。</p><p>转换为 <code>terms lookup</code> 查询为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;user_item_id&quot;: &#123;</span><br><span class="line">              &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">              &quot;type&quot;: &quot;user&quot;,</span><br><span class="line">              &quot;id&quot;: &quot;0f42d65be1f5287e1c9c26e3728814aa&quot;,</span><br><span class="line">              &quot;path&quot;: &quot;friends&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200216174317.png" alt="场景一查询结果" title="场景一查询结果"></p><p>可以看到查询出来 2743 条主帖，这样的查询方式是不是很方便呢。</p><p>下面可以拆分步骤简单验证一下，先查询用户索引，把关注列表查出来：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-user/user/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;id&quot;: [</span><br><span class="line">              &quot;0f42d65be1f5287e1c9c26e3728814aa&quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_source&quot;: [</span><br><span class="line">    &quot;item_id&quot;,</span><br><span class="line">    &quot;friends&quot;,</span><br><span class="line">    &quot;birth_year&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200216175058.png" alt="场景一验证用户索引" title="场景一验证用户索引"></p><p>可以看到有 3 个用户，接着使用 <code>item_id</code> 列表去查询主帖：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;user_item_id&quot;: [</span><br><span class="line">              &quot;98681482902&quot;,</span><br><span class="line">              &quot;63639783663&quot;,</span><br><span class="line">              &quot;59956667929&quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200216175113.png" alt="场景一验证主帖索引" title="场景一验证主帖索引"></p><p>可以看到，也是 2743 条数据，完全一致。</p><h2 id="场景二"><a href="# 场景二" class="headerlink" title="场景二"></a>场景二 </h2><p> 查询出生日期是 1994 年的所有用户发表的主帖。【不可以支持】</p><p>查询思路分两个步骤，一是利用 <code>birth_year</code> 查询用户索引，返回满足条件的所有 <code>item_id</code>；二是利用一步骤中返回的 <code>itemt_id</code> 列表，去匹配主帖的 <code>user_item_id</code> 字段，从而查询所有的主帖。</p><p>转换为 <code>terms lookup</code> 查询为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;user_item_id&quot;: &#123;</span><br><span class="line">              &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">              &quot;type&quot;: &quot;user&quot;,</span><br><span class="line">              &quot;birth_year&quot;: 1994,</span><br><span class="line">              &quot;path&quot;: &quot;item_id&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200216175820.png" alt="场景二查询结果" title="场景二查询结果"></p><p>可以看到，报错了：<code>[terms] query does not support [birth_year] within lookup element</code>，想象很美好，现实很残酷，其实 <code>Elasticsearch</code> 并不支持对用户索引使用非 <code>id</code> 字段条件，也就是指定内层的索引条件，只能是和 <code>id</code> 有关的，这也是一种限制。</p><h2 id="引申说明"><a href="# 引申说明" class="headerlink" title="引申说明"></a>引申说明 </h2><p><code>terms</code> 个数限制，对于场景一来说，如果关注列表中的 <code>item_id</code> 过多，也会导致查询主帖的 <code>terms</code> 匹配失败，因为 <code>terms</code> 查询是有个数限制的。可以通过配置更改，设置 <code>terms</code> 最大个数：<code>index.max_terms_count</code>，默认最大个数为 65535，可以根据集群情况降低，例如设置为 10000，为了集群稳定，一般不需要设置那么大。</p><p> 内层返回字段需要存储，对于场景一来说，如果关注列表 <code>friends</code> 字段没有存储【<code>stored_fields</code> 属性】，只是做了索引，也是无法支持的，会报错：<code>[terms] query does not support [friends] within lookup element</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200216180618.png" alt="不支持未存储的字段" title="不支持未存储的字段"></p><p>对于场景二来说，表现的就是 <code>terms lookup</code> 无法支持复杂的查询条件，只能是和 <code>id</code> 字段有关的，这样就降低了 <code>Elasticsearch</code> 的计算量。</p><h1 id="流程总结"><a href="# 流程总结" class="headerlink" title="流程总结"></a>流程总结 </h1><p> 回顾我们发送到 <code>Elasticsearch</code> 的查询条件，可以看到，它只是一个简单的过滤查询，包含一个 <code>terms</code> 过滤器，匹配指定的 <code>user_item_id</code>。只是该查询条件中的 <code>terms</code> 过滤器使用了一种不同的技巧，即不是明确指定某些 <code>term</code> 的值【没有明确指定 <code>user_item_id</code> 取值列表】，而是从其它的索引中动态加载【从用户索引中加载】。</p><p>可以看到，我们的过滤器是基于 <code>user_item_id</code> 字段，但是并没有进一步指定取值列表，而是引用了新的属性：<code>index</code>、<code>type</code>、<code>id</code>、<code>path</code>。<code>index</code> 属性指明了加载 <code>terms</code> 的索引名称【在上面的例子中是 <code>my-index-user</code>】，<code>type</code> 属性指明了索引类型【在上面的例子中是 <code>user</code>】，<code>id</code> 属性指明了我们在指定索引上使用的查询匹配条件，最后 <code>path</code> 指明了 <code>Elasticsearch</code> 应该从哪个字段中加载 <code>terms</code>【在上面的例子中是 <code>friends</code>】。</p><p>总结一下，<code>Elasticsearch</code> 所做的工作就是从 <code>my-index-user</code> 索引的 <code>user</code> 类型中，<code>id</code> 为 <code>0f42d65be1f5287e1c9c26e3728814aa</code> 的文档里加载 <code>friends</code> 字段中的所有取值。这些取得的值将用于 <code>terms filter</code> 来过滤从 <code>my-index-post</code> 索引中查询到的文档，过滤条件是文档的 <code>user_item_id</code> 字段的值在过滤器中存在。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>1、需要注意的是，由于使用到了缓存机制，比较消耗 <code>Elasticsearch</code> 的内存，不建议大量任意使用，使用前一定要思考：「这个过滤器会被多次重复使用吗？」，避免不必要的资源浪费。</p><p>2、<code>path</code> 参数指定的字段必须是存储在 <code>Elasticsearch</code> 中的，可以返回，如果只是做了索引是不支持的【使用 <code>_source.excludes</code> 关键字排除，只支持查询而已，无法返回】。</p><p>a</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>lookup</tag>
        <tag>filter</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 客户端设置 Windows 下的字符编码</title>
    <url>/2019031901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在 Linux 以及大多数托管网站上，默认的字符编码均是 UTF-8，而 Windows 系统默认编码不是 UTF-8，一般是 GBK。如果在 Windows 平台使用 Git 客户端，不设置 Git 字符编码为 UTF-8，Git 客户端在处理中文内容时会出现乱码现象，很是烦人。但是，如果能正确设置字符编码，则可以有效解决处理中文和中文显示的问题。大多数技术从业者应该都遇到过各种各样的编码问题，后来渐渐习惯了使用英文，尽量避免中文，但是也有一些场景是必须使用中文的。本文就记录解决 Git 中文处理和中文显示的问题的过程，系统环境基于 Windows7 X64，Git 基于 v2.18.0。</p><a id="more"></a><h1 id="乱码现象"><a href="# 乱码现象" class="headerlink" title="乱码现象"></a>乱码现象 </h1><p>Git 是一款非常好用的分布式版本控制系统，为了更好地使用它，一般都需要 Git 客户端的配合，下载使用参考：<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a> 。</p><p> 在 Windows 平台使用 Git 客户端的过程中，有一个问题你一定逃不掉，那就是乱码问题。这是因为 Windows 系统的编码是 GBK，而 Git 客户端的编码是 UTF-8，当两种不同的编码相遇，必然有一方会乱码。如果设置 Git 客户端的编码为 GBK，那么在使用 Git 客户端处理系统文件的时候可以正常显示，但是处理 Git 版本控制内容的时候，就会乱码，无法支持中文。如果反过来呢，把 Git 客户端的编码设置为 UTF-8，那么处理版本控制内容就可以有效支持中文，但是处理系统文件的时候又会乱码。</p><p>Git 客户端设置 UTF-8 编码，处理系统文件显示乱码 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17blzgl2zj20l50cpjt9.jpg" alt="ls 命令中文乱码" title="ls 命令中文乱码"></p><h1 id="解决方式"><a href="# 解决方式" class="headerlink" title="解决方式"></a> 解决方式 </h1><p> 这样看起来似乎没有解决方法，其实不是的，还是有很好的解决方法的。我这里为了完全支持版本管理系统，版本管理优先，肯定要统一设置为 UTF-8 编码，然后通过 Git 客户端的编码自动转换来支持系统的 GBK 编码。</p><p>这里先提前说明，在使用 Git 客户端的时候，Git 的安装目录【一般默认是 C:\Program Files\Git】，也就是 Git 的根目录。在使用 <strong>ls</strong> 等命令处理文件时，如果携带了 <strong>/</strong> 字符，其实就表示从 Git 的安装目录开始。例如在里面寻找 etc 目录，如果是使用 Git Bash 打开的，可以直接使用根目录的方式，<strong>cd /etc/</strong>。再例如 <strong>vi /etc/git-completion.bash</strong> 不是表示从系统的根目录开始寻找文件【Windows 系统也没有根目录的概念】，而是表示从 Git 的安装目录开始寻找文件。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17bn7wtv0j20nd0dumyg.jpg" alt="Git 安装目录" title="Git 安装目录"></p><h2 id="设置 -Git- 客户端"><a href="# 设置 -Git- 客户端" class="headerlink" title="设置 Git 客户端"></a>设置 Git 客户端 </h2><p> 打开 Git 客户端的主页面，右键打开菜单栏【或者点击窗口的左上角也可以打开】，选择 <strong>Options</strong> 选项。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17bmpt7mnj20l50cp0tw.jpg" alt="Options 选项" title="Options 选项"></p><p>接着选择 <strong>Text</strong> 参数配置，把编码方式由 GBK 改为 UTF-8【locale 也要设置为 zh_CN】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17bnna4xyj20l50cpacj.jpg" alt="Text 参数配置" title="Text 参数配置"></p><p>设置完成后，一定会导致一个现象，那就是使用 <strong>ls</strong> 查看系统文件时，带有中文的目录和带有中文的文件，一定是乱码的，根本看不清楚显示的是什么。不过不用担心，后面会通过设置让它恢复正常的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17blzgl2zj20l50cpjt9.jpg" alt="ls 命令中文乱码" title="ls 命令中文乱码"></p><p>接下来要解决的是显示的问题，目的是保证 Windows 的 GBK 编码可以在 Git 客户端正常显示。由于 Git 客户端被设置为了 UTF-8 编码，使用 <strong>ls</strong> 命令查看目录文件详情的时候，一定是乱码的，什么也看不出来【数字和英文不受影响】。那就需要设置 <strong>ls</strong> 命令的参数，让它按照 Git 客户端的编码来显示，不支持的字符也要显示，这样再使用 <strong>ls</strong> 命令的时候，就会自动把 GBK 编码转为 UTF-8 编码，那么带有中文的目录、带有中文的文件都能正常显示了。</p><p>最简单的做法，就是需要指定 <strong>ls</strong> 命令的附加参数【–show-control-chars】，为了方便，直接更改配置文件 <strong>/etc/git-completion.bash</strong> 【没有的话新建一个既可】，在行尾增加配置项 <strong>alias ls=”ls –show-control-chars –color”</strong> 。其实就是通过新建别名这个技巧把 <strong>ls</strong> 命令的含义扩展了，让它可以根据 Git 客户端的编码转换系统的编码【在这里就是把 GBK 转为 UTF-8】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/git-completion.bash</span><br><span class="line">alias ls=&quot;ls --show-control-chars --color&quot;</span><br></pre></td></tr></table></figure><p>更改完成后，可以看到能正常显示系统中的带有中文名称的文件了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17bo2mcrej20l50cpq4y.jpg" alt="ls 可以正常显示中文" title="ls 可以正常显示中文"></p><p>但是还要注意一点，如果使用 Git 客户端的 Bash 处理其它命令，一定会乱码的，因为不像 <strong>ls</strong> 那样做了编码转换。以下 2 例【分别时使用 elasticsearch、java 命令】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g185ktkbutj20l50cp0ul.jpg" alt="elasticsearch 命令乱码" title="elasticsearch 命令乱码"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g185l2lrrhj20l50ghmz2.jpg" alt="java 命令乱码" title="java 命令乱码"></p><p>那这个现象有没有办法解决呢，网上大多数解决办法都是说把 Git 客户端的编码设置为和 Windows 系统一样，一般设置为 GBK，这显然是又倒退回去了【为了满足 Git 一定要设置为 UTF-8】。其实唯一的解决办法就是从命令的参数下手，把原生的命令利用别名机制给加上编码有关的参数，和修改 <strong>ls</strong> 命令的做法一致。以下供参考：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 在文件最后追加，不要修改文件原有的内容 </span><br><span class="line">vi /etc/bash.bashrc</span><br><span class="line">alias javac=&quot;javac -J-Dfile.encoding=UTF-8&quot;</span><br><span class="line">alias java=&quot;java -Dfile.encoding=UTF-8&quot;</span><br></pre></td></tr></table></figure><h2 id="设置 -Git"><a href="# 设置 -Git" class="headerlink" title="设置 Git"></a>设置 Git</h2><p>接下来就是设置 Git 进行版本控制时使用的编码方式，例如提交信息时支持输入中文日志、输出 log 可以正常显示中文。</p><p>设置 Git 有两种方式，一种是通过更改配置文件，另一种是通过 Git 自带的命令来配置参数。为了显得没有手动去破坏 Git 的原有配置文件，我就使用 Git 自带的命令来配置编码。当然，通过更改配置文件的方式也会一同描述出来。</p><p>1、通过命令行把 Git 的各种编码都设置为 UTF-8</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global core.quotepath false          # 显示 status 编码 </span><br><span class="line">git config --global gui.encoding utf-8            # 图形界面编码 </span><br><span class="line">git config --global i18n.commit.encoding utf-8    # 处理提交信息编码 </span><br><span class="line">git config --global i18n.logoutputencoding utf-8  # 输出 log 编码 </span><br><span class="line">export LESSCHARSET=utf-8                          # 因为 git log 默认使用 less 分页，所以需要 bash 对 less 命令处理时使用 utf-8 编码 </span><br></pre></td></tr></table></figure><p>2、如果通过配置文件的方式来更改，则需要编辑配置文件 <strong>/etc/gitconfig</strong> 【没有则新建一个】，在里面设置以下内容。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[core]</span><br><span class="line">        quotepath = false </span><br><span class="line">[gui]</span><br><span class="line">        encoding = utf-8 </span><br><span class="line">[i18n]</span><br><span class="line">        commitencoding = utf-8 </span><br><span class="line">        logoutputencoding = utf-8</span><br></pre></td></tr></table></figure><p>另外还需要在配置文件 <strong>/etc/profile</strong> 中新增 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export LESSCHARSET=utf-8</span><br></pre></td></tr></table></figure><p>3、特殊说明</p><p><strong>gui.encoding = utf-8</strong> 是为了解决 git gui 和 gitk 中的中文乱码问题，如果发现代码中的注释显示乱码，可以在所属项目的根目录中 <strong>.git/config</strong> 文件中添加：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[gui]</span><br><span class="line">        encoding = utf-8</span><br></pre></td></tr></table></figure><p><strong>i18n.commitencoding = utf-8</strong> 是为了设置 commit log 提交时使用 UTF-8 编码。<br><strong>i18n.logoutputencoding = utf-8</strong> 是为了保证在 <strong>git log</strong> 时使用 UTF-8 编码。<br><strong>export LESSCHARSET=utf-8</strong> 是为了保证 <strong>git log</strong> 翻页时使用 UTF-8 编码，这样就可以正常显示中文了【配合前面的 <strong>i18n.logoutputencoding</strong> 设置】。</p><h2 id="验证"><a href="# 验证" class="headerlink" title="验证"></a> 验证 </h2><p>add 执行的时候 Git 输出的日志都是中文显示的，特别是带有中文名称的文件。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17bv0ph2yj20l50f20uh.jpg" alt="add 命令输出中文" title="add 命令输出中文"></p><p> 验证提交时填写日志信息，可以直接填写中文日志，另外 Git 的输出日志也是以中文来显示的，可以看到哪些文件变更了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17boorhqyj20l50cpgn8.jpg" alt="验证提交时填写中文日志" title="验证提交时填写中文日志"></p><p>验证使用 <strong>git log</strong> 查看历史日志时正常显示中文内容 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17bosnlsnj20l50cp0tt.jpg" alt="查看历史日志时正常显示中文内容 1" title="查看历史日志时正常显示中文内容 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g17box3cduj20l50cp3zx.jpg" alt="查看历史日志时正常显示中文内容 2" title="查看历史日志时正常显示中文内容 2"></p><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项</h1><p>1、此外，Cygwin 在 Windows 平台上也有同样的问题，设置方式也是类似的。当然，如果只是查看目录文件，使用基本的命令，请尽量脱离带有中文的目录和带有中文的文件，避免踩坑，这样还可以把编码直接设置为 GBK 了，但是遇到特殊的情况还是脱离不了 UTF-8 编码。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Windows</tag>
        <tag>中文乱码</tag>
        <tag>gbk</tag>
        <tag>utf-8</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 常用命令总结</title>
    <url>/2019080701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在软件工程师的工具列表中，<code>Git</code> 肯定是少不了的，作为分布式版本控制系统，<code>Git</code> 在目前非常流行，可以说，掌握 <code>Git</code> 的使用是工程师的基本功。而且，<code>Git</code> 也会为我们带来诸多的便利，根本离不开它。本文会记录一些常用的 <code>Git</code> 命令，不仅可以自查，也可以帮助读者。</p><p>另外，说明一下，关于远程仓库的选择，目前有多种多样，例如：<code>GitHub</code>、<code>GitLab</code>、<code>Gitee</code>【码云】、<code>coding</code> 等等，读者自行选择。其中，最流行的莫过于 <code>GitHub</code>，在全球非常受欢迎，被微软收购后也没有大家想象的那么可怕，反而更加开源了，现在都可以免费使用 3 个私有仓库了，可见微软还是愿意拥抱开源世界的。</p><p>本文中的远程仓库地址格式会以 <code>GitHub</code> 的 <code>HTTPS</code> 协议为准，即：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https://github.com/your_user_name/your_project_name.git</span><br></pre></td></tr></table></figure><p>需要用户输入用户名、密码。</p><p>当然，还有一种格式是 <code>SSH</code> 协议的，即：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git@github.com:your_user_name/your_project_name.git</span><br></pre></td></tr></table></figure><p>需要用户在本地生成秘钥，读者使用时可以自行选择。</p><a id="more"></a><h1 id="下载安装"><a href="# 下载安装" class="headerlink" title="下载安装"></a>下载安装 </h1><p> 为了使用 <code>Git</code>，本地肯定要先安装好，在次不再赘述，请读者根据自己的操作系统类型选择合适的版本。<code>Git</code> 客户端下载官方网站：<a href="https://git-scm.com" target="_blank" rel="noopener">git-scm</a> 。</p><p>这里需要注意 <strong>回车换行符 </strong>的标准选择问题，需要先了解回车符【Carriage Return】、换行符【Line Feed】这两个概念，在计算机出现之前，为了解决打字机换行时的字符丢失问题，研发人员发明了这两个符号，回车符号告诉打字机把打印头定位在左边界，换行符号告诉打字机把纸向下移一行。</p><p>但是后来计算机出现后，科学家觉得用两个符号浪费存储空间【当时的存储硬件很昂贵】，保留一个符号就可以，这时候分歧出现了，也就导致现在的多种局面：在 <code>Mac</code> 系统里，每行结尾只有回车符 <code>CR</code>，即 <code>\\r</code>；在 <code>Unix</code> 系统里，每行结尾只有换行符 <code>LF</code>，即 <code>\\n</code>；在 <code>Windows</code> 系统里，每行结尾有回车换行两个符号 <code>CR LF</code>，即 <code>\\r\\n</code> 。</p><p>这就会导致一个问题，在不同操作系统之间传输文本文件，打开后行会错乱，或者行尾多了不可见符号。</p><p>而通过 <code>Git</code> 管理项目时，一般都是代码文件、配置文件，远程仓库如果是 <code>Unix</code> 系统，那么文本文件的每行末尾都是换行符。而当我们本地开发时，用的是 <code>Windows</code> 系统或者 <code>Mac</code> 系统，而且伴随着代码更新、代码推送，多种符号会相互混在一起，就会显得很混乱。不过不用担心，在 <code>Git</code> 中可以设置回车换行符号的标准，在安装客户端时，选择当前操作系统对应的标准，那么每次在 <code>pull</code>、<code>push</code> 时，<code>Git</code> 会自动转换回车换行符号，保证一致性，这样在跨操作系统编辑文件时也不用担心这两个符号的问题。</p><h1 id="初始化"><a href="# 初始化" class="headerlink" title="初始化"></a>初始化 </h1><p> 对于新建的本地文件【以及文件夹】来说，需要初始化并关联到远程仓库【例如在 <code>GitHub</code> 新建了一个空白项目】，然后才能方便管理这个项目，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 进入项目目录 </span><br><span class="line">cd your_project_dir</span><br><span class="line"># 初始化 </span><br><span class="line">git init</span><br><span class="line"># 添加所有文件 </span><br><span class="line">git add .</span><br><span class="line"># 提交到本地仓库 </span><br><span class="line">git commit -m &quot;first commit&quot;</span><br><span class="line"># 关联到远程仓库 </span><br><span class="line">git remote add origin https://github.com/your_user_name/your_project_name.git</span><br><span class="line"># 推送更新到远程仓库 </span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure><p>如果本地的文件夹已经是一个标准 <code>Git</code> 项目，并且没有关联到任何远程分支，则直接关联即可，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 关联到远程仓库 </span><br><span class="line">git remote add origin https://github.com/your_user_name/your_project_name.git</span><br><span class="line"># 推送更新到远程仓库 </span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure><p>需要注意，如果远程仓库已经初始化【例如在 <code>GitHub</code> 上面新建一个包含 <code>README</code> 文件的项目】，本地仓库也已经初始化【执行 <code>init</code>】，此时关联后进行提交或者拉取更新会失败。<code>git pull</code> 返回错误 <code>fatal: refusing to merge unrelated histories</code>，提示仓库混乱【本地、远程是两个不同的仓库】，不能拉取；而 <code>git push</code> 则返回 <code>error: failed to push some refs to xx</code>，也不能提交。</p><p>此时不用担心，可以使用参数 <code>git pull origin master --allow-unrelated-histories</code> 来拉取远程仓库的内容，并合并所有内容，紧接着就可以提交本地的变更了。</p><h1 id="检出仓库"><a href="# 检出仓库" class="headerlink" title="检出仓库"></a>检出仓库 </h1><p> 如果本地目录是空白的，还没有任何项目，则需要从远程仓库克隆项目到本地，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 从远程仓库克隆项目，或者说是检出代码 </span><br><span class="line">git clone https://github.com/your_user_name/your_project_name.git</span><br><span class="line"># 进入项目目录 </span><br><span class="line">cd your_project_dir</span><br></pre></td></tr></table></figure><h1 id="添加提交更新"><a href="# 添加提交更新" class="headerlink" title="添加提交更新"></a>添加提交更新 </h1><p> 如果更新了代码，或者新增了文件，需要提交更新，这样才能与别人合作开发项目，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 添加文件，对于新增的文件而言 </span><br><span class="line">git add your_file_name</span><br><span class="line"># 点号表示添加本目录所有文件 </span><br><span class="line">git add .</span><br><span class="line"># 提交变更到本地仓库，适当添加注释 </span><br><span class="line">git commit -m &apos;commit message&apos;</span><br><span class="line"># 当然，仅仅提交到本地仓库还不够，还需要推送到远程仓库 </span><br><span class="line">git push</span><br><span class="line"># 在推送时可以指定分支，不指定则表示当前分支 </span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure><h1 id="拉取更新"><a href="# 拉取更新" class="headerlink" title="拉取更新"></a>拉取更新 </h1><p> 如果在和别人合作开发的过程中，需要拉取别人的变更到本地，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 拉取更新 (如果遇到代码冲突会麻烦，往下看)</span><br><span class="line">git pull</span><br><span class="line"># git pull 其实相当于 2 个步骤 </span><br><span class="line">git fetch</span><br><span class="line">git merge</span><br><span class="line"># 如果 merge 遇到冲突，需要手动解决 </span><br><span class="line"># 1 - 改代码，把冲突文件改掉，可以使用 git diff &lt;source_branch&gt; &lt;target_branch&gt; 比较不同点 </span><br><span class="line"># 2 - 使用 git add your_file 标记改动完成 </span><br><span class="line"># 3 - 使用 git commit -m &quot;conflict fixed&quot; 提交冲突解决后的变更 </span><br></pre></td></tr></table></figure><h1 id="管理分支"><a href="# 管理分支" class="headerlink" title="管理分支"></a>管理分支 </h1><p> 如果在开发过程中多人协作，肯定会有多个分支，此时涉及到管理分支的问题，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 新建分支并切换过去 </span><br><span class="line">git checkout -b your_branch_name</span><br><span class="line"># 切换到指定的分支 </span><br><span class="line">git checkout your_branch_name</span><br><span class="line"># 删除分支，切记不能删除当前分支，必须先切换到别的分支 </span><br><span class="line">git branch -d your_branch_name</span><br><span class="line"># 将分支推送到远程仓库，不推送别人不可见 </span><br><span class="line">git push origin your_branch_name</span><br><span class="line"># 当然，如果是处在当前分支，推送可以省略参数 </span><br><span class="line">git push</span><br><span class="line"># 合并指定分支到当前分支 </span><br><span class="line">git merge your_branch_name</span><br></pre></td></tr></table></figure><p>当然，此种情况有可能也会遇到代码冲突问题，参见 <strong>拉取更新 </strong>小节，需要手动解决冲突。</p><h1 id="冲突解决"><a href="# 冲突解决" class="headerlink" title="冲突解决"></a>冲突解决 </h1><p> 参见 <strong>拉取更新 </strong>小节，需要手动解决冲突。</p><h1 id="更换关联远程分支"><a href="# 更换关联远程分支" class="headerlink" title="更换关联远程分支"></a>更换关联远程分支 </h1><p> 如果本地代码，已经关联了远程分支，但是想更换远程分支，例如想从 <code>GitHub</code> 切换到 <code>GitLab</code>，或者想在不同的项目之间切换。则需要先解除对远程分支的关联，再关联到新的远程分支，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解除对远程仓库的关联 </span><br><span class="line">git remote remove origin</span><br><span class="line"># 关联到新的远程仓库 </span><br><span class="line">git remote add origin https://github.com/your_user_name/your_project_name.git</span><br><span class="line"># 接下来写代码、提交即可 </span><br></pre></td></tr></table></figure><h1 id="强制更新覆盖本地修改"><a href="# 强制更新覆盖本地修改" class="headerlink" title="强制更新覆盖本地修改"></a>强制更新覆盖本地修改 </h1><p> 有些时候我们只想要 <code>Git</code> 远程仓库的代码，而对于本地的项目中修改不做任何理会【即本地的修改不提交，放弃不要了】，这时候就需要用到 <code>Git pull</code> 的强制覆盖，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 拉取远程最新的版本，或者使用 git fetch origin 也行 </span><br><span class="line">git fetch --all</span><br><span class="line"># 或者直接使用 git reset --hard HEAD 也行 </span><br><span class="line">git reset --hard origin/master </span><br><span class="line">git pull</span><br><span class="line"># 如果只想更改某个文件 (不会影响新文件、已经 commit 的文件)</span><br><span class="line">git checkout -- your_file_name</span><br></pre></td></tr></table></figure><h1 id="保存用户名密码"><a href="# 保存用户名密码" class="headerlink" title="保存用户名密码"></a>保存用户名密码 </h1><p><code>Git</code> 可以将用户名、密码和仓库链接保存在硬盘中，而不用在每次 <code>git push</code> 的时候都输入密码。保存密码到硬盘只要一条命令就可以：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config credential.helper store</span><br></pre></td></tr></table></figure><p> 当 <code>git push</code> 的时候输入一次用户名和密码后，就会被记录下来，以后不用再次输入。但是，这样保存的密码是明文的，保存在用户家目录的 <code>~/.git-credentials</code> 文件中，读者可以查看内容，使用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat ~/.git-credentials</span><br></pre></td></tr></table></figure><p>由于这种方式密码是明文存储在文件中的，所以不安全，还是推荐大家使用 <code>SSH</code> 的方式。</p><p>此外，如果想手动设置用户名、邮箱，可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 如果项目的环境众多，就不要带 --global 参数，否则全局的参数设置会影响到其它 Git 项目 </span><br><span class="line">git config --global user.name [username]</span><br><span class="line">git config --global user.email [email]</span><br></pre></td></tr></table></figure><h1 id="管理标签"><a href="# 管理标签" class="headerlink" title="管理标签"></a>管理标签 </h1><p> 在软件开发的过程中，创建标签是很有必要的，可以跟踪当前的开发进度，出问题也能及时回退。可以按照如下流程操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建标签，标签名字为 1.0.1,commit_id 是当次提交唯一标识 </span><br><span class="line">git tag 1.0.1 commit_id</span><br><span class="line"># 当然，这里的 commit_id 会很长，不用全部写出来，一般 6-10 位足够了，只要保证它是唯一的就行 </span><br><span class="line"># 如果需要获取 commit_id, 可以使用 log 命令 </span><br><span class="line">git log</span><br><span class="line"></span><br><span class="line"># 删除本地标签 </span><br><span class="line">git tag -d your_tag_name</span><br><span class="line"># 删除远程标签 </span><br><span class="line">git push origin :refs/tags/your_tag_name</span><br><span class="line"></span><br><span class="line"># 删除本地子模块的标签 </span><br><span class="line">git submodule foreach git tag -d your_tag_name</span><br><span class="line"># 删除远程子模块的标签 </span><br><span class="line">git submodule foreach git push origin :refs/tags/your_tag_name</span><br><span class="line"></span><br><span class="line"> 注意：有时候，项目子模块的标签是不允许被删除的，就会有一些关于权限的错误提示，只要到管理员那里添加对应的权限就行。</span><br></pre></td></tr></table></figure><h1 id="同步远程分支信息"><a href="# 同步远程分支信息" class="headerlink" title="同步远程分支信息"></a>同步远程分支信息 </h1><p> 有时候发现本地的分支信息与远程的不一致，例如远程的分支已经被删除，但是每次 <code>git pull</code> 的时候并不能同步到本地，在本地依然显示这些分支。</p><p>此时需要净化分支，使用命令：<code>git remote prune origin</code> 即可，或者也可以使用 <code>git remote update origin --prune</code>，效果一致。</p><h1 id="代理设置"><a href="# 代理设置" class="headerlink" title="代理设置"></a>代理设置 </h1><p> 有时候遇到网络问题，或者被墙的问题，下载的速度非常慢，可以设置代理：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--global 是全局的意思 </span><br><span class="line"> 设置代理 </span><br><span class="line">git config --global https.proxy http://127.0.0.1:1080</span><br><span class="line">git config --global https.proxy https://127.0.0.1:1080</span><br><span class="line">git config --global http.proxy &apos;socks5://127.0.0.1:1080&apos;</span><br><span class="line">git config --global https.proxy &apos;socks5://127.0.0.1:1080&apos;</span><br><span class="line"></span><br><span class="line"> 取消代理 </span><br><span class="line">git config --global --unset http.proxy</span><br><span class="line">git config --global --unset https.proxy</span><br></pre></td></tr></table></figure><h1 id="查看日志"><a href="# 查看日志" class="headerlink" title="查看日志"></a>查看日志 </h1><p> 查看日志，可以看到变更的文件信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git log --stat</span><br></pre></td></tr></table></figure><h1 id="一些建议"><a href="# 一些建议" class="headerlink" title="一些建议"></a>一些建议 </h1><p> 在使用 <code>Git</code> 的时候，会有一些隐藏的小功能，可以增加使用体验，下面列出几个：</p><ul><li>自带的图形化工具，使用 <code>gitk</code> 命令即可 </li><li> 设置彩色的内容输出，使用 <code>git config color.ui true</code> 设置 </li><li> 查看历史记录时，只显示一行注释信息，使用 <code>git config format.pretty oneline</code> 设置 </li><li> 添加文件时，如果想使用询问交互的模式，使用 <code>git add -i</code>，其实就是加了一个 <code>-i</code> 参数 </li></ul><p> 此外，在使用 <code>Git</code> 相关的命令时，由于需要反复操作，时间久了会觉得很麻烦，因为每个命令都很长，由多个单词组成，每次都敲一遍还是很低效的。那么有没有什么好办法呢？其实可以合理利用 <code>Linux</code> 系统的别名特性，把自己常用的命令收集起来，分别给它们创建别名，这样在使用时只要简单敲几个字母就行。</p><p>我一般是在家目录下的 <code>.bashrc</code> 文件中指定别名，这样每次登录时会自动加载，可以直接在会话终端使用，关于 <code>Git</code> 的别名内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alias gp=&apos;git pull&apos;</span><br><span class="line">alias gb=&apos;git branch&apos;</span><br><span class="line">alias gc=&apos;git checkout&apos;</span><br><span class="line">alias gcs=&apos;git config credential.helper store&apos;</span><br><span class="line">alias gcfgn=&apos;git config --global user.name &apos;</span><br><span class="line">alias gcfge=&apos;git config --global user.email &apos;</span><br></pre></td></tr></table></figure><p>设置别名后，直接使用 <code>gp</code> 就相当于调用了 <code>git pull</code>，这就很方便了，其它命令也是类似的效果，读者可以根据自己的需要灵活设置。</p><h1 id="资源推荐"><a href="# 资源推荐" class="headerlink" title="资源推荐"></a>资源推荐 </h1><p> 下面列出一些常见的资源、网站、工具等信息，可能对读者有帮助：</p><ul><li><code>git-tower</code> 工具，可视化管理，官网：<a href="https://www.git-tower.com" target="_blank" rel="noopener">git-tower</a></li><li><code>sourcetree</code> 工具，可视化管理，官网：<a href="https://www.sourcetreeapp.com" target="_blank" rel="noopener">sourcetreeapp</a></li><li><code>GitHub desktop</code> 工具，可视化管理，官网：<a href="https://desktop.github.com" target="_blank" rel="noopener">desktop</a></li><li><code>Git</code> 社区参考书：<a href="https://book.git-scm.com" target="_blank" rel="noopener">book.git-scm</a></li><li><code>GitHub</code> 帮助文档：<a href="https://help.github.com" target="_blank" rel="noopener">help.github</a></li><li>像 <code>Git</code> 一样思考：<a href="http://think-like-a-git.net" target="_blank" rel="noopener">think-like-a-git</a></li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>pull</tag>
        <tag>push</tag>
        <tag>commit</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub 个人站点绑定独立的域名</title>
    <url>/2018112701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>随着越来越多的人使用 GitHub，都在里面创建了自己的仓库，或者 clone 了别人的优秀项目，也有很多人想利用 GitHub 自带的 GitHub Pages 来搭建个人博客，此时就可以使用独立的域名 <a href="https://www.username.github.io" target="_blank" rel="noopener">https://www.username.github.io</a> 访问自己的博客，全部的资源都来自于 GitHub，并且是免费的，不需要其它任何配置或者购买，这里面包含域名、流量、带宽、存储空间、Htpps 认证等服务。但是，有的人可能购买了自己的独立域名，例如： <a href="https://www.abc.com" target="_blank" rel="noopener">https://www.abc.com</a> ，并且想把域名直接绑定到 GitHub 免费的域名上面，这样以后访问博客的时候更容易辨识，本文就描述 GitHub Pages 绑定独立域名的操作过程，前提是 GitHub Pages 已经创建完成。</p><a id="more"></a><p>我在 Godaddy 上面购买了域名：playpi.org，选择 Godaddy 主要是不想备案，国内的域名服务商都要求备案，我以前在阿里云上面买过一个，后来没按照要求备案就不能用了，我也放弃了。</p><h1 id="购买域名"><a href="# 购买域名" class="headerlink" title="购买域名"></a>购买域名 </h1><p> 当然，大家可以选择自己喜欢的域名服务商，例如腾讯云、阿里云等，但是这些域名服务商需要给域名备案，有点麻烦【当然不是所有的域名都需要备案】。所以我选择的域名服务商是 Godaddy，主页地址：<a href="https://sg.godaddy.com/zh" target="_blank" rel="noopener">https://sg.godaddy.com/zh</a> ，在主页中点击左上角的 <strong>域名 </strong>，开始搜索域名。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0sbcstwqoj21hc0rfe4y.jpg" alt="Godaddy 主页" title="Godaddy 主页"></p><p>我这里输入域名 <strong>playpi.org</strong>，可以看到被占用了，已经已经被我购买了，可以看到右侧显示出了可以购买的域名列表，并且带有报价。在左侧，可以添加筛选条件，过滤掉自己不想要的域名。如果找到了满意的域名，加入购物车购买就行了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0sbcjq2a0j21hc0q9q5x.jpg" alt="Godaddy 域名搜索" title="Godaddy 域名搜索"></p><h1 id="选择域名服务器"><a href="# 选择域名服务器" class="headerlink" title="选择域名服务器"></a>选择域名服务器 </h1><p> 有了域名，还没有用，因为还没有把域名用起来，所以接下来需要找域名服务器，把你的域名解析到 GitHub Pages 去。这样，才能保证访问你的域名，自动跳转到 GitHub Pages 去。</p><p>我一开始选择的 Godaddy 自己的域名服务器，只需要在 <strong>我的产品 </strong>-&gt;<strong> 域名 </strong>-&gt;<strong>DNS</strong>，设置一些解析记录即可。Godaddy 的配置解析规则可以参考下图【可以先忽略解析规则，后面会讲到的】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovn10ghwj20wt0mvgm6.jpg" alt="Godaddy 原有的解析记录" title="Godaddy 原有的解析记录"></p><p>后来由于 GitHub Pages 屏蔽百度爬虫的问题，我必须设置一条专门的解析规则去解析百度爬虫的请求，引入到我自己的 Web 服务器上面，但是 Godaddy 不支持线路的自定义，比较笼统，所以我就放弃了。转而选择了腾讯的 DNSPod，还是比较好用的，虽然前不久刚出过问题，大量的网络瘫痪，但是解析速度还是挺快的。</p><p>先在 DNSPod 中添加域名，也就是在 Godaddy 中购买的域名【如果是直接在腾讯云中购买的，就不用配置了，默认就有】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0oviygtn3j21hc0qxgnz.jpg" alt="在 DNSPod 中添加域名" title="在 DNSPod 中添加域名"></p><p>添加完成后，可以看到提示我 NS 地址还未修改，也就是目前仍旧是 Godaddy 负责解析这个域名，所以要把域名服务器给切换过来。如果不知道是什么意思，可以点击提示链接查看帮助手册【其实就是去购买域名的服务商那里绑定 DNSPod 的域名服务器】</p><p>提示我们修改 NS 地址 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovkf6k08j21hc0qxtb9.jpg" alt="提示我们修改 NS 地址" title="提示我们修改 NS 地址"></p><p> 帮助手册 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovkoigmaj20s60lymyk.jpg" alt="帮助手册" title="帮助手册"></p><p> 我在这就直接查看当前的域名的 NS 地址，选择域名，进入配置页面查看。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0safaacorj21190i4gmy.jpg" alt="查看 NS 地址" title="查看 NS 地址"></p><p>去 Godaddy 中配置域名服务器，替换掉原本默认的。在 <strong>我的产品 </strong>-&gt;<strong> 域名 </strong>-&gt;<strong>DNS</strong>：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovncqfzuj20ww0atdfw.jpg" alt="Godaddy 原有的域名服务器" title="Godaddy 原有的域名服务器"></p><p>我把它修改为我在 DNSPod 中查到的属于我的域名的域名服务器，一般都会有 2 个，保证可靠性。配置完成新的域名服务器【以前的解析记录都消失了】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovnq0lhgj20yi0m7q3i.jpg" alt="配置完成新的域名服务器" title="配置完成新的域名服务器"></p><p>配置完成，域名解析的工作就完全交给 DNSPod 了，我们可以退出 Godaddy 了【只是在这里买了一个域名】，接下来全程都要在 DNSPod 中配置其它信息。</p><h1 id="配置域名的解析规则"><a href="# 配置域名的解析规则" class="headerlink" title="配置域名的解析规则"></a>配置域名的解析规则 </h1><p> 上一步骤我已经配置完成了域名的基本信息，接下来需要配置的就非常关键了，是域名的解析规则，它会指引着访问域名的请求怎么跳转。这里先提前说一下配置规则：</p><ul><li><strong>主机记录 </strong>为 @表示直接访问域名，例如访问 playpi.org</li><li><strong>主机记录 </strong>为其它字符表示访问二级域名，例如访问 <a href="http://www.playpi.org">www.playpi.org</a> 、blog.playpi.org</li><li><strong>记录类型 </strong>为 A 表示跳转到 ip 地址，后面的 <strong>记录值 </strong>就需要填 ip，例如 66.32.122.18</li><li><strong>记录类型 </strong>为 CNAME 表示跳转到域名，后面的 <strong>记录值 </strong>就需要填域名，例如 blog.playpi.org</li><li><strong>线路类型 </strong>是 DNSPod 自定义的逻辑分类，给访问的请求分类，例如百度爬虫、搜狗爬虫，这个选项对于我来说很有用，可以解决 GitHub Pages 屏蔽爬虫的问题 </li></ul><p> 我把 Godaddy 中的解析记录直接抄过来就行，不同的是由于使用的是 DNSPod 免费版本，A 记录会少配置 2 个，基本不会有啥影响 <strong>【其实不配置 A 记录最好，直接配置 CNAME 就行了，会根据域名自动寻找 ip，以前我不懂】</strong>。另外还有一个就是需要针对百度爬虫专门配置一条 www 的 A 记录，针对百度的线路指向自己服务器的 ip【截图只是演示，其中 CNAME 记录应该配置域名，A 记录才是配置 ip】。如果使用的是第三方托管服务，直接添加 CNAME 记录，配置域名就行【例如 yoursite.gitcafe.io】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovjinxzvj21hc0qxac2.jpg" alt="添加域名解析记录" title="添加域名解析记录"></p><p>上面的配置里面的 A 记录明显是多余的，而且还要通过 ping 去寻找那几个 ip【我这里是 <strong>ping iplaypi.github.io</strong> 得到，大家换为自己的 GitHub 用户名即可，每个用户之间的 ip 应该有差别，不会完全一样】。所以建议大家不使用 A 记录的配置方式，直接使用 CNAME 配置。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovk0xljij21hc0qxta3.jpg" alt="不使用 A 记录的配置方式" title="不使用 A 记录的配置方式"></p><p>配置完成后使用 <strong>域名设置 </strong>里面的 <strong>自助诊断 </strong>功能，可以看到域名存在异常，主要是因为更改配置后的时间太少了，要耐心等待全球递归 DNS 服务器刷新【最多 72 小时】，不过一般 10 分钟就可以访问主页了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovl23kqbj20tl0lfabk.jpg" alt="自助诊断" title="自助诊断"></p><p>但是后来我发现，那个 GitHub 的域名【iplaypi.github.io】被墙了而 ip 没被墙，表现为每天总会有一段时间访问不了【DNSPod 也会给我发告警邮件，说宕机了，当然是他们的域名测试服务器连不上这个域名】，而且我用自己的浏览器也访问不了。而 blog 那个二级域名却可以正常访问，这就说明 GitHub 的那个域名不好使，而我自己给 blog 专门部署 Web 服务是正常的。因此，在主机记录为 @ 的解析规则里面还是配置 A 记录吧，把几个 ip 都配置上去【免费版本的 DNSPod 只能添加 2 条，可怜】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0sbad2ia9j215c0h2myv.jpg" alt="我目前的配置" title="我目前的配置"></p><p>这样做还会引起 GitHub 的警告，因为这个 ip 地址可能会变化，所以 GitHub 建议配置域名。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0scgaveyhj20vl0mlta4.jpg" alt="来自 GitHub 的警告" title="来自 GitHub 的警告"></p><p>如果想知道域名对应的 ip 地址，除了使用 ping 之外，还有更快捷的方法：dig 命令。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0sbqoihqxj20ju0cndg9.jpg" alt="2-dig 快速获取 ip 地址" title="2-dig 快速获取 ip 地址"></p><h1 id="在 -GitHub- 中设置 -CNAME"><a href="# 在 -GitHub- 中设置 -CNAME" class="headerlink" title="在 GitHub 中设置 CNAME"></a>在 GitHub 中设置 CNAME</h1><p>关于域名的配置都完成了，最后还有一个重要的步骤，需要在 GitHub 的项目中添加一个文件，文件名称是 CNAME，文件内容就是域名【我这里使用的是二级域名，也可以，就是在直接访问域名的时候多了一次转换】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0sc5i982jj211o0djdgd.jpg" alt="查看我的 CNAME 文件" title="查看我的 CNAME 文件"></p><p>那这个文件的作用是什么呢，为什么要这么配置呢？其实，CNAME 是一个别名记录，它允许你将多个名字映射到同一台计算机，还决定着主页的链接最终展示的样子，直接是域名【<a href="https://playpi.org" target="_blank" rel="noopener">https://playpi.org</a> 】还是带二级域名【<a href="https://www.playpi.org">https://www.playpi.org</a> 】。这里有 GitHub 的官方说明：<a href="https://help.github.com/en/articles/using-a-custom-domain-with-github-pages" target="_blank" rel="noopener">https://help.github.com/en/articles/using-a-custom-domain-with-github-pages</a> 。</p><p>此外，在 GitHub 中还可以开启 https 认证，这样你的每一个文档链接都会有把小绿锁了，GitHub 使用的是 Lets Encrypt 的证书，有效期 3 个月，不过别担心过期问题，GitHub 会自动更新的。开启了 https 认证后，哪怕使用 http 的链接访问，也会自动跳转的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0sce6tflfj20tp09gaac.jpg" alt="开启 https" title="开启 https"></p><p>那如果有人想把我的域名访问指向自己的 GitHub，是不是他在自己的仓库里面新建一个 CNAME 文件，并且填上我的域名就行了呢？其实不行，GitHub 是禁止这样做的。即使有人真的在自己的仓库里面新建了 CNAME 文件并且填写了我的域名，GitHub 是不认可的并且会给出警告。当然，如果我自己在 GitHub 中没有使用这个域名，别人当然可以使用。</p><p>现在突然想到一个问题，我把自己的域名和域名服务器都暴漏了，会不会有人在 DNSPod 中把我的域名解析到其它地方去了【看起来所有的 DNSPod 的域名服务器都是一样的 2 台机器】，然后我就访问不了自己网站了，或者说流量变小了。</p><p>我觉得 DNSPod 一定会禁止这种行为，否则岂不是乱套了，所以不同担心。经过实际测试，DNSPod 是不会允许这个现象发生的，如果别人要配置你的域名，DNSPod 检测到有第二个人配置同一个域名，会拒绝。如果你想主动给别人使用，需要第一个人解除绑定，然后第二个人才能继续使用，所以可以放心操作。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>个人站点</tag>
        <tag>绑定域名</tag>
      </tags>
  </entry>
  <entry>
    <title>Google 账号开启两步验证与应用专用密码</title>
    <url>/2018111901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>使用 Google 账号的都知道，带来了很多方便，不仅有强大的免费搜索服务，还有 Google 文档、云主机、云存储等各种服务，但是唯一的缺点是需要翻墙，让一些人望而却步，把很多人挡在了便利门外。本文是针对已经实现翻墙愿望，并在日常工作中会使用到 Google 账号的人，说不定可以给你带来一些冷知识，解决一些小问题。</p><a id="more"></a><h1 id="Google- 账号的便利性"><a href="#Google- 账号的便利性" class="headerlink" title="Google 账号的便利性"></a>Google 账号的便利性 </h1><p> 目前在日常工作与生活中，查找资料时，基本使用的都是 Google 搜索，并且使用非常好用的 Chrome 浏览器。其中我用的最多就是标签收藏，平时偶尔搜到什么有用的知识点或者需要反复查看的网页，来不及看完整理，就先把网页分类收藏了，以便日后查漏补缺。</p><p>此时，利用 Chrome 浏览器的标签收藏功能，可以很方便地把一切网页收藏起来，并且可以很好地分类存放，清晰明了。可能有人说也有很多其它的工具可以做到这一点，不久收藏吗？但是我觉得还是利用 Chrome 浏览器自带的这个功能比较好，再配合 Google 账号，就可以达到同步更新的效果了，公司的电脑、家里的电脑，只要都登录了 Google 账号，所有收藏的标签都可以实时同步。而且，所有的浏览记录、搜索历史、记住的账号密码等等，都可以同步，跨机器使用也很方便。再配合 Chrome 浏览器的插件，对收藏的网页搜索起来非常方便。</p><h1 id="Google- 账号开启两步验证"><a href="#Google- 账号开启两步验证" class="headerlink" title="Google 账号开启两步验证"></a>Google 账号开启两步验证 </h1><p> 为了安全起见，最好给 Google 账号开启两步验证，可以选择绑定手机号、启用身份验证器、安全密钥等方式，为了方便，我选择了绑定手机号。开启两步验证后，在陌生的设备上登录 Google 账号（包括 Google 自家的各种应用，例如邮件、YouTube 等）需要验证码的二次验证，当然，如果把设备设置为可信任的设备，则不需要每次都重复输入验证码。</p><p>开启的方式非常简单，登录 Google 账号，在” 登录与安全 “中有” 两步验证 “的开启选项，选择自己需要的方式，继续即可。</p><p>启两步验证 1<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdpircndxj21hc0q2ac6.jpg" alt="开启两步验证 1" title="开启两步验证 1"></p><p>启两步验证 2<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdpjdxg23j21hc0q20u8.jpg" alt="开启两步验证 2" title="开启两步验证 2"></p><p>如果使用” 身份验证器 “的方式，还需要在手机上安装一个” 身份验证器 “应用，校准时间后，每隔 30 秒更新验证码，登录账号时需要使用当前的验证码，并且在有效期内完成登录的操作，否则验证码过期，需要使用新的验证码，类似于手机收到的验证码只有 1 分钟一样。同时，如果使用 Google 邮箱账号注册了其它平台的账号，例如注册了 Twitter，注册了 Facebook，为了安全起见也可以使用” 身份验证器 “的方式，一种验证方式管理着多种账号的安全。</p><h1 id="开启两步验证后带来的问题"><a href="# 开启两步验证后带来的问题" class="headerlink" title="开启两步验证后带来的问题"></a>开启两步验证后带来的问题 </h1><p> 我遇到的问题之一就是自己手机的邮件客户端无法登录 Google 邮箱了，我使用的时第三方邮件客户端，总是提示我密码错误，其实密码没有错误，是因为 Google 账号开启两步验证后，邮箱的登录也需要对应方式的验证，但是第三方邮件应用并没有做这个验证，所以无法登录。</p><p>本来是想着单独把 Google 邮箱的两步验证关闭，但是找了半天设置选项也没有找到，看来 Google 账号已经是一个大统一的账号，不允许单独设置涉及安全性的信息，可以理解。</p><p>同理，使用其它应用客户端也会遇到相同的问题，当然，Google 官方解释说明也解释了有部分设备不需要关注这个问题，其它大部分设备或者应用还是要受到影响的。</p><p>见：<a href="https://support.google.com/mail/answer/185833?hl=zh-Hans&amp;visit_id=636782289170925112-3791602481&amp;rd=1" target="_blank" rel="noopener">使用应用专用密码登录 </a><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdpwpmmroj20ru0oimyf.jpg" alt="解释说明" title="解释说明"></p><p> 此时，需要使用” 应用专用密码 “或者在手机上开发一个” 具有账号访问权限的应用 “用来代理整个 Google 的账号访问。</p><h1 id="问题的解决方法"><a href="# 问题的解决方法" class="headerlink" title="问题的解决方法"></a>问题的解决方法 </h1><h2 id="应用专用密码方式的使用"><a href="# 应用专用密码方式的使用" class="headerlink" title="应用专用密码方式的使用"></a> 应用专用密码方式的使用 </h2><h3 id="1、在 -Google- 账号的登录和安全中，可以找到”- 应用专用密码 -“这个选项："><a href="#1、在 -Google- 账号的登录和安全中，可以找到”- 应用专用密码 -“这个选项：" class="headerlink" title="1、在 Google 账号的登录和安全中，可以找到” 应用专用密码 “这个选项："></a>1、在 Google 账号的登录和安全中，可以找到” 应用专用密码 “这个选项：</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdq2531orj21hc0q2wgl.jpg" alt="应用专用密码" title="应用专用密码"></p><h3 id="2、点击进入后，可以看到选择应用与选择设备，由于我使用的是一种不知名的 -Android- 手机，所以官方选项中没有可以选择的，只好自定义一种，随便起一个名字标识即可。"><a href="#2、点击进入后，可以看到选择应用与选择设备，由于我使用的是一种不知名的 -Android- 手机，所以官方选项中没有可以选择的，只好自定义一种，随便起一个名字标识即可。" class="headerlink" title="2、点击进入后，可以看到选择应用与选择设备，由于我使用的是一种不知名的 Android 手机，所以官方选项中没有可以选择的，只好自定义一种，随便起一个名字标识即可。"></a>2、点击进入后，可以看到选择应用与选择设备，由于我使用的是一种不知名的 Android 手机，所以官方选项中没有可以选择的，只好自定义一种，随便起一个名字标识即可。</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdq4j220pj21hc0q2wfb.jpg" alt="应用设备选择" title="应用设备选择"></p><h3 id="3、选择完成后，会生成一串 -16- 位的密码，这个密码就可以在其它设备上登录的时候使用，不需要使用原来的密码，也不需要使用 -Google- 验证码。"><a href="#3、选择完成后，会生成一串 -16- 位的密码，这个密码就可以在其它设备上登录的时候使用，不需要使用原来的密码，也不需要使用 -Google- 验证码。" class="headerlink" title="3、选择完成后，会生成一串 16 位的密码，这个密码就可以在其它设备上登录的时候使用，不需要使用原来的密码，也不需要使用 Google 验证码。"></a>3、选择完成后，会生成一串 16 位的密码，这个密码就可以在其它设备上登录的时候使用，不需要使用原来的密码，也不需要使用 Google 验证码。</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdq6klijxj21hc0q2ta4.jpg" alt="生成专用密码" title="生成专用密码"></p><h3 id="4、在使用过程中还可以看到设备的情况。"><a href="#4、在使用过程中还可以看到设备的情况。" class="headerlink" title="4、在使用过程中还可以看到设备的情况。"></a>4、在使用过程中还可以看到设备的情况。</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdqasrztdj21hc0q20ud.jpg" alt="设备活动和安全事件" title="设备活动和安全事件"></p><h2 id="具有账号访问权限的应用的使用"><a href="# 具有账号访问权限的应用的使用" class="headerlink" title="具有账号访问权限的应用的使用"></a> 具有账号访问权限的应用的使用 </h2><p> 这种方式就是手机本身有一个后台应用，代理了 Google 账号的一切请求，把信息转发到本地应用（比如 Chrome 浏览器就是这样一个应用，只不过是官方开发的，只要登录了 Google 账号，邮件、YouTube、搜索、Play、相册、日历等等这些应用同步一起使用，不需要额外再登录，这也是我使用 Chrome 浏览器的原因。），所以后台应用如果知道了 Google 账号的用户名、密码，就可以代理所有 Google 应用的请求，无需关心 应用专用密码了。</p><p>我发现锤子手机的 Smartisan OS 系统（v6.0.3，Android 版本 7.1.1）对邮件就做了这个后台应用 Smartisan Mail，所以在使用内置的邮件客户端时，即使开启了两步验证，也无需关心验证码的问题（第一次登录还是需要验证的）。</p><p>下面截图则是一步一步设置：</p><h3 id="1、在邮件客户端设置中添加 -Google- 邮箱"><a href="#1、在邮件客户端设置中添加 -Google- 邮箱" class="headerlink" title="1、在邮件客户端设置中添加 Google 邮箱"></a>1、在邮件客户端设置中添加 Google 邮箱</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdqs7cpoqj20u01meq6k.jpg" alt="添加 Google 邮箱 1" title="添加 Google 邮箱 1"></p><h3 id="2、输入 -Google- 账号密码（也是邮箱密码）"><a href="#2、输入 -Google- 账号密码（也是邮箱密码）" class="headerlink" title="2、输入 Google 账号密码（也是邮箱密码）"></a>2、输入 Google 账号密码（也是邮箱密码）</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdqt5xsawj20u01mf0vr.jpg" alt="添加 Google 邮箱 2" title="添加 Google 邮箱 2"></p><h3 id="3、输入验证码（由于开启了两步验证，一定需要），此时切记勾选”- 在此计算机上不再询问 -“，才能保证邮件客户端正常收发 -Goole- 邮件，否则不行。"><a href="#3、输入验证码（由于开启了两步验证，一定需要），此时切记勾选”- 在此计算机上不再询问 -“，才能保证邮件客户端正常收发 -Goole- 邮件，否则不行。" class="headerlink" title="3、输入验证码（由于开启了两步验证，一定需要），此时切记勾选” 在此计算机上不再询问 “，才能保证邮件客户端正常收发 Goole 邮件，否则不行。"></a>3、输入验证码（由于开启了两步验证，一定需要），此时切记勾选” 在此计算机上不再询问 “，才能保证邮件客户端正常收发 Goole 邮件，否则不行。</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdqto569aj20u01mcjvf.jpg" alt="添加 Google 邮箱 3" title="添加 Google 邮箱 3"></p><h3 id="4、允许，可以看到 -Smartisan-Mail- 想要访问 -Google- 账号"><a href="#4、允许，可以看到 -Smartisan-Mail- 想要访问 -Google- 账号" class="headerlink" title="4、允许，可以看到 Smartisan Mail 想要访问 Google 账号"></a>4、允许，可以看到 Smartisan Mail 想要访问 Google 账号</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdqtv52cej20u01mejz8.jpg" alt="添加 Google 邮箱 4" title="添加 Google 邮箱 4"></p><h3 id="5、点开 -Smartisan-Mail，可以看到开发者信息，里面其实设置了代理转发"><a href="#5、点开 -Smartisan-Mail，可以看到开发者信息，里面其实设置了代理转发" class="headerlink" title="5、点开 Smartisan Mail，可以看到开发者信息，里面其实设置了代理转发"></a>5、点开 Smartisan Mail，可以看到开发者信息，里面其实设置了代理转发</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdqtysi1cj20u01matef.jpg" alt="添加 Google 邮箱 5" title="添加 Google 邮箱 5"></p><h3 id="6、此外，在登录成功后，在 -Google- 账号的登录和安全中，可以看到具有账号访问权限的应用："><a href="#6、此外，在登录成功后，在 -Google- 账号的登录和安全中，可以看到具有账号访问权限的应用：" class="headerlink" title="6、此外，在登录成功后，在 Google 账号的登录和安全中，可以看到具有账号访问权限的应用："></a>6、此外，在登录成功后，在 Google 账号的登录和安全中，可以看到具有账号访问权限的应用：</h3><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxdqoifycuj21hc0q2myw.jpg" alt="Smartisan Mail" title="Smartisan Mail"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Google 账号</tag>
        <tag>两步验证</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase 异常：RpcRetryingCaller-Call exception</title>
    <url>/2019091701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天天气不错，我心情很好，但是在测试代码功能的时候遇到了一个问题，浪费了一些时间，感到惋惜。还好，最终解决了问题，只是集群环境的问题。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 我的本意是想写一个 <code>MapReduce</code> 程序来扫描 <code>HBase</code> 数据，统计一些信息，但是在测试的时候发现程序卡住了，等了几分钟之后开始出现连续的超时日志，我感觉是连接 <code>HBase</code> 超时，无法读取表的元信息。</p><p><code>MapReduce</code> 扫描数据报错，报错信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">18:06:43.022 [main] INFO  o.a.h.h.util.RegionSizeCalculator - Calculating region sizes for table &quot;YOUR_TABLE_NAME&quot;.</span><br><span class="line">18:07:52.298 [htable-pool2-t1] INFO  o.a.h.hbase.client.RpcRetryingCaller - Call exception, tries=10, retries=35, started=69237 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,,00000000000000&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">18:08:12.336 [htable-pool2-t1] INFO  o.a.h.hbase.client.RpcRetryingCaller - Call exception, tries=11, retries=35, started=89279 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,,00000000000000&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">18:08:32.358 [htable-pool2-t1] INFO  o.a.h.hbase.client.RpcRetryingCaller - Call exception, tries=12, retries=35, started=109301 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,,00000000000000&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">18:08:52.522 [htable-pool2-t1] INFO  o.a.h.hbase.client.RpcRetryingCaller - Call exception, tries=13, retries=35, started=129465 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,,00000000000000&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">18:09:12.560 [htable-pool2-t1] INFO  o.a.h.hbase.client.RpcRetryingCaller - Call exception, tries=14, retries=35, started=149503 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,,00000000000000&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190917203629.png" alt="MapReduce 报错信息" title="MapReduce 报错信息"></p><p>此时我又去检查正在运行的 <code>Spark</code> 程序写入数据有没有问题，发现也是在写入 <code>HBase</code> 时有同样的错误，报错日志如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/09/17 18:22:49 INFO RpcRetryingCaller: Call exception, tries=10, retries=35, started=68431 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,14df3e2b1626e6e02fc1d772eb34f8ad,99999999999999&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">19/09/17 18:23:09 INFO RpcRetryingCaller: Call exception, tries=11, retries=35, started=88446 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,14df3e2b1626e6e02fc1d772eb34f8ad,99999999999999&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">19/09/17 18:23:29 INFO RpcRetryingCaller: Call exception, tries=12, retries=35, started=108564 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,14df3e2b1626e6e02fc1d772eb34f8ad,99999999999999&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">19/09/17 18:23:49 INFO RpcRetryingCaller: Call exception, tries=13, retries=35, started=128578 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,14df3e2b1626e6e02fc1d772eb34f8ad,99999999999999&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">19/09/17 18:24:09 INFO RpcRetryingCaller: Call exception, tries=14, retries=35, started=148657 ms ago, cancelled=false, msg=row &apos;YOUR_TABLE_NAME,14df3e2b1626e6e02fc1d772eb34f8ad,99999999999999&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190917203619.png" alt="Spark 报错信息" title="Spark 报错信息"></p><p>接着我想使用 <code>HBase</code> 自带的 <code>RowCounter</code> 执行 <code>MapReduce</code> 任务扫描数据，测试一下，使用命令：<br><code>hbase org.apache.hadoop.hbase.mapreduce.RowCounter &#39;YOUR_TABLE_NAME&#39;</code>。</p><p>结果也是超时报错，报错信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:</span><br><span class="line">Tue Sep 17 18:10:02 CST 2019, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=68315: row &apos;YOUR_TABLE_NAME,,00000000000000&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line"></span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.throwEnrichedException (RpcRetryingCallerWithReadReplicas.java:271)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call (ScannerCallableWithReplicas.java:203)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call (ScannerCallableWithReplicas.java:60)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries (RpcRetryingCaller.java:200)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientScanner.call (ClientScanner.java:320)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner (ClientScanner.java:295)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction (ClientScanner.java:160)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientScanner.&lt;init&gt;(ClientScanner.java:155)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.getScanner (HTable.java:821)</span><br><span class="line">	at org.apache.hadoop.hbase.client.MetaScanner.metaScan (MetaScanner.java:193)</span><br><span class="line">	at org.apache.hadoop.hbase.client.MetaScanner.metaScan (MetaScanner.java:89)</span><br><span class="line">	at org.apache.hadoop.hbase.client.MetaScanner.allTableRegions (MetaScanner.java:324)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HRegionLocator.getAllRegionLocations (HRegionLocator.java:88)</span><br><span class="line">	at org.apache.hadoop.hbase.util.RegionSizeCalculator.init (RegionSizeCalculator.java:94)</span><br><span class="line">	at org.apache.hadoop.hbase.util.RegionSizeCalculator.&lt;init&gt;(RegionSizeCalculator.java:81)</span><br><span class="line">	at org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.getSplits (TableInputFormatBase.java:256)</span><br><span class="line">	at org.apache.hadoop.hbase.mapreduce.TableInputFormat.getSplits (TableInputFormat.java:237)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits (JobSubmitter.java:301)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits (JobSubmitter.java:318)</span><br><span class="line">	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal (JobSubmitter.java:196)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job$10.run (Job.java:1290)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job$10.run (Job.java:1287)</span><br><span class="line">	at java.security.AccessController.doPrivileged (Native Method)</span><br><span class="line">	at javax.security.auth.Subject.doAs (Subject.java:422)</span><br><span class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs (UserGroupInformation.java:1709)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.submit (Job.java:1287)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Job.waitForCompletion (Job.java:1308)</span><br><span class="line">	at org.apache.hadoop.hbase.mapreduce.RowCounter.main (RowCounter.java:210)</span><br><span class="line">Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=68315: row &apos;YOUR_TABLE_NAME,,00000000000000&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=dev6,16020,1565930591664, seqNum=0</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries (RpcRetryingCaller.java:159)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run (ResultBoundedCompletionService.java:65)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">Caused by: java.net.ConnectException: Connection refused</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190917203602.png" alt="RowCounter 报错信息" title="RowCounter 报错信息"></p><p>由此可以断定，<code>HBase</code> 集群有问题了。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><p> 首先查看集群的服务是不是还正常，一看果然不正常，<code>RegionServer</code> 已经挂了，那就好办了，直接重启即可。</p><p>由于是在测试环境，平时不太关注，所以没有注意到服务已经挂了，让运维人员花了 1 分钟帮忙重启一下，确认后没有问题。</p><p>最后打开 <code>RegionServer</code> 管理界面，查看集群信息，恢复正常。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190917203513.png" alt="RegionServer 状态正常" title="RegionServer 状态正常"></p><p>我的 <code>MapReduce</code> 任务又欢快地跑起来了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190917203533.png" alt="MapReduce 正常执行" title="MapReduce 正常执行"></p><p>再试了一下 <code>RowCounter</code> 任务，也可以正常执行。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190917203542.png" alt="RowCounter 正常执行" title="RowCounter 正常执行"></p><p>至此，这个小问题解决。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 在搜索资料的过程中，也有人说是以下原因，但是我这里不是这个原因，所以记录下来，仅供读者参考：</p><ul><li>添加 <code>jar</code> 包，<code>com.yammer.metrics</code> -&gt; <code>metrics-core</code></li><li><code>hosts</code> 添加 <code>ip</code> 映射</li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>RegionServer</tag>
        <tag>RowCounter</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase 错误：NotServingRegionException</title>
    <url>/2019101201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在使用 <code>SparkStreaming</code> 程序处理数据，结果写入 <code>HBase</code> 时，遇到异常 <code>NotServingRegionException</code>，只是突然出现一次，平时正常，怀疑是和开发环境有关，本文记录查找问题的过程。本文中涉及的开发环境为 <code>HBase v1.1.2</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p><code>SparkStreaming</code> 程序处理数据，结果写入 <code>HBase</code>，出现异常，并且一直持续：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-10-13_16:40:31 [JobGenerator] INFO consumer.SimpleConsumer:68: Reconnect due to socket error: java.nio.channels.ClosedChannelException</span><br><span class="line">2019-10-13_16:40:32 [JobGenerator] INFO scheduler.JobScheduler:58: Added jobs for time 1570869630000 ms</span><br><span class="line">2019-10-13_16:40:33 [Executor task launch worker-0] INFO client.AsyncProcess:1656: #3, waiting for some tasks to finish. Expected max=0, tasksInProgress=29</span><br><span class="line">2019-10-13_16:40:34 [htable-pool3-t1] INFO client.AsyncProcess:1174: #3, table=YOUR_TABLE, attempt=29/35 failed=64ops, last exception: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region YOUR_TABLE,f,1565318245911.a70001dfe6d9320600286510318bfeb6. is not online on dev6,16020,1570795214262</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName (HRegionServer.java:2898)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion (RSRpcServices.java:947)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi (RSRpcServices.java:1994)</span><br><span class="line">	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod (ClientProtos.java:32213)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcServer.call (RpcServer.java:2114)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.CallRunner.run (CallRunner.java:101)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop (RpcExecutor.java:130)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run (RpcExecutor.java:107)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line"> on dev6,16020,1569724523487, tracking started null, retrying after=20058ms, replay=64ops</span><br><span class="line">2019-10-13_16:40:46 [scheduled-rate-update] INFO streaming.ScheduledRateController:136: MinRateCondition, rateLimit = -1, minRate = 400</span><br><span class="line">2019-10-13_16:40:46 [stream-rate-update] INFO streaming.ScheduledRateController:155: MinRateCondition&apos;s execute, numOfBatches = 38 vs 80</span><br><span class="line">2019-10-13_16:40:54 [Executor task launch worker-0] INFO client.AsyncProcess:1656: #3, waiting for some tasks to finish. Expected max=0, tasksInProgress=30</span><br><span class="line">2019-10-13_16:40:54 [htable-pool3-t1] INFO client.AsyncProcess:1174: #3, table=YOUR_TABLE, attempt=30/35 failed=64ops, last exception: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region YOUR_TABLE,f,1565318245911.a70001dfe6d9320600286510318bfeb6. is not online on dev6,16020,1570795214262</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName (HRegionServer.java:2898)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion (RSRpcServices.java:947)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi (RSRpcServices.java:1994)</span><br><span class="line">	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod (ClientProtos.java:32213)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcServer.call (RpcServer.java:2114)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.CallRunner.run (CallRunner.java:101)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop (RpcExecutor.java:130)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run (RpcExecutor.java:107)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line"> on dev6,16020,1569724523487, tracking started null, retrying after=20050ms, replay=64ops</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191012204453.png" alt="HBase 错误日志" title="HBase 错误日志"></p><p> 留意重点信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NotServingRegionException</span><br><span class="line">is not online on dev6,16020,1570795214262</span><br></pre></td></tr></table></figure><p>通过初步排查，发现只有一个数据表有此问题，更换其它表数据就可以正常写入，看来是和环境有关。</p><p>通过 <code>phoenix</code> 进行查询，发现也无法查询出数据，报错超时：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.RuntimeException: org.apache.phoenix.exception.PhoenixIOException: org.apache.phoenix.exception.PhoenixIOException: Failed after attempts=36, exceptions:</span><br><span class="line">Sat Oct 12 16:30:48 CST 2019, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=70197: row &apos;0&apos; on table &apos;YOUR_TABLE&apos; at region=YOUR_TABLE,0,1565318245911.157723c2d47bbae2226f6286a56f0256., hostname=dev6,15020,1569724523487, seqNum=1627</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191012204535.png" alt="phoenix 查询超时" title="phoenix 查询超时"></p><p>但是从这个超时异常中看不到有效的线索。</p><p>接着通过 <code>RegionServer</code> 查看 <code>Region</code> 的分布，尝试搜索日志中出现的 <code>Region YOUR_TABLE,f,1565318245911.a70001dfe6d9320600286510318bfeb6</code>，发现不存在，看来这个表的 <code>Region</code> 信息有异常。</p><p>通过搜索问题关键词，在 <code>stackoverflow</code> 上面找到一个例子，出现这种现象是因为这个表的 <code>Region</code> 损坏了，导致无法找到指定的 <code>Region</code>，但是可以手动修复。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 找问题原因，并且进一步得到了建议的解决方案，准备实施。</p><p>首先使用 <code>hbase hbck&quot;YOUR_TABLE&quot;</code> 检测数据表的状态，等待几十秒，会陆续打印出集群的状态以及表的状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-10-13 17:44:20,160 INFO  [main-SendThread (dev5:2181)] zookeeper.ClientCnxn: Opening socket connection to server dev5/172.18.5.205:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">2019-10-13 17:44:20,247 INFO  [main-SendThread (dev5:2181)] zookeeper.ClientCnxn: Socket connection established to dev5/172.18.5.205:2181, initiating session</span><br><span class="line">2019-10-13 17:44:20,359 INFO  [main-SendThread (dev5:2181)] zookeeper.ClientCnxn: Session establishment complete on server dev5/172.18.5.205:2181, sessionid = 0x26d539786987a13, negotiated timeout = 40000</span><br><span class="line">Version: 1.1.2.2.4.2.0-258</span><br><span class="line">Number of live region servers: 3</span><br><span class="line">Number of dead region servers: 0</span><br><span class="line">Master: dev6,16000,1563773138374</span><br><span class="line">Number of backup masters: 1</span><br><span class="line">Average load: 382.6666666666667</span><br><span class="line">Number of requests: 0</span><br><span class="line">Number of regions: 1148</span><br><span class="line">Number of regions in transition: 30</span><br><span class="line">2019-10-13 17:44:24,693 INFO  [main] util.HBaseFsck: Loading regionsinfo from the hbase:meta table</span><br><span class="line"></span><br><span class="line">Number of empty REGIONINFO_QUALIFIER rows in hbase:meta: 0</span><br><span class="line">2019-10-13 17:44:24,954 INFO  [main] util.HBaseFsck: getHTableDescriptors == tableNames =&gt; [YOUR_TABLE]</span><br><span class="line">...</span><br><span class="line">2019-10-13 17:44:26,621 INFO  [main] util.HBaseFsck: Checking and fixing region consistency</span><br><span class="line">ERROR: Region &#123; meta =&gt; YOUR_TABLE,6,1565318245911.60686e402d3b0e25edc210190f8290c6., hdfs =&gt; hdfs://dev-hdfs/apps/hbase/data/data/default/YOUR_TABLE/60686e402d3b0e25edc210190f8290c6, deployed =&gt; , replicaId =&gt; 0 &#125; not deployed on any region server.</span><br><span class="line">ERROR: Region &#123; meta =&gt; YOUR_TABLE,9,1565318245911.3dab1e5fc8211112c46041544c8cf6a1., hdfs =&gt; hdfs://dev-hdfs/apps/hbase/data/data/default/YOUR_TABLE/3dab1e5fc8211112c46041544c8cf6a1, deployed =&gt; , replicaId =&gt; 0 &#125; not deployed on any region server.</span><br><span class="line">ERROR: Region &#123; meta =&gt; YOUR_TABLE,0,1565318245911.157723c2d47bbae2226f6286a56f0256., hdfs =&gt; hdfs://dev-hdfs/apps/hbase/data/data/default/YOUR_TABLE/157723c2d47bbae2226f6286a56f0256, deployed =&gt; , replicaId =&gt; 0 &#125; not deployed on any region server.</span><br><span class="line">ERROR: Region &#123; meta =&gt; YOUR_TABLE,3,1565318245911.8e6507c0aa0ba2f7864fb6adbab58cd4., hdfs =&gt; hdfs://dev-hdfs/apps/hbase/data/data/default/YOUR_TABLE/8e6507c0aa0ba2f7864fb6adbab58cd4, deployed =&gt; , replicaId =&gt; 0 &#125; not deployed on any region server.</span><br><span class="line">ERROR: Region &#123; meta =&gt; YOUR_TABLE,f,1565318245911.a70001dfe6d9320600286510318bfeb6., hdfs =&gt; hdfs://dev-hdfs/apps/hbase/data/data/default/YOUR_TABLE/a70001dfe6d9320600286510318bfeb6, deployed =&gt; , replicaId =&gt; 0 &#125; not deployed on any region server.</span><br><span class="line">ERROR: Region &#123; meta =&gt; YOUR_TABLE,c,1565318245911.e247e3f852573308fd554e07452fbe93., hdfs =&gt; hdfs://dev-hdfs/apps/hbase/data/data/default/YOUR_TABLE/e247e3f852573308fd554e07452fbe93, deployed =&gt; , replicaId =&gt; 0 &#125; not deployed on any region server.</span><br><span class="line">2019-10-13 17:44:26,732 INFO  [main] util.HBaseFsck: Handling overlap merges in parallel. set hbasefsck.overlap.merge.parallel to false to run serially.</span><br><span class="line">ERROR: There is a hole in the region chain between 0 and 1.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: There is a hole in the region chain between 3 and 4.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: There is a hole in the region chain between 6 and 7.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: There is a hole in the region chain between 9 and a.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: There is a hole in the region chain between c and d.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: Last region should end with an empty key. You need to create a new region and regioninfo in HDFS to plug the hole.</span><br><span class="line">ERROR: Found inconsistency in table YOUR_TABLE</span><br><span class="line">2019-10-13 17:44:26,747 INFO  [main] util.HBaseFsck: Computing mapping of all store files</span><br><span class="line">...</span><br><span class="line">2019-10-13 17:44:30,038 INFO  [main] util.HBaseFsck: Finishing hbck</span><br><span class="line">Summary:</span><br><span class="line">Table YOUR_TABLE is inconsistent.</span><br><span class="line">    Number of regions: 11</span><br><span class="line">    Deployed on:  dev4,16020,1570795191487 dev5,16020,1570795198827</span><br><span class="line">Table hbase:meta is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  dev5,16020,1570795198827</span><br><span class="line">12 inconsistencies detected.</span><br><span class="line">Status: INCONSISTENT</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191012204717.png" alt="hbase hbck 查看输出日志 - 1" title="hbase hbck 查看输出日志 - 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191012204734.png" alt="hbase hbck 查看输出日志 - 2" title="hbase hbck 查看输出日志 - 2"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191012204747.png" alt="hbase hbck 查看输出日志 - 3" title="hbase hbck 查看输出日志 - 3"></p><p>首先注意到前面那个不存在的 <code>Region</code> <code>a70001dfe6d9320600286510318bfeb6</code> 处于未部署状态，<code>RegionServer</code> 当然无法找到了。</p><p>可以看到最终的结论：<code>INCONSISTENT</code>，就是数据不一致。并且在输出日志里面还有说明出现了 <code>Region</code> 空洞【<code>Region hole</code>】。</p><p>那怎么解决呢，可以先尝试使用 <code>hbase hbck -fix&quot;YOUR_TABLE&quot;</code> 解决。</p><p>这里如果遇到操作 <code>HDFS</code> 无权限，记得切换用户 <code>export HADOOP_USER_NAME=hbase</code>，当然最好还是直接使用管理员权限操作：<br><code>sudo -u hbase hbase hbck -fix&quot;YOUR_TABLE&quot;</code>。</p><p>在修复过程中，仍旧会不断输出日志，如果看到：<br><code>util.HBaseFsck: Sleeping 10000ms before re-checking after fix...</code><br>则说明修复完成，为了验证修复结果，<code>HBase</code> 还会自动检测一次。</p><p>再次检测后，如果看到如下信息，说明修复成功：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Summary:</span><br><span class="line">Table YOUR_TABLE is okay.</span><br><span class="line">    Number of regions: 17</span><br><span class="line">2019-10-13 18:20:02,145 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down</span><br><span class="line">    Deployed on:  dev4,16020,1570795191487 dev5,16020,1570795198827</span><br><span class="line">Table hbase:meta is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  dev5,16020,1570795198827</span><br><span class="line">0 inconsistencies detected.</span><br><span class="line">Status: OK</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191012204942.png" alt="hbase hbck fix 修复完成" title="hbase hbck fix 修复完成"></p><p>接着就可以继续正常写入数据了。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 参考 <code>stackoverflow</code> 上面的例子：<a href="https://stackoverflow.com/questions/37507878/hbase-fails-with-org-apache-hadoop-hbase-notservingregionexception-region-is-not" target="_blank" rel="noopener">notservingregionexception</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>SparkStreaming</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase 错误：The node hbase is not in ZooKeeper</title>
    <url>/2019101901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>使用 <code>phoenix</code> 向 <code>HBase</code> 中导入数据，使用的是 <code>phoenix</code> 自带的脚本 <code>psql.py</code>，结果报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/10/18 11:47:29 ERROR client.ConnectionManager$HConnectionImplementation: The node /hbase is not in ZooKeeper. It should have been written by the master. Check the value configured in &apos;zookeeper.znode.parent&apos;. There could be a mismatch with the one configured in the master.</span><br></pre></td></tr></table></figure><p>看起来是 <code>ZooKeeper</code> 环境有问题，本文记录解决过程。</p><p>本文开发环境基于 <code>HBase v1.1.2</code>、<code>phoenix v4.2.0</code> 。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 使用 <code>phoenix</code> 自带的导数脚本 <code>psql.py</code>，执行导入操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">psql.py -t YOUR_TABLE dev4:2181 ./content.csv</span><br></pre></td></tr></table></figure><p>其中，<code>dev4:2191</code> 是 <code>Zookeeper</code> 集群节点，<code>./content.csv</code> 是数据文件，结果出现异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/10/18 11:47:29 ERROR client.ConnectionManager$HConnectionImplementation: The node /hbase is not in ZooKeeper. It should have been written by the master. Check the value configured in &apos;zookeeper.znode.parent&apos;. There could be a mismatch with the one configured in the master.</span><br><span class="line">19/10/18 11:47:29 ERROR client.ConnectionManager$HConnectionImplementation: The node /hbase is not in ZooKeeper. It should have been written by the master. Check the value configured in &apos;zookeeper.znode.parent&apos;. There could be a mismatch with the one configured in the master.</span><br><span class="line">19/10/18 11:47:29 ERROR client.ConnectionManager$HConnectionImplementation: The node /hbase is not in ZooKeeper. It should have been written by the master. Check the value configured in &apos;zookeeper.znode.parent&apos;. There could be a mismatch with the one configured in the master.</span><br><span class="line">19/10/18 11:47:30 ERROR client.ConnectionManager$HConnectionImplementation: The node /hbase is not in ZooKeeper. It should have been written by the master. Check the value configured in &apos;zookeeper.znode.parent&apos;. There could be a mismatch with the one configured in the master.</span><br><span class="line">19/10/18 11:47:31 ERROR client.ConnectionManager$HConnectionImplementation: The node /hbase is not in ZooKeeper. It should have been written by the master. Check the value configured in &apos;zookeeper.znode.parent&apos;. There could be a mismatch with the one configured in the master.</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191019204203.png" alt="导入数据异常" title="导入数据异常"></p><p>看起来是 <code>Zookeeper</code> 中缺失 <code>/hbase</code> 节点目录。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 从 <code>stackoverflow</code> 上面查到一条类似的问题，见备注链接。</p><p>表面原因的确是 <code>Zookeeper</code> 中缺失 <code>/hbase</code> 节点目录，因为 <code>phoenix</code> 需要从这个节点获取 <code>HBase</code> 集群的信息，例如表结构，节点目录缺失则无法获取。</p><p>查看 <code>conf/hbase-site.xml</code> 文件，找到配置项：<code>zookeeper.znode.parent</code>，它就是表示 <code>HBase</code> 在 <code>ZooKeeper</code> 中的管理目录，里面存储着关于 <code>HBase</code> 集群的各项重要信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zookeeper.znode.parent&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/hbase-unsecure&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>再去查看 <code>conf/hbase-env.sh</code> 里面的配置信息：<code>HBASE_MANAGES_ZK</code>，这个参数是告诉 <code>HBase</code> 是否使用自带的 <code>ZooKeeper</code> 管理 <code>HBase</code> 集群。如果为 <code>true</code>，则使用自带的 <code>ZooKeeper</code>；如果为 <code>false</code>，则使用外部的 <code>ZooKeeper</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191019204433.png" alt="查看 hbase-env.sh 文件" title="查看 hbase-env.sh 文件"></p><p>可以看到我这里的参数设置的是 <code>false</code>，也就是使用外部的 <code>ZooKeeper</code> 集群。</p><p>在这里多说一下这个参数的不同值的使用场景：</p><ul><li>默认值为 <code>true</code>，但是，自带的 <code>ZooKeeper</code> 只能为单机或伪分布模式下的 <code>HBase</code> 提供服务，一般用于学习场景或者测试环境，比较方便管理 </li><li> 如果设置为 <code>false</code>，则使用外部的 <code>ZooKeeper</code> 管理 <code>HBase</code>，此时 <code>HBase</code> 既可以是单机模式、伪分布式模式，也可以是分布式模式，重点只有一个，需要自己搭建一套 <code>ZooKeeper</code> 集群 </li><li> 如果设置为 <code>true</code>，并且 <code>HBase</code> 使用伪分布式模式，则在启动 <code>HBase</code> 时，<code>HBase</code> 将 <code>Zookeeper</code> 作为自身的一部分运行，进程变为 <code>HQuorumPeer</code></li><li>一般建议使用 <code>false</code>，然后自己再单独搭建一套 <code>ZooKeeper</code>，这才是真生的分布式环境；当然，如果觉得复杂，只是自己学习、测试的时候使用，可以设置为 <code>true</code></li></ul><p>言归正传，既然使用的是外部的 <code>ZooKeeper</code>，也就是我这里指定的 <code>dev4:2181</code>，可见 <code>HBase</code> 集群已经设置了自己在 <code>Zookeeper</code> 中的元信息管理目录，而 <code>phoenix</code> 为什么要去另外一个目录 <code>/hbase</code> 获取呢。这里可能是 <code>phoenix</code> 的配置有问题。</p><p>不妨先去里面看一下是否存在 <code>/hbase</code> 节点即可，经过查看，没有这个节点。如果没有的话，也不妨先重新创建一个，使用：<code>create /hbase&quot;&quot;</code> 创建一个空内容节点，确保节点存在。</p><p>注意，这里只是创建了一个空节点，里面并没有任何信息，所以 <code>phoenix</code> 从里面是无法获取关于 <code>HBase</code> 集群的信息的。</p><p>测试了一下，果然，还是无法导入数据，抛出超时异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/10/19 20:47:12 WARN impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-phoenix.properties,hadoop-metrics2.properties</span><br><span class="line">org.apache.phoenix.exception.PhoenixIOException: callTimeout=600000, callDuration=1024368: </span><br><span class="line">	at org.apache.phoenix.util.ServerUtil.parseServerException (ServerUtil.java:108)</span><br><span class="line">	at org.apache.phoenix.query.ConnectionQueryServicesImpl.ensureTableCreated (ConnectionQueryServicesImpl.java:840)</span><br><span class="line">	at org.apache.phoenix.query.ConnectionQueryServicesImpl.createTable (ConnectionQueryServicesImpl.java:1134)</span><br><span class="line">	at org.apache.phoenix.query.DelegateConnectionQueryServices.createTable (DelegateConnectionQueryServices.java:110)</span><br><span class="line">	at org.apache.phoenix.schema.MetaDataClient.createTableInternal (MetaDataClient.java:1591)</span><br><span class="line">	at org.apache.phoenix.schema.MetaDataClient.createTable (MetaDataClient.java:569)</span><br><span class="line">	at org.apache.phoenix.compile.CreateTableCompiler$2.execute (CreateTableCompiler.java:175)</span><br><span class="line">	at org.apache.phoenix.jdbc.PhoenixStatement$2.call (PhoenixStatement.java:271)</span><br><span class="line">	at org.apache.phoenix.jdbc.PhoenixStatement$2.call (PhoenixStatement.java:263)</span><br><span class="line">	at org.apache.phoenix.call.CallRunner.run (CallRunner.java:53)</span><br><span class="line">	at org.apache.phoenix.jdbc.PhoenixStatement.executeMutation (PhoenixStatement.java:261)</span><br><span class="line">	at org.apache.phoenix.jdbc.PhoenixStatement.executeUpdate (PhoenixStatement.java:1043)</span><br><span class="line">	at org.apache.phoenix.query.ConnectionQueryServicesImpl$9.call (ConnectionQueryServicesImpl.java:1561)</span><br><span class="line">	at org.apache.phoenix.query.ConnectionQueryServicesImpl$9.call (ConnectionQueryServicesImpl.java:1530)</span><br><span class="line">	at org.apache.phoenix.util.PhoenixContextExecutor.call (PhoenixContextExecutor.java:77)</span><br><span class="line">	at org.apache.phoenix.query.ConnectionQueryServicesImpl.init (ConnectionQueryServicesImpl.java:1530)</span><br><span class="line">	at org.apache.phoenix.jdbc.PhoenixDriver.getConnectionQueryServices (PhoenixDriver.java:162)</span><br><span class="line">	at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver.connect (PhoenixEmbeddedDriver.java:126)</span><br><span class="line">	at org.apache.phoenix.jdbc.PhoenixDriver.connect (PhoenixDriver.java:133)</span><br><span class="line">	at java.sql.DriverManager.getConnection (DriverManager.java:664)</span><br><span class="line">	at java.sql.DriverManager.getConnection (DriverManager.java:208)</span><br><span class="line">	at org.apache.phoenix.util.PhoenixRuntime.main (PhoenixRuntime.java:182)</span><br><span class="line">Caused by: java.net.SocketTimeoutException: callTimeout=600000, callDuration=1024368: </span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries (RpcRetryingCaller.java:156)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable (HBaseAdmin.java:3390)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HBaseAdmin.getTableDescriptor (HBaseAdmin.java:408)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HBaseAdmin.getTableDescriptor (HBaseAdmin.java:429)</span><br><span class="line">	at org.apache.phoenix.query.ConnectionQueryServicesImpl.ensureTableCreated (ConnectionQueryServicesImpl.java:772)</span><br><span class="line">	... 20 more</span><br><span class="line">Caused by: org.apache.hadoop.hbase.MasterNotRunningException: java.io.IOException: Can&apos;t get master address from ZooKeeper; znode data == null</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation$StubMaker.makeStub (ConnectionManager.java:1671)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation$MasterServiceStubMaker.makeStub (ConnectionManager.java:1697)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getKeepAliveMasterService (ConnectionManager.java:1914)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HBaseAdmin$MasterCallable.prepare (HBaseAdmin.java:3363)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries (RpcRetryingCaller.java:125)</span><br><span class="line">	... 24 more</span><br><span class="line">Caused by: java.io.IOException: Can&apos;t get master address from ZooKeeper; znode data == null</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MasterAddressTracker.getMasterAddress (MasterAddressTracker.java:114)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation$StubMaker.makeStubNoRetries (ConnectionManager.java:1597)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation$StubMaker.makeStub (ConnectionManager.java:1643)</span><br><span class="line">	... 28 more</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191019211617.png" alt="导入数据再次出现异常" title="导入数据再次出现异常"></p><p>可以看到，里面有 <code>Can&#39;t get master address from ZooKeeper</code> 字样，也就是无法从 <code>Zookeeper</code> 指定的目录中获取关于 <code>HBase</code> 的主节点信息，可见，单纯在 <code>Zookeeper</code> 中创建一个 <code>/hbase</code> 目录是没用的。因此，源头应该在于 <code>phoenix</code> 为什么不去 <code>/hbase-unsecure</code> 目录中获取 <code>HBase</code> 集群信息【这才是 <code>HBase</code> 集群的信息所在地】，是哪里的配置出了问题。</p><p>经过排查，<code>phoenix</code> 脚本在加载 <code>hbase_conf_dir</code> 参数的时候，目录错误，因此没有获取到 <code>HBase</code> 相的配置文件，最终导致没有去 <code>Zookeeper</code> 的 <code>/hbase-unsecure</code> 目录读取数据。这里排查的是 <code>psql.py</code>、<code>phoenix_utils.py</code> 这两个文件，里面有关于加载 <code>HBase</code>、<code>Hadoop</code> 集群的配置目录的参数，如果赋值错误就会导致上述现象。</p><p>把 <code>hbase_conf_dir</code> 参数的加载过程梳理清楚，确保可以加载到 <code>HBASE_HOME/conf</code> 目录，接着就可以顺利导入数据了。</p><p>同时当然也需要 <code>HADOOP_HOME/conf</code>，但是我这里已经是正确的了，如果读者没有配置好，可能会遇到找不到 <code>hdfs</code> 的相关类，例如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.hdfs.DistributedFileSystem not found</span><br></pre></td></tr></table></figure><p>最后一点需要注意，上传的 <code>csv</code> 文件内容列数要确保和 <code>HBase</code> 表的列数一致，并且不需要表头，否则无法成功导入【表头也会被当做内容】，日志也会报错提醒的。当然，字段也是有顺序的，<code>csv</code> 文件中字段的顺序要和 <code>HBase</code> 表中定义的一致。</p><p>顺利导入数据，导入成功，耗时 12 秒，导入 12000 条数据，从输出日志中可以看到详情。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191021215944.png" alt="数据导入成功" title="数据导入成功"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>1、参考：<a href="https://stackoverflow.com/questions/28605301/the-node-hbase-is-not-in-zookeeper" target="_blank" rel="noopener">HBase</a> ，这是个相似的问题。</p><p>2、如果数据量比较大的话，就不建议使用这种脚本导入的方式，反而可以使用 <code>xxx-client.jar</code> 包里面自带的处理类来执行，并提前把数据文件上传至 <code>hdfs</code>，然后后台会提交 <code>MapReduce</code> 任务来大批量导入数据。</p><p>3、数据导入、数据导出还可以使用 <code>pig</code> 这个工具。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>Phoenix</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS 异常之 READ is not supported in state standby</title>
    <url>/2018122702.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天查看日志发现，以前正常运行的 Spark 程序会不断抛出异常：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.ipc.RemoteException (org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby</span><br></pre></td></tr></table></figure><p></p><p>但是却没有影响到功能的正常运行，只不过是抛出了大量的上述异常，而且内容都一样，也都是操作 HDFS 产生的，所以猜测与 HDFS 集群（或者配置）有关系。本文就记录发现问题、解决问题的过程。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 按照日常操作，查看 Spark 任务的 Driver 端的日志，结果发现了大量的重复异常，又看了一下对功能的影响，结果发现没有影响，所有功能均正常运行，产生的结果也是期望的。</p><h2 id="问题分析"><a href="# 问题分析" class="headerlink" title="问题分析"></a>问题分析 </h2><p> 详细来看一下 Driver 端的日志异常信息：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">2018-12-26_23:25:40 [main] INFO retry.RetryInvocationHandler:140: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over hadoop1/192.168.10.162:8020. Trying to fail over immediately.</span><br><span class="line">org.apache.hadoop.ipc.RemoteException (org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation (StandbyState.java:<span class="number">87</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation (NameNode.java:<span class="number">1722</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation (FSNamesystem.java:<span class="number">1362</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo (FSNamesystem.java:<span class="number">4414</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo (NameNodeRpcServer.java:<span class="number">893</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo (ClientNamenodeProtocolServerSideTranslatorPB.java:<span class="number">835</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$<span class="number">2</span>.callBlockingMethod (ClientNamenodeProtocolProtos.java)</span><br><span class="line">	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call (ProtobufRpcEngine.java:<span class="number">619</span>)</span><br><span class="line">	at org.apache.hadoop.ipc.RPC$Server.call (RPC.java:<span class="number">962</span>)</span><br><span class="line">	at org.apache.hadoop.ipc.Server$Handler$<span class="number">1</span>.run (Server.java:<span class="number">2039</span>)</span><br><span class="line">	at org.apache.hadoop.ipc.Server$Handler$<span class="number">1</span>.run (Server.java:<span class="number">2035</span>)</span><br><span class="line">	at java.security.AccessController.doPrivileged (Native Method)</span><br><span class="line">	at javax.security.auth.Subject.doAs (Subject.java:<span class="number">422</span>)</span><br><span class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs (UserGroupInformation.java:<span class="number">1628</span>)</span><br><span class="line">	at org.apache.hadoop.ipc.Server$Handler.run (Server.java:<span class="number">2033</span>)</span><br><span class="line">	at org.apache.hadoop.ipc.Client.call (Client.java:<span class="number">1468</span>)</span><br><span class="line">	at org.apache.hadoop.ipc.Client.call (Client.java:<span class="number">1399</span>)</span><br><span class="line">	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke (ProtobufRpcEngine.java:<span class="number">232</span>)</span><br><span class="line">	at com.sun.proxy.$Proxy30.getFileInfo (Unknown Source)</span><br><span class="line">	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo (ClientNamenodeProtocolTranslatorPB.java:<span class="number">768</span>)</span><br><span class="line">	at sun.reflect.GeneratedMethodAccessor34.invoke (Unknown Source)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">	at java.lang.reflect.Method.invoke (Method.java:<span class="number">498</span>)</span><br><span class="line">	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod (RetryInvocationHandler.java:<span class="number">187</span>)</span><br><span class="line">	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke (RetryInvocationHandler.java:<span class="number">102</span>)</span><br><span class="line">	at com.sun.proxy.$Proxy31.getFileInfo (Unknown Source)</span><br><span class="line">	at org.apache.hadoop.hdfs.DFSClient.getFileInfo (DFSClient.java:<span class="number">2007</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.DistributedFileSystem$<span class="number">19</span>.doCall (DistributedFileSystem.java:<span class="number">1136</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.DistributedFileSystem$<span class="number">19</span>.doCall (DistributedFileSystem.java:<span class="number">1132</span>)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve (FileSystemLinkResolver.java:<span class="number">81</span>)</span><br><span class="line">	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus (DistributedFileSystem.java:<span class="number">1132</span>)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.isFile (FileSystem.java:<span class="number">1426</span>)</span><br></pre></td></tr></table></figure><p>注意一下核心异常所在：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over hadoop1/192.168.10.162:8020. Trying to fail over immediately.</span><br><span class="line">org.apache.hadoop.ipc.RemoteException (org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby</span><br></pre></td></tr></table></figure><p></p><p>当去从 hadoop1/192.168.10.162:8020 这里 getFileInfo 的时候，抛出了异常，而且明确告诉我们这台机器处于 standby 状态，不支持读取操作。此时，可以想到，肯定是 hadoop1/192.168.10.162:8020 这台机器已经处于 standby 状态了，无法提供服务，所以抛出此异常。既然问题找到了，那么问题产生的原因是什么呢，以及为什么对功能没有影响，接下来一一分析。</p><p>首先查看 hdfs-site.xml 配置文件，看看 namenode 相关的配置项：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>r-cluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.r-cluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.r-cluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.r-cluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>rocket15:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>可以看到，namenode 相关配置有 2 台机器：nn1、nn2，而上述产生异常的信息表明连接 nn1 被拒绝，那么我去看一下 HDFS 集群的状态，发现 nn1 果然是 standby 状态的，而 nn2（rocket15） 才是 active 状态。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fyluqlzruwj20ln0b6mxq.jpg" alt="nn2 的 active 状态" title="nn2 的 active 状态"></p><p>再仔细查看日志，没有发现连接 nn2 的异常，那就说明是第一次连接 nn1 抛出异常，然后试图连接 nn2，成功连接，没有抛出异常，接下来程序就正常处理数据了，对功能没有任何影响。</p><p>到这里，我们已经分析出了整个过程，现象表明这个异常只是连接了 standby 状态的 namenode，是正常抛出的。然后会再次连接另外一台 active 状态的 namenode，连接成功。</p><h2 id="抛异常的流程细节"><a href="# 抛异常的流程细节" class="headerlink" title="抛异常的流程细节"></a>抛异常的流程细节 </h2><p>1、客户端在连接 HDFS 的时候，会从配置文件 hdfs-site.xml 中，读取 nameservices 的配置，获取机器编号，我这里是 nn1 和 nn2，分别对应着 2 台 namenode 机器；</p><p>2、客户端会首先选择编号较小的 namenode（我这里是 nn1，对应着 hadoop1），试图连接；</p><p>3、如果这台 namenode 是 active 状态，则客户端可以正常处理请求；但是如果这台 namenode 是 standby 状态，则客户端抛出由服务端返回的异常：Operation category READ is not supported in state standby，同时打印 ip 信息，接着会尝试连接另外一台编号较大的 namenode（我这里是 nn2，即 rocket15）；</p><p>4、如果连接成功，则客户端可以正常处理请求；如果 nn2 仍然像 nn1 一样，客户端会抛出一样的异常，此时会继续反复重试 nn1 与 nn2（重试次数有配置项，间隔时间有配置项）；如果有成功的，则客户端可以正常处理请求，如果全部失败，则客户端无法正常处理请求，此时应该要关注解决 namenode 为什么全部都处在 standby 状态。</p><p> 配置参数如下（参考 <a href="https://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">Hadoop 官方文档 </a>）：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 客户端重试次数，默认 15 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.max.attempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>15<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 客户端 2 次重试间隔时间，默认 500 毫秒 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.sleep.base.millis<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>500<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 客户端 2 次重试间隔时间，默认 1500 毫秒 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.sleep.max.millis<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1500<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 客户端 1 次连接中重试次数，默认 0, 在网络不稳定时建议加大此值 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.connection.retries<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 客户端 1 次连接中超时重试次数，仅是指超时重试，默认 0, 在网络不稳定时建议加大此值 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.connection.retries.on.timeouts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a> 问题解决 </h1><p> 既然明确了问题，并且分析出了具体原因，解决起来就简单了，对于我这种情况，有 2 种方法：</p><p>1、不用解决，也无需关心，这个异常没有任何影响，会自动重连另外一台 active 状态的 namenode 机器的；</p><p>2、如果就是一心想把异常消除掉，那就更改 hdfs-site.xml 配置文件里面的 nameservices 配置项对应的机器，把编号最小的机器设置成状态为 active 的 namenode（例如我这里把 nn1、nn2 的对应的机器 ip 地址交换一下即可，确保 nn1 是 active 状态的），那么连接 HDFS 的时候第一次就会直接连接这台机器，就不会抛出异常了（但是要注意 namenode 以后可能是会挂的，挂了会自动切换，那么到那个时候还要更改这个配置项）。</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.r-cluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>rocket15:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.r-cluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结</h1><p>1、参考：<a href="http://support-it.huawei.com/docs/zh-cn/fusioninsight-all/maintenance-guide/zh-cn_topic_0062904132.html" target="_blank" rel="noopener">http://support-it.huawei.com/docs/zh-cn/fusioninsight-all/maintenance-guide/zh-cn_topic_0062904132.html</a></p><p>2、这个问题其实不是问题，只不过抛出了异常，我看到有点担心而已，但是如果连接所有的机器都抛出这种异常，并且重试了很多次就有影响了，说明所有的 namenode 都挂了，根本无法正常操作 HDFS 系统；</p><p>3、根据 2 进行总结：如果只是在操作 HDFS 的时候打印一次（每次操作都会打印一次），说明第一次连接到了 standby 状态的 namenode，是正常的，不用关心；但是，如果出现了大量的异常（比如连续 10 次，连续 20 次），说明 namenode 出问题了，此时应该关心 namenode 的状态，确保正常服务。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Hadoop 从零基础到入门系列</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
        <tag>HDFS</tag>
        <tag>nameNode</tag>
        <tag>standby</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop 入门系列 0-- 初识 Hadoop</title>
    <url>/2017040101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天是愚人节，可以说是个好日子，也可以说是个坏日子。那我就选择从今天开始整理 <strong>Hadoop 入门系列 </strong>的博客内容，给自己开个玩笑，同时也给自己定一个目标，看看自己能不能坚持写下去。本文是这一系列博客内容的第零篇：<strong> 初识 Hadoop</strong>，会讲一些关于 <code>Hadoop</code> 的基础概念以及基本知识点，不需要技术基础，也不需要手动操作，能看懂就行。</p><a id="more"></a><p>首先声明，以下内容基于 <code>Hadoop v1.x</code> 讲解，不存在 <code>HA（High Availability，高可用）</code> 的概念，了解 <code>v1.x</code> 的基础概念后，才能更好的继续学习 <code>v2.x、v3.x</code> 的内容。由于 <code>Hadoop</code> 的 <code>v2.x、v3.x</code> 与 <code>v1.x</code> 的版本差异比较大，更为复杂，一些概念一开始难以理解，所以采用这种由易入难的方式能循序渐进，有利于初学者、零基础者。</p><h1 id="入门概念"><a href="# 入门概念" class="headerlink" title="入门概念"></a>入门概念 </h1><p> 首先需要了解，<code>Hadoop</code> 是什么？简单来说，<code>Hadoop</code> 是适合大数据的 <strong>分布式存储平台 </strong>与 <strong>分布式计算平台 </strong>，包含两个核心组件，即 <code>HDFS</code> 与 <code>MapReduce</code>。其中，<code>HDFS</code> 的全称是 <code>Hadoop Distributed File System</code>，表示一种 <strong>分布式文件系统 </strong>，<code>MapReduce</code> 表示一种 <strong>并行计算框架 </strong>。</p><p>它的创始人是 <code>Doug Cutting</code>，现在是 <code>Cloudera</code> 的首席架构师。</p><p>再说一下关于 <code>Hadoop</code> 这个名字的趣事，<code>Hadoop</code> 的发音是 <code>hædu:p</code>，它的来源是这样的：<code>Doug Cutting</code> 的儿子在牙牙学语时，抱着一个黄色的小象玩偶，嘴里发出类似于 <code>hædu:p</code> 的发音，<code>Doug Cutting</code> 灵光闪现，就把当时正在开发的项目命名为 <code>Hadoop</code>。</p><p>所以，这个名字不是一个缩写，也不是一个单词，它是一个虚构的名字。该项目的创建者，<code>Doug Cutting</code> 如此解释 <code>Hadoop</code> 的命名：首先它是我的孩子在玩耍时发出的声音，而我的命名标准就是简短、容易发音、拼写，小孩子都能发出来，就说明选对了。众所周知，给软件命名不是件太容易的事，要尽量找没有被使用过、没有带有特殊意义的词、不会被用于别处，否则把它写进了程序就可能会影响编程。</p><p><code>Hadoop</code> 的版本发布有两种：</p><ul><li><code>Apache</code> 开源版本，官方版本 </li><li><code>Cloudera</code> 公司维护的打补丁版本，稳定、有商业支持，下载使用比较多</li></ul><h1 id="HDFS- 基础知识"><a href="#HDFS- 基础知识" class="headerlink" title="HDFS 基础知识"></a>HDFS 基础知识</h1><p><code>HDFS</code> 是基于 <code>Google</code> 的论文 <code>The Google File System</code> 而开发实现的。</p><h2 id="文件结构"><a href="# 文件结构" class="headerlink" title="文件结构"></a> 文件结构 </h2><p><code>HDFS</code> 中的文件有自己独特的存储方式，一个文件会被划分为大小固定的多个文件块，称之为 <code>block</code>，分布存储在集群中的多个数据节点上，每个文件块的大小默认为 <code>64MB</code>【在 v1.x 中是这个默认值，在 v2.x 默认是 128MB】。</p><p> 文件块的大小参数如下，单位是字节【134217728B 即 128MB】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt; </span><br><span class="line">  &lt;name&gt;dfs.blocksize&lt;/name&gt;  </span><br><span class="line">  &lt;value&gt;134217728&lt;/value&gt; </span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190812004101.jpg" alt="文件块参数设置" title="文件块参数设置"></p><p>关于这个文件块参数的解释说明：</p><blockquote><p>The default block size for new files, in bytes. You can use the following suffix (case insensitive): k (kilo), m (mega), g (giga), t (tera), p (peta), e (exa) to specify the size (such as 128k, 512m, 1g, etc.), Or provide complete size in bytes (such as 134217728 for 128 MB).</p></blockquote><p>参考官网：<a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">hdfs-default.xml</a> 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190812004121.jpg" alt="文件块参数解释说明" title="文件块参数解释说明"></p><h2 id="副本概念"><a href="# 副本概念" class="headerlink" title="副本概念"></a>副本概念 </h2><p> 同时，为了保证数据文件安全，避免丢失，同一个文件块在不同的数据节点中有多个副本。</p><p><code>HDFS</code> 设置副本数的参数是在 <code>hdfs-site.xml</code> 配置文件中，默认为 3，在一般场景下都是可以保证数据安全的。如果觉得浪费资源可以设置为 2，但是磁盘的价格是不贵的，多一份可以保障数据更加安全，当然，太多了也没有必要，会造成磁盘的浪费。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190812004034.png" alt="副本数参数设置" title="副本数参数设置"></p><p>注意，<code>HDFS</code> 中的副本参数的概念不是中文语境下的复制次数，而是总的数量，例如把 <strong>dfs.replication</strong> 设置为 3，虽然翻译为副本数为 3，其实表示的总共有 3 份数据【主本 1 份 + 副本 2 份】。</p><p>注意，如果按照中文语境下的含义来解释，副本数应该是 2，加上主本一共有 3 份数据，这看起来有歧义，也会令人疑惑。它不像在 <code>Elastisearch</code> 中设置副本的参数 <strong>number_of_replicas</strong>，表示的就是副本数，如果想保存总共 3 份数据，需要把 <strong>number_of_replicas</strong> 设置为 2 。下图中此参数的值设置为 1，即副本为 1，表示总共保存 2 份数据。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190812003816.jpg" alt="Elastisearch 设置副本数" title="Elastisearch 设置副本数"></p><h2 id="文件系统"><a href="# 文件系统" class="headerlink" title="文件系统"></a>文件系统 </h2><p> 到了这里，我们会思考，文件结构好像还有点复杂，那么 <code>HDFS</code> 是怎么管理这些文件的呢？这是接下来的重点。</p><p><code>HDFS</code> 这个分布式文件系统遵循 <strong>主从结构 </strong>，有一个主节点，称之为 <code>NameNode</code>【NN，管理节点】，有多个从节点，称之为 <code>DataNode</code>【DN，数据节点】。</p><p>它们各自的作用如下。</p><p><code>NameNode</code> 节点的作用：</p><ul><li>接收客户端的请求 </li><li> 维护分布式文件系统的目录结构 </li><li> 管理文件与 <code>block</code> 之间的关系，管理 <code>block</code> 与 <code>DataNode</code> 节点之间的关系 </li></ul><p><code>DataNode</code> 节点的作用：</p><ul><li> 真正存储文件 </li><li> 文件被分成文件块存储到磁盘上，文件块默认大小为 64MB，可以配置 </li><li> 为了保证数据安全，文件会被有多个副本，即备份，默认值为 3</li></ul><h2 id="问题思考"><a href="# 问题思考" class="headerlink" title="问题思考"></a>问题思考 </h2><p>1、如果从客户端上传一个文件，大小为 128MB，会有多少个文件块？</p><p> 答：根据文件块的大小，此时应该有 2 个文件块，但是由于副本的存在，总计是 6 个文件块。</p><p>2、如果从客户端上传一个文件，大小为 65MB，会有多少个文件块？</p><p>答：此时有 2 个块，一个块大小是 64MB，一个块大小是 1MB，后者占用的真实存储空间也是 1MB，并不是 64MB。副本也是同样的大小。</p><p>3、如果从客户端再上传一个大小为 24MB 的文件，那么这个文件块会与 2 中的那个 1MB 的文件块进行合并吗？</p><p>答：不会，文件块不会合并，它只是一个逻辑概念，实际占用的存储空间是以文件大小为准的。所以这个 24MB 的文件上传后是一个独立的文件块，占用存储空间大小为 24MB。</p><p>那么有读者可能会疑惑，既然是这样，那这个文件块有什么必要，它的作用是什么？请看 <code>Hadoop Community</code> 的解释说明：</p><blockquote><p>The block size is a meta attribute. If you append tothe file later, it still needs to know when to split further - so it keeps that value as a mere metadata it can use to advise itself on write boundaries.</p></blockquote><p>可见，文件块的概念是一种 <strong>元数据 </strong>信息，这种概念在很多大数据框架中都能见到，它可以在追加文件时合理地给文件分块【随着对 <code>HDFS</code> 的深入理解，后面的博客内容还会解释文件块的合理性】。</p><p>此外，使用 <code>hdfs fsck</code> 命令【也可以使用已经被废弃的 hadoop fsck】可以查看 <code>HDFS</code> 文件的详细信息。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190812003754.jpg" alt="查看文件详细信息" title="查看文件详细信息"></p><p>这里需要看两个重点内容：<code>Total size:24135B</code>、<code>Total blocks (validated):22 (avg. block size 1097B)</code>，其中，前者表示文件的总大小，总计 24135B，后者表示文件块的个数，有 22 个。但是留意一下最后还有一个备注信息 ：<code>avg. block size 1097B</code>，看起来像是文件块的大小【元数据】，其实不是，它是单个文件的平均大小【文件真实大小】，乘以 22 就等于前面的文件总大小。</p><p>关于这一点，<code>Hadoop Community</code> 也给出过解释说明：</p><blockquote><p>The fsck is showing you an “average blocksize”, not the block size metadata attribute of the file like stat shows. In this specific case, the average is just the length of your file, which is lesser than one whole block.</p></blockquote><p>此外，从上图中还可以看到文件的 <strong>备份数 </strong>、<strong> 机架数 </strong>等信息。</p><h2 id="副本存放策略"><a href="# 副本存放策略" class="headerlink" title="副本存放策略"></a>副本存放策略 </h2><p> 副本的存放策略在不同版本之间存在差异，主要是很久之前的低版本与现在的版本有差异，主要版本分界点在 <code>v0.17</code>，下面就以默认的三份副本数为例描述副本的存放策略【如果有更多的副本数，参见 <strong>其它副本 </strong>的描述】。</p><p><code>v0.17</code> 之前【不包含 v0.17】：</p><ul><li>副本一：同 <code>Client</code> 一个机架的不同 <code>DataNode</code> 节点 </li><li> 副本二：同 <code>Client</code> 一个机架的另一个 <code>DataNode</code> 节点 </li><li> 副本三：不同 <code>Client</code> 机架的另一个 <code>DataNode</code> 节点 </li><li> 其它副本：随机挑选 </li></ul><p><code>v0.17</code> 之后【包含 v0.17】：</p><ul><li> 副本一：同 <code>Client</code> 的 <code>DataNode</code> 节点 </li><li> 副本二：不同 <code>Client</code> 机架的一个 <code>DataNode</code> 节点 </li><li> 副本三：同副本二的机架中的另一个 <code>DataNode</code> 节点 </li><li> 其它副本：随机选择 </li></ul><p> 这种副本存放策略有利于数据的安全，就算有的 <code>DataNode</code> 节点出问题，也不会引起数据丢失，哪怕事故很严重【例如某个交换机损坏】，导致整个机架的 <code>DataNode</code> 节点都出问题，也不会引起数据丢失，这也是副本设置为三份的好处。</p><h2 id="机架知识"><a href="# 机架知识" class="headerlink" title="机架知识"></a>机架知识 </h2><p> 上文的 <strong>副本存放策略 </strong>中出现了一个名词：<strong> 机架 </strong>【Rack】，下面使用文字与图片简单描述一下 <strong>机架 </strong>的概念，免不了还会涉及到 <strong>主机 </strong>【服务器】、<strong> 交换机 </strong>、<strong> 机柜 </strong>的概念。</p><p>主机：物理概念，就是一台服务器，永远在运行。</p><p>机柜：物理概念，有序存放主机的一个柜子，为了合理利用空间，一个机柜中可以存放多台主机。</p><p>交换机：物理概念，连接多台主机的设备，用来给不同主机之间通信使用，一般有连接数量限制，要看交换机上面有多少个网口。</p><p>机架：逻辑概念，使用一台交换机连接的所有主机以及机柜构成了一个机架，一个机架可以包含多个机柜、多台主机。</p><p>下面给出一个简单的示意图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190812003731.png" alt="机架示意图" title="机架示意图"></p><h1 id="MapReduce- 基础知识"><a href="#MapReduce- 基础知识" class="headerlink" title="MapReduce 基础知识"></a>MapReduce 基础知识 </h1><p><code>MapReduce</code> 是基于 <code>Google</code> 的论文 <code>Simplified Data Proceessing on Large Clusters</code> 而开发实现的。</p><h2 id="基本概念"><a href="# 基本概念" class="headerlink" title="基本概念"></a> 基本概念 </h2><p><code>MapReduce</code> 是一种编程模型，具体实现后是一种并行计算框架，用于大规模数据集的并行计算，过程可以拆分为： <code>Map</code>、<code>Reduce</code>，它是分布式计算的利器，采用分而治之的思维，节约内存【速度比较慢】，并行计算，适合海量数据的处理。</p><p> 其它的计算框架都采用了类似的思想，理解了 <code>MapReduce</code> 就更容易在以后的时间学习其它的框架，例如 <strong>Spark</strong>、<strong>Hive</strong>、<strong>HBase</strong>。</p><h2 id="场景举例"><a href="# 场景举例" class="headerlink" title="场景举例"></a>场景举例 </h2><p> 例如当前有一个文本文件，每行有一个数字，求出所有数字中最大的那个，需要分别考虑文件大小为 1MB、1GB、1TB 等情况。</p><p>如果文件比较小，可以随便读取文件的内容加载到内存中，然后遍历元素，进行简单判断，保留最大的那个数字即可。但是，当文本文件非常大的时候，是不可能加载到内存中的，此时需要采用基础算法中的一种常用思想：<strong> 分而治之 </strong>，即把文本文件拆分为很小的多份文本文件，分别计算最大的数字，最后再汇总，汇总后数据量已经小了很多，最终再计算即可得出想要的结果。</p><p>可以从下图看出这种简单的思路过程，比较符合人类自然的思考过程：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190813000921.png" alt="MapReduce 示意图" title="MapReduce 示意图"></p><p>当然，这种方式必然牺牲了时间，拆分文件越多越耗时，但是却节约了空间，不用很大的内存也可以处理海量的数据，这就是 <code>MapReduce</code> 的核心思想。</p><h2 id="主从架构"><a href="# 主从架构" class="headerlink" title="主从架构"></a>主从架构 </h2><p> 和 <code>HDFS</code> 一样，<code>MapReduce</code> 也是 <strong>主从架构 </strong>，两种节点分别为 <code>JobTracker</code>、<code>TaskTracker</code>，前者称之为主节点【管理节点】，只有一个，后者称之为从节点【计算节点】，可以有多个。</p><p>下面总结一下主节点、从节点各自的作用，读者可以与 <code>HDFS</code> 中的 <code>NameNode</code>、<code>DataNode</code> 的作用对比一下。</p><p><code>JobTracker</code> 的作用：</p><ul><li>接收客户端提交的计算任务 </li><li> 把计算任务分配给 <code>TaskTracker</code> 执行 </li><li> 监控 <code>TaskTracker</code> 的执行情况 </li></ul><p><code>TaskTracker</code> 的作用：</p><ul><li> 执行 <code>JobTracker</code> 分配过来的计算任务 </li><li> 向 <code>JobTracker</code> 汇报任务的执行情况 </li></ul><p> 读者可以思考一下，这种架构是不是很像生活中的领导与员工的关系，或者更为具体一些，像是产品经理与工程师之间的关系，一个人负责接收需求、分配任务、监督执行情况，另外一群人负责具体实现，并定时汇报进度。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Hadoop 从零基础到入门系列</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HDFS</tag>
        <tag>Zookeeper</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 的踩坑经验</title>
    <url>/2019022501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>大家知道，我是使用 Hexo 来构建我的静态站点的，每次使用 Markdown 语法书写 md 文档即可。写完后在本地使用 hexo g &amp; hexo s 命令【在本地生成并且部署，默认主页是 localhost:4000】来验证一下是否构建正常。如果有问题或者对页面效果不满意就返回重新修改，如果没有问题就准备提交到 GitHub 上面的仓库里面【在某个项目的某个分支】，后续 travid-cli 监控对应的分支变化，然后自动构建，并推送到 master 分支。至此，更新的页面就发布完成了，本人需要做的就是管理书写 md 文档，然后确保没问题就提交到 GitHub 的仓库。</p><a id="more"></a><h1 id="问题清单"><a href="# 问题清单" class="headerlink" title="问题清单"></a>问题清单 </h1><p> 前言描述的很好，很理想，但是有时候总会出现一些未知的问题，而我又不了解其中的技术，所以解决起来很麻烦，大部分时候都是靠蒙的【当然，也可以直接在 Hexo 的官方项目上提出 Issue，让作者帮忙解决】。下面就记录一些遇到的问题，以及我自己找到的原因。</p><h1 id="1-Markdown- 语法不规范"><a href="#1-Markdown- 语法不规范" class="headerlink" title="1-Markdown 语法不规范"></a>1-Markdown 语法不规范 </h1><p> 这个错误有在 travis 上面出现过，在 travis 的 116 号、117 号错误：<a href="https://travis-ci.org/iplaypi/iplaypi.github.io/builds/476399853" target="_blank" rel="noopener">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/476399853</a> 。</p><p>在使用 hexo 框架的时候，一定要确保 markdown 文件里面的代码块标识【标记代码的类型，例如：java、bash、html 等】使用正确。否则使用 <strong>hexo g</strong> 生成静态网页的时候，不会报错，但是却没有成功生成 html 静态网页，虽然 html 静态文件是有的，但是却查看不了，显示一片空白。</p><p>代码块示例：</p><p>Java 格式 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7gk7162j20jn04bt8o.jpg" alt="Java 格式" title="Java 格式"></p><p>xml 格式<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7hmem4lj20de054mx2.jpg" alt="xml 格式" title="xml 格式"></p><p>bash 格式<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7hyp6j3j209o02j0si.jpg" alt="bash 格式" title="bash 格式"></p><p> 例如我把图一的 java 误写成了 bash，<strong>hexo g</strong> 的时候没有报错，但是生成的 html 静态网页却是空白一片，打开了什么也看不到。</p><p>空白页面 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7if0nmuj21hk0s5q4y.jpg" alt="空白页面" title="空白页面"></p><p> 但是如果把 java 误写成了 xml，在本地执行 <strong>hexo g</strong> 的时候不会报错，生成的 html 静态网页也是正常的。而一旦使用 travis-cli 执行自动构建的时候，构建是失败的【在 travis 的 116 号、117 号错误：<a href="https://travis-ci.org/iplaypi/iplaypi.github.io/builds/476399853" target="_blank" rel="noopener">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/476399853</a> 】，并且可以看到错误信息，图四，但是我看不懂错误原因，只能猜测找到问题所在，比较耗时。</p><p>travis-cli 报错日志【我看不懂】：<br>travis-cli 日志 1<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7iqv9msj20th0ld0to.jpg" alt="travis-cli 日志 1" title="travis-cli 日志 1"></p><p>travis-cli 日志 2<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7jt59f2j20rh0nvjur.jpg" alt="travis-cli 日志 2" title="travis-cli 日志 2"></p><p>travis-cli 日志 3<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7jokkp6j20rh0p4dj2.jpg" alt="travis-cli 日志 3" title="travis-cli 日志 3"></p><p>此外，写 Markdown 文档，使用代码块标记的时候，使用 3 个反单引号来标记，如果不熟悉代码块里面的编程语言，可以省略类型，例如 java、bash、javascript，不要填写，否则填错了生成的 html 静态文件是空白的。还有就是如果代码块里面放的是一段英文文本，和编程语言无关，也不要填写类型，否则生成的 html 静态文件也是空白的。</p><h1 id="2-Hexo- 报错奇怪"><a href="#2-Hexo- 报错奇怪" class="headerlink" title="2-Hexo 报错奇怪"></a>2-Hexo 报错奇怪 </h1><p> 这个错误还没有到 travis 上面，所以 travis 上面没有记录；</p><p>在本地测试过程中，无论是 <strong>hexo s</strong> 还是 <strong>hexo g</strong> 都会报错，错误信息如图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7kb9p5zj20jt02k3yk.jpg" alt="报错信息" title="报错信息"></p><p>看着这个信息，很像在当前项目的目录中找不到 hexo 命令，和 java 类似，我就怀疑是不是安装的 hexo 被什么时候卸载了，其实不是的，在其它项目中还能用。后来我发现是当前项目使用的模块缺失，为什么会缺失我也不知道，由于这些缺失的模块是通过 hexo 引入的，所以直接报错：hexo not found，给人以误导。</p><p>总的来说，就是报错有误导性，没有报模块缺失，而我又不懂这些，查了一些资料，手动测试了一些方法，总算找到原因所在。找到原因，那解决办法很简单了，直接安装缺失的模块即可，使用 <strong>nmp install</strong> 命令安装 package.json 里面的模块。</p><h1 id="3-Hexo- 配置错误引起的误导性"><a href="#3-Hexo- 配置错误引起的误导性" class="headerlink" title="3-Hexo 配置错误引起的误导性"></a>3-Hexo 配置错误引起的误导性 </h1><p> 这个错误还没有到 travis 上面，所以 travis 上面没有记录；</p><p>这个错误和上面的类似，但是如果从报错信息上面看，也具有误导性。在更改了 _config.yml 配置文件后，按照正常步骤去生成、部署的时候【使用 <strong>hexo g &amp; hexo s</strong> 命令，直接报错了，把我整蒙了，报错信息如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7kzx1vij20k50iqq4q.jpg" alt="报错信息" title="报错信息"></p><p>关键配置部分如下，后续找到问题确实出在这里：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7les4wdj20lu08wt9j.jpg" alt="关键配置部分" title="关键配置部分"></p><p>从图中看信息，我也看不到什么原因，因为确实不懂。注意，我为了测试，发现 <strong>hexo g</strong> 是没有问题的，也就是生成没问题，那问题就出在部署步骤了，它会不认这个 <strong>hexo s</strong> 命令？我查了资料，发现大部分人都说缺失 hexo server 模块，我通过检查可以确保本机有这个模块，而且卸载了重新装，所以不是这个问题。</p><p>最后发现是配置信息里面的参数【官方定义的关键词】错误了，里面的 <strong>Plugins</strong> 这个参数应该使用首字母大写，这谁能想到，正确的配置参数如下图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0j7lre005j20nb08udgb.jpg" alt="plugins 改为首字母大写" title="plugins 改为首字母大写"></p><h1 id="4-travis- 配置问题"><a href="#4-travis- 配置问题" class="headerlink" title="4-travis 配置问题"></a>4-travis 配置问题 </h1><p> 这个错误有在 travis 上面出现过，在 travis 的 27 号：<a href="https://travis-ci.org/iplaypi/iplaypi.github.io/builds/448152737" target="_blank" rel="noopener">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/448152737</a> 。</p><p>在使用 travis 自动构建时，有一次突发奇想，想使用最新版本的 node_js，于是在 travis.yml 配置文件中，把 node_js 设为了 stable，即稳定版本，这样在构建的时候会使用最新稳定版本的 node_js，没想到就出问题了。</p><p>node_js 的配置如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0k90kw0e8j20oy0dujsd.jpg" alt="node_js 的配置" title="node_js 的配置"></p><p>travis 报错日志如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0k91bjlrxj20rq0qxq4q.jpg" alt="travis 报错日志" title="travis 报错日志"></p><p>重要部分：<br></p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">error nunjucks@<span class="number">3.1</span><span class="number">.3</span>: The engine <span class="string">"node"</span> is incompatible <span class="keyword">with</span> <span class="keyword">this</span> <span class="built_in">module</span>. Expected version <span class="string">"&gt;= 6.9.0 &lt;= 11.0.0-0"</span>. Got <span class="string">"11.0.0"</span></span><br><span class="line">error Found incompatible <span class="built_in">module</span></span><br></pre></td></tr></table></figure><p></p><p>看来还是在搞清楚新旧版本之间的差异后再想着升级版本，不要随意来，要不然浪费的是自己的时间。后来解决办法就是手动指定 node_js 的版本。</p><h1 id="5- 无缘无故出现的问题"><a href="#5- 无缘无故出现的问题" class="headerlink" title="5 - 无缘无故出现的问题"></a>5 - 无缘无故出现的问题 </h1><p> 这个错误有在 travis 上面出现过，在 travis 的 133 号、134 号错误、135 号错误、136 号错误，举例：<a href="https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498318318" target="_blank" rel="noopener">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498318318</a> ；</p><p>日志部分截图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0k91nhkhkj20rk0l6761.jpg" alt="日志内容" title="日志内容"></p><p>这错误信息里面对我来说确实看不到有效的内容，还没找到解决办法，看似是文件路径不存在，但是项目配置也没变过。</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm ERR! path /home/travis/.nvm/versions/node/v10<span class="number">.10</span><span class="number">.0</span>/lib/node_modules/hexo-cli/node_modules/highlight.js/tools/build.js</span><br><span class="line">npm ERR! code ENOENT</span><br><span class="line">npm ERR! errno <span class="number">-2</span></span><br><span class="line">npm ERR! syscall chmod</span><br><span class="line">npm ERR! enoent ENOENT: no such file or directory, chmod <span class="string">'/home/travis/.nvm/versions/node/v10.10.0/lib/node_modules/hexo-cli/node_modules/highlight.js/tools/build.js'</span></span><br><span class="line">npm ERR! enoent This is related to npm not being able to find a file.</span><br><span class="line">npm ERR! enoent </span><br><span class="line">npm ERR! A complete log <span class="keyword">of</span> <span class="keyword">this</span> run can be found <span class="keyword">in</span>:</span><br><span class="line">npm ERR!     <span class="regexp">/home/</span>travis/.npm/_logs/<span class="number">2019</span><span class="number">-02</span><span class="number">-25</span>T18_45_08_713Z-debug.log</span><br></pre></td></tr></table></figure><p>等待找问题的原因。</p><p>好，仔细看了日志、找了博客文档，没有解决方法，我也不懂，看到可能是版本原因【我不能升级 nodejs 版本，与 yarn 有关】，可能是权限问题。我用 sudo npm install -g hexo-cli 试了试，明显不行：<a href="https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498794142" target="_blank" rel="noopener">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498794142</a> ，然后我就放弃了，直接改回来提交了，没想到无缘无故就可以了，构建日志：<a href="https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498796865" target="_blank" rel="noopener">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498796865</a> 。</p><p>准备发邮件问问 travis 客服，我现在单方面怀疑是 travis 的环境问题或者构建脚本所依赖的环境问题。由于时差问题，先记录几个时区的缩写，方便查看邮件内容的时候核对时间：UTC【世界标准时间】、EST【东部标准时间，UTC-5】、CET【欧洲中部时间，UTC+1】。</p><p>我发送的邮件内容如下【发送于北京时间 2019-02-28 14:42:00】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0s7r7q8rsj230g1rswyo.jpg" alt="我发送的邮件内容" title="我发送的邮件内容"></p><p>完整文字版供参考 <br></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Automatic building is failed</span><br><span class="line"></span><br><span class="line">Hello,</span><br><span class="line">I hava a repository in GitHub,and i use travis-ci to build it automatically.</span><br><span class="line">I configured the correct script,and it has been built successfully more than one hundred times.</span><br><span class="line">My script is :</span><br><span class="line">https://github.com/iplaypi/iplaypi.github.io/blob/source/.travis.yml ;</span><br><span class="line"></span><br><span class="line">But it built failed at 2019-02-26,the all log as follows (i retry it three times,but still failed):</span><br><span class="line">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498267014</span><br><span class="line">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498278045</span><br><span class="line">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498297576</span><br><span class="line">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498318318</span><br><span class="line"></span><br><span class="line">I cannot find any usefuI information in my log.I am very sad and helpless.</span><br><span class="line">But i retry it at 2019-02-27,it actually build successfully,amazing.</span><br><span class="line">I swear I have not changed any files,the successful log is:</span><br><span class="line">https://travis-ci.org/iplaypi/iplaypi.github.io/builds/498796865 ;</span><br><span class="line">So i am puzzled,i donnot know why,i suspect it is a problem with the machine.</span><br><span class="line">Can you help me?</span><br><span class="line">Best wishes.</span><br></pre></td></tr></table></figure><p></p><p> 发送后对方自动有一个回复，告知我他们的工作时间【中国北京时间与对方时差 + 13】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0s7rpd5kbj219x0lq401.jpg" alt="对方自动回复" title="对方自动回复"></p><p>等了好几天，对方终于回复了【回复于北京时间 2019-03-04 11:00:00】，对方回复内容如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0s7s5bo3uj219x0lswfv.jpg" alt="对方回复" title="对方回复"></p><p>对方回复重要文字内容 <br></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Hey there,</span><br><span class="line"></span><br><span class="line">Thanks for reaching out and I&apos;m sorry for these spurious failures you have experienced.</span><br><span class="line"></span><br><span class="line">I think it could be an issue with the package itself or the NPM registry on that specific day. I&apos;ve looked at NPM&apos;s status and their was an incident on Feb. 27th. See https://status.npmjs.org/incidents/ptnlj2rtwfwm. Maybe it was already happening on Feb. 26th? Sorry for not having a better explanation.</span><br><span class="line"></span><br><span class="line">Please let us know if this issue resurfaces again, we would be happy to have another look.</span><br><span class="line"></span><br><span class="line">Thanks in advance and happy building!</span><br></pre></td></tr></table></figure><p></p><p> 看起来技术支持也没发现是啥问题，只是说有可能是 NPM 的问题，还给了一个链接：<a href="https://status.npmjs.org/incidents/ptnlj2rtwfwm" target="_blank" rel="noopener">https://status.npmjs.org/incidents/ptnlj2rtwfwm</a>，根据链接可以看到 NPM 的状态在某个时间点出问题了【时间点为 2019-02-27 15:46:00 UTC，也就是北京时间 2019-02-27 23:46:00】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0s7sku7hvj20p00k0gmb.jpg" alt="nmp 问题" title="nmp 问题"></p><p>但是我那个自动构建的问题是出在北京时间 2019-02-26 凌晨的，时间点也对不上，所以技术支持只是怀疑，也没有结论，那我也就不管了，继续观察以后有没有相同的问题出现。</p><h1 id="6- 排版问题"><a href="#6- 排版问题" class="headerlink" title="6 - 排版问题"></a>6 - 排版问题 </h1><p>1、在 Markdown 文件中关于链接的，要使用 []、() 这 2 个完整的标记，不要直接放一个链接出来，会导致生成的 html 文件带链接的内容居中对齐，导致文字分散开来，不好看。</p><p>2、中文括号不要使用，也会导致居中对齐的问题，文字排版不好看，使用方括号吧：【内容示例】。</p><h1 id="7- 草稿问题"><a href="#7- 草稿问题" class="headerlink" title="7 - 草稿问题"></a>7 - 草稿问题</h1><p> 我在使用 Hexo 的草稿功能时，发现一个问题，操作完成发布时，发现 Markdown 文档的头部描述信息变化了。例如我本来设置的 id 又变回了日期【可以理解，因为模板就是这样设置的】，然后 tags 的中括号中的标签变为了无需列表【不可理解】。暂时还没发现内容的变化，可能是内容中没有特殊符号。</p><p>导致的问题就是草稿发布后【内容已经变化了】，提交到 source 分支，自动构建时，提交到主分支 master 后，这些文章的链接变为了日期的乱格式【因为是基于错误的 Markdown 文件构建的】。所以以后还是不要使用草稿功能了，没有必要，还麻烦，没写完也可以发布嘛，没啥大问题。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tkfnu178j20w50gj0tq.jpg" alt="文章链接是错误的" title="文章链接是错误的"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>markdown</tag>
        <tag>java</tag>
        <tag>bash</tag>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA 热部署配置方法总结</title>
    <url>/2016120801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>前不久临时在搞一个 Java Web 项目，需要做一点点修改，由于对原有的代码不熟悉，所以附带需要大量的测试，搞清楚程序执行的流程。在一开始的操作过程中，我就是不断修改代码，然后关闭 Tomcat 服务器，再重启，操作了几次我就不想这么干了，太浪费时间了。大量的时间都用在了关闭重启服务上面，在最新更改的代码没有加载完成前，只能干等着，后面我就发现了有 <strong>热部署 </strong>这个技巧，可以节省大量的时间。本文就记录在 IDEA 中热部署的配置方式，操作系统环境基于 Windows7 X64，Web 容器基于 Tomcat 6.x。</p><a id="more"></a><h1 id="大背景"><a href="# 大背景" class="headerlink" title="大背景"></a>大背景 </h1><p> 在 Web 开发中，如果需要调试最新更新的代码，最先想到的思路就是重新启动 Web 容器，以加载最新的资源文件。但是显然，这种做法是很浪费时间的，而且当 Web 项目整体比较大的时候，重启一次需要很长的时间，更加凸显了这种做法的低效。</p><p>回头思考一下，有时候只是更改了某个方法的几行代码，却要重启整个服务，这动作太大了，肯定有更加方便快捷的方式来做这件事，例如 <strong>热部署 </strong>。</p><p>还有，有时候更新的不一定是 Java 类文件【或者其它编程语言的后台资源文件】，而是 HTML 静态文件、JavaScript 静态文件、项目配置文件【例如 Spring 的配置文件、日志配置文件】等，这时候是不是一定要重启 Web 服务呢，能不能也做到热部署，其实是可以的。</p><h1 id="热部署配置"><a href="# 热部署配置" class="headerlink" title="热部署配置"></a>热部署配置 </h1><h2 id="热部署基础配置"><a href="# 热部署基础配置" class="headerlink" title="热部署基础配置"></a> 热部署基础配置 </h2><p> 如果还没有为 Web 项目配置好 Tomcat 服务器，可以在 <code>Run</code> -&gt; <code>Edit Configurations</code> 中先把 Web 服务器的基本信息【例如本地服务器安装目录、默认浏览器、服务端口、JRE 环境】配置好。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609025955.png" alt="先配置 Tomcat 服务器" title="先配置 Tomcat 服务器"></p><p>具体配置可以参考下图：名字、本地安装的服务器、启动的浏览器、本地 JRE 环境、HTTP 服务端口。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609025912.png" alt="Tomcat 服务器具体配置信息" title="Tomcat 服务器具体配置信息"></p><p>配置完成 Tomcat 服务器的基本信息，再接着配置部署优化信息，如图打开 Tomcat 的 <code>Edit Configurations</code>。如果刚刚执行完前面的 Tomcat 基础信息配置，可以不用关闭窗口，直接可以进入下一步骤进行配置，如果已经使用过 Tomcat 服务器，可以按照如图快捷方式打开配置窗口。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030044.png" alt="打开 Tomcat 部署窗口" title="打开 Tomcat 部署窗口"></p><p>打开 <code>Deployment</code> 选项卡，默认在启动项【startup】里面是没有任何东西的【面板中部也提示 <code>Nothing to deploy</code>】，需要手动添加，也就是为 Tomcat 服务器添加一个应用，这样在 Tomcat 启动时就会加载这个应用，也可以说是把这个应用部署到 Tomcat 服务器上面。点击右侧的绿色小加号，选择 <code>Artifact</code>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030125.png" alt="Deployment 选项卡配置应用" title="Deployment 选项卡配置应用"></p><p>接着选择部署应用的类型，建议选择 <code>exploded</code> 的类型，不需要单纯的 <code>war</code> 包类型，这个相当于更改 Tomcat 的 <code>CATALINA_HOME</code>，效率比较高一点，选择后点击 <code>ok</code> 确认即可。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030158.png" alt="添加 exploded 类型的应用" title="添加 exploded 类型的应用"></p><p>配置完成 <code>Deployment</code> 信息后，如果有默认的 <code>Make</code> 操作记得删除【在 <code>Deployment</code> 选项卡的底部，有一个 <code>Before launch</code> 清单】，可以提高效率，只保留项目的 <code>exploded</code> 类型即可，选中后使用红色的减号来删除。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030231.png" alt="删除 Make 提升效率" title="删除 Make 提升效率"></p><p>接着返回 <code>Server</code> 选项卡，可以看到有两项重要的配置：<code>On &#39;Update&#39; action</code>、<code>On frame deactivation</code>，如果在前面的 <code>Deployment</code> 选项卡中没有配置 <code>exploded</code> 类型的 war 包的话，这里是不会有 <code>On frame deactivation</code> 这个配置项的。接着把这两个重要的配置选项都设置为 <code>Update classes and resources</code>，否则类修改热部署不会生效，或者第三方模版框架例如 Freemarker 的热部署也不会生效。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030252.png" alt="Server 选项卡配置" title="Server 选项卡配置"></p><p>配置完成了以上信息，在 Debug 模式下，IDEA 失去焦点时【场景：开启 Debug 模式，更改完代码去浏览器操作测试】，则会自动加载更新从而达到热部署的效果。不难发现，这个过程还是有点缓慢，原因是什么呢，因为前面的配置效果都是基于 JVM 提供的热加载来实现的，仅支持方法块内代码的修改，并且只有 Debug 模式下，同时是在 IDEA 失去焦点时【<code>On frame deactivation</code> 配置产生的效果】才会触发热加载，相对来说整个流程的速度仍旧略显缓慢。</p><p>那么，怎么优化这个流程呢，继续往下面看。</p><h2 id="热部署进阶配置"><a href="# 热部署进阶配置" class="headerlink" title="热部署进阶配置"></a>热部署进阶配置 </h2><p> 前面提到的热部署速度仍旧缓慢，必须在 Debug 模式下并且焦点离开 IDEA 时才会触发热加载，是因为还没有开启 IDEA 的自动编译功能。</p><p>众所周知，在 Eclipse 中是默认开启自动编译的特性的，也就说你只要更改了项目的文件，点击保存，Eclipse 就会立即执行编译操作，把文件编译一遍，虽然优点消耗资源，但是能在开发人员无感的情况下保证所有的执行文件都是最新的，避免诡异的问题出现。</p><p>但是在 IDEA 中，自动编译这个特性默认是关闭的，也就是说如果你更改了文件，但是没有及时编译，等到运行时使用的仍旧是上次的可执行文件，这就会导致一些诡异的现象发生。例如刚刚改了代码然后运行，发现运行的代码逻辑和更改的不一致，这就是因为虽然原文件被改了【肉眼可以看到改变】，但是可执行文件仍旧是旧的【运行程序观察到的现象是没变】。举个具体的例子就是在 IDEA 中写 Maven 项目，尽管在每次 Run 的时候 IDEA 都会重新编译 Java 类文件，保证运行的 class 文件都是最新的，但是有时候不知道怎么回事运行的 class 文件并不是最新的，我一直认为这是 IDEA 的 bug，另一方面，如果变更的是 xml 配置文件，IDEA 也会漏掉，因此，此时运行前最好先执行一下 <code>mvn clean</code> 来清空一下项目的编译结果。</p><p>下面开始进入正题，记录开启 IDEA 自动编译的方法。</p><p>首先设置自动构建【包含编译】，在 <strong>Settings</strong> -&gt; <strong>Build，Execution，Deployment</strong> -&gt; <strong>Compiler</strong> 中，勾选 <code>Build project automatically</code>，这个配置项表示自动构建项目，但是仅在项目没有运行或者 Debug 的状态下才会有效。那这样肯定不行，因为热部署就是表示项目一直在运行中，热加载更改代码后自动编译的文件，这个设置在运行状态下不会自动编译，别急，还有下一个步骤的设置。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030350.png" alt="设置自动构建" title="设置自动构建"></p><p>设置允许运行中的程序自动编译，先使用 <code>Ctrl + Shift + a</code> 调出搜索 Action 的对话框【这个快捷方式是基于 Windows 平台的 Eclipse 快捷方式，也可以在主界面根据 <strong>Help</strong> -&gt; <strong>Find Action</strong> 进入】，在里面搜索 <strong>Registry</strong>，选择结果中的 <strong>Registry…</strong>，接着就会进入详细设置页面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030409.png" alt="在 Action 搜索对话框中搜索 Registry" title="在 Action 搜索对话框中搜索 Registry"></p><p>在详细设置页面继续搜索 <strong>compiler.automake.allow.when.app.running</strong>，直接输入即可，不需要搜索框，或者输入关键词 <strong>app.running</strong>，会在左上角显示搜索内容：<code>Search for: app.running</code>，下面也会实时展示搜索结果。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030445.png" alt="搜索 app.running" title="搜索 app.running"></p><p>看到我想要的结果了，直接勾选 <code>compiler.automake.allow.when.app.running</code>，这就表示允许在程序运行时自动编译，但是还要留意一点，看到最上面的红色字体的提示：<code>Changing these values may cause unwanted behavior of IntelliJ IDEA.Please do not change these unless you have been asked</code>，其实就是在警告你不要随意更改这里面的配置，可能会对 IDEA 造成影响，除非你完全了解你更改的内容。关于这个选项的含义，可以直接看最下面的 <code>Description</code> 里面的描述：<code>Allow auto-make to start even if developed application is currently running. Note that automatically started make may eventually delete some classes that are required by the application.</code>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030509.png" alt="勾选需要的选项" title="勾选需要的选项"></p><h2 id="配置效果总结"><a href="# 配置效果总结" class="headerlink" title="配置效果总结"></a>配置效果总结 </h2><p> 如此一来，每当我的 Web 项目里面的 Java 文件、JavaScript 文件等资源更新时【例如更改了代码，重新配置了参数等】，Tomcat 服务会重新载入这些原始文件对应的编译文件，从而达到热部署的效果，这样我就可以不用在每次更改了一点东西，想测试一下效果，还需要关闭重启，浪费时间。</p><p>Tomcat 热部署时重新载入资源给出的提示信息 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030529.png" alt="Tomcat 热部署给出的提示信息" title="Tomcat 热部署给出的提示信息"></p><p> 还要注意一点，在 Debug 时，为了验证刚刚更改的代码有没有被热加载，可以添加一个断点，看看断点的状态有没有生效，即在红色的断点标记处有一个对勾标识【√】，如果没有对勾也没有叉【×】，而是一个单独的红圆圈，说明更改的代码没有生效。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190609030537.png" alt="断点标记查看" title="断点标记查看"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>1、如果需要方便地调试 JavaScript 代码【需要在 <code>Server</code> 配置中勾选 <code>with JavaScript debugger</code>】，还可以借助 IDEA 的官方浏览器插件：<a href="https://chrome.google.com/webstore/detail/jetbrains-ide-support/hmhgeddbohgjknpmjagkdomcpobmllji" target="_blank" rel="noopener">JetBrains IDE Support</a> ，可以很方便地对静态资源进行调试。</p><p>2、另外关于热部署还有一款超级好用的工具：<a href="https://jrebel.com" target="_blank" rel="noopener">JRebel</a> ，可以使用 Tomcat 参数配置的方式或者 IDEA 插件的方式，这款工具不是免费的，可以免费试用一段时间，请大家支持正版。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>Tomcat</tag>
        <tag>deploy</tag>
        <tag>JRebel</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 中数值精度损失导致的 bug 现象</title>
    <url>/2016092001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在 <code>Java</code> 中隐藏着一个看似是 <code>bug</code> 的冷门现象：在一些数值计算中得不到你想象的结果，会多很多位小数点后面的数字。其实，这是浮点型数字的精度损失问题，本文简单做一个现象记录，以供读者参考。</p><a id="more"></a><p>在此说明，以下内容中涉及的代码已经被我上传至 <code>Github</code>：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/main/java/org/playpi/study/javabug" target="_blank" rel="noopener">LossPrecision</a> ，读者可以提前下载查看。</p><h1 id="现象演示记录"><a href="# 现象演示记录" class="headerlink" title="现象演示记录"></a>现象演示记录 </h1><p> 假如读者按照下面的代码运行，猜猜看是什么结果。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void lossPrecisionTest () &#123;</span><br><span class="line">	// 结果不等于 0.06</span><br><span class="line">	log.info (&quot;====sum:[&#123;&#125;]&quot;, 0.05 + 0.01);</span><br><span class="line">	// 结果不等于 0.58</span><br><span class="line">	log.info (&quot;====sum:[&#123;&#125;]&quot;, 1 - 0.42);</span><br><span class="line">	// 结果不等于 401.5</span><br><span class="line">	log.info (&quot;====sum:[&#123;&#125;]&quot;, 4.015 * 100);</span><br><span class="line">	// 结果不等于 1.233</span><br><span class="line">	log.info (&quot;====sum:[&#123;&#125;]&quot;, 123.3 / 100);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请读者看到结果不要惊讶，是的，你没有看错，运行结果真的不是你想象的那样，总会多一点或者少一点。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-24_00:38:55 [main] INFO javabug.LossPrecision:15: ====sum:[0.060000000000000005]</span><br><span class="line">2020-01-24_00:38:55 [main] INFO javabug.LossPrecision:17: ====sum:[0.5800000000000001]</span><br><span class="line">2020-01-24_00:38:55 [main] INFO javabug.LossPrecision:19: ====sum:[401.49999999999994]</span><br><span class="line">2020-01-24_00:38:55 [main] INFO javabug.LossPrecision:21: ====sum:[1.2329999999999999]</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200124004608.png" alt="精度损失代码示例" title="精度损失代码示例"></p><p>在 <code>Java</code> 中的简单浮点数类型 <code>float</code> 和 <code>double</code>，有时候不能够进行运算，其实不光是在 <code>Java</code> 中，在其它很多编程语言中也有这样的问题【本质在于硬件寄存器存储二进制数字会有精度损失】。尽管在大多数的情况下，计算的结果是准确的，但是有时候会出现意想不到的精度损失问题，读者也需要注意。</p><p>那么如何解决这个问题呢？【下面示例都以 4.015 这个数字演示】</p><h2 id="简单四舍五入"><a href="# 简单四舍五入" class="headerlink" title="简单四舍五入"></a>简单四舍五入 </h2><p> 我的第一个反应是做四舍五入【通过四舍五入把多余的数字尾巴清除掉，保留正确的数值】，<code>Math</code> 类中的 <code>round</code> 方法不能设置保留几位小数，只能像这样保留两位小数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 1-Math 四舍五入 </span><br><span class="line">double val = 4.015;</span><br><span class="line">log.info (&quot;====sum:[&#123;&#125;]&quot;, Math.round (val * 100) / 100.0);</span><br></pre></td></tr></table></figure><p>非常不幸，上面的代码并不能正常工作，得到的结果是错误的，给这个方法传入 4.015 它将返回 4.01 而不是 4.02，如我们在上面看到的：<code>4.015 * 100 = 401.49999999999994</code>。</p><p>得到结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-24_01:04:13 [main] INFO javabug.LossPrecision:25: ====round:[4.01]</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200124010553.png" alt="简单四舍五入" title="简单四舍五入"></p><p>它只能保留 2 位小数，而且得到的结果还是错误的。</p><p>因此，如果我们需要做到精确的四舍五入，不能利用简单类型做任何运算，要想想其它方法。</p><h2 id="数值格式化"><a href="# 数值格式化" class="headerlink" title="数值格式化"></a>数值格式化 </h2><p> 那么这种问题还有没有其它办法呢？当然有，可以使用 <code>DecimalFormat</code> 格式化，代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 2-DecimalFormat 格式化，四舍五入，保留 2 位小数 </span><br><span class="line">DecimalFormat decimalFormat = new DecimalFormat (&quot;0.00&quot;);</span><br><span class="line">decimalFormat.setRoundingMode (RoundingMode.HALF_UP);</span><br><span class="line">log.info (&quot;====format:[&#123;&#125;]&quot;, decimalFormat.format (val));</span><br></pre></td></tr></table></figure><p>运行后读者又发现，并没有得到想象的结果，仍旧是错误的，因为计算过程还是涉及到数值的精度损失问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-24_02:12:56 [main] INFO javabug.LossPrecision:33: ====format:[4.01]</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200124021515.png" alt="数值格式化结果" title="数值格式化结果"></p><p>此时想必一些读者已经陷入了懵圈。</p><h2 id="大数值计算"><a href="# 大数值计算" class="headerlink" title="大数值计算"></a>大数值计算 </h2><p> 那么这种问题有没有其它办法可以彻底解决问题呢？当然有，可以使用 <code>BigDecimal</code> 计算。</p><p>其实，<code>float</code> 和 <code>double</code> 只能用来做 <strong>科学计算 </strong>或者是 <strong>工程计算 </strong>【允许损失一定的数值精度】，而在 <strong>商业计算 </strong>中我们要用 <code>BigDecimal</code>【不允许损失数值精度】，精度是可以保证的。</p><p>但是要注意，<code>BigDecimal</code> 有 2 种构造方法，一个是：<code>BigDecimal (double val)</code>，另外一个是：<code>BigDecimal (String val)</code>，请确保使用 <code>String</code> 来构造，否则在计算时还是会出现精度丢失问题，这算是 <code>BigDecimal</code> 的一个坑，很多人应该也遇到过。</p><p>代码示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 3-BigDecimal, 四舍五入，保留 2 位小数 </span><br><span class="line">BigDecimal bigDecimal1 = new BigDecimal (double.toString (val));</span><br><span class="line">BigDecimal bigDecimal2 = new BigDecimal (double.toString (1D));</span><br><span class="line">log.info (&quot;====multiply:[&#123;&#125;]&quot;, bigDecimal1.multiply (bigDecimal2).setScale (2, BigDecimal.ROUND_HALF_UP));</span><br><span class="line">// 如果直接使用 double 构造，得到的结果仍旧是错误的 </span><br><span class="line">BigDecimal bigDecimal3 = new BigDecimal (val);</span><br><span class="line">BigDecimal bigDecimal4 = new BigDecimal (1D);</span><br><span class="line">log.info (&quot;====multiply:[&#123;&#125;]&quot;, bigDecimal3.multiply (bigDecimal4).setScale (2, BigDecimal.ROUND_HALF_UP));</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-01-24_02:12:56 [main] INFO javabug.LossPrecision:37: ====multiply:[4.02]</span><br><span class="line">2020-01-24_02:12:56 [main] INFO javabug.LossPrecision:41: ====multiply:[4.01]</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200124021359.png" alt="大数值计算结果" title="大数值计算结果"></p><p>可以看到，使用 <code>String</code> 构造 <code>BigDecimal</code> 对象可以准确计算结果，而使用 <code>double</code> 构造 <code>BigDecimal</code> 对象还是会损失精度。</p><h2 id="工具类"><a href="# 工具类" class="headerlink" title="工具类"></a>工具类 </h2><p> 现在已经可以解决这个问题了，原则上是使用 <code>BigDecimal</code> 并且一定要用 <code>String</code> 来够造对象。</p><p>但是想像一下，如果我们要做一个加法运算，需要先将两个浮点数转为 <code>String</code> 类型，然后再构造成 <code>BigDecimal</code> 对象，在其中一个对象上调用 <code>add</code> 方法，传入另一个 <code>BigDecimal</code> 对象作为参数。然后把运算的结果，也是一个 <code>BigDecimal</code> 对象，再转换为浮点数。</p><p>我们能够忍受这么烦琐的过程吗？肯定不能，所以我在此提供一个工具类 <code>BigDecimalUtil</code> 来简化操作，它提供以下静态方法【参考下面的方法声明】，包括加减乘除和四舍五入，调用时可以传参从而灵活设置结果的精度和取舍的模式【四舍五入、去尾、进位等等】。</p><p>代码已经被我上传至 <code>Github</code>：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-common-core/src/main/java/org/playpi/study/util" target="_blank" rel="noopener">BigDecimalUtil</a> ，在这里就只贴出方法声明【类注释中可以看到】，读者可以自行下载使用。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 大数值计算工具类 </span><br><span class="line"> *</span><br><span class="line"> * @see #add (double, double, int, int)</span><br><span class="line"> * @see #subtract (double, double, int, int)</span><br><span class="line"> * @see #multiply (double, double, int, int)</span><br><span class="line"> * @see #div (double, double)</span><br><span class="line"> * @see #div (double, double)</span><br><span class="line"> * @see #round (double, int, int)</span><br><span class="line"> */</span><br></pre></td></tr></table></figure><p>试运行结果如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200124162810.png" alt="大数值计算工具类试运行结果" title="大数值计算工具类试运行结果"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><h2 id="小问题"><a href="# 小问题" class="headerlink" title="小问题"></a> 小问题 </h2><p> 以下记录一个常见的判断差值为 0 的小问题。</p><p>如果在项目中碰到了如下的业务逻辑计算：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">double val1 = 61.5;</span><br><span class="line">double val2 = 60.4;</span><br><span class="line">double dif = 1.1;</span><br><span class="line">// 判断差值结果为 0 的问题 </span><br><span class="line">if (Math.abs (val1 - val2 - dif) == 0) &#123;</span><br><span class="line">	log.info (&quot;==== 差值结果为 0&quot;);</span><br><span class="line">	//do things</span><br><span class="line">&#125; else &#123;</span><br><span class="line">	log.info (&quot;==== 差值结果不为 0&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果发现这一组数据：<code>61.5、60.4、1.1</code> 无法达到正确的预期结果，即结果不为 0，有些人可能想破了脑袋也无法发现问题所在【千万不要试图拿计算器计算的结果对比，因为这是精度损失的问题】。</p><p>如果是有经验的开发人员一眼就可以发现问题所在，也知道应该采用如下的方式修改代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 加上允许精度损失的判断逻辑 </span><br><span class="line">double exp = 10E-10;</span><br><span class="line">if (Math.abs (val1 - val2 - dif) &gt; -1 * exp &amp;&amp; Math.abs (val1 - val2 - dif) &lt; exp) &#123;</span><br><span class="line">	log.info (&quot;==== 差值结果为 0&quot;);</span><br><span class="line">	//do things</span><br><span class="line">&#125; else &#123;</span><br><span class="line">	log.info (&quot;==== 差值结果不为 0&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样的话，运行结果就会与期望一致了【同样的数值，只是更改了判断逻辑：允许精度损失】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2016/20200124022757.png" alt="差值为 0 的问题演示" title="差值为 0 的问题演示"></p><h2 id="引申问题"><a href="# 引申问题" class="headerlink" title="引申问题"></a>引申问题 </h2><p> 除了精度损失的问题，还有一种 <code>byte</code> 类型自动转换的坑【当然，编译器有可能自动识别了问题代码，无法通过编译】。</p><p>有数值或者变量参与的加法运算，结果会转为 <code>int</code> 类型，再赋值给 <code>byte</code> 类型的变量无法通过编译，问题代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 类型自动转换问题 </span><br><span class="line">int num1 = 5;</span><br><span class="line">//1 - 类型无法强转，编译无法通过 </span><br><span class="line">//        byte num2 = num1;</span><br><span class="line">byte num3 = 5;</span><br><span class="line">byte num4 = 127;</span><br><span class="line">//2 - 溢出，编译无法通过 </span><br><span class="line">//        byte num5 = 128;</span><br><span class="line">byte num6 = 12;</span><br><span class="line">//3 - 类型无法强转，编译无法通过 (有数值参与加法运算，结果会转为 int 类型)</span><br><span class="line">//        num6 = num6 + 1;</span><br><span class="line">num6 += 1;</span><br><span class="line">num6++;</span><br><span class="line">// 类型自动转换问题 </span><br><span class="line">int i = 7;</span><br><span class="line">byte b = 5;</span><br><span class="line">// 1 - 类型无法强转，编译无法通过 (有数值参与加法运算，结果会转为 int 类型)</span><br><span class="line">//        b = b + b;</span><br><span class="line">b += b;</span><br><span class="line">// 2 - 类型无法强转，编译无法通过 (有数值参与加法运算，结果会转为 int 类型)</span><br><span class="line">//        b = b + 7;</span><br><span class="line">// 3 - 类型无法强转，编译无法通过 (有数值参与加法运算，结果会转为 int 类型)</span><br><span class="line">//        b = b + i;</span><br><span class="line">b += i;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx 配置 SSL 证书实现 HTTPS 访问</title>
    <url>/2019030501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>由于 GitHub Pages 把百度爬虫屏蔽了，导致百度爬虫爬取不到我的个人主页，所以被百度收录的内容很少，能收录的基本都是我手动提交的。后来我的解决办法就是自己搭建了一台 Web 服务器，然后在 DNSPod 中把百度爬虫的访问流量引到我的 Web 服务器上面，服务器主机是我自己购买的 VPS，服务器应用我选择的是强大的 Nginx。本文就记录 Web 服务器搭建以及配置 SSL 证书这个过程。</p><a id="more"></a><h1 id="安装 -Nginx"><a href="# 安装 -Nginx" class="headerlink" title="安装 Nginx"></a>安装 Nginx</h1><p>Nginx 官方网站：<a href="https://www.nginx.com/resources/wiki/start/topics/tutorials/install" target="_blank" rel="noopener">https://www.nginx.com/resources/wiki/start/topics/tutorials/install</a> 。</p><p>我的 VPS 是 CentOS 7 X64 版本的，所以安装 Nginx 的过程比较麻烦一点，需要自己下载源码、编译、安装，如果需要用到附加模块【例如 http_ssl 证书模块】，还需要重新编译，整个过程比较耗时。如果不熟悉的话，遇到问题也要折腾半天才能解决。所以，我在不熟悉的 Nginx 的情况下选择了一种简单的方式，直接自动安装，并自带了一些常用的模块，例如 ssl 证书模块。但是缺点就是安装过程稍微长一点，在网络好的情况下可能需要 3-5 分钟。我还参考了别人的文档：<a href="https://gist.github.com/ifels/c8cfdfe249e27ffa9ba1" target="_blank" rel="noopener">https://gist.github.com/ifels/c8cfdfe249e27ffa9ba1</a> ，但是仅供参考，因为我发现也有一些不能使用的地方。</p><h2 id="创建源配置文件"><a href="# 创建源配置文件" class="headerlink" title="创建源配置文件"></a>创建源配置文件 </h2><p> 在 /etc/yum.repos.d/ 目录下创建一个源配置文件 nginx.repo，如果不存在这个目录，先使用 mkdir 命令创建目录，然后在目录中添加一个文件 nginx.repo，使用命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi nginx.repo</span><br></pre></td></tr></table></figure><p>进入编辑模式，填写如下内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">name=nginx repo</span><br><span class="line">baseurl=http://nginx.org/packages/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure><p>编辑完成后保存即可。</p><h2 id="自动安装 -Nginx"><a href="# 自动安装 -Nginx" class="headerlink" title="自动安装 Nginx"></a>自动安装 Nginx</h2><p>接下来就是使用命令自动安装 Nginx 了【敲下命令，看着就行了，会有刷屏的日志输出】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install nginx -y</span><br></pre></td></tr></table></figure><p>安装完成后，使用以下命令启动：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><p>可以使用命令 <strong>service nginx status</strong> 查看 Nginx 是否启动：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tj7nqpidj20pi085jrs.jpg" alt="查看 Nginx 状态" title="查看 Nginx 状态"></p><p>然后你就能看到 Nginx 的主页了，默认是 80 端口，直接使用 ip 访问即可【如果这里打不开，可能是端口 80 没有开启，被防火墙禁用了，需要重新开启，开启方法参考后面的章节】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tj9c3v7aj20hw075t92.jpg" alt="Nginx 主页" title="Nginx 主页"></p><h1 id="获取 -SSL- 证书、配置参数"><a href="# 获取 -SSL- 证书、配置参数" class="headerlink" title="获取 SSL 证书、配置参数"></a>获取 SSL 证书、配置参数 </h1><h2 id="SSL- 证书获取"><a href="#SSL- 证书获取" class="headerlink" title="SSL 证书获取"></a>SSL 证书获取</h2><p> 证书的获取可以参考我的文章：<a href="https://www.playpi.org/2019030401.html">利用阿里云申请免费的 SSL 证书 </a>。我在阿里云获取的证书是免费的、有效期一年的，等证书过期了可以重新申请【不知道能不能自动续期】，因为我有阿里云的帐号，所以就直接使用了。当然，通过其它方式也可以获取 SSL 证书，大家自行选择。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tj9zp4g1j21hc0qx0ub.jpg" alt="阿里云申请的 SSL 证书" title="阿里云申请的 SSL 证书"></p><p> 直接下载即可，下载后上传到站点的任意目录，但是要记住文件的位置，因为等一下配置 Nginx 的时候需要指定证书的位置。我把它们放在了 /site/ 目录，一共有 2 个文件：.key 文件时私钥文件，.pem 文件时公钥文件。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tjanlqz3j20o80dbaav.jpg" alt="SSL 证书的 2 个文件" title="SSL 证书的 2 个文件"></p><h2 id="Nginx- 参数配置"><a href="#Nginx- 参数配置" class="headerlink" title="Nginx 参数配置"></a>Nginx 参数配置 </h2><p> 更改配置文件，打开文件【使用 vi 命令会自动创建不存在的文件】，进入编辑模式：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 配置 </span><br><span class="line">vi /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><p>填写内容如下【我这里只是配置基本的参数 server 有关内容，大家当然可以根据实际需要配置更为丰富的参数】，留意证书的公钥与私钥这 2 个文件的配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 80 端口是用来接收基本的 http 请求，里面做了永久重定向，重定向到 https 的链接 </span><br><span class="line">    server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  blog.playpi.org;</span><br><span class="line">    access_log   /site/iplaypi.github.io.http-blog-access.log  main;</span><br><span class="line">    rewrite ^/(.*)$ https://blog.playpi.org/$1 permanent;</span><br><span class="line">    &#125;</span><br><span class="line"># 443 端口是用来接收 https 请求的 </span><br><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl;# 监听端口 </span><br><span class="line">    server_name blog.playpi.org;# 域名 </span><br><span class="line">    access_log   /site/iplaypi.github.io.https-blog-access.log  main;</span><br><span class="line">    root         /site/iplaypi.github.io;</span><br><span class="line">    ssl_certificate /site/1883927_blog.playpi.org.pem;# 证书路径 </span><br><span class="line">    ssl_certificate_key /site/1883927_blog.playpi.org.key;#key 路径 </span><br><span class="line">    ssl_session_cache shared:SSL:1m;# 储存 SSL 会话的缓存类型和大小 </span><br><span class="line">    ssl_session_timeout 5m;# 配置会话超时时间 </span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;# 为建立安全连接，服务器所允许的密码格式列表 </span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_prefer_server_ciphers on;# 依赖 SSLv3 和 TLSv1 协议的服务器密码将优先于客户端密码 </span><br><span class="line">    #减少点击劫持 </span><br><span class="line">    add_header X-Frame-Options DENY;</span><br><span class="line">    #禁止服务器自动解析资源类型 </span><br><span class="line">    add_header X-Content-Type-Options nosniff;</span><br><span class="line">    #防 XSS 攻击 </span><br><span class="line">    add_header X-Xss-Protection 1;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>只要按照如上的配置，就可以同时接收 http 请求与 https 请求【实际上 http 的请求被永久重定向到了 https】，我的配置如下图【请忽略 www 二级域名的配置项】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tjbahmnzj20rm0kv75t.jpg" alt="Nginx 配置项 server" title="Nginx 配置项 server"></p><h2 id="验证参数是否准确"><a href="# 验证参数是否准确" class="headerlink" title="验证参数是否准确"></a>验证参数是否准确 </h2><p> 有时候配置了参数，可能因为字符、参数名问题导致启动失败，然后再回来改配置文件，比较繁琐，所以可以直接使用 Nginx 提供的命令来验证配置文件的内容是否合法，如果有问题可以在输出警告日志中看到，改起来也非常方便。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><p>可以看到，配置项正常，接下来就可以启动 Nginx 了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tjbrqeeuj20f603cglj.jpg" alt="Nginx 配置项检测" title="Nginx 配置项检测"></p><h1 id="开启端口、启动 -Nginx"><a href="# 开启端口、启动 -Nginx" class="headerlink" title="开启端口、启动 Nginx"></a>开启端口、启动 Nginx</h1><p>在上面的步骤中，如果在一开始想启动 Nginx，虽然启动成功了，但是却访问不了 Nginx 的主页，那很大可能是服务器的端口没有开启，导致访问请求被拒绝，所以需要适当开启必要的端口【如果没有安装防火墙工具 firewall 请自行安装】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看已经开启的端口 </span><br><span class="line">firewall-cmd --list-ports</span><br><span class="line"># 开启端口 80</span><br><span class="line">firewall-cmd --permanent --zone=public --add-port=80/tcp</span><br><span class="line"># 开启端口 443</span><br><span class="line">firewall-cmd --permanent --zone=public --add-port=443/tcp</span><br><span class="line"># 重载更新的端口信息 </span><br><span class="line">firewall-cmd --reload</span><br><span class="line"># 这种方式可以，启动 Nginx</span><br><span class="line">service nginx start</span><br><span class="line"># 停止 Nginx</span><br><span class="line">service nginx stop</span><br><span class="line"># 如果需要重启，直接使用下面的更方便 </span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><p>大家看一下我的服务器的端口开启信息：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tjc9ygu2j20bo02s0sl.jpg" alt="服务器端口开启情况" title="服务器端口开启情况"></p><h1 id="验证站点"><a href="# 验证站点" class="headerlink" title="验证站点"></a>验证站点 </h1><p> 打开站点 <a href="https://blog.playpi.org" target="_blank" rel="noopener">https://blog.playpi.org</a> ，可以愉快地访问了，可以看到 https 链接的绿锁。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tjcrc2zbj21hk0s6n10.jpg" alt="安全的站点主页" title="安全的站点主页"></p><p>接着查看一下 SSL 证书的信息。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0tjd5kowxj20d60i90t0.jpg" alt="查看 SSL 证书信息" title="查看 SSL 证书信息"></p><h1 id="题外话"><a href="# 题外话" class="headerlink" title="题外话"></a>题外话 </h1><h2 id="重定向问题思考"><a href="# 重定向问题思考" class="headerlink" title="重定向问题思考"></a> 重定向问题思考 </h2><p> 关于开启 https 的访问，我一开始也配置了 www 的二级域名，但是通过日志发现没有通过 301 重定向访问 <a href="https://www.playpi.org">https://www.playpi.org</a> 的请求，一直不明白原因。后来发现，因为做重定向的时候还是重定向到 GitHub 上面了。同理，如果使用 ip 直接访问，可以观察到自动跳转到 <a href="https://www.playpi.org">https://www.playpi.org</a> 了，查看证书还是 GitHub 的证书。所以后来直接把百度爬虫的请求转发到 blog 的二级域名还是明智的【www 的二级域名就不用自己再搞一套了】，否则百度爬虫还是抓取不到。如果百度爬虫直接使用 https 链接抓取还是可以的，但是看百度站长里面的说明，是通过 http 的 301 重定向抓取的。</p><h2 id="Nginx- 的 -https- 模块安装"><a href="#Nginx- 的 -https- 模块安装" class="headerlink" title="Nginx 的 https 模块安装"></a>Nginx 的 https 模块安装 </h2><p> 由于我使用的是简单小白的安装方式，不需要关心额外用到的模块，例如 http_ssl 模块，因为安装包里面自带了这个模块，可以使用 <strong>nginx -V</strong> 命令查看。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0uj2a8vf6j21gm08smxy.jpg" alt="http_ssl 模块查看" title="http_ssl 模块查看"></p><p>因此，如果大家有使用源码编译安装的方式，注意 https 模块不能缺失，否则不能开启 https 的方式。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>https</tag>
        <tag>ssl</tag>
        <tag>证书</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis Desktop Manager 的安装及使用</title>
    <url>/2017030301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在技术类岗位的工作中，一般都会使用到 Redis 这个非关系型数据库，在很多场景下它会被作为一个缓存数据库使用。而如果在日常工作中接触到了 Redis，哪怕使用得不是很深入，也需要了解一些 Redis 的基础知识以及常用的命令，以备不时之需。然而，为了方便使用 Redis，还有另外一条路可以选，那就是借助可视化管理工具，让新手或者非技术人员也可以轻松使用 Redis 数据库【例如产品经理、测试人员都可以灵活查询数据库】。而在众多的可视化管理工具中，Redis Desktop Manager 又是比较好用而且轻量的一款工具。本文除了简单介绍一下 Redis 的基础知识，其它篇幅主要讲解这款工具的安装使用，环境基于 Windows 10 X64，Redis Desktop Manager 的版本为 v0.8.8。</p><a id="more"></a><h1 id="数据库的知识入门"><a href="# 数据库的知识入门" class="headerlink" title="数据库的知识入门"></a>数据库的知识入门 </h1><p> 在这里，我先简单介绍一下数据库分类的入门知识，方便大家理解。</p><h2 id="关系型数据库"><a href="# 关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库 </h2><p> 如果是学计算机技术相关专业的人，或者学统计学、数学应用专业的人，一定会接触到数据库的知识，而且一定用过数据库的产品，否则日常的学习无法进行下去。例如在做统计分析的时候，在数据量比较小的情况下，可能使用 Excel 或者 csv 即可完成，但是如果数据量稍微大一点【例如几十万上百万】，此时再使用文件的方式处理数据就比较吃力了，而且效率低下。那么，在这种情况下可以顺势使用数据库【而且一般都是关系型数据库】，数据处理起来迅速而且方便。</p><p>上面提到的 Excel、csv、数据库，在日常工作学习中，一般需要用到它们时处理的都是结构化的数据，通俗点说就是数据的格式是规范的行列形式，数据一共有 m 行 n 列，很规范，每一行是一条数据，每一列是一个属性，这也符合人类的基本认知。而为了方便存储、分析这类数据，产生的数据库都是关系型数据库，比较常见的产品有：Oracle【甲骨文公司出品】、MySql【免费开源，小巧好用】、SQL Server【微软公司出品】。使用这些产品，你就可以把数据直接导入数据库，然后做查询分析，例如全校的学生信息、成绩信息、选课信息等。</p><h2 id="非关系型数据库"><a href="# 非关系型数据库" class="headerlink" title="非关系型数据库"></a>非关系型数据库 </h2><p> 但是，在某些场景下，关系型数据库的缺点暴露了出来，或者说关系型数据库根本无法适应这些场景。最常见的场景就是在当前的互联网环境下，每天会有海量的数据产生，而且数据格式五花八门，为了分析、存储这些数据，只靠关系型数据库根本行不通。一是需要高并发的读写需求【分布式读写】，二是需要高效率的读写需求【高速读写】，三是需要高扩展性【例如在数据量增加的情况下灵活扩展资源、数据结构灵活变更】，四是需要高可用性【负载均衡、备份迁移】，在这些方面，传统的关系型数据库产品无法应对。</p><p>此时，非关系型数据库的概念也就出来了，相应的产品也就问世了，例如 MongodDB【可以在海量的数据中快速地查询数据】、HBase【海量非结构化数据的分布式存储，可扩展】、Neo4j【高性能的 NoSql 图形数据库】、Redis【应用广泛，具有极高的并发读写性能】。如果要提一个非关系型数据库与关系型数据库最直观的不同点，则可以说是数据结构，非关系型数据库的数据结构不固定，可以根据实际场景灵活变更。例如在 HBase 中，列【在 HBase 中称为 colomn qualifier，另外还有一个列簇的概念 colomn family】的个数可以任意指定【这种特性称为列式存储】，列名称也可以任意指定，不会受到表结构的限制。</p><p>还有一点需要说明，非关系型数据库出现的时间比较短，而且为了应对多样的实际场景，产品众多，不像关系型数据库那样只有几款产品就可以一统江湖，这也是非关系型数据库的天然特性。但是，非关系型数据库的产品大多数都是开源的，任何人都可以使用。</p><h2 id="Redis- 介绍"><a href="#Redis- 介绍" class="headerlink" title="Redis 介绍"></a>Redis 介绍 </h2><p>Redis 是一款具有高性能并发读写的 key-value 数据库，而且是开源的。如果大家没有用过它的话，我也无法给大家描述清楚它的概念，只好列举一下它具有的特点【没有使用过的人可以了解一下】，如下：</p><ul><li> 基于内存 </li><li> 支持数据持久化，可以将内存中的数据保存在磁盘中，重启的时候再次加载 </li><li> 数据类型丰富，除了 String，还有 Set、List、Hash 等结构 </li><li> 高性能读写 </li><li> 原子性，所有的操作都是原子性的 </li><li> 丰富的特性，例如 publish/subscribe、key 过期等 </li></ul><h2 id="常用命令举例"><a href="# 常用命令举例" class="headerlink" title="常用命令举例"></a> 常用命令举例 </h2><p> 我在这里只是列举一种数据结构【List】的常用命令，其它的可以举一反三，或者根据实际需要查看备注中给出的帮助文档。</p><ul><li>llen key，获取 List 的长度 </li><li>lpush key value，从左侧添加一个元素，key 不存在则新建</li><li>lindex key index，在 key 存在的情况下才从左侧添加一个元素，否则不添加</li><li>lpop key，弹出左侧的第一个元素</li><li>lrange key start stop，根据下标获取所有元素，从 0 开始，-1 表示最大下标</li><li>lset key index value，在指定下标添加一个元素</li><li>linsert key BEFORE|AFTER pivot value，从左侧开始，在指定值的前 / 后插入一个元素</li><li>lrem key count value，从左侧开始，移除指定数量的值等于指定值的元素</li></ul><p> 可以看到命令都以字母 <code>l</code> 【单词 left 的首字母，L 对应的小写字母】开头，表示所有的操作都是从 List 的左侧【小索引的位置】开始，如果把 <code>l</code> 改成 <code>r</code> 则表示操作从右侧【大索引的位置】开始。例如 <code>lpush</code> 表示给 List 的 0 号位索引添加一个元素，而 <code>rpush</code> 表示给 List 的最大索引位置添加一个元素。</p><h1 id="可视化管理工具的安装使用"><a href="# 可视化管理工具的安装使用" class="headerlink" title="可视化管理工具的安装使用"></a>可视化管理工具的安装使用 </h1><p> 就像在使用关系型数据库的时候，有众多的可视化管理工具可以使用，例如：<strong>MySQL Workbench</strong>、<strong>Navicat</strong>、<strong>phpMyAdmin</strong> 等等。类比一下，在管理 Redis 的时候，就可以使用 Redis 的管理工具 <strong>Redis Desktop Manager</strong>，以下内容介绍这款工具的安装使用，只是入门级别的使用，零基础完全可以上手。</p><h2 id="安装"><a href="# 安装" class="headerlink" title="安装"></a>安装 </h2><p> 从官方网站购买下载，<a href="https://redisdesktop.com/download" target="_blank" rel="noopener">下载地址 </a> ，安装包不大，大概 27MB。下载完成后直接双击应用程序，根据引导完成安装即可，注意根据实际需要选择安装目录。</p><p> 下载程序 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606005025.png" alt="下载程序" title="下载程序"></p><p> 双击安装 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606005035.png" alt="双击安装" title="双击安装"></p><p> 选择安装目录 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606005046.png" alt="选择安装目录" title="选择安装目录"></p><p> 安装完成 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606005052.png" alt="安装完成" title="安装完成"></p><p> 启动主界面 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606005100.png" alt="启动主界面" title="启动主界面"></p><h2 id="创建连接"><a href="# 创建连接" class="headerlink" title="创建连接"></a> 创建连接 </h2><p> 打开主界面，可以看到左下角有一个绿色的加号，并标识：<code>Connect to Redis Server</code>，也就是创建连接，直接点击加号，弹出一个对话框，里面填写连接 Redis 的基本信息：连接名称、主机、端口、认证信息。<br>创建连接 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606005619.png" alt="创建连接" title="创建连接"></p><p> 请大家根据实际情况填写参数，我填写的如下图，连接名称可以是任意的字符串，但是为了有意义不要随便起名字，以免混淆。<br>填写连接信息 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606011842.png" alt="填写连接信息" title="填写连接信息"></p><p> 本来填写完参数就可以直接创建连接了，但是实际的场景可能没有这么简单，可能工作环境不允许直接从本机连接远程的 Redis 服务器，而是需要经过 <strong>SSL 秘钥 </strong>、<strong>SSH 隧道 </strong>【SSH Tunnel】等认证方式。无论是哪种认证方式，都需要额外配置，例如我的环境需要 <strong>SSH 隧道 </strong>认证，其实就是经过一个中间的代理服务器去连接真实线上环境的 Redis 服务器，都是为了安全。因此，我需要额外配置，在 SSH Tunnel 选项卡中填写补充信息，需要填写 SSH 主机的地址、端口、用户名、密码等，记得勾选 <code>Use SSH Tunnel</code> 选项。</p><p>填写 SSH 隧道信息 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606011854.png" alt="填写 SSH 隧道信息" title="填写 SSH 隧道信息"></p><p> 所有的信息填写完成后，不要着急点击 <code>OK</code> 创建连接，可以先点击左下角的 <code>Test Connection</code> 来测试一下能不能连接成功，用测试连接的结果来验证参数填写是否有误。如果连接失败，会显示失败的具体原因，例如认证不通过、找不到主机、端口访问拒绝等错误，遇到错误再根据实际情况解决即可。下图是我的测试连接，直接成功通过。</p><p>测试连接成功 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606011907.png" alt="测试连接成功" title="测试连接成功"></p><p> 最后一步，点击 <code>OK</code> 按钮，创建连接成功，可以看到主界面左侧的面板中有一个连接，它的名字就是刚才指定的连接名字。</p><p>主界面左侧面板 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606012247.png" alt="主界面左侧面板" title="主界面左侧面板"></p><h2 id="使用"><a href="# 使用" class="headerlink" title="使用"></a> 使用 </h2><p> 在主界面的左侧面板中，选择任意一个连接【如果有多个连接的话】，鼠标左键选中时它会自动连接，可以在主界面的中部下方看到有一个 <code>System log</code> 的选项卡，里面会实时输出打印连接日志。打开连接后，可以看到 Redis 数据库的默认 16 个桶，编号从 0 到 15，一般只会用到其中的一个桶，可以看到我这里有两个桶【0 号和 3 号】被使用。</p><p>打开连接 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606013705.png" alt="打开连接" title="打开连接"></p><p> 如果需要进一步操作数据，直接在展开的树形结构中，选择需要操作的 key，然后可以使用右侧的操作按钮直接操作，例如 <strong>删除 </strong>、<strong> 添加 </strong>、<strong> 设置 TTL 值 </strong>等，也可以使用鼠标右键选择对应的功能。</p><p>查看 Redis 数据 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606013715.png" alt="查看 Redis 数据" title="查看 Redis 数据"></p><p> 到这里可以看出，一切操作都是肉眼可见的，很方便而且很容易理解，非技术人员也可以熟练操作。但是，如果你作为一个技术人员，觉得这样用鼠标点来点去很麻烦，想直接使用命令操作怎么办？有办法，这款工具也支持使用命令行操作。</p><p>在选中连接后，使用鼠标右键打开选择列表，选择 <strong>Console</strong> 打开连接，即表示连接后进入命令行。<br>打开命令行 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606014427.png" alt="打开命令行" title="打开命令行"></p><p> 接着在主界面的下方就会打开一个名字和连接名字一样的选项卡，里面的背景是灰黑色的，可以看到里面有一个 <code>Connected</code> 关键词，这就是进入命令行的样子，接着就可以自由自在地敲下你熟悉的命令了。</p><p>使用命令 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190606014434.png" alt="使用命令" title="使用命令"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a> 备注</h1><p>1、Redis Desktop Manager 官方网站：<a href="https://redisdesktop.com" target="_blank" rel="noopener">https://redisdesktop.com</a> ，它是一款收费的软件，价格不贵，不过项目是开源的，贡献代码可以免费使用一定的时间【目前是一年】。</p><p>2、Redis 命令大全，参见官方网站：<a href="https://redis.io/commands" target="_blank" rel="noopener">https://redis.io/commands</a> ，列举了十几个系列的命令，总计两百多个命令，请根据实际情况查询使用。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Manager</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 异常之 Failed to create local dir</title>
    <url>/2020010201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天的 <code>Spark Streaming</code> 程序莫名出现异常【对于一个 <code>task</code> 来说，<code>Spark Streaming</code> 会重试 4 次，全部重试都失败后整个 <code>Stage</code> 才会失败】，紧接着 <code>task</code> 中的 <code>batch</code> 就会卡住不动【后来查到卡住是其它原因造成的】，使得整个 <code>Spark Streaming</code> 任务进程进入到等待状态，所有的 <code>batch</code> 都处于 <code>queued</code> 状态，数据流无法继续执行。本文内容基于 <code>Spark v1.6.2</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 线上一个一直很稳定的 <code>Spark Streaming</code> 程序，突然出现异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Job aborted due to stage failure: Task 0 in stage 2174.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2174.0 (TID 32656, host): java.io.IOException: Failed to create local dir in /cloud/data2/spark/local/spark-4fccb5c2-29f5-45f9-926e-1c6e33636884/executor-30fdf8f9-6459-43c0-bba5-3a406db7e700/blockmgr-7edadea3-1fa3-4f32-bef2-1cf81230042a/07.</span><br><span class="line">	at org.apache.spark.storage.DiskBlockManager.getFile (DiskBlockManager.scala:73)</span><br><span class="line">	at org.apache.spark.storage.DiskStore.contains (DiskStore.scala:161)</span><br><span class="line">	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$getCurrentBlockStatus (BlockManager.scala:398)</span><br><span class="line">	at org.apache.spark.storage.BlockManager.doPut (BlockManager.scala:827)</span><br><span class="line">	at org.apache.spark.storage.BlockManager.putBytes (BlockManager.scala:700)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$anonfun$$getRemote$1$1.apply (TorrentBroadcast.scala:130)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$anonfun$$getRemote$1$1.apply (TorrentBroadcast.scala:127)</span><br><span class="line">	at scala.Option.map (Option.scala:145)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.org$apache$spark$broadcast$TorrentBroadcast$$anonfun$$getRemote$1 (TorrentBroadcast.scala:127)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$1.apply (TorrentBroadcast.scala:137)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$1.apply (TorrentBroadcast.scala:137)</span><br><span class="line">	at scala.Option.orElse (Option.scala:257)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp (TorrentBroadcast.scala:137)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply (TorrentBroadcast.scala:120)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply (TorrentBroadcast.scala:120)</span><br><span class="line">	at scala.collection.immutable.List.foreach (List.scala:318)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks (TorrentBroadcast.scala:120)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply (TorrentBroadcast.scala:175)</span><br><span class="line">	at org.apache.spark.util.Utils$.tryOrIOException (Utils.scala:1205)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock (TorrentBroadcast.scala:165)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute (TorrentBroadcast.scala:64)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast._value (TorrentBroadcast.scala:64)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast.getValue (TorrentBroadcast.scala:88)</span><br><span class="line">	at org.apache.spark.broadcast.Broadcast.value (Broadcast.scala:70)</span><br><span class="line">	at org.apache.spark.scheduler.ResultTask.runTask (ResultTask.scala:62)</span><br><span class="line">	at org.apache.spark.scheduler.Task.run (Task.scala:89)</span><br><span class="line">	at org.apache.spark.executor.Executor$TaskRunner.run (Executor.scala:227)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">Driver stacktrace:</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200211004947.png" alt="异常信息" title="异常信息"></p><p>重点内容在于 <code>java.io.IOException: Failed to create local dir</code>。</p><p>为了不影响业务逻辑，首先尝试重启，重启后短暂恢复正常，大概运行 20-40 分钟后，继续出现上述异常，非常诡异【重启 5 次左右仍旧出现】。</p><p>同时，伴随着部分 <code>Stage</code> 失败，<code>Spark Streaming</code> 任务出现了 <code>batch</code> 卡住的现象，有 2 个 <code>btach</code> 一直处于 <code>processing</code> 状态，极不正常。导致后面所有的 <code>batch</code> 都处于 <code>queued</code> 状态，数据流无法继续执行，最终整个 <code>Spark Streaming</code> 任务会卡住不动，类似于假死。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200211010335.png" alt="batch 卡住" title="batch 卡住"></p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><p> 查了一下文档，发现有两种情况会造成这个异常，一是没有权限写入磁盘，二是磁盘空间不足。</p><p>找运维人员协助查看了一下，服务器的磁盘没有问题，根据进程的用户判断权限也没有问题，而且有好几个其它类似的 <code>Spark Straming</code> 任务可以正常运行，一点问题没有。</p><p>于是回顾一下最近的代码变动，发现有问题的 <code>Spark Streaming</code> 任务都变更过一个第三方接口的调用，于是联系对应的开发人员。</p><p>经过沟通测试，发现了问题，第三方接口有一个异常没有捕捉，导致上述异常产生。同时，由此会导致资源不释放的 <code>bug</code>，进而影响了 <code>Spark Streaming</code> 任务的 <code>batch</code> 卡住。</p><p>以上这些问题都与 <code>Spark</code> 无关，后面紧急升级第三方接口，任务得以正常运行，后续又观察了三天，都没有问题。</p><h1 id="深入探究"><a href="# 深入探究" class="headerlink" title="深入探究"></a>深入探究 </h1><p> 问题虽然解决了，但还是要关注一下这个异常的场景，通过查看源码，发现这个异常是在创建目录的时候产生的，如下图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200211011126.png" alt="查看源码" title="查看源码"></p><p>那这个场景就很简单了，如果进程没有写入磁盘的权限或者磁盘空间不足，都会产生这个异常。</p><p>进一步思考，为什么会创建这个目录，作用是什么呢？</p><p>原来，<code>Spark</code> 在 <code>shuffle</code> 时需要通过 <code>diskBlockManage</code> 将 <code>map</code> 结果写入本地，优先写入 <code>memory store</code>，在 <code>memore store</code> 空间不足时会创建临时文件。这是一个二级目录，如异常中的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/cloud/data2/spark/local/spark-4fccb5c2-29f5-45f9-926e-1c6e33636884/executor-30fdf8f9-6459-43c0-bba5-3a406db7e700/blockmgr-7edadea3-1fa3-4f32-bef2-1cf81230042a/07</span><br></pre></td></tr></table></figure><p>使用完成后会立即删除。</p><p>那 <code>shuffle</code> 又是咋回事呢？<code>Spark</code> 作为并行计算框架，同一个作业会被划分为多个任务在多个节点上执行，<code>reduce</code> 的输入可能存在于多个节点，因此需要 <code>shuffle</code> 将所有 <code>reduce</code> 的输入汇总起来。这一步比较消耗内存或者说是磁盘，视选择的缓存方式而定。</p><p>那上面的 <code>memory store</code> 的大小是多少，什么情况下会超出上限从而选择使用 <code>disk store</code>？其实，<code>memory store</code> 的大小取决于 <code>spark.excutor.memory</code> 的大小，默认为 <code>spark.excutor.memory * 0.6</code>。此外，官方是不建议更改 0.6 这个系数的【参数：<code>spark.storage.memoryFraction</code>】，参考：<a href="https://spark.apache.org/docs/1.6.2/configuration.html" target="_blank" rel="noopener">configuration-1.6.2</a> 。</p><p>那临时文件的目录，可以更改吗，例如磁盘空间不足后，新挂载了一块磁盘。是可以的，在 <code>spark.env</code> 中添加 <code>SPARK_LOCAL_DIRS</code> 变量即可【通过 <code>spark-env.sh</code> 脚本可以添加】，或者直接在程序中配置【<code>spark conf</code>，参数名是 <code>spark.local.dir</code>】，可配置多个路径，使用英文逗号分隔，这样可以增强 <code>IO</code> 效率。这个参数的官方说明如下，默认目录是 <code>/tmp</code>。</p><blockquote><p>Directory to use for “scratch” space in Spark, including map output files and RDDs that get stored on disk. This should be on a fast, local disk in your system. It can also be a comma-separated list of multiple directories on different disks. NOTE: In Spark 1.0 and later this will be overriden by SPARK_LOCAL_DIRS (Standalone, Mesos) or LOCAL_DIRS (YARN) environment variables set by the cluster manager.</p></blockquote><p>综上所述，在生产环境中一定要确保磁盘空间充足和磁盘写权限，切记磁盘空间按需配置，不可乱用，运维侧也要加上磁盘相关的监控，有问题可以及时预警。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 异常参考：<a href="https://stackoverflow.com/questions/41238121/spark-java-ioexception-failed-to-create-local-dir-in-tmp-blockmgr" target="_blank" rel="noopener">stackoverflow</a> 。</p><p>官方文档参考：<a href="https://spark.apache.org/docs/1.6.2/configuration.html" target="_blank" rel="noopener">configuration-1.6.2</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Streaming</tag>
        <tag>IOException</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 异常之 Netty 相关</title>
    <url>/2019011401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在做项目的时候，需要新引入一个外部依赖，于是很自然地在项目的 pom.xml 文件中加入了依赖坐标，然后进行编译、打包、运行，没想到直接抛出了异常：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">18</span>:<span class="number">52</span> [sparkDriverActorSystem-akka.actor.<span class="keyword">default</span>-dispatcher-<span class="number">5</span>] ERROR actor.ActorSystemImpl:<span class="number">66</span>: Uncaught fatal error from thread [sparkDriverActorSystem-akka.remote.<span class="keyword">default</span>-remote-dispatcher-<span class="number">7</span>] shutting down ActorSystem [sparkDriverActorSystem]</span><br><span class="line">java.lang.VerifyError: (class: org/jboss/netty/channel/socket/nio/NioWorkerPool, method: createWorker signature: (Ljava/util/concurrent/Executor;) Lorg/jboss/netty/channel/socket/nio/AbstractNioWorker;) Wrong return type in function</span><br></pre></td></tr></table></figure><p>任务运行失败，仔细看日志觉得很莫名奇妙，是一个 java.lang.VerifyError 错误，以前从来没见过类似的。本文记录这个错误的解决过程。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在上述错误抛出之后，可以看到 SparkContext 初始化失败，然后进程就终止了；</p><p>完整日志如下：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">18</span>:<span class="number">52</span> [sparkDriverActorSystem-akka.actor.<span class="keyword">default</span>-dispatcher-<span class="number">5</span>] ERROR actor.ActorSystemImpl:<span class="number">66</span>: Uncaught fatal error from thread [sparkDriverActorSystem-akka.remote.<span class="keyword">default</span>-remote-dispatcher-<span class="number">7</span>] shutting down ActorSystem [sparkDriverActorSystem]</span><br><span class="line">java.lang.VerifyError: (class: org/jboss/netty/channel/socket/nio/NioWorkerPool, method: createWorker signature: (Ljava/util/concurrent/Executor;) Lorg/jboss/netty/channel/socket/nio/AbstractNioWorker;) Wrong return type in function</span><br><span class="line">	at akka.remote.transport.netty.NettyTransport.(NettyTransport.scala:<span class="number">283</span>)</span><br><span class="line">	at akka.remote.transport.netty.NettyTransport.(NettyTransport.scala:<span class="number">240</span>)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0 (Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance (NativeConstructorAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance (DelegatingConstructorAccessorImpl.java:<span class="number">45</span>)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance (Constructor.java:<span class="number">423</span>)</span><br><span class="line">	at akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$<span class="number">2</span>.apply (DynamicAccess.scala:<span class="number">78</span>)</span><br><span class="line">	at scala.util.Try$.apply (Try.scala:<span class="number">161</span>)</span><br><span class="line">	at akka.actor.ReflectiveDynamicAccess.createInstanceFor (DynamicAccess.scala:<span class="number">73</span>)</span><br><span class="line">	at akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$<span class="number">3</span>.apply (DynamicAccess.scala:<span class="number">84</span>)</span><br><span class="line">	at akka.actor.ReflectiveDynamicAccess$$anonfun$createInstanceFor$<span class="number">3</span>.apply (DynamicAccess.scala:<span class="number">84</span>)</span><br><span class="line">	at scala.util.Success.flatMap (Try.scala:<span class="number">200</span>)</span><br><span class="line">	at akka.actor.ReflectiveDynamicAccess.createInstanceFor (DynamicAccess.scala:<span class="number">84</span>)</span><br><span class="line">	at akka.remote.EndpointManager$$anonfun$<span class="number">9</span>.apply (Remoting.scala:<span class="number">711</span>)</span><br><span class="line">	at akka.remote.EndpointManager$$anonfun$<span class="number">9</span>.apply (Remoting.scala:<span class="number">703</span>)</span><br><span class="line">	at scala.collection.TraversableLike$WithFilter$$anonfun$map$<span class="number">2</span>.apply (TraversableLike.scala:<span class="number">722</span>)</span><br><span class="line">	at scala.collection.Iterator$class.foreach (Iterator.scala:727)</span><br><span class="line">	at scala.collection.AbstractIterator.foreach (Iterator.scala:<span class="number">1157</span>)</span><br><span class="line">	at scala.collection.IterableLike$class.foreach (IterableLike.scala:72)</span><br><span class="line">	at scala.collection.AbstractIterable.foreach (Iterable.scala:<span class="number">54</span>)</span><br><span class="line">	at scala.collection.TraversableLike$WithFilter.map (TraversableLike.scala:<span class="number">721</span>)</span><br><span class="line">	at akka.remote.EndpointManager.akka$remote$EndpointManager$$listens (Remoting.scala:<span class="number">703</span>)</span><br><span class="line">	at akka.remote.EndpointManager$$anonfun$receive$<span class="number">2</span>.applyOrElse (Remoting.scala:<span class="number">491</span>)</span><br><span class="line">	at akka.actor.Actor$class.aroundReceive (Actor.scala:467)</span><br><span class="line">	at akka.remote.EndpointManager.aroundReceive (Remoting.scala:<span class="number">394</span>)</span><br><span class="line">	at akka.actor.ActorCell.receiveMessage (ActorCell.scala:<span class="number">516</span>)</span><br><span class="line">	at akka.actor.ActorCell.invoke (ActorCell.scala:<span class="number">487</span>)</span><br><span class="line">	at akka.dispatch.Mailbox.processMailbox (Mailbox.scala:<span class="number">238</span>)</span><br><span class="line">	at akka.dispatch.Mailbox.run (Mailbox.scala:<span class="number">220</span>)</span><br><span class="line">	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec (AbstractDispatcher.scala:<span class="number">397</span>)</span><br><span class="line">	at scala.concurrent.forkjoin.ForkJoinTask.doExec (ForkJoinTask.java:<span class="number">260</span>)</span><br><span class="line">	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask (ForkJoinPool.java:<span class="number">1339</span>)</span><br><span class="line">	at scala.concurrent.forkjoin.ForkJoinPool.runWorker (ForkJoinPool.java:<span class="number">1979</span>)</span><br><span class="line">	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run (ForkJoinWorkerThread.java:<span class="number">107</span>)</span><br><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">18</span>:<span class="number">52</span> [sparkDriverActorSystem-akka.actor.<span class="keyword">default</span>-dispatcher-<span class="number">6</span>] INFO remote.RemoteActorRefProvider$RemotingTerminator:<span class="number">74</span>: Shutting down remote daemon.</span><br><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">18</span>:<span class="number">52</span> [sparkDriverActorSystem-akka.actor.<span class="keyword">default</span>-dispatcher-<span class="number">6</span>] INFO remote.RemoteActorRefProvider$RemotingTerminator:<span class="number">74</span>: Remote daemon shut down; proceeding with flushing remote transports.</span><br><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">18</span>:<span class="number">52</span> [sparkDriverActorSystem-akka.actor.<span class="keyword">default</span>-dispatcher-<span class="number">6</span>] ERROR Remoting:<span class="number">65</span>: Remoting system has been terminated abrubtly. Attempting to shut down transports</span><br><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">18</span>:<span class="number">52</span> [sparkDriverActorSystem-akka.actor.<span class="keyword">default</span>-dispatcher-<span class="number">6</span>] INFO remote.RemoteActorRefProvider$RemotingTerminator:<span class="number">74</span>: Remoting shut down.</span><br><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">19</span>:<span class="number">02</span> [main] ERROR spark.SparkContext:<span class="number">95</span>: Error initializing SparkContext.</span><br><span class="line">java.util.concurrent.TimeoutException: Futures timed out after [<span class="number">10000</span> milliseconds]</span><br><span class="line">	at scala.concurrent.impl.Promise$DefaultPromise.ready (Promise.scala:<span class="number">219</span>)</span><br><span class="line">	at scala.concurrent.impl.Promise$DefaultPromise.result (Promise.scala:<span class="number">223</span>)</span><br><span class="line">	at scala.concurrent.Await$$anonfun$result$<span class="number">1</span>.apply (<span class="keyword">package</span>.scala:<span class="number">107</span>)</span><br><span class="line">	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn (BlockContext.scala:<span class="number">53</span>)</span><br><span class="line">	at scala.concurrent.Await$.result (<span class="keyword">package</span>.scala:<span class="number">107</span>)</span><br><span class="line">	at akka.remote.Remoting.start (Remoting.scala:<span class="number">179</span>)</span><br><span class="line">	at akka.remote.RemoteActorRefProvider.init (RemoteActorRefProvider.scala:<span class="number">184</span>)</span><br><span class="line">	at akka.actor.ActorSystemImpl.liftedTree2$<span class="number">1</span>(ActorSystem.scala:<span class="number">620</span>)</span><br><span class="line">	at akka.actor.ActorSystemImpl._start$lzycompute (ActorSystem.scala:<span class="number">617</span>)</span><br><span class="line">	at akka.actor.ActorSystemImpl._start (ActorSystem.scala:<span class="number">617</span>)</span><br><span class="line">	at akka.actor.ActorSystemImpl.start (ActorSystem.scala:<span class="number">634</span>)</span><br><span class="line">	at akka.actor.ActorSystem$.apply (ActorSystem.scala:<span class="number">142</span>)</span><br><span class="line">	at akka.actor.ActorSystem$.apply (ActorSystem.scala:<span class="number">119</span>)</span><br><span class="line">	at org.apache.spark.util.AkkaUtils$.org$apache$spark$util$AkkaUtils$$doCreateActorSystem (AkkaUtils.scala:<span class="number">121</span>)</span><br><span class="line">	at org.apache.spark.util.AkkaUtils$$anonfun$<span class="number">1</span>.apply (AkkaUtils.scala:<span class="number">53</span>)</span><br><span class="line">	at org.apache.spark.util.AkkaUtils$$anonfun$<span class="number">1</span>.apply (AkkaUtils.scala:<span class="number">52</span>)</span><br><span class="line">	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$<span class="number">1</span>.apply$mcVI$sp (Utils.scala:<span class="number">2024</span>)</span><br><span class="line">	at scala.collection.immutable.Range.foreach$mVc$sp (Range.scala:<span class="number">141</span>)</span><br><span class="line">	at org.apache.spark.util.Utils$.startServiceOnPort (Utils.scala:<span class="number">2015</span>)</span><br><span class="line">	at org.apache.spark.util.AkkaUtils$.createActorSystem (AkkaUtils.scala:<span class="number">55</span>)</span><br><span class="line">	at org.apache.spark.SparkEnv$.create (SparkEnv.scala:<span class="number">266</span>)</span><br><span class="line">	at org.apache.spark.SparkEnv$.createDriverEnv (SparkEnv.scala:<span class="number">193</span>)</span><br><span class="line">	at org.apache.spark.SparkContext.createSparkEnv (SparkContext.scala:<span class="number">288</span>)</span><br><span class="line">	at org.apache.spark.SparkContext.(SparkContext.scala:<span class="number">457</span>)</span><br><span class="line">	at org.apache.spark.api.java.JavaSparkContext.(JavaSparkContext.scala:<span class="number">59</span>)</span><br><span class="line">	at com.ds.octopus.job.utils.SparkContextUtil.refresh (SparkContextUtil.java:<span class="number">77</span>)</span><br><span class="line">	at com.ds.octopus.job.utils.SparkContextUtil.getJsc (SparkContextUtil.java:<span class="number">34</span>)</span><br><span class="line">	at com.ds.octopus.job.executors.impl.WeiboZPZExporter.action (WeiboZPZExporter.java:<span class="number">95</span>)</span><br><span class="line">	at com.ds.octopus.job.executors.impl.WeiboZPZExporter.action (WeiboZPZExporter.java:<span class="number">41</span>)</span><br><span class="line">	at com.ds.octopus.job.executors.SimpleExecutor.execute (SimpleExecutor.java:<span class="number">40</span>)</span><br><span class="line">	at com.ds.octopus.job.client.OctopusClient.run (OctopusClient.java:<span class="number">162</span>)</span><br><span class="line">	at com.yeezhao.commons.buffalo.job.AbstractBUTaskWorker.runTask (AbstractBUTaskWorker.java:<span class="number">63</span>)</span><br><span class="line">	at com.ds.octopus.job.client.TaskLocalRunnerCli.start (TaskLocalRunnerCli.java:<span class="number">109</span>)</span><br><span class="line">	at com.yeezhao.commons.util.AdvCli.initRunner (AdvCli.java:<span class="number">191</span>)</span><br><span class="line">	at com.ds.octopus.job.client.TaskLocalRunnerCli.main (TaskLocalRunnerCli.java:<span class="number">41</span>)</span><br><span class="line"><span class="number">2019</span>-<span class="number">01</span>-<span class="number">13_17</span>:<span class="number">19</span>:<span class="number">02</span> [main] INFO spark.SparkContext:<span class="number">58</span>: Successfully stopped SparkContext</span><br></pre></td></tr></table></figure><p></p><p>错误日志截图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5j8uvmnrj219y0kqdil.jpg" alt="错误日志局部" title="错误日志局部"></p><p>根据日志没有看出有关 Java 层面的什么问题，只能根据 JNI 字段描述符：<br></p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">class: org/jboss/netty/channel/socket/nio/NioWorkerPool</span><br></pre></td></tr></table></figure><p></p><p>猜测是某一个类的问题，根据：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">method: createWorker signature: (Ljava/util/concurrent/Executor;) Lorg/jboss/netty/channel/socket/nio/AbstractNioWorker;) Wrong <span class="keyword">return</span> type in function</span><br></pre></td></tr></table></figure><p></p><p>猜测是某个方法的问题，方法的返回类型错误。</p><p>然后在项目中使用 ctrl+shift+t 快捷键（全局搜索 Java 类，每个人的开发工具设置的可能不一样）搜索类：NioWorkerPool，发现这个类的来源不是新引入的依赖包，而是原本就有的 netty 相关包，所以此时就可以断定这个莫名其妙的错误的原因就在于这个类的 createWorker 方法返回类型上面了。</p><p>搜索类 NioWorkerPool<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5j9dcym1j216q0aztai.jpg" alt="搜索 NioWorkerPool" title="搜索 NioWorkerPool"></p><p>日志的 JNI 字段描述符显示返回类型是 AbstractNioWorker，但是这个一看就是抽象类，不是我们要找的，去类里面看源码，发现 createWorker 方法返回类型是 NioWorker：</p><p>类 NioWorkerPool 源码 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5j9wfx1mj20wu0et3z8.jpg" alt="NioWorkerPool 源码" title="NioWorkerPool 源码"></p><p> 继续搜索类 NioWorker<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5jagdz1qj216t09wwg0.jpg" alt="搜索 NioWorker" title="搜索 NioWorker"></p><p>好，此时发现问题了，这个类有 2 个，居然存在两个相同的包名，但是依赖坐标不一样，所以这个隐藏的原因在于类冲突，但是并不能算是依赖冲突引起的。也就是说，NioWorker 这个类重复了，但是依赖包坐标不一样，类的包路径却是一模一样的，不会引起版本冲突问题，而在实际运行任务的时候会抛出运行时异常，所以我觉得找问题的过程很艰辛。</p><p>使用依赖树查看依赖关系，是看不到版本冲突问题的，2 个依赖都存在：<br>io.netty 依赖 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5jaxljmvj20mb05fglv.jpg" alt="io.netty 依赖" title="io.netty 依赖"></p><p>org.jboss.netty 依赖<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5jb7z4o0j20la031t8r.jpg" alt="org.jboss.netty 依赖" title="org.jboss.netty 依赖"></p><p> 于是又在网上搜索了一下，发现果然是 netty 的问题，也就是新引入的依赖包导致的，但是根本原因令人哭笑：netty 的组织结构变化，发布的依赖坐标名称变化，但是所有的类的包名称并没有变化，导致了这个错误。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 问题找到了，解决方法就简单了，移除传递依赖即可，同时也要注意以后再添加新的依赖一定要慎重，不然找问题的过程很是令人崩溃。</p><p>移除依赖 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fz5jbj046wj20g907amxa.jpg" alt="移除依赖" title="移除依赖"></p><p> 移除配置示例 <br></p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 移除引发冲突的 jar 包 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.jboss.netty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>netty<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a> 问题总结 </h1><p>1、参考：<a href="https://stackoverflow.com/questions/33573587/apache-spark-wrong-akka-remote-netty-version" target="_blank" rel="noopener">https://stackoverflow.com/questions/33573587/apache-spark-wrong-akka-remote-netty-version</a> ；</p><p>2、netty 的组织结构（影响发布的 jar 包坐标名称）变化了，但是所有的类的包名称仍然是一致的，很奇怪，导致我找问题也觉得莫名其妙，因为这不会引发版本冲突问题（但是本质上又是 2 个一模一样的类被同时使用，引发类冲突）；</p><p>3、这个错误信息挺有意思的，解决过程也很好玩，边找边学习；</p><p>4、对于这种重名的类【类的包路径名、类名】，竟然对应的 jar 包不一样，这种极其特殊的情况也可以使用插件检测出来：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt;</span><br></pre></td></tr></table></figure><p> 使用 <strong>enforcer:enforce</strong> 命令即可。</p><p>当然，这个插件还可以用来校验很多地方，例如代码中引用了 <strong>@Deprecated</strong> 的方法，也会给出提示信息，可以按照需求给插件配置需要校验的方面。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>netty</tag>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 警告：Not enough space to cache rdd in memory</title>
    <url>/2020012201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在常规的 <code>Spark</code> 任务中，出现警告：<code>Not enough space to cache rdd_0_255 in memory! (computed 8.3 MB so far)</code>，接着任务就卡住，等了很久最终 <code>Spark</code> 任务失败。排查到原因是 <code>RDD</code> 缓存的时候内存不够，无法继续处理数据，等待资源释放，最终导致假死现象。本文中的开发环境基于 <code>Spark v1.6.2</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在服务器上面执行一个简单的 <code>Spark</code> 任务，代码逻辑里面有 <code>rdd.cache ()</code> 操作，结果在日志中出现类似如下的警告：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">01:35:42.207 [Executor task launch worker-4] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_28 as it would require dropping another block from the same RDD</span><br><span class="line">01:35:42.211 [Executor task launch worker-4] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_28 in memory! (computed 340.2 MB so far)</span><br><span class="line">01:35:42.213 [Executor task launch worker-4] INFO  org.apache.spark.storage.MemoryStore - Memory use = 8.3 KB (blocks) + 4.9 GB (scratch space shared across 106 tasks (s)) = 4.9 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:35:49.104 [Executor task launch worker-0] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_15 as it would require dropping another block from the same RDD</span><br><span class="line">01:35:49.105 [Executor task launch worker-0] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_15 in memory! (computed 341.4 MB so far)</span><br><span class="line">01:35:49.105 [Executor task launch worker-0] INFO  org.apache.spark.storage.MemoryStore - Memory use = 8.3 KB (blocks) + 4.9 GB (scratch space shared across 106 tasks (s)) = 4.9 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:35:51.375 [Executor task launch worker-11] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_33 as it would require dropping another block from the same RDD</span><br><span class="line">01:35:51.375 [Executor task launch worker-11] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_33 in memory! (computed 341.4 MB so far)</span><br><span class="line">01:35:51.376 [Executor task launch worker-11] INFO  org.apache.spark.storage.MemoryStore - Memory use = 8.3 KB (blocks) + 4.9 GB (scratch space shared across 106 tasks (s)) = 4.9 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:35:52.188 [Executor task launch worker-12] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_48 as it would require dropping another block from the same RDD</span><br><span class="line">01:35:52.188 [Executor task launch worker-12] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_48 in memory! (computed 341.4 MB so far)</span><br><span class="line">01:35:52.189 [Executor task launch worker-12] INFO  org.apache.spark.storage.MemoryStore - Memory use = 8.3 KB (blocks) + 4.9 GB (scratch space shared across 106 tasks (s)) = 4.9 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:35:52.213 [Executor task launch worker-6] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_58 as it would require dropping another block from the same RDD</span><br><span class="line">01:35:52.213 [Executor task launch worker-6] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_58 in memory! (computed 342.6 MB so far)</span><br><span class="line">01:35:52.214 [Executor task launch worker-6] INFO  org.apache.spark.storage.MemoryStore - Memory use = 8.3 KB (blocks) + 4.9 GB (scratch space shared across 106 tasks (s)) = 4.9 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:35:56.619 [Executor task launch worker-2] INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_41 stored as values in memory (estimated size 378.7 MB, free 378.7 MB)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200122021258.png" alt="Storage 内存不足警告" title="Storage 内存不足警告"></p><p>看起来这只是一个警告，显示 <code>Storage</code> 内存不足，无法进行 <code>rdd.cache ()</code>，等待一段时间之后，<code>Spark</code> 任务的部分 <code>Task</code> 可以接着运行。</p><p>但是后续还是会发生同样的事情：内存不足，导致 <code>Task</code> 一直在等待，最后假死【或者说 <code>Spark</code> 任务基本卡住不动】。</p><p>里面有一个明显的提示：<code>Storage limit = 5.0 GB.</code>，也就是 <code>Storage</code> 的上限是 <code>5GB</code>。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><p> 查看业务代码，里面有一个：<code>rdd.cache ();</code> 操作，显然会占用大量的内存。</p><p>查看官方文档的配置：<a href="https://spark.apache.org/docs/1.6.2/configuration.html" target="_blank" rel="noopener">1.6.2-configuration</a> ，里面有一个重要的参数：<code>spark.storage.memoryFraction</code>，它是一个系数，决定着缓存上限的大小【基数是 <code>spark.excutor.memory</code>】。</p><blockquote><p>(deprecated) This is read only if spark.memory.useLegacyMode is enabled. Fraction of Java heap to use for Spark’s memory cache. This should not be larger than the “old” generation of objects in the JVM, which by default is given 0.6 of the heap, but you can increase it if you configure your own old generation size.</p></blockquote><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200122023358.png" alt="memoryFraction 参数" title="memoryFraction 参数"></p><p>另外还有 2 个相关的参数，读者也可以了解一下。</p><p>读者可以注意到，官方是不建议使用这个参数的，也就是不建议变更。当然如果你非要使用也是可以的，可以提高系数的值，这样的话缓存的空间就会变多。显然这样做不合理。</p><p>那有没有别的方法了呢？有！当然有。</p><p>主要是从缓存的方式入手，不要直接使用 <code>rdd.cache ()</code>，而是通过序列化 <code>RDD</code> 数据：<code>rdd.persist (StorageLevel.MEMORY_ONLY_SER)</code>，减少空间的占用，或者直接缓存一部分数据到磁盘：<code>rdd.persist (StorageLevel.MEMORY_AND_DISK)</code>，避免内存不足。</p><p>我下面演示使用后者，即直接缓存一部分数据到磁盘，当然，使用这种方式，<code>Spark</code> 任务执行速度肯定是慢了不少。</p><p>我这里测试后，得到的结果：耗时是以前的 3 倍【可以接受】。</p><p>再接着执行 <code>Spark</code> 任务，日志中还是会出现上述警告：<code>Not enough space to cache rdd in memory!</code>，但是接着会提示数据被缓存到磁盘了：<code>Persisting partition rdd_0_342 to disk instead.</code>。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">01:55:24.414 [Executor task launch worker-3] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_342 as it would require dropping another block from the same RDD</span><br><span class="line">01:55:24.414 [Executor task launch worker-3] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_342 in memory! (computed 96.8 MB so far)</span><br><span class="line">01:55:24.414 [Executor task launch worker-3] INFO  org.apache.spark.storage.MemoryStore - Memory use = 3.0 GB (blocks) + 2.0 GB (scratch space shared across 339 tasks (s)) = 5.0 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:55:24.414 [Executor task launch worker-3] WARN  org.apache.spark.CacheManager - Persisting partition rdd_0_342 to disk instead.</span><br><span class="line">01:55:33.262 [Executor task launch worker-12] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_229 as it would require dropping another block from the same RDD</span><br><span class="line">01:55:33.262 [Executor task launch worker-12] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_229 in memory! (computed 342.6 MB so far)</span><br><span class="line">01:55:33.262 [Executor task launch worker-12] INFO  org.apache.spark.storage.MemoryStore - Memory use = 3.0 GB (blocks) + 2.0 GB (scratch space shared across 339 tasks (s)) = 5.0 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:55:33.262 [Executor task launch worker-12] WARN  org.apache.spark.CacheManager - Persisting partition rdd_0_229 to disk instead.</span><br><span class="line">01:55:40.247 [Executor task launch worker-13] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_254 as it would require dropping another block from the same RDD</span><br><span class="line">01:55:40.248 [Executor task launch worker-13] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_254 in memory! (computed 18.0 MB so far)</span><br><span class="line">01:55:40.248 [Executor task launch worker-13] INFO  org.apache.spark.storage.MemoryStore - Memory use = 3.0 GB (blocks) + 2.0 GB (scratch space shared across 339 tasks (s)) = 5.0 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:55:40.248 [Executor task launch worker-13] WARN  org.apache.spark.CacheManager - Persisting partition rdd_0_254 to disk instead.</span><br><span class="line">01:56:28.062 [dispatcher-event-loop-9] INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_255 on disk on localhost:55066 (size: 146.4 MB)</span><br><span class="line">01:56:28.194 [Executor task launch worker-1] INFO  org.apache.spark.storage.MemoryStore - Will not store rdd_0_255 as it would require dropping another block from the same RDD</span><br><span class="line">01:56:28.194 [Executor task launch worker-1] WARN  org.apache.spark.storage.MemoryStore - Not enough space to cache rdd_0_255 in memory! (computed 8.3 MB so far)</span><br><span class="line">01:56:28.194 [Executor task launch worker-1] INFO  org.apache.spark.storage.MemoryStore - Memory use = 3.0 GB (blocks) + 2.0 GB (scratch space shared across 339 tasks (s)) = 5.0 GB. Storage limit = 5.0 GB.</span><br><span class="line">01:56:28.194 [Executor task launch worker-1] INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_255 locally</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200122024437.png" alt="一部分数据被缓存到磁盘" title="一部分数据被缓存到磁盘"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 综上所述，有三种方式可以解决这个问题：</p><ul><li>提高缓存空间系数：<code>spark.storage.memoryFraction</code>【或者增大 <code>spark.excutor.memory</code>，不建议】</li><li>使用序列化 <code>RDD</code> 数据的方式：<code>rdd.persist (StorageLevel.MEMORY_ONLY_SER)</code></li><li>使用磁盘缓存的方式：<code>rdd.persist (StorageLevel.MEMORY_AND_DISK)</code></li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title>VLOOKUP 函数跨工作表跨文件使用方式</title>
    <url>/2017051401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天在处理 <code>Excel</code> 文件的时候，需要使用 <code>VLOOKUP</code> 函数，感觉很方便。内心有一种掌握了一个小技巧就可以节省很多时间的骄傲感，同时，除了入门级别的使用，还进一步发现了可以跨工作表、跨文件使用这个函数，顿时觉得更加方便了。我觉得这个函数在日常工作中应该很常用，而且很好用，所以本文就记录这个函数的使用方式，以及简单介绍 <code>Excel</code> 中的函数概念。</p><p>本文中涉及的 <code>Excel</code> 文件已经被我上传至 <code>GitHub</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20170514" target="_blank" rel="noopener">Excel 示例文件 </a> ，文件名为：<code> 学生表成绩表.xlsx</code> 。</p><a id="more"></a><h1 id="基础概念介绍"><a href="# 基础概念介绍" class="headerlink" title="基础概念介绍"></a>基础概念介绍 </h1><h2 id="什么是函数"><a href="# 什么是函数" class="headerlink" title="什么是函数"></a> 什么是函数 </h2><p> 在 <code>Excel</code> 中，函数就是官方定义的一种通用公式，例如求和、求平均数、计数、查找，可以帮助用户方便快捷地处理数据。掌握了这些函数，用起来 <code>Excel</code> 才算是合格水平，有时候遇到难以处理的数据，可能使用几个公式就解决了。<code>Excel</code> 的基础功能就是存数据，然后基于这些数据再做进一步处理，此时为了方便高效，就产生了很多函数。</p><p>以下内容中提及的 <strong>函数 </strong>或者 <strong>公式 </strong>都是同一个概念。</p><h2 id="函数的优点"><a href="# 函数的优点" class="headerlink" title="函数的优点"></a>函数的优点 </h2><p> 各个行业的人使用 <code>Excel</code> 肯定有自己的感悟，以及觉得 <code>Excel</code> 某些函数特别好用，也就是可以说，一千个使用 <code>Excel</code> 函数的人眼里，有一千个函数的优点。我在这里只是泛泛地列举几个例子。</p><p>1、常用的四则运算函数完全可以替代计算器。</p><p>2、财务方面的函数可以帮助财务工作人员快速处理数据。</p><p>3、逻辑方面的函数可以处理一些简单的逻辑，即使用简单的函数脚本解决。</p><p>4、查找引用方面的函数，可以高效地进行搜索替换。</p><p>在 <code>Excel</code> 中可以看到常用的函数分类：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6xb9ba7j20nf04q0sw.jpg" alt="常用的函数分类" title="常用的函数分类"></p><h1 id="函数使用"><a href="# 函数使用" class="headerlink" title="函数使用"></a>函数使用 </h1><p> 先简单介绍一下求和函数【<code>SUM</code>】，以保证有个基本的认知。例如有一个 <code>Excel</code> 文件，有三列数字，分别是语文、数学、英语的成绩，现在需要计算每一行的第一列到第三列的和，求和结果放在第四列，也就是总成绩。</p><p>只要在第四列中，输入函数以及参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">=SUM (A2:C2)</span><br></pre></td></tr></table></figure><p>截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6y3b0lhj20d806ft8q.jpg" alt="SUM 函数基本使用方式" title="SUM 函数基本使用方式"></p><p>其中，<strong>=SUM ()</strong> 是函数名称，表示累加求和，括号里面的 <strong>A2:C2</strong> 是单元格的位置，<strong>:</strong> 表示从 <code>A2</code> 到 <code>C2</code>，总结起来就是把第二行的 <code>A</code> 列到 <code>C</code> 列的值累加求和，得出结果。</p><p>按回车键，就会触发计算，得出结果，结果存放在写有函数的那个单元格。如果需要接着计算第三行、第四行、第五行，是不需要重复输入函数以及参数的，直接选中已经有结果的单元格，鼠标的光标放在单元格右下角，光标会变成一个黑色的十字，鼠标左键长按往下拖拽即可。</p><p>选中单元格，注意观察单元格右下角的大点 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6yembmpj20dd04vdft.jpg" alt="选中单元格" title="选中单元格"></p><p> 往下拖拽，自动计算 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6yiz1c5j20de05sweg.jpg" alt="往下拖拽，自动计算" title="往下拖拽，自动计算"></p><p> 注意，使用复制下拉功能时，行号参数是会自动变化的，也就是说 <strong>每一行 </strong>的求和结果都是 <strong>当前行 </strong>的第一列到第三列的数值之和。可以任意选择一行的结果单元格，查看单元格的内容：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6ytxla3j20dj06naa3.jpg" alt="函数的行号自动变化" title="函数的行号自动变化"></p><p>那这个是怎么做到自动化的呢？其实这是 <code>Excel</code> 自带的功能，术语称为 <strong>自动填充 </strong>，不知道你有没有看到，在往下拖拽完成后，可以点开右下角的三角下拉列表，看到里面有三种模式选择，默认的就是 <strong>复制单元格 </strong>【你也可以试玩一下其它的两种模式】。<strong> 复制单元格 </strong>对于普通的单元格来说，直接复制内容，对于函数单元格来说，还会自动变更里面的参数。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6z2gx85j20fi07d0sv.jpg" alt="函数结果自动填充" title="函数结果自动填充"></p><p>结果已经完全出来，可以正常使用。另外再说一个隐藏的注意点，这种通过函数产生的结果，是不能复制粘贴到别的地方使用的，因为复制粘贴过去的内容是函数公式，不是那个计算结果值。因此如果直接复制粘贴到别的地方，它还会用这个函数计算，得到的结果就与单元格数据当前所在的地方有关，结果肯定和以前不一样，或者根本没有结果。</p><p>例如我把总成绩和姓名这两列复制粘贴到别的 <code>Excel</code> 文件里面，可以看到得到的结果都是 0，这是因为通过函数计算得出的结果就是 0，表格的第一列到第三列根本没有值。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6zexgfmj20dk06taa2.jpg" alt="直接复制函数结果没有值" title="直接复制函数结果没有值"></p><p>那怎么解决这个问题呢，其实方法是有的：复制时还是正常的复制函数，粘贴时不能默认了，要选择 <strong>粘贴为数值 </strong>，或者 <strong>选择性粘贴 </strong>。这样，粘贴结果单元格里面就是真实的数值了，函数公式已经不见了。此时的单元格就是普通的单元格，里面是文本内容，可以随意复制粘贴使用。</p><p>粘贴为数值 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6zp2tlhj20l90fx752.jpg" alt="粘贴为数值" title="粘贴为数值"></p><p> 选择性粘贴 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h6zsqu80j20op0dn756.jpg" alt="选择性粘贴" title="选择性粘贴"></p><p> 接下来介绍本文的重点：<code>VLOOKUP</code> 函数。先提前说明，<strong> 工作表 </strong>就是指 <code>Excel</code> 文件中的 <strong>Sheet</strong> 概念，新建的 <code>Excel</code> 文件一般默认有 3 个 <code>Sheet</code>。以下内容基于两份数据：学生表、成绩表。</p><h2 id="基本使用方式"><a href="# 基本使用方式" class="headerlink" title="基本使用方式"></a>基本使用方式 </h2><p><strong>VLOOKUP</strong> 是一个文本类型的函数，用来匹配搜索的。如果在单一的工作表中使用，例如根据姓名搜索总成绩，可以使用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">=VLOOKUP (H2,A:E,5,FALSE)</span><br></pre></td></tr></table></figure><p> 截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h707j1i4j20rg08zmxi.jpg" alt="VLOOKUP 基本使用方式" title="VLOOKUP 基本使用方式"></p><p>其中，<strong>VLOOKUP</strong> 是函数名称，<strong>H2</strong> 表示需要查找的数据列，<strong>A:E</strong> 表示搜索的数据范围【此时不需要指定单元格的行号】，<strong>5</strong> 表示搜索命中的的结果列，5 一定是在 <code>A:E</code> 之间，<strong>FALSE</strong> 表示关闭模糊搜索，即精确搜索。这里总结起来就是根据 <code>H2</code> 的值，在 <code>A:E</code> 之间搜索【会搜索所有的行】，如果命中了结果，把 <code>A:E</code> 之间的命中那一行的第 5 列单元格【也就是 <code>E</code> 列】的值返回，搜索时使用精确匹配。</p><p>结合上面的截图，更通俗地说，就是根据 <code>H2</code> 的姓名，在成绩表 <code>A:E</code> 的所有行中搜索同姓名的人，把命中行 <code>E</code> 列的成绩返回，匹配姓名时必须完全相等才算命中。</p><p>也可以选中结果下拉，自动填充其他人的总成绩。</p><h2 id="跨工作表使用"><a href="# 跨工作表使用" class="headerlink" title="跨工作表使用"></a>跨工作表使用 </h2><p> 上面的内容是在同一个工作表中搜索，如果是跨工作表使用怎么办呢？，例如一个 <code>Excel</code> 文件有两个工作表：学生表、成绩表，现在要根据学生表的姓名从成绩表中搜索总成绩。</p><p>其实做法也是很简单，函数都是同一个函数，只不过在指定数据范围这个参数的时候，需要加上工作表的名称：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">=VLOOKUP (A2, 成绩表！A:E,5,FALSE)</span><br></pre></td></tr></table></figure><p>成绩表信息 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h70cwm2tj20dm0n3t98.jpg" alt="成绩表信息" title="成绩表信息"></p><p> 学生表信息 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2h70g4a24j20hn0oodgj.jpg" alt="学生表信息" title="学生表信息"></p><p> 这里除了额外指定了参数 <strong>成绩表！A:E</strong> 来指定 <strong>成绩表 </strong>这个 <code>Sheet</code>，其它的参数仍旧与前面一致。</p><h2 id="跨文件使用"><a href="# 跨文件使用" class="headerlink" title="跨文件使用"></a>跨文件使用 </h2><p> 接着又有问题了，如果两个表是分开两个文件呢，聪明人已经可以想到，肯定是继续更改参数的值：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">=VLOOKUP (A2,[成绩表.xlsx] 成绩表！A:E,5,FALSE)</span><br></pre></td></tr></table></figure><p>其中，<strong>[成绩表.xlsx] 成绩表！A:E</strong> 就是用来指定文件、工作表、数据列的。</p><p>但是这里需要同时打开两个文件，这样编辑器才能找到文件的内容。这里也可以看出来，为什么在 <code>Excel</code> 中不能同时打开两个同名的文件了，因为 <code>Excel</code> 要以文件名作为一份数据的唯一标识，哪怕两份同名的文件存放在不同的目录，也会被 <code>Excel</code> 当做同一份文件。</p><p>此外，还有一个小特性，只要函数生成完毕，就可以把成绩表关闭了，不会影响已经搜索出来的结果。而且，如果继续在学生表中增加姓名，还可以继续完成搜索，也就是说 <code>Excel</code> 是把成绩表做了缓存，可以一直使用。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>VLOOKUP</tag>
        <tag>Excel</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper 日志查看</title>
    <url>/2019092001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p><code>Zookeeper</code> 是大数据组件中不可或缺的一种组件，是一个开源的分布式协调服务，提供了诸如统一命名服务、配置管理、集群管理等功能，在很多场景中都可以见到它的身影。本文简单介绍 <code>Zookeeper</code> 的日志查看，开发环境基于 <code>v3.4.6</code>。</p><a id="more"></a><h1 id="开篇"><a href="# 开篇" class="headerlink" title="开篇"></a>开篇 </h1><p><code>Zookeeper</code> 服务器会产生三类日志：<strong> 事务日志 </strong>、<strong> 快照日志 </strong> 和 <strong>log4j 日志 </strong>。</p><p>在 <code>Zookeeper</code> 默认的配置文件 <code>zoo.cfg</code>【也可以修改文件名，在 <code>bin/zkEnv.sh</code> 指定使用的配置文件】中有一个配置项 <code>dataDir</code>，该配置项用于配置 <code>Zookeeper</code> 快照日志和事务日志的存储地址。</p><p>在官方提供的默认参考配置文件 <code>zoo_sample.cfg</code> 中【解压下载的安装包后，在 <code>conf</code> 目录下可以找到】，只有 <code>dataDir</code> 配置项，配置为：<code>dataDir=/tmp/zookeeper</code>。其实在实际应用中，还可以为事务日志专门配置存储地址，配置项名称为 <code>dataLogDir</code>，在 <code>zoo_sample.cfg</code> 中并未体现出来。</p><p>在没有 <code>dataLogDir</code> 配置项的时候，<code>Zookeeper</code> 默认将事务日志文件和快照日志文件都存储在 <code>dataDir</code> 对应的目录下。但是我们建议将事务日志【<code>dataLogDir</code>】与快照日志【<code>dataDir</code>】单独配置，存储时分开存储，因为当 <code>Zookeeper</code> 集群进行频繁的数据读写操作时，会产生大量的事务日志信息，将两类日志分开存储会提高系统的性能。而且，还可以允许将两类日志存储在不同的存储介质上，减少单一的磁盘压力。</p><p>总结，<code>dataDir</code> 表示快照日志目录，<code>dataLogDir</code> 表示事务日志目录【不配置的时候事务日志目录同 <code>dataDir</code>】。</p><p>而 <code>log4j</code> 用于记录 <code>Zookeeper</code> 集群服务器运行日志，该日志的配置项在安装包解压后的 <code>conf</code> 目录下的 <code>log4j.properties</code> 文件中【这个想必很多读者都熟悉了】。在 <code>bin/zkEnv.sh</code> 文件中有使用到一个变量 <code>ZOO_LOG_DIR=.</code>，表示 <code>log4j</code> 日志文件与执行程序【<code>zkServer.sh</code>】在同一目录下，当执行 <code>zkServer.sh</code> 时，在该目录下会产生 <code>zookeeper.out</code> 日志文件；另外还有一个变量 <code>ZOO_LOG4J_PROP</code> 表示日志级别。而这些变量，都可以在 <code>conf/zookeeper-env.sh</code> 文件中提前设置好，例如：<code>export ZOO_LOG_DIR=/var/log/zookeeper</code>。</p><p>下面主要介绍 <strong>事务日志 </strong>与 <strong>快照日志 </strong>。</p><h1 id="事务日志"><a href="# 事务日志" class="headerlink" title="事务日志"></a>事务日志 </h1><p> 事务日志是指 <code>Zookeeper</code> 系统在正常运行过程中，针对所有的更新操作，在返回客户端 <strong>更新成功 </strong>的响应前，<code>Zookeeper</code> 会保证已经将本次更新操作的事务日志写到磁盘上，只有这样，整个更新操作才会生效。</p><p>根据上文所述，可以通过 <code>zoo.cfg</code> 文件中的 <code>dataLogDir</code> 配置项找到事务日志存储的路径：<code>dataLogDir=/cloud/data1/hadoop/zookeeper</code>【如果没有配置就看 <code>dataDir</code> 参数】，在 <code>dataLogDir</code> 对应的目录下存在一个文件夹 <code>version-2</code>，该文件夹中保存着所有事务日志文件，例如：<code>log.6305208d3f</code>。</p><p>事务日志文件的命名规则为 <code>log.**</code>，文件大小为 <code>64MB</code>【超过后就会生成新的事务日志文件】，<code>**</code> 表示写入该日志文件的第一个事务的 <code>ID</code>【也可以说触发该日志文件的事务】，十六进制表示。日志文件的个数与参数 <code>autopurge.snapRetainCount</code> 配置有关，默认是 3 个，本文最后也会讲到。</p><h2 id="事务日志可视化"><a href="# 事务日志可视化" class="headerlink" title="事务日志可视化"></a>事务日志可视化 </h2><p><code>Zookeeper</code> 的事务日志为二进制文件，不能通过 <code>vim</code> 等工具直接访问，其实可以通过 <code>Zookeeper</code> 自带的 <code>jar</code> 包中的工具类读取事务日志文件。</p><p> 首先将 <code>libs</code> 中的 <code>slf4j-api-1.6.1.jar</code> 文件和 <code>Zookeeper</code> 根目录下的 <code>Zookeeper-3.4.6.jar</code> 文件复制到临时文件夹 <code>tmplibs</code> 中【不复制也可以，只要明确 <code>jar</code> 包位置，引用一下即可】，然后执行如下命令，将原始事务日志内容输出至 <code>6305208d3f.log</code> 文件中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -classpath .:./slf4j-api-1.6.1.jar:./zookeeper-3.4.6.2.2.6.0-2800.jar org.apache.zookeeper.server.LogFormatter ./log.6305208d3f &gt; 6305208d3f.log</span><br></pre></td></tr></table></figure><p>实际上就是手动调用 <code>Zookeeper</code> 包里面的实现类，把二进制日志内容格式化，转换为人类可以理解的日志。<code>-classpath</code> 就是在 <code>Java</code> 中设置第三方 <code>jar</code> 包的方式。</p><p>产生可以查看的日志文件一份：<code>6305208d3f.log</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200212010141.png" alt="事务日志文件转换" title="事务日志文件转换"></p><h2 id="事务日志分析"><a href="# 事务日志分析" class="headerlink" title="事务日志分析"></a>事务日志分析 </h2><p> 声明一下，每次对 <code>Zookeeper</code> 操作导致的状态改变都会产生一个 <code>zxid</code>，即 <code>ZooKeeper Transaction Id</code>。</p><p>接着就可以挑一些日志进行简单分析一下，输出前 10 行，最好能挑到前后有关联的，例如同一个会话的打开、关闭操作。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ZooKeeper Transactional Log File with dbid 0 txnlog format version 2</span><br><span class="line">19-9-20 下午 06 时 04 分 05 秒 session 0x46d0bf6e8cc50b8 cxid 0x1 zxid 0x6305208d3f error -101</span><br><span class="line"></span><br><span class="line">19-9-20 下午 06 时 04 分 05 秒 session 0x56af0a7efa70533 cxid 0x2 zxid 0x6305208d40 closeSession null</span><br><span class="line">19-9-20 下午 06 时 04 分 05 秒 session 0x46d0bf6e8cc50b8 cxid 0x2 zxid 0x6305208d41 closeSession null</span><br><span class="line">19-9-20 下午 06 时 04 分 05 秒 session 0x56af0a7efa70534 cxid 0x3 zxid 0x6305208d42 closeSession null</span><br><span class="line">19-9-20 下午 06 时 04 分 05 秒 session 0x66af3690a390cc4 cxid 0x0 zxid 0x6305208d43 createSession 4000</span><br><span class="line"></span><br><span class="line">19-9-20 下午 06 时 04 分 05 秒 session 0x66af3690a390cc4 cxid 0x3 zxid 0x6305208d44 closeSession null</span><br><span class="line">19-9-20 下午 06 时 04 分 05 秒 session 0x76af0f5294b008c cxid 0x6c3549 zxid 0x6305208d45 setData &apos;/storm/supervisors/a7d11d05-8b97-4bc5-ad43-f43cd28f98cc,#ffffffacffffffed05737202b6261636b747970652e73746f726d2e6461656d6f6e2e636... 太长省略，2025456</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200212010948.png" alt="事务日志内容查看" title="事务日志内容查看"></p><p>第一行：<code>ZooKeeper Transactional Log File with dbid 0 txnlog format version 2</code>，这是每个事务日志文件都有的日志头，输出了 <code>dbid</code> 还有 <code>version</code>。</p><p>第二行：<code>... session 0x46d0bf6e8cc50b8 cxid 0x1 zxid 0x6305208d3f error -101</code>，这也就是具体的事务日志内容了，这里是说某一时刻有一个 <code>sessionid</code> 为 <code>0x46d0bf6e8cc50b8</code>，<code>cxid</code> 为 <code>0x1</code>，<code>zxid</code> 为 <code>0x6305208d3f</code> 的请求，但是出错了。</p><p>继续看第五行【第三行是空白】：<code>... session 0x46d0bf6e8cc50b8 cxid 0x2 zxid 0x6305208d41 closeSession null</code>，还是第二行那个 <code>sessionid</code>，请求类型为 <code>closeSession</code>，表示关闭了会话。</p><p>看第七行：<code>... session 0x66af3690a390cc4 cxid 0x0 zxid 0x6305208d43 createSession 4000</code>，这个请求是 <code>createSession</code> 类型，表示创建会话，超时时间为 4000 毫秒。</p><p>直接看第十行：<code>... session 0x76af0f5294b008c cxid 0x6c3549 zxid 0x6305208d45 setData ...</code>，请求类型是 <code>setData</code>，表示写入数据，数据内容是经过 <code>ASCII</code> 编码的。</p><h1 id="快照日志"><a href="# 快照日志" class="headerlink" title="快照日志"></a>快照日志 </h1><p><code>Zookeeper</code> 的数据在内存中是以树形结构进行存储的，而快照就是每隔一段时间会把整个 <code>DataTree</code> 的数据序列化后，存储在磁盘中，这就是 <code>Zookeeper</code> 的快照日志。</p><p><code>Zookeeper</code> 快照日志的存储路径同样可以在 <code>zoo.cfg</code> 中查看，如上文所示，访问 <code>dataDir</code> 对应的路径就可以看到 <code>version-2</code> 文件夹。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dataDir=/cloud/data1/hadoop/zookeeper</span><br></pre></td></tr></table></figure><p><code>Zookeeper</code> 快照日志文件的命名规则为 <code>snapshot.**</code>，其中 <code>**</code> 表示 <code>Zookeeper</code> 触发快照的那个瞬间，提交的最后一个事务的 <code>ID</code>，类似于前面的事务日志文件命名规则，文件示例：<code>snapshot.6501d41a74</code>。</p><h2 id="快照日志可视化"><a href="# 快照日志可视化" class="headerlink" title="快照日志可视化"></a> 快照日志可视化 </h2><p> 与事务日志文件一样，快照日志文件不可直接查看，需要通过 <code>Zookeeper</code> 为快照日志文件提供的可视化工具转换，对应的类为 <code>org.apache.zookeeper.server</code> 包中的 <code>SnapshotFormatter</code>，接下来就使用该工具转换该事务日志文件，并举例解释部分内容。</p><p>执行命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -classpath .:./slf4j-api-1.6.1.jar:./zookeeper-3.4.6.2.2.6.0-2800.jar org.apache.zookeeper.server.SnapshotFormatter ./snapshot.6501d41a74 &gt; 6501d41a74.snapshot.log</span><br></pre></td></tr></table></figure><p>把快照文件转换为普通的文本文件，结果输出到 <code>6501d41a74.snapshot.log</code> 文件中。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200212215807.png" alt="快照日志文件转换" title="快照日志文件转换"></p><h2 id="快照日志分析"><a href="# 快照日志分析" class="headerlink" title="快照日志分析"></a>快照日志分析 </h2><p> 由于快照日志文件的内容比较长，把 <code>Zookeeper</code> 的所有节点内容全部输出，主要是因为 <code>Zookeeper</code> 的目录比较多，所以只需要挑两个出来即可分析，其它目录都是类似的内容。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ZNode Details (count=26650):</span><br><span class="line">----</span><br><span class="line">/</span><br><span class="line">  cZxid = 0x00000000000000</span><br><span class="line">  ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">  mZxid = 0x00000000000000</span><br><span class="line">  mtime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">  pZxid = 0x00006401bcbf78</span><br><span class="line">  cversion = 75</span><br><span class="line">  dataVersion = 0</span><br><span class="line">  aclVersion = 0</span><br><span class="line">  ephemeralOwner = 0x00000000000000</span><br><span class="line">  dataLength = 0</span><br><span class="line">----</span><br><span class="line">/prc</span><br><span class="line">  cZxid = 0x000063029f34a0</span><br><span class="line">  ctime = Sat Jul 27 14:14:01 CST 2019</span><br><span class="line">  mZxid = 0x000063029f34a0</span><br><span class="line">  mtime = Sat Jul 27 14:14:01 CST 2019</span><br><span class="line">  pZxid = 0x000063029f34a1</span><br><span class="line">  cversion = 1</span><br><span class="line">  dataVersion = 0</span><br><span class="line">  aclVersion = 0</span><br><span class="line">  ephemeralOwner = 0x00000000000000</span><br><span class="line">  no data</span><br><span class="line">----</span><br><span class="line">... 省略很多内容 </span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200212220328.png" alt="快照日志内容查看" title="快照日志内容查看"></p><p>看到第一行：<code>ZNode Details (count=26650):</code>，表示 <code>ZNode</code> 节点的个数，我这里有 26650 个，太多了。</p><p>从 <code>----</code> 开始到下一个 <code>----</code> 结束，就是一个 <code>ZNode</code> 的信息，包含路径、创建时间、数据长度等等，下面简单说明【以上面的 <code>/prc</code> 为例】：</p><ul><li><code>/prc</code>，路径 </li><li><code>cZxid</code>，创建节点时的 <code>Zxid</code></li><li><code>ctime</code>，创建节点的时间</li><li><code>mZxid</code>，节点最近一次更新对应的 <code>Zxid</code></li><li><code>mtime</code>，节点最近一次更新的时间</li><li><code>pZxid</code>，父节点的 <code>Zxid</code></li><li><code>cversion</code>，子节点更新次数</li><li><code>dataVersion</code>，数据更新次数</li><li><code>aclVersion</code>，节点 <code>acl</code> 更新次数</li><li><code>ephemeralOwner</code>，如果节点为 <code>ephemeral</code> 节点则该值为 <code>sessionid</code>，否则为 0</li><li><code>no data</code>，表示没有数据，如果有的话会显示 <code>dataLength = xx</code>，即数据长度为 <code>xx</code></li></ul><p> 在快照文件的末尾，会有很多如下格式的内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Session Details (sid, timeout, ephemeralCount):</span><br><span class="line">0x56efad063889c37, 60000, 0</span><br><span class="line">0x1703047aa123b27, 60000, 1</span><br><span class="line">0x4701974cffc62fa, 90000, 0</span><br><span class="line">0x56efad063885c32, 90000, 0</span><br><span class="line">0x4701974cffc62fc, 90000, 0</span><br><span class="line">0x56efad063885c33, 90000, 0</span><br><span class="line">0x66f1c157df79788, 10000, 0</span><br><span class="line">0x4701974cffc62fe, 90000, 0</span><br><span class="line">0x76efad06454f9ed, 90000, 0</span><br><span class="line">0x4701974cffc62ff, 90000, 0</span><br><span class="line">... 省略很多个 </span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200212223216.png" alt="快照日志文件末尾" title="快照日志文件末尾"></p><p>这里表达的是当前抓取快照日志文件的时间，<code>Zookeeper</code> 中 <code>session</code> 的详情，第一个 <code>session</code> 的超时时间是 60000 毫秒，<code>ephemeral</code> 节点为 0；第二个 <code>session</code> 的超时时间是 60000 毫秒，<code>ephemeral</code> 节点为 1。</p><h1 id="清理机制"><a href="# 清理机制" class="headerlink" title="清理机制"></a>清理机制 </h1><p> 有两个参数，从不同维度考虑，配置在 <code>zoo.cfg</code> 文件中，实现日志文件的清理。</p><ul><li><code>autopurge.purgeInterval=24</code>，在 <code>v3.4.0</code> 及之后的版本，<code>Zookeeper</code> 提供了自动清理事务日志文件和快照日志文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个 1 或更大的整数。默认是 0，表示不开启自动清理功能</li><li><code>autopurge.snapRetainCount=30</code>，参数指定了需要保留的事务日志文件和快照日志文件的数目，默认是保留 3 个，和 <code>autopurge.purgeInterval</code> 搭配使用</li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title>es-hadoop 版本不匹配导致 discoverNodes 异常</title>
    <url>/2018052901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在业务中遇到一个由 <code>elasticsearch-hadoop</code> 版本不匹配引发的异常，然后通过查看源代码的方式分析问题、解决问题。不仅解决了业务上的问题，也对 <code>elasticsearch-hadoop</code> 的使用有了更多的了解，同时对于不同版本的 <code>Elasticsearch</code> 集群信息有了更多的认识，这些认识可以让我以后在遇到技术问题时快速定位、少走弯路。</p><p>本文涉及的开发环境：<code>Elasticsearch v1.7.5</code>、<code>Elasticsearch v2.4.5</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 业务中使用的 <code>elasticsearch-hadoop</code> 版本为 <code>v2.1.0</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt; </span><br><span class="line">  &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;elasticsearch-hadoop&lt;/artifactId&gt;  </span><br><span class="line">  &lt;version&gt;2.1.0&lt;/version&gt; </span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200225011632.png" alt="es-hadoop 依赖" title="es-hadoop 依赖"></p><p>一直都是处理 <code>Elasticsearch 1.7.5</code> 的数据，某次临时处理了 <code>Elasticsearch v2.4.5</code> 的数据，结果发现异常，<code>Spark</code> 进程无法启动：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.StringIndexOutOfBoundsException: String index out of range: -1</span><br><span class="line">at java.lang.String.substring (String.java:1967)</span><br><span class="line">at org.elasticsearch.hadoop.rest.RestClient.discoverNodes (RestClient.java:110)</span><br><span class="line">at org.elasticsearch.hadoop.rest.InitializationUtils.discoverNodesIfNeeded (InitializationUtils.java:58)</span><br><span class="line">at org.elasticsearch.hadoop.rest.RestService.findPartitions (RestService.java:227)</span><br><span class="line">at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions$lzycompute (AbstractEsRDD.scala:51)</span><br><span class="line">at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions (AbstractEsRDD.scala:50)</span><br><span class="line">at org.elasticsearch.spark.rdd.AbstractEsRDD.getPartitions (AbstractEsRDD.scala:26)</span><br><span class="line">at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply (RDD.scala:239)</span><br><span class="line">at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply (RDD.scala:237)</span><br><span class="line">at scala.Option.getOrElse (Option.scala:120)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200225011729.png" alt="异常信息" title="异常信息"></p><p>如果只看 <code>StringIndexOutOfBoundsException</code> 异常，发现就是一个普通的下标越界而已，得不到任何有用的信息，毕竟这是 <code>elasticsearch-hadoop</code> 框架抛出的，给出这样一个异常，并没有指明常见异常类型【例如网络连接问题、数据格式不对等等】，只能顺藤摸瓜去看源代码了。</p><p>再看异常栈里面有一个 <code>RestClient.discoverNodes</code> 定位，基本可以找到源代码所在位置。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><h2 id="源码查看"><a href="# 源码查看" class="headerlink" title="源码查看"></a> 源码查看 </h2><p> 直接定位到源代码位置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SuppressWarnings (&#123;&quot;rawtypes&quot;, &quot;unchecked&quot;&#125;)</span><br><span class="line">public List&lt;String&gt; discoverNodes () &#123;</span><br><span class="line">	String endpoint = &quot;_nodes/transport&quot;;</span><br><span class="line">	Map&lt;String, Map&gt; nodes = (Map&lt;String, Map&gt;) get (endpoint, &quot;nodes&quot;);</span><br><span class="line">	List&lt;String&gt; hosts = new ArrayList&lt;String&gt;(nodes.size ());</span><br><span class="line">	for (Map value : nodes.values ()) &#123;</span><br><span class="line">		String inet = (String) value.get (&quot;http_address&quot;);</span><br><span class="line">		if (StringUtils.hasText (inet)) &#123;</span><br><span class="line">			int startIp = inet.indexOf (&quot;/&quot;) + 1;</span><br><span class="line">			int endIp = inet.indexOf (&quot;]&quot;);</span><br><span class="line">			inet = inet.substring (startIp, endIp);</span><br><span class="line">			hosts.add (inet);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return hosts;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200225011754.png" alt="版本 210 源码" title="版本 210 源码"></p><p>可以看到这是一个发现节点的方法，结合异常栈里面的 <code>RestService.findPartitions</code> 可以猜测这是在读取数据前寻找节点，然后再创建连接。</p><p>异常代码是这一行，如上图红框中的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">inet = inet.substring (startIp, endIp);</span><br></pre></td></tr></table></figure><p>截取网络地址从而获取 <code>ip:port</code> 信息，出现异常，说明网络地址格式不对，以至于按照标准方法截取时出现异常。</p><p>通过代码中的 <code>_nodes/transport</code> 接口【再获取 <code>http_address</code> 的值】，我们可以自己看一下集群的信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">localhost:9202/_nodes/transport</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200225011812.png" alt="版本 245 节点信息" title="版本 245 节点信息"></p><p>可以看到 <code>http_address</code> 的值是 <code>ip:port</code> 的格式，而在源代码中是通过截取 <code>/</code>、<code>]</code> 之间的子串来确定 <code>ip:port</code> 的值，这显然会造成 <code>substring</code> 的异常【<code>startIp</code>=0，<code>endIp</code>=-1】。</p><p>其实，对于 <code>ip:port</code> 这种格式的 <code>http_address</code> ，应该直接获取值就行了，不需要截取，但是 <code>v2.1.0</code> 的 <code>elasticsearch-hadoop</code> 还无法考虑到 <code>Elasticsearch v2.4.5</code> 的节点格式，毕竟很难做到向后兼容。</p><p>那我们再回头看一下 <code>v1.7.5</code> 的 <code>Elasticsearch</code> 节点信息：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200225011936.png" alt="版本 175 节点信息" title="版本 175 节点信息"></p><p>可以看到 <code>http_address</code> 的值是 <code>inet [/ip:port]</code> 的格式，这个刚好可以被源码处理。</p><p>总而言之，<code>v2.1.0</code> 的 <code>elasticsearch-hadoop</code> 无法正确读取处理 <code>Elasticsearch v2.4.5</code> 的节点信息，所以也就无法处理数据了。</p><h2 id="升级版本"><a href="# 升级版本" class="headerlink" title="升级版本"></a>升级版本 </h2><p> 解决方案也很简单，直接升级 <code>elasticsearch-hadoop</code> 的版本即可，找到适配 <code>Elasticsearch v2.4.5</code> 的，那干脆配置一个一样的版本：<code>v2.4.5</code>。</p><p>不妨也来看一看它的源码是怎样的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SuppressWarnings (&#123; &quot;rawtypes&quot;, &quot;unchecked&quot; &#125;)</span><br><span class="line">public List&lt;String&gt; discoverNodes () &#123;</span><br><span class="line">	String endpoint = &quot;_nodes/transport&quot;;</span><br><span class="line">	Map&lt;String, Map&gt; nodes = (Map&lt;String, Map&gt;) get (endpoint, &quot;nodes&quot;);</span><br><span class="line">	List&lt;String&gt; hosts = new ArrayList&lt;String&gt;(nodes.size ());</span><br><span class="line">	for (Map value : nodes.values ()) &#123;</span><br><span class="line">		String inet = (String) value.get (&quot;http_address&quot;);</span><br><span class="line">		if (StringUtils.hasText (inet)) &#123;</span><br><span class="line">			hosts.add (StringUtils.parseIpAddress (inet).toString ());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return hosts;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200225011953.png" alt="版本 245 源码 1" title="版本 245 源码 1"></p><p>可以看到，源码单独重新写了一个方法处理 <code>ip:port</code> 的信息，想必是考虑了多种情况，接着往下看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static IpAndPort parseIpAddress (String httpAddr) &#123;</span><br><span class="line">	//strip ip address - regex would work but it&apos;s overkill</span><br><span class="line">	//there are four formats - ip:port, hostname/ip:port or [/ip:port] and [hostname/ip:port]</span><br><span class="line">	//first the ip is normalized</span><br><span class="line">	if (httpAddr.contains (&quot;/&quot;)) &#123;</span><br><span class="line">		int startIp = httpAddr.indexOf (&quot;/&quot;) + 1;</span><br><span class="line">		int endIp = httpAddr.indexOf (&quot;]&quot;);</span><br><span class="line">		if (endIp &lt; 0) &#123;</span><br><span class="line">			endIp = httpAddr.length ();</span><br><span class="line">		&#125;</span><br><span class="line">		if (startIp &lt; 0) &#123;</span><br><span class="line">			throw new EsHadoopIllegalStateException (&quot;Cannot parse http address &quot; + httpAddr);</span><br><span class="line">		&#125;</span><br><span class="line">		httpAddr = httpAddr.substring (startIp, endIp);</span><br><span class="line">	&#125;</span><br><span class="line">	//then split</span><br><span class="line">	int portIndex = httpAddr.lastIndexOf (&quot;:&quot;);</span><br><span class="line">	if (portIndex &gt; 0) &#123;</span><br><span class="line">		String ip = httpAddr.substring (0, portIndex);</span><br><span class="line">		int port = Integer.valueOf (httpAddr.substring (portIndex + 1));</span><br><span class="line">		return new IpAndPort (ip, port);</span><br><span class="line">	&#125;</span><br><span class="line">	return new IpAndPort (httpAddr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200225012005.png" alt="版本 245 源码 2" title="版本 245 源码 2"></p><p>果然，考虑周全，一共四种情况全部考虑到。这样的话，就可以利用 <code>elasticsearch-hadoop v2.4.5</code> 愉快地处理各种版本的 <code>Elasticsearch</code> 集群里面的数据了。</p><h2 id="多版本小技巧"><a href="# 多版本小技巧" class="headerlink" title="多版本小技巧"></a>多版本小技巧 </h2><p> 在 <code>Maven</code> 项目中，如果的确需要应对多版本的 <code>Elasticsearch</code> 环境，而又不能同时依赖两个版本的 <code>elasticsearch-hadoop</code> 包，那怎么办呢，总不能写两套代码吧，或者至少需要两份 <code>pom.xml</code> 文件。</p><p>其实，大可不必，<code>Maven</code> 中有非常好用的 <code>profile</code> 功能，可以在编译打包时动态指定激活哪一份配置。</p><p>在 <code>pom.xml</code> 中设置全局变量：<code>elastisearch.hadoop.version</code>，默认值为 <code>2.1.0</code>，在指定 <code>elasticsearch-hadoop</code> 依赖版本时直接使用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 全局变量 </span><br><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;elastisearch.hadoop.version&gt;2.1.0&lt;/elastisearch.hadoop.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line"> 直接使用 </span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;elasticsearch-hadoop&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;$&#123;elastisearch.hadoop.version&#125;&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>这样的话打包时使用的是 <code>elasticsearch-hadoop v2.1.0</code>。</p><p>如果接着利用 <code>profile</code> 功能【一般加载线上环境、测试环境的配置文件时也会用到这个特性】，在 <code>pom.xml</code> 中配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;profiles&gt;</span><br><span class="line">    &lt;profile&gt;</span><br><span class="line">        &lt;id&gt;es-245&lt;/id&gt;</span><br><span class="line">        &lt;properties&gt;</span><br><span class="line">            &lt;elastisearch.hadoop.version&gt;2.4.5&lt;/elastisearch.hadoop.version&gt;</span><br><span class="line">        &lt;/properties&gt;</span><br><span class="line">    &lt;/profile&gt;</span><br><span class="line">&lt;/profiles&gt;</span><br></pre></td></tr></table></figure><p>它其实就是更改了 <code>elastisearch.hadoop.version</code> 变量的值，但是需要编译打包时激活才会有效，编译打包时使用 <code>-P</code> 参数指定配置对应的 <code>id</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn clean compile package -P es-245</span><br></pre></td></tr></table></figure><p>表示激活 <code>es-245</code> 这个配置，那么 <code>elastisearch.hadoop.version</code> 变量的值就变为 <code>2.4.5</code> 了，则对应的依赖版本也就是它了，灵活好用。</p><h1 id="等价的依赖"><a href="# 等价的依赖" class="headerlink" title="等价的依赖"></a>等价的依赖 </h1><p> 另外还有一种 <code>elasticsearch-spark</code> 依赖，它和 <code>elasticsearch-hadoop</code> 一样，添加了对 <code>Elasticsearch</code> 并发处理的支持扩展，并且它们大部分的源码是一样的，只不过对于 <code>Spark SQL</code> 的版本支持不一致。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt; </span><br><span class="line">  &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;elasticsearch-spark_2.10&lt;/artifactId&gt;  </span><br><span class="line">  &lt;version&gt;2.1.0&lt;/version&gt; </span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200224011208.png" alt="es-spark 依赖" title="es-spark 依赖"></p><p>看官网说明是为了支持 <code>spark SQL</code> 的，链接：<a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html" target="_blank" rel="noopener">Supported Spark SQL versions</a> 。</p><blockquote><p>Spark SQL while becoming a mature component, is still going through significant changes between releases. Spark SQL became a stable component in version 1.3, however it is not backwards compatible with the previous releases. Further more Spark 2.0 introduced significant changed which broke backwards compatibility, through the Dataset API. elasticsearch-hadoop supports both version Spark SQL 1.3-1.6 and Spark SQL 2.0 through two different jars: elasticsearch-spark-1.x-\<version>.jar and elasticsearch-hadoop-\<version>.jar support Spark SQL 1.3-1.6 (or higher) while elasticsearch-spark-2.0-\<version>.jar supports Spark SQL 2.0. In other words, unless you are using Spark 2.0, use elasticsearch-spark-1.x-\<version>.jar</version></version></version></version></p></blockquote><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 最好还是升级 <code>elasticsearch-hadoop</code> 版本与 <code>Elasticsearch</code> 保持一致，例如升级到 <code>v2.4.5</code>【与 <code>Elasticsearch</code> 版本保持一致】。</p><p>但是，<code>v2.4.5</code> 版本的 <code>elasticsearch-hadoop</code> 自有它的坑【是很严重的 <code>bug</code>】，那就是它在处理数据时，会过滤掉中文的字段，导致读取中文字段丢失，影响中间的 <code>ETL</code> 处理逻辑。而如果数据处理完成后，再写回去原来的 <code>Elasticsearch</code> 索引就悲剧了，采用 <code>index</code> 方式会覆盖数据，导致中文字段全部丢失；采用 <code>update</code> 方式不会导致数据覆盖。</p><p>中文字段丢失问题，只针对某些版本，关于此问题的踩坑记录可以参考我的另外一篇博客：<a href="https://www.playpi.org/2017102301.html">es-hadoop 读取中文字段丢失问题</a> 。</p><p><code>Elasticsearch-hadoop v5.x</code> 版本分散了依赖包的功能，单独拆分出来 <code>elasticsearch-rest-client</code> 用于请求相关的功能，类的包名也变为了 <code>org.elasticsearch.rest</code>。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
        <tag>elasticsearch-hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>es-hadoop 遇上 Elasticsearch 的 Date 类型字段</title>
    <url>/2018041801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近在项目中遇到一个由 <code>Elasticsearch</code> 版本差异引起的奇怪现象，导致程序异常，一开始还以为是程序的问题，后来排查发现是由 <code>Elasticsearch</code> 的 <code>Date</code> 类型字段引起的，本文记录解决过程。开发环境基于 <code>Elasticsearch v1.7.5</code>、<code>Elasticsearch v2.4.5</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 业务场景是利用 <code>es-hadoop</code> 官方工具包读取 <code>Elasticsearch</code> 数据，进行一连串 <code>ETL</code> 处理，最后再写入 <code>Elasticsearch</code> 中。某一次照常处理一批数据，发现异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.IllegalArgumentException: 2017/07/23</span><br><span class="line">... 省略 </span><br><span class="line">org.elasticsearch.hadoop.util.DateUtils.parseDateJdk (DateUtils.java:62)</span><br><span class="line">org.elasticsearch.hadoop.serailization.builder.JdkValueReader.parseDate (JdkValueReader:351)</span><br><span class="line">... 省略 </span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215180154.png" alt="异常信息" title="异常信息"></p><p>这导致 <code>Spark</code> 进程没有起来，程序退出。通过上面的异常可以明确看到日期转换的错误，无法转换日期为 <code>2017/07/23</code> 的数据，下面还有好几个类似的异常，进一步推断是无法转换 <code>yyyy/MM/dd</code> 格式的日期。</p><p>查看 <code>Elasticsearch</code> 的索引 <code>mapping</code> 定义，可以看到有一个 <code>publish_date</code> 字段的类型为 <code>Date</code>，并且设置了自定义格式 <code>yyyy/MM/dd HH:mm:ss||yyyy/MM/dd</code>，可以合理对应出现这种现象的数据。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215180503.png" alt="publish_date 字段" title="publish_date 字段"></p><p>看来是这个 <code>Date</code> 类型的字段导致了这个异常，我又翻看了以前的成功任务记录，发现它们处理的数据也有 <code>publish_date</code> 字段，但是字段类型是 <code>long</code>，存储的是秒级时间戳，所以不会有这个问题。</p><p>我又仔细检查了一下线上环境，才发现线上的 <code>Elasticsearch</code> 版本升级了【部分业务使用了新的 <code>Elasticsearch</code> 集群】，升级为 <code>v2.4.5</code>，而以前是 <code>v1.7.5</code>，目前处于两者共存的状态，估计以后会逐渐升级。</p><p>好，目前把业务场景排查清楚了，接下来准备解决问题。</p><h1 id="分析解决"><a href="# 分析解决" class="headerlink" title="分析解决"></a>分析解决 </h1><p> 先查看一下源码【基于 <code>elasticsearch-hadoop v2.1.0</code>】，看看转换逻辑，可以发现，源码中能解析的是国际标准格式的日期，例如：<code>2018-02-07T05:01:05+08:00</code>【<code>ISO date</code>】，里面带着时区，而现在我们这种 <code>2017/07/23</code> 字符串格式的格式化日期，不能被解析。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static Calendar parseDateJdk (String value) &#123;</span><br><span class="line">    //check for colon in the time offset</span><br><span class="line">    int timeZoneIndex = value.indexOf (&quot;T&quot;);</span><br><span class="line">    if (timeZoneIndex &gt; 0) &#123;</span><br><span class="line">        int sign = value.indexOf (&quot;+&quot;, timeZoneIndex);</span><br><span class="line">        if (sign &lt; 0) &#123;</span><br><span class="line">            sign = value.indexOf (&quot;-&quot;, timeZoneIndex);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // +4 means it&apos;s either hh:mm or hhmm</span><br><span class="line">        if (sign &gt; 0) &#123;</span><br><span class="line">            // +3 points to either : or m</span><br><span class="line">            int colonIndex = sign + 3;</span><br><span class="line">            // +hh - need to add :mm</span><br><span class="line">            if (colonIndex &gt;= value.length ()) &#123;</span><br><span class="line">                value = value + &quot;:00&quot;;</span><br><span class="line">            &#125;</span><br><span class="line">            else if (value.charAt (colonIndex) != &apos;:&apos;) &#123;</span><br><span class="line">                value = value.substring (0, colonIndex) + &quot;:&quot; + value.substring (colonIndex);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return DatatypeConverter.parseDateTime (value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215190242.png" alt="源码查看" title="源码查看"></p><p>那怎么办呢，再通过查看文档，发现有一个 <code>elasticsearch-hadoop</code> 参数可以控制日期类型数据的解析与否，参数名称为：<code>es.mapping.date.rich</code>，默认为 <code>true</code>，表示自动转换 <code>Date</code> 类型的字段，如上面的源码，会尝试解析为 <code>Calendar</code> 格式。</p><p>但是遇到格式错误的日期取值就抛出异常了，此时可以把这个选项关掉，设置为 <code>false</code>，不自动转换，而是直接读取字符串的格式，对字段的校验处理由我们业务的 <code>ETL</code> 进行，遇到的不合法的格式直接丢弃并记录就行，不影响整个程序的运行。</p><p>下图可以看到源码的解析流程，受到 <code>richDate</code> 参数的控制。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215191343.png" alt="源码查看" title="源码查看"></p><p>注意，这个参数需要 <code>elasticsearch-hadoop</code> 的支持，例如 <code>v1.x</code> 就不行，必须使用 <code>v2.x</code> 或者以上版本。</p><p>同时，如果不想更改配置，还有另外一种解决方案，使用 <code>es.read.field.include</code> 参数指定必要的某些字段【不包含 <code>publish_date</code> 字段】，这样读取数据时就不会把 <code>publish_date</code> 字段读取出来了，也就不会涉及格式转换问题。但是此时需要确保处理完成后的数据不会再写回原来的索引，否则会导致数据被覆盖，<code>publish_date</code> 字段就会丢失，如果非要写回原来的索引，写入方式使用 <code>update</code> 而不是 <code>index</code>。</p><h1 id="扩展"><a href="# 扩展" class="headerlink" title="扩展"></a>扩展 </h1><p> 那如果 <code>Elasticsearch</code> 里面存储的是毫秒时间戳格式的日期，<code>elasticsearch-hadoop</code> 在读取时又是如何处理的呢？下面来验证一下。</p><p>首先，在测试的索引里面写入一些测试数据，有一个字段是毫秒时间戳格式：<code>publish_timestamp</code>，从 <code>Elasticsearch</code> 中挑选 1 条数据如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 6,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 80,</span><br><span class="line">    &quot;successful&quot;: 80,</span><br><span class="line">    &quot;skipped&quot;: 0,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 1,</span><br><span class="line">    &quot;max_score&quot;: 11.363798,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;ds-banyan-newsforum-post-year-2019-v3&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;post&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;ae75c92981148654195408f9f5260930&quot;,</span><br><span class="line">        &quot;_score&quot;: 11.363798,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;id&quot;: &quot;ae75c92981148654195408f9f5260930&quot;,</span><br><span class="line">          &quot;url&quot;: &quot;https://fxhh.jd.com/detail.html?id=226608850&quot;,</span><br><span class="line">          &quot;publish_timestamp&quot;: 1575129850000</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215184320.png" alt="查看测试数据" title="查看测试数据"></p><p>配置 <code>pom.xml</code> 文件，引入 <code>v2.4.5</code> 的 <code>elasticsearch-hadoop</code> 依赖。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 2.4.5 版本获取 Node 过程兼容了 2.1.0 版本，但是读取 ES 数据中文字段会丢失 --&gt;</span><br><span class="line">&lt;elasticsearch-hadoop.version&gt;2.4.5&lt;/elasticsearch-hadoop.version&gt;</span><br><span class="line"></span><br><span class="line">        &lt;!-- es-spark, 要指定 es-hadoop 新版本 --&gt;</span><br><span class="line">        &lt;!-- 以下 2 个依赖包都需要 --&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;elasticsearch-hadoop&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;elasticsearch-hadoop.version&#125;&lt;/version&gt;</span><br><span class="line">            &lt;!-- 必须移除，与 spark-core_2.10 里面有冲突 --&gt;</span><br><span class="line">            &lt;exclusions&gt;</span><br><span class="line">                &lt;exclusion&gt;</span><br><span class="line">                    &lt;groupId&gt;com.esotericsoftware&lt;/groupId&gt;</span><br><span class="line">                    &lt;artifactId&gt;kryo&lt;/artifactId&gt;</span><br><span class="line">                &lt;/exclusion&gt;</span><br><span class="line">            &lt;/exclusions&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;4.0.1&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>测试程序的逻辑就是一个简单的读取数据、<code>ETL</code> 处理流程。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JavaPairRDD&lt;String, Map&lt;String, Object&gt;&gt; esRDD = JavaEsSpark.esRDD (jsc, sparkConf);</span><br></pre></td></tr></table></figure><p>在 <code>ETL</code> 处理时会取出 <code>publish_timestamp</code> 字段进行使用，我们可以本地 <code>debug</code> 查看它的取值。</p><p>默认情况下，<code>es.mapping.date.rich</code> 是开启的【取值为 <code>true</code>，自动转换日期字段】，本地 <code>debug</code>，查看 <code>publish_timestamp</code> 字段的取值，可以发现已经被转为了 <code>Java</code> 中的 <code>Date</code> 类型【取值 <code>Sun Dec 01 00:04:10 CST 2019</code>】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215191943.png" alt="转为 Date 类型" title="转为 Date 类型"></p><p>接着关闭 <code>es.mapping.date.rich</code>，本地 <code>debug</code>，查看 <code>publish_timestamp</code> 字段的取值，可以发现仍旧是毫秒时间戳【取值为 <code>1575129850000</code>】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215192158.png" alt="仍旧是时间戳格式" title="仍旧是时间戳格式"></p><p>把这个毫秒时间戳转为格式化日期，可以看到取值是 <code>Sun Dec 1 00:04:10 CST 2019</code>，与上面的 <code>debug</code> 结果一致。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200215192346.png" alt="格式化时间戳" title="格式化时间戳"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 关于 <code>elasticsearch-hadoop</code> 版本的选择，需要慎重，不仅要考虑匹配 <code>Elasticsearch</code> 环境的版本，还要注意一些坑。</p><p>例如，如果 <code>Elasticsearch</code> 版本为 <code>v2.4.5</code>，而使用 <code>elasticsearch-hadoop</code> 的版本为 <code>v2.1.0</code>，此时还无法完美支持 <code>Date</code> 字段，进而会导致程序异常，原因就是无法处理 <code>Date</code> 类型的字段，配置参数 <code>es.mapping.date.rich</code> 可以关闭转换逻辑。</p><p>此外最好还是升级 <code>elasticsearch-hadoop</code> 版本与 <code>Elasticsearch</code> 保持一致，例如升级到 <code>v2.4.5</code>【与 <code>Elasticsearch</code> 版本保持一致】。</p><p>但是，<code>v2.4.5</code> 版本的 <code>elasticsearch-hadoop</code> 自有它的坑【是很严重的 <code>bug</code>】，那就是它在处理数据时，会过滤掉中文的字段，导致读取中文字段丢失，影响中间的 <code>ETL</code> 处理逻辑。而如果数据处理完成后，再写回去原来的 <code>Elasticsearch</code> 索引就悲剧了，采用 <code>index</code> 方式会覆盖数据，导致中文字段全部丢失；采用 <code>update</code> 方式不会导致数据覆盖。</p><p>中文字段丢失问题，只针对某些版本，关于此问题的踩坑记录可以参考我的另外一篇博客：<a href="https://www.playpi.org/2017102301.html">es-hadoop 读取中文字段丢失问题</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Hadoop</tag>
        <tag>Date</tag>
      </tags>
  </entry>
  <entry>
    <title>一个诡异的 ES-Hadoop 问题</title>
    <url>/2019061301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近在处理 Elasticsearch 数据的时候，使用的是 ES-Hadoop 组件，方便快捷，但是今天遇到一个小问题，让我着实折腾了一番。折腾的原因在于我本以为一切顺利，确实没想到会有一些奇怪的事情发生，这也让我积累了经验，其中错误的核心内容为：<code>Incompatible types found in multi-mapping: Field [your_field] has conflicting types</code>，本文详细记录分析问题的过程，文中内容涉及的开发环境为 <code>Elasticsearch v5.6.8</code>、<code>Windows7 X64</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 代码的逻辑很简单，使用 Spark 连接 Elasticsearch 集群【使用 ES-Hadoop 组件】，读取数据，然后简单处理一下就写入 HDFS 中，没有任何复杂的逻辑。但是在程序运行的过程中，出现了异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Incompatible types found in multi-mapping: Field [query.bool.must.match.content] has conflicting types of [OBJECT] and [KEYWORD].</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619230522.png" alt="异常信息日志" title="异常信息日志"></p><p>根据图中的异常信息，可以猜测是字段问题：类型冲突，下面来逐步分析。</p><h1 id="问题分析"><a href="# 问题分析" class="headerlink" title="问题分析"></a>问题分析 </h1><p> 看起来是存在不兼容的 <code>type</code>，根本原因是字段类型冲突，一个字段同时存在两种类型：OBJECT、KEYWORD，但是这个字段名称也太诡异了：<code>query.bool.must.match.content</code>，不用说，肯定是有人在查询时误把查询语句作为数据 <code>put</code> 到了 Elasticsearch 数据库中，导致产生了这种奇怪的字段名称，去数据库查询一下就知道。</p><h2 id="查询数据量"><a href="# 查询数据量" class="headerlink" title="查询数据量"></a>查询数据量 </h2><p> 由于从异常信息中无法得知其它有效信息，只能使用 <code>exists</code> 查询语句，看看有几条这种数据，查询语句如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;exists&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;query.bool.must.match.content&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619230502.png" alt="查询数据结果" title="查询数据结果"></p><p>通过查询，可以看到有一条数据，这一看就是一条标准的查询语句，被作为数据存入了 Elasticsearch 数据库，应该是有人误操作。</p><p>可以看到，整个索引别名【底下可能会有多个真实索引名称】里面只有这一条数据，那为什么会冲突呢？其实，不能只看数据量，因为可能数据被删除了，但是 <code>mapping</code> 中仍旧保留着字段信息【Elasticsearch 的 <code>mapping</code> 无法针对字段粒度进行删除、更新】，所以要进一步查看索引别名下面的每个真实索引名称对应的 <code>mapping</code> 中是不是都有这个字段。因此，直接查看 <code>mapping</code> 更为准确。</p><h2 id="查看索引配置"><a href="# 查看索引配置" class="headerlink" title="查看索引配置"></a>查看索引配置 </h2><p> 这里需要特别注意一个问题，现在很多索引的 <code>mapping</code> 都是使用 <strong>匹配模版 </strong>构造的，即定义了一些规则【例如字段名称以什么开头、以什么结尾就会存储成对应的类型】，然后字段都以这些规则自动生成，例如如果写入一条数据，里面的内容字段以 <code>_content</code> 结尾，则会自动分词，方便检索。这种方式的好处是可以综合考虑多种情况，提前全部设置为模版，不仅管理起来方便，也为以后的字段扩展留下余地。</p><p>一般的模版信息格式如下，了解一下即可：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">        &quot;your_index_name&quot;: &#123;</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">                &quot;excludes&quot;: [</span><br><span class="line">                    &quot;content&quot;,</span><br><span class="line">                    &quot;author&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;dynamic_templates&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;template_1&quot;: &#123;</span><br><span class="line">                        &quot;mapping&quot;: &#123;</span><br><span class="line">                            &quot;index&quot;: &quot;not_analyzed&quot;,</span><br><span class="line">                            &quot;type&quot;: &quot;string&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;match&quot;: &quot;*&quot;,</span><br><span class="line">                        &quot;match_mapping_type&quot;: &quot;string&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;content1&quot;: &#123;</span><br><span class="line">                        &quot;mapping&quot;: &#123;</span><br><span class="line">                            &quot;analyzer&quot;: &quot;wordsEN&quot;,</span><br><span class="line">                            &quot;type&quot;: &quot;text&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;match&quot;: &quot;*_content&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;price&quot;: &#123;</span><br><span class="line">                        &quot;mapping&quot;: &#123;</span><br><span class="line">                            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;match&quot;: &quot;*_price&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619230438.png" alt="查看模版信息" title="查看模版信息"></p><p>模版里面的内容其实是一个 JSON 数组，可以设置多个匹配规则，方便字段的规范管理。</p><p>接着使用 <code>head</code> 插件查看 <code>mapping</code>，把几个真实的索引下面的 <code>mapping</code> 都检查了一遍【一共四个】，只在两个索引下面找到了期望的 <code>mapping</code> 信息，如下：</p><p>第一处：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">                &quot;bool&quot;: &#123;</span><br><span class="line">                    &quot;properties&quot;: &#123;</span><br><span class="line">                        &quot;must&quot;: &#123;</span><br><span class="line">                            &quot;properties&quot;: &#123;</span><br><span class="line">                                &quot;match&quot;: &#123;</span><br><span class="line">                                    &quot;properties&quot;: &#123;</span><br><span class="line">                                        &quot;content&quot;: &#123;</span><br><span class="line">                                            &quot;properties&quot;: &#123;</span><br><span class="line">                                                &quot;query&quot;: &#123;</span><br><span class="line">                                                    &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">                                                &#125;,</span><br><span class="line">                                                &quot;type&quot;: &#123;</span><br><span class="line">                                                    &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">                                                &#125;</span><br><span class="line">                                            &#125;</span><br><span class="line">                                        &#125;</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;,</span><br><span class="line">                                &quot;range&quot;: &#123;</span><br><span class="line">                                    &quot;properties&quot;: &#123;</span><br><span class="line">                                        &quot;publish_date&quot;: &#123;</span><br><span class="line">                                            &quot;properties&quot;: &#123;</span><br><span class="line">                                                &quot;from&quot;: &#123;</span><br><span class="line">                                                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                                                &#125;,</span><br><span class="line">                                                &quot;include_lower&quot;: &#123;</span><br><span class="line">                                                    &quot;type&quot;: &quot;boolean&quot;</span><br><span class="line">                                                &#125;,</span><br><span class="line">                                                &quot;include_upper&quot;: &#123;</span><br><span class="line">                                                    &quot;type&quot;: &quot;boolean&quot;</span><br><span class="line">                                                &#125;,</span><br><span class="line">                                                &quot;to&quot;: &#123;</span><br><span class="line">                                                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                                                &#125;</span><br><span class="line">                                            &#125;</span><br><span class="line">                                        &#125;</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619230357.png" alt="第一处 mapping" title="第一处 mapping"></p><p>第二处：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">                &quot;bool&quot;: &#123;</span><br><span class="line">                    &quot;properties&quot;: &#123;</span><br><span class="line">                        &quot;must&quot;: &#123;</span><br><span class="line">                            &quot;properties&quot;: &#123;</span><br><span class="line">                                &quot;match&quot;: &#123;</span><br><span class="line">                                    &quot;properties&quot;: &#123;</span><br><span class="line">                                        &quot;content&quot;: &#123;</span><br><span class="line">                                            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">                                        &#125;</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;,</span><br><span class="line">                                &quot;term&quot;: &#123;</span><br><span class="line">                                    &quot;properties&quot;: &#123;</span><br><span class="line">                                        &quot;site_id&quot;: &#123;</span><br><span class="line">                                            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">                                        &#125;</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619230345.png" alt="第二处 mapping" title="第二处 mapping"></p><p>虽然只找到了两处，但是足够造成前面的异常，通过对比可以发现其中的细微不同之处，核心的地方在于 <code>content</code> 的类型不一致，对比如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- OBJECT</span><br><span class="line">&#123;</span><br><span class="line">    &quot;content&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;query&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;type&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">-- KEYWORD</span><br><span class="line">&#123;</span><br><span class="line">    &quot;content&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好了，破案了，问题根本原因被找到，那么怎么解决呢？</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 直接查看源码，先看看 ES-Hadoop 是怎么处理的，根据异常信息里面的方法调用，主要就是看 <code>MappingSet.addToFieldTable ()</code>，我的环境依赖的 ES-Hadoop 坐标为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;elasticsearch-hadoop&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;5.6.8&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>我查询到的源代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SuppressWarnings (&quot;unchecked&quot;)</span><br><span class="line">    private static void addToFieldTable (Field field, String parent, Map&lt;String, Object []&gt; fieldTable) &#123;</span><br><span class="line">	String fullName = parent + field.name ();</span><br><span class="line">	Object [] entry = fieldTable.get (fullName);</span><br><span class="line">	if (entry == null) &#123;</span><br><span class="line">		// Haven&apos;t seen field yet.</span><br><span class="line">		if (FieldType.isCompound (field.type ())) &#123;</span><br><span class="line">			//visit its children</span><br><span class="line">			Map&lt;String, Object []&gt; subTable =  new LinkedHashMap&lt;String, Object []&gt;();</span><br><span class="line">			entry = new Object []&#123;field, subTable&#125;;</span><br><span class="line">			String prefix = fullName + &quot;.&quot;;</span><br><span class="line">			for (Field subField : field.properties ()) &#123;</span><br><span class="line">				addToFieldTable (subField, prefix, subTable);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			//note that we saw it</span><br><span class="line">			entry = new Object []&#123;field&#125;;</span><br><span class="line">		&#125;</span><br><span class="line">		fieldTable.put (fullName, entry);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		// We&apos;ve seen this field before.</span><br><span class="line">		Field previousField = (Field) entry [0];</span><br><span class="line">		//ensure that it doesn&apos;t conflict</span><br><span class="line">		if (!previousField.type ().equals (field.type ())) &#123;</span><br><span class="line">			throw new EsHadoopIllegalArgumentException (&quot;Incompatible types found in multi-mapping: &quot; +</span><br><span class="line">			                        &quot;Field [&quot;+fullName+&quot;] has conflicting types of [&quot;+previousField.type ()+&quot;] and [&quot;+</span><br><span class="line">			                        field.type ()+&quot;].&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">		// If it does not conflict, visit it&apos;s children if it has them</span><br><span class="line">		if (FieldType.isCompound (field.type ())) &#123;</span><br><span class="line">			Map&lt;String, Object []&gt; subTable = (Map&lt;String, Object []&gt;) entry [1];</span><br><span class="line">			String prefix = fullName + &quot;.&quot;;</span><br><span class="line">			for (Field subField : field.properties ()) &#123;</span><br><span class="line">				addToFieldTable (subField, prefix, subTable);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190619230307.png" alt="源代码片段" title="源代码片段"></p><p>看到这里就没有什么办法了，因为 Elasticsearch 数据不规范【本来是正常的，后来人为因素破坏了 <code>mapping</code> 数据结构】，导致 ES-Hadoop 无法处理，从而抛出异常。</p><p>但是，仔细思考一下，ES-Hadoop 的这种处理逻辑显然有点问题，因为客户端在读取数据的时候，可以指定同一个索引下的多个类型，当然，也可以同时指定多个索引。然而，有时候为了方便，会把很多索引的别名设置成同一个，这样在查询或者取数的时候就不用指定索引名称的列表了。</p><p>如果是这样，多个索引下面的 <code>mapping</code> 不能保证一致，由于是手动设置的索引别名，索引数据可能多种多样【另一层面的知识点，Elasticsearch 官方是不允许同一个索引下的多个类型拥有不同的字段属性的，而且，6.x 取消了索引类型的概念】，但是客户端在读取数据的时候是可以过滤字段的，使用 <code>es.read.field.include</code>、<code>es.read.field.exclude</code> 参数分别设置必要的字段、过滤的字段。这样的话，开发者就可以把可能有问题的字段去除掉，避免影响程序的正常运行。然而可以看到，ES-Hadoop 没有给任何机会，遇到类型冲突的字段直接抛出异常，程序无法正常运行。</p><p>我觉得应该在日志中给出警告，提醒开发者可能出现的问题，但是程序仍旧可以正常运行，在运行的过程中，如果真的遇到字段冲突的问题【例如同时读取了不同索引中的相同字段，但是字段类型不一致，无法处理】，程序自会抛出运行时异常，而如果从头至尾没有任何字段问题，程序就可以正常运行了，开发者甚至毫无感知发生了什么。</p><p>于是，接着我找到一个 GitHub 的讨论帖子：<br><a href="https://github.com/elastic/elasticsearch-hadoop/issues/1074" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch-hadoop/issues/1074</a>、<br><a href="https://github.com/elastic/elasticsearch-hadoop/issues/1192" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch-hadoop/issues/1192</a>，<br>发现早就有人遇到同样的问题了，并且提出了建议，作者也把它作为开发特性，计划在以后的版本发布。目前来看，应该在 v6.4.2、v6.5.0 修复了这个问题，但是我使用的还是 v5.6.8，而且在帖子中也可以看到一些人同样是 v5.6.0、v5.6.1、v5.6.5 版本有问题。此时，我要么升级版本，要么更改源码，要么重建数据源，这些方式对于我来说都有未知的风险，我陷入了沉思。</p><p>突然，一阵灵光闪现，我觉得可以适当降低小版本号，可能以前 ES-Hadoop 是没有这个限制的，以防走弯路，同时我又参考了别的项目代码，发现 v5.5.0 可以使用。于是，我更改了构件的版本号，其它地方不用变动【要确保低版本的构件可以支持高板的 Elasticsearch】，测试了一下，果然可以，遇到字段冲突不会抛出异常，程序可以正常运行。此时，我再想查查源代码是怎么处理的，发现已经找不到 v5.6.8 那个 <code>MappingSet</code> 类了。</p><p>依赖构件坐标如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;elasticsearch-hadoop&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;5.5.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>这种情况虽然看起来有潜在的危险，我也知道，但是我在自定义配置中，使用 <code>es.read.field.include</code> 参数只读取少量的字段，就可以保证有冲突的字段不影响我的业务处理逻辑，也认为对整个应用程序没有什么危害。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Hadoop</tag>
        <tag>es-hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Hexo、GitHub 搭建个人博客教程</title>
    <url>/2017093001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>对于喜欢写作的技术人员来说，可以使用 <strong>CSDN</strong>、<strong> 简书 </strong>、<strong>WordPress</strong>、<strong> 博客园 </strong>等产品，不仅可以记录自己在日常工作中遇到的难点、解决的 bug 等，还可以分享经验，让别人也学习进步。但是，有的人可能会觉得这些产品不好用，或者功能的扩展太掣肘，或者觉得这种方式不够酷，他们想追求更加自由的方式来写博客。</p><p>这时候，我觉得 <code>Hexo</code> 就可以出场了，它其实只是一个博客框架，如果你是新手，只需要几个命令十几分钟，就可以搭建自己的博客，而如果你技术高超并且愿意花时间的话，可以折腾出很多花样，博客从里到外你都可以自定义实现。本文记录我的博客搭建过程以及优化过程。</p><p>在此先声明，这篇博客内容是从 <strong>2017-09-30</strong> 开始写的，为了与时俱进，会保持不断更新，可能会删掉无用的旧内容并添加新内容，目前最新修改时间为 <strong>2019-06-09</strong>，所以请读者以最新的内容为准。</p><a id="more"></a><h1 id="历史的记忆"><a href="# 历史的记忆" class="headerlink" title="历史的记忆"></a>历史的记忆 </h1><p> 我从 2015 年就开始整理包含各种知识点的笔记，大部分都是和技术有关的，其它的都是一些生活感悟、阅读笔记、游记等等。当然，2015 年我还没有毕业，只是在外面的公司实习，由于当时每天都会接触到很多重要的技术知识，在询问同事、查阅资料的过程中又会延伸涉及到更多的知识点，我迫切需要记笔记，方便我快速查阅学习。一开始我本想听从身边同事的建议，使用 <strong>CSDN</strong> 写博客，但是我觉得 CSDN 使用起来不方便，对于字数多一点的笔记，排版、添加图片都很麻烦，因此没有使用。</p><p>后来自行查阅资料，有人建议使用 <strong>简书 </strong>、<strong>WordPress</strong>、<strong> 有道云笔记 </strong>等产品，我觉得好像都不错，并使用了一段时间的有道云笔记。但是突然有一天我发现了 <code>Hexo</code> 这个博客框架产品以及 <code>Markdown</code> 这种语法，我被深深吸引了，当即决定改用它。</p><p>当然，这时候不得不提一下 <code>Jekyll</code> 这个博客框架，它其实是一个静态文件生成器，和 <code>Hexo</code> 类似，用户可以基于 <code>Markdown</code> 文件写博客，然后 <code>Jekyll</code> 帮助用户生成静态文件。更重要的是，<code>GitHub</code> 默认是支持 <code>Jekyll</code> 的，用户可以直接管理 <code>Markdown</code> 文件，其它的都交给 <code>GitHub</code>、<code>Jekyll</code> 了，也就是说用户可以直接在线编辑 <code>Markdown</code> 文件，生成过程、发布过程都无需关心。</p><p>那为什么我没有选择 Jekyll 呢？上面的介绍看起来很美好是不是，但是不能忽略了它的缺点：一是 Liquid 语法不友好，需要学习成本；二是如果在本地搭建 Jekyll 环境的话，步骤比较复杂【基于 Ruby，听说有 Docker 环境可以快速搭建 Jekyll 环境】，出了问题很是折腾人；三是博客内容过多的时候【几百篇】，生成的速度会极慢，也就是性能低下；四是 GitHub 对 Jekyll 的插件有很多限制，导致很多插件不能使用，这就违背了自定义的概念，不够灵活。因此，此时此刻我暂且按下 Jekyll 不表，需要了解的可以参考 GitHub Pages 的帮助文档：<a href="https://help.github.com/en/articles/about-github-pages-and-jekyll" target="_blank" rel="noopener">help.github.com</a> ，让继续我回到 Hexo 这个话题上面来。</p><p>回来继续说 Hexo，这里面还有一段趣事，不久之前，我经常浏览 <a href="http://www.jasongj.com" target="_blank" rel="noopener">郭俊的博客 </a> ，里面的大数据技术知识整理归纳得很好，我读了几天之后，突然有一天我的注意力竟然被博客的框架吸引住了：界面简洁、交互优雅、配色简单，我就在那里点来点去，越来越喜欢。然后我决定我也要使用这个框架，但是我对这个框架一无所知，而且郭俊的博客底部也没有留下类似 <strong>Powered by xx</strong> 的标识，一开始一筹莫展。接着我就想到去郭俊的微博、微信公众号里面留言，说我很喜欢这个框架，能不能透露一下关于这个框架的简介。过了几天他回了一个单词：<strong>Hexo</strong>，然后我就疯狂地搜索关于这个框架的信息，并着手开始使用它。</p><p> 一开始我并没有考虑那么多，例如博客主题的各种优化配置、远程仓库协作、搭建自己的云主机、绑定域名、SEO 优化等等一系列的升级改造，我只是想使用这个框架，然后搭配 Markdown 语法进行写作。我先在本地创建了一个博客站点，然后逐步把有道云笔记里面的内容迁移过来，现在我发现也积累了不少内容，才决定投入 GitHub 与 GitHub Pages 的怀抱，想把个人博客慢慢做起来。</p><p>我知道这将是一个漫长而消耗精力的过程，希望我能坚持住，这就快到国庆节了，我会抽出 2-3 天时间好好整理一下博客站点的优化清单，并在以后的日子里逐步实现。</p><h1 id="初次搭建"><a href="# 初次搭建" class="headerlink" title="初次搭建"></a>初次搭建 </h1><h2 id="环境初始化"><a href="# 环境初始化" class="headerlink" title="环境初始化"></a> 环境初始化 </h2><p> 参考 <code>Hexo</code> 的安装文档进行环境初始化，新建一个站点并在本地启动，用浏览器打开查看默认的站点。</p><p><code>https://www.jianshu.com/p/88c9e72978b4</code></p><p><code>Jekyll</code> 配合 <code>GitHub Pages</code> 搭建博客，里面提到了可以使用 <code>Docker</code> 安装 <code>Jekyll</code> 环境，方便快捷。那么，对于 <code>Hexo</code> 环境来说，是否存在通过 <code>Docker</code> 来安装的方法呢？【待寻找】</p><h2 id="新建站点"><a href="# 新建站点" class="headerlink" title="新建站点"></a>新建站点 </h2><p> 详细过程待整理。</p><h1 id="优化教程"><a href="# 优化教程" class="headerlink" title="优化教程"></a>优化教程 </h1><p> 优化教程主要整理针对博客站点做的优化点，例如 UI 优化、SEO 优化、部署管理优化等等，这一部分内容会非常多，并且会在以后不断更新，至于有没有尽头我也不好说。</p><h2 id="添加版权声明"><a href="# 添加版权声明" class="headerlink" title="添加版权声明"></a>添加版权声明 </h2><p> 版权声明，一般就是指在博客的末尾添加类似 <code>本博客内容除特别声明外，均采用 xx 许可协议，转载请注明出处！</code> 这样的声明，一是用来提醒读者能意识到博客站点的版权，二是警告读者不要随意抄袭搬运博客内容。</p><p>对于 Hexo 来说，由于默认已经集成了这个功能，用户开启版权声明就比较简单了，直接在主题配置文件中【例如我使用的主题为 NexT，则在主目录中找到 themes/next 子目录，再找到 _config.yml 配置文件】，找到 <code>post_copyright</code> 配置项，设置为开启。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post_copyright:</span><br><span class="line">  enable: true</span><br><span class="line">  license: CC BY-NC-SA 3.0</span><br><span class="line">  license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/</span><br></pre></td></tr></table></figure><p>其中，<code>enable: true</code> 表示开启版权声明，<code>license</code> 表示版权协议的名称，<code>license_url</code> 表示版权协议的官方网站。至于使用哪一种版权协议，大家根据实际情况选择，如果需要了解更多的版权协议知识，请自行查询。</p><p>开启版权声明后，在每一篇博客的最后都会看到如下图所示的版权声明信息。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190610210907.png" alt="博客文章末尾的版权声明信息" title="博客文章末尾的版权声明信息"></p><p>此外，为了在站点概览中增加版权协议的图标和链接，继续在上述的配置文件中找到 <code>creative_commons</code> 配置项，根据上述的版权协议情况填写。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">creative_commons: by-nc-sa</span><br></pre></td></tr></table></figure><p>配置完成后，在侧边栏的站点概览中，可以看到版权协议的图标，如果点击图标会自动跳转到版权协议的官方网站。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190610210920.png" alt="站点概览的版权声明信息" title="站点概览的版权声明信息"></p><h2 id="搜索引擎优化"><a href="# 搜索引擎优化" class="headerlink" title="搜索引擎优化"></a>搜索引擎优化 </h2><p> 关于在百度、Google 的站长工具中管理站点的方法，参考我的博客内容：<a href="yy">博客待整理 </a> 。</p><h2 id="使用远程仓库"><a href="# 使用远程仓库" class="headerlink" title="使用远程仓库"></a> 使用远程仓库 </h2><p> 我使用 GitHub 作为远程仓库，方便多环境写博客，并使用 GitHub Pages 作为免费云主机，参考我的博客内容：<a href="xx">博客待整理 </a> 。</p><h2 id="绑定独立的域名"><a href="# 绑定独立的域名" class="headerlink" title="绑定独立的域名"></a> 绑定独立的域名 </h2><p> 由于我使用了 GitHub Pages，所以域名的绑定、SSL 证书的申请都比较简单，参考我的博客内容：<a href="https://www.playpi.org/2018112701.html">GitHub 个人站点绑定独立的域名 </a> 。</p><h2 id="解决百度蜘蛛爬虫的问题"><a href="# 解决百度蜘蛛爬虫的问题" class="headerlink" title="解决百度蜘蛛爬虫的问题"></a> 解决百度蜘蛛爬虫的问题 </h2><p> 由于众所周知的原因，GitHub Pages 把百度蜘蛛爬虫的请求全部拦截，这就导致百度无法爬取博客的内容【当然主动提交的还是可以的】，我使用多主机、百度请求跳转的方式解决这个问题，参考我的博客内容：<a href="https://www.playpi.org/2019010501.html">GitHub Pages 禁止百度蜘蛛爬取的问题 </a> 。</p><h2 id="添加宠物挂件"><a href="# 添加宠物挂件" class="headerlink" title="添加宠物挂件"></a> 添加宠物挂件 </h2><p> 在博客站点的左下角添加宠物挂件，我选择了一只猫，并且它会根据光标的位置来回看，希望能给看我博客的读者带去一点好心情。参考我的博客内容：<a href="https://www.playpi.org/2017031801.html">给博客站点增加一个可以交互的挂件 </a> 。</p><h2 id="图床选择"><a href="# 图床选择" class="headerlink" title="图床选择"></a> 图床选择 </h2><p> 一开始我经过多天的调研，最终选择的是微博图床，理由有：免费、自动压缩、SSL 协议、CDN 加速，使用了很长时间，效果很好。但是后来发生了黑产攻击微博图床的事件【时间点大概在 2019-04-24】，给微博图床带去了安全风险，于是微博图床开启了防盗链，所有正常的访问均被拒绝，进而导致博客文章里面的图片全部打不开。</p><p>后来经过反复思考，又在网上看到很多别人的经验，最终我决定直接使用 GitHub 作为图床工具，安全可靠，参考我的博客内容：<a href="https://www.playpi.org/2019042701.html">解决微博图床防盗链的问题 </a> 、<a href="https://www.playpi.org/2019050201.html"> 使用 Java 代码迁移微博图床到 GitHub 图床 </a> 。</p><h2 id="站内搜索"><a href="# 站内搜索" class="headerlink" title="站内搜索"></a> 站内搜索 </h2><p> 我使用的站内搜索是 <code>Hexo</code> 提供的解决方案，只要在配置文件 <code>_config.yml</code> 中配置是否开启本地搜索功能即可，很简洁，不必关心其它，如图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190724223206.png" alt="站内搜索相关配置" title="站内搜索相关配置"></p><p>它的背后其实使用了一个叫 <code>hexo-generator-search</code> 的插件，详情见：<br><a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener">https://github.com/wzpan/hexo-generator-search</a> ，原理也很容易理解，就是把网站的关键词全部收集起来，存在一个文件中：<code>search.xml</code>，搜索时直接根据关键词从文件中查找。</p><p><code>Hexo</code> 内置了这个插件，所以我只需要在配置文件中配置几行信息，就可以开启站内搜索功能，如果是比较老旧的 <code>Hexo</code> 的版本，可能还没有内置这个站内搜索插件，可以升级 <code>Hexo</code> 或者自行安装这个插件：<code>npm install --save hexo-generator-search</code>。</p><p>当然，如果内容过多，查找速度会变慢，例如我的博客有十几万字，我已经觉得很慢了。另外，在 <code>Hexo</code> 的插件仓库也可以找到这个插件的介绍，<code>Hexo</code> 插件仓库地址：<br><a href="https://hexo.io/plugins" target="_blank" rel="noopener">https://hexo.io/plugins</a> 。</p><h2 id="添加开源协议"><a href="# 添加开源协议" class="headerlink" title="添加开源协议"></a>添加开源协议 </h2><p> 我使用 <code>MIT</code> 开源协议，增加 <code>LICENSE</code> 文件，使用模板即可，必须放在 <code>master</code> 分支才会生效。</p><p>在项目中选择 <code>Create new file</code>，创建一个新文件，命名为：<code>LICENSE</code>，然后在右侧可以看到会有开源协议列表给你选择，选择需要的开源协议，其它内容会自动生成。</p><p>新建文件时选择开源协议模板 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818033915.png" alt="选择开源协议模板" title="选择开源协议模板"></p><p> 根据模板生成开源协议内容 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818033908.png" alt="生成开源协议内容" title="生成开源协议内容"></p><p> 创建成功后，就可以在项目的属性中看到开源协议信息，例如：<code>MIT</code>。</p><p>开源协议生效后在项目中的效果如下图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190814202201.png" alt="开源协议效果图" title="开源协议效果图"></p><h2 id="添加徽章"><a href="# 添加徽章" class="headerlink" title="添加徽章"></a>添加徽章 </h2><p> 除了构建结果徽章使用的是 <code>travis</code>，其它徽章使用的是 <code>GitHub</code> 的官方徽章库：<a href="https://shields.io" target="_blank" rel="noopener">shields.io</a>，增加了 <code>Issue</code> 的打开关闭数量、使用的语言【自定义的徽章】、开源协议。</p><p><code>README</code> 文件中的文本内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[![Build Status](https://travis-ci.org/iplaypi/iplaypi.github.io.svg?branch=source)](https://travis-ci.org/iplaypi/iplaypi.github.io)</span><br><span class="line">![GitHub issues](https://img.shields.io/github/issues/iplaypi/iplaypi.github.io?color=blue&amp;style=flat)</span><br><span class="line">![GitHub closed issues](https://img.shields.io/github/issues-closed/iplaypi/iplaypi.github.io?color=red&amp;style=flat)</span><br><span class="line">![](https://img.shields.io/badge/language-markdown-orange.svg)</span><br><span class="line">![GitHub](https://img.shields.io/github/license/iplaypi/iplaypi.github.io?color=green)</span><br></pre></td></tr></table></figure><p>徽标可视化效果展示如下图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190814201843.png" alt="徽标可视化展示效果" title="徽标可视化展示效果"></p><h1 id="参考资料"><a href="# 参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>1、Hexo 的官方网站：<a href="https://hexo.io" target="_blank" rel="noopener">https://hexo.io</a> 。</p><p>2、Hexo 的安装文档中文版：<a href="https://hexo.io/zh-cn/docs" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Java 代码迁移微博图床到 GitHub 图床</title>
    <url>/2019050201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>由于微博图床开启了防盗链，导致我的博客里面的图片全部不可见，因此要切换图床。当然，一开始我使用的是极其简单的方法，直接设置博客页面的 <strong>referer</strong> 属性即可【设置为 noreferrer】，这样微博图床就检测不到引用来源，也就不会拒绝访问了。但是后续又遇到了其它问题，这些内容我在前几天的博客里面都记录了：<a href="https://www.playpi.org/2019042701.html">解决微博图床防盗链的问题 </a> 。后来我实在找不到更为恰当的解决方案，于是决定直接迁移图床。本来一开始准备使用 PicGo 这个工具，但是发现有问题，在我比较着急的情况下，决定自己写一写代码，完成迁移操作。本文就记录这些代码的逻辑。</p><a id="more"></a><h1 id="依赖构件"><a href="# 依赖构件" class="headerlink" title="依赖构件"></a> 依赖构件 </h1><p> 为了减少代码量，精简代码，需要引入几个第三方 jar 包，当然不引入也行，如果不引入有一些繁琐而又简单的业务逻辑需要自己实现，有点浪费时间了。</p><p>主要要依赖几个 <code>jar</code> 包：处理文件的 <code>io</code> 包、处理网络请求的 <code>httpclient</code> 包、处理 <code>git</code> 的 <code>jgit</code> 包，<code>pom.xml</code> 配置文件内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;commons-io&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.3.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;httpclient&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;4.5.6&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;4.8.0.201706111038-r&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h1 id="代码结构"><a href="# 代码结构" class="headerlink" title="代码结构"></a>代码结构 </h1><p> 写代码也比较简单，主要有四个步骤：读取 <code>Markdown</code> 文件内容并利用正则抽取微博图床的图片链接、下载所有图片并上传至 <code>GitHub</code>、替换内容中抽取出的所有图片链接为 <code>GitHub</code> 的图片链接、内容写回新文件。</p><p>使用 <code>Java</code> 处理不需要多少代码，大概有不到 200 行代码，真正的业务逻辑代码更少，当然，关于网络请求的部分还是不够精简，目前我觉得能用就行。代码放在 <code>GitHub</code> 上面，仅供参考：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/main/java/org/playpi/study/migratepic" target="_blank" rel="noopener">MigratePic.java</a> ，搜索 <strong>MigratePic</strong> 类即可。</p><p>代码主体调用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void main (String [] args) &#123;</span><br><span class="line">    //        String dir = &quot;e:\baktest&quot;;</span><br><span class="line">    //        String outDir = &quot;e:\baktest-out&quot;;</span><br><span class="line">    String dir = &quot;e:\bak&quot;;</span><br><span class="line">    String outDir = &quot;e:\bak-out&quot;;</span><br><span class="line">    Set&lt;File&gt; fileSet = getAllFiles (dir);</span><br><span class="line">    LOGGER.info (&quot;==== 文件个数:&quot; + fileSet.size ());</span><br><span class="line">    for (File file : fileSet) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            // 1 - 读取文件，抽取微博图床的链接与图片名称 </span><br><span class="line">            String content = FileUtils.readFileToString (file, &quot;utf-8&quot;);</span><br><span class="line">            Map&lt;String, String&gt; imgMap = extractImg (content);</span><br><span class="line">            // 2 - 下载图片并上传至 GitHub</span><br><span class="line">            Map&lt;String, String&gt; urlMap = uploadGithub (imgMap);</span><br><span class="line">            // 3 - 替换所有链接 </span><br><span class="line">            content = replaceUrl (content, urlMap);</span><br><span class="line">            // 4 - 内容写回新文件 </span><br><span class="line">            String outFile = outDir + File.separator + file.getName ();</span><br><span class="line">            FileUtils.writeStringToFile (new File (outFile), content, &quot;utf-8&quot;);</span><br><span class="line">            LOGGER.info (&quot;==== 处理文件完成:&#123;&#125;, 获取新浪图床链接个数:&#123;&#125;, 上传 GitHub 个数:&#123;&#125;&quot;, file.getAbsolutePath (), imgMap.size (), urlMap.size ());</span><br><span class="line">        &#125;</span><br><span class="line">        catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace ();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要指定输入、输出目录。</p><p>截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190504004133.png" alt="代码主体调用" title="代码主体调用"></p><p>其中，<strong>getAllFiles</strong> 方法是获取指定目录的所有文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 获取指定文件夹内的所有文件 </span><br><span class="line">     *</span><br><span class="line">     * @param dir</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">private static Set&lt;File&gt; getAllFiles (String dir) &#123;</span><br><span class="line">    Set&lt;File&gt; fileSet = new HashSet&lt;&gt;();</span><br><span class="line">    File file = new File (dir + File.separator);</span><br><span class="line">    for (File textFile : file.listFiles ()) &#123;</span><br><span class="line">        fileSet.add (textFile.getAbsoluteFile ());</span><br><span class="line">    &#125;</span><br><span class="line">    return fileSet;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在代码的细节中，可以看到我是每个文件单独处理的，比较耗时间的就是下载图片、上传到 <code>GitHub</code> 这两个过程，而且由于我是文件分开处理，所以总的时间更长了。如果想节约点时间，可以一次性把所有的图片全部下载完成，最后一次提交到 <code>GitHub</code> 即可，这样就节约了多次频繁地与 <code>GitHub</code> 建立连接、断开连接所消耗的时间，如果是几次提交无所谓，但是几十次提交就多消耗很多时间了。例如按照我这个量，78 个文件，500-600 张图片，运行程序消耗了十几分钟，但是我估计如果一次性处理完成，时间应该在 5 分钟以内。</p><p>接下来分别描述四个步骤。</p><h2 id="读取文件抽取图片链接"><a href="# 读取文件抽取图片链接" class="headerlink" title="读取文件抽取图片链接"></a>读取文件抽取图片链接 </h2><p><code>Markdown</code> 文件其实也就是普通的文本文件，没有特殊的格式，这就给程序处理带来了极大方便，直接使用工具包读取就行。此外，抽取微博图床的图片链接需要使用正则表达式，代码内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static Pattern PATTERN = Pattern.compile (&quot;https://[0-9a-zA-Z]&#123;3&#125;\.sinaimg\.cn/large/[0-9a-zA-Z]&#123;8,50&#125;\.jpg&quot;);</span><br><span class="line">/**</span><br><span class="line">     * 抽取微博图床的图片链接与图片文件名 </span><br><span class="line">     *</span><br><span class="line">     * @param string</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">private static Map&lt;String, String&gt; extractImg (String string) &#123;</span><br><span class="line">    Map&lt;String, String&gt; imgMap = new HashMap&lt;&gt;();</span><br><span class="line">    Matcher matcher = PATTERN.matcher (string);</span><br><span class="line">    while (matcher.find ()) &#123;</span><br><span class="line">        String oldUrl = matcher.group ();</span><br><span class="line">        int index = oldUrl.lastIndexOf (&quot;/&quot;);</span><br><span class="line">        if (0 &lt; index) &#123;</span><br><span class="line">            String imgName = oldUrl.substring (index + 1);</span><br><span class="line">            imgMap.put (oldUrl, imgName);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return imgMap;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这里列举一个图片链接的例子：<br><a href="https://ws1.sinaimg.cn/large/b7f2e3a3gy1g2hlkwnfm9j214a0hr75v.jpg" target="_blank" rel="noopener">https://ws1.sinaimg.cn/large/b7f2e3a3gy1g2hlkwnfm9j214a0hr75v.jpg</a> 。</p><h2 id="下载图片并上传新图床"><a href="# 下载图片并上传新图床" class="headerlink" title="下载图片并上传新图床"></a>下载图片并上传新图床 </h2><p> 这是一个很重要的步骤，需要把上一个步骤完成后获取到的图片下载下来，并且提交到 <code>GitHub</code> 上面去【提交可以不使用代码，直接手动提交也行】，然后获取新图片链接。</p><p>为了完成这个步骤，需要先在 <code>GitHub</code> 上面新建一个项目，专门用来存放图片，然后把这个项目 <code>clone</code> 到本地，用来存放下载的图片，最后直接提交即可。</p><p>下载图片并提交到 <code>GitHub</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static String githubUrl = &quot;https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/&quot;;</span><br><span class="line">/**</span><br><span class="line">     * 提交本地的图片到 GitHub, 并拼接新的图片链接 </span><br><span class="line">     *</span><br><span class="line">     * @param imgMap</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">private static Map&lt;String, String&gt; uploadGithub (Map&lt;String, String&gt; imgMap) &#123;</span><br><span class="line">    String imgDir = &quot;E:\img\img-playpi\img\old\&quot;;</span><br><span class="line">        Map&lt;String, String&gt; urlMap = new HashMap&lt;&gt;();</span><br><span class="line">        for (Map.Entry&lt;String, String&gt; entry : imgMap.entrySet ()) &#123;</span><br><span class="line">            String oldUrl = entry.getKey ();</span><br><span class="line">            String imgName = entry.getValue ();</span><br><span class="line">            boolean isSuc = downloadImg (oldUrl, imgDir, imgName);</span><br><span class="line">            if (isSuc) &#123;</span><br><span class="line">                String newUrl = githubUrl + imgName;</span><br><span class="line">                urlMap.put (oldUrl, newUrl);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        LOGGER.info (&quot;==== 开始上传文件到 GitHub, size: &#123;&#125;&quot;, urlMap.size ());</span><br><span class="line">        // 统一上传到 GitHub, 这一步骤可以省略，留到最后手动提交即可 </span><br><span class="line">        boolean gitSuc = JGitUtil.commitAndPush (&quot;add and commit by Java client,img size: &quot; + urlMap.size ());</span><br><span class="line">        if (!gitSuc) &#123;</span><br><span class="line">            urlMap.clear ();</span><br><span class="line">        &#125;</span><br><span class="line">        return urlMap;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>注意下载图片需要指定本地项目的路径，方便提交到 <code>GitHub</code>，例如我这里是 <strong>E:\img\img-playpi\img\old\</strong>，拼接 <code>GitHub</code> 的图片链接时需要指定固定的域名部分、用户名、分支名、子目录，例如我这里是：<br><strong><a href="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/" target="_blank" rel="noopener">https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/</a> </strong>。</p><p>这里列举一个 <code>GitHub</code> 图片链接的例子：<br><a href="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/20190502183444.png" target="_blank" rel="noopener">https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/20190502183444.png</a> 。</p><p>下载图片的详细逻辑：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 下载图片到指定的文件目录 </span><br><span class="line">     */</span><br><span class="line">public static Boolean downloadImg (String url, String dir, String fileName) &#123;</span><br><span class="line">    Boolean isSuc = false;</span><br><span class="line">    HttpClient httpclient = null;</span><br><span class="line">    int retry = 5;</span><br><span class="line">    while (0 &lt; retry--) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            httpclient = new DefaultHttpClient ();</span><br><span class="line">            HttpGet httpget = new HttpGet (url);</span><br><span class="line">            httpget.setHeader (&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.79 Safari/537.1&quot;);</span><br><span class="line">            httpget.setHeader (&quot;Accept&quot;, &quot;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&quot;);</span><br><span class="line">            HttpResponse resp = httpclient.execute (httpget);</span><br><span class="line">            if (HttpStatus.SC_OK == resp.getStatusLine ().getStatusCode ()) &#123;</span><br><span class="line">                HttpEntity entity = resp.getEntity ();</span><br><span class="line">                InputStream in = entity.getContent ();</span><br><span class="line">                isSuc = savePicToDisk (in, dir, fileName);</span><br><span class="line">                return isSuc;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace ();</span><br><span class="line">            LOGGER.error (&quot;!!!! 下载失败，重试一次 & quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        finally &#123;</span><br><span class="line">            httpclient.getConnectionManager ().shutdown ();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return isSuc;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">     * 根据输入流，保存内容到指定的目录文件 </span><br><span class="line">     *</span><br><span class="line">     * @param in</span><br><span class="line">     * @param dirPath</span><br><span class="line">     * @param filePath</span><br><span class="line">     */</span><br><span class="line">private static Boolean savePicToDisk (InputStream in, String dirPath, String filePath) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        File dir = new File (dirPath);</span><br><span class="line">        if (dir == null || !dir.exists ()) &#123;</span><br><span class="line">            dir.mkdirs ();</span><br><span class="line">        &#125;</span><br><span class="line">        // 拼接文件完整路径 </span><br><span class="line">        String realPath = dirPath.concat (filePath);</span><br><span class="line">        File file = new File (realPath);</span><br><span class="line">        if (file == null || !file.exists ()) &#123;</span><br><span class="line">            file.createNewFile ();</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputStream fos = new FileOutputStream (file);</span><br><span class="line">        byte [] buf = new byte [1024];</span><br><span class="line">        int len = 0;</span><br><span class="line">        while ((len = in.read (buf)) != -1) &#123;</span><br><span class="line">            fos.write (buf, 0, len);</span><br><span class="line">        &#125;</span><br><span class="line">        fos.flush ();</span><br><span class="line">        fos.close ();</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace ();</span><br><span class="line">        LOGGER.error (&quot;!!!! 写入文件失败 & quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    finally &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            in.close ();</span><br><span class="line">        &#125;</span><br><span class="line">        catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace ();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>提交图片到 <code>GitHub</code> 的代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 提交并推送代码至远程服务器 </span><br><span class="line"> *</span><br><span class="line"> * @param desc 提交描述 </span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">public static boolean commitAndPush (String desc) &#123;</span><br><span class="line">    boolean commitAndPushFlag = false;</span><br><span class="line">    try (Git git = Git.open (new File (LOCAL_REPOGIT_CONFIG))) &#123;</span><br><span class="line">        UsernamePasswordCredentialsProvider provider = new UsernamePasswordCredentialsProvider (GIT_USERNAME, GIT_PASSWORD);</span><br><span class="line">        git.add ().addFilepattern (&quot;.&quot;).call ();</span><br><span class="line">        // 提交 </span><br><span class="line">        git.commit ().setMessage (desc).call ();</span><br><span class="line">        // 推送到远程，不报错默认为成功 </span><br><span class="line">        git.push ().setCredentialsProvider (provider).call ();</span><br><span class="line">        commitAndPushFlag = true;</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        e.printStackTrace ();</span><br><span class="line">        LOGGER.error (&quot;Commit And Push error!&quot; + e.getMessage ());</span><br><span class="line">    &#125;</span><br><span class="line">    return commitAndPushFlag;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里需要指定本地项目的配置文件路径，例如我的是 <strong>E:\img\img-playpi\.git</strong>，与前面的下载路径是在同一个父目录，另外还需要指定用户名密码。</p><h2 id="使用新链接替换旧链接"><a href="# 使用新链接替换旧链接" class="headerlink" title="使用新链接替换旧链接"></a>使用新链接替换旧链接 </h2><p> 如果前面的步骤完成，就说明图片已经被成功迁移到 <code>GitHub</code> 上面，并且获取到了新的图片链接，接着直接替换掉旧链接即可。</p><p>代码逻辑如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 替换所有的图片链接 </span><br><span class="line"> *</span><br><span class="line"> * @param string</span><br><span class="line"> * @param urlMap</span><br><span class="line"> * @return</span><br><span class="line"> */</span><br><span class="line">private static String replaceUrl (String string, Map&lt;String, String&gt; urlMap) &#123;</span><br><span class="line">    for (Map.Entry&lt;String, String&gt; entry : urlMap.entrySet ()) &#123;</span><br><span class="line">        String oldUrl = entry.getKey ();</span><br><span class="line">        String newUrl = entry.getValue ();</span><br><span class="line">        string = string.replaceAll (oldUrl, newUrl);</span><br><span class="line">    &#125;</span><br><span class="line">    return string;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="替换后内容写回新文件"><a href="# 替换后内容写回新文件" class="headerlink" title="替换后内容写回新文件"></a>替换后内容写回新文件 </h2><p> 写入新文件是很简单的，直接调用 <code>io</code> 包即可完成，但是为了安全起见，文件放在新的目录中，不要直接替换掉原来的文件，否则程序出现意外就麻烦了。</p><h1 id="迁移结果"><a href="# 迁移结果" class="headerlink" title="迁移结果"></a>迁移结果 </h1><p> 随意打开一篇博客，使用文件对比工具查看替换前后的区别，可以看到除了图片链接被替换掉，其它内容没有任何变化。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190504004204.png" alt="替换文件对比" title="替换文件对比"></p><p>在本地仓库查看，图片已经全部下载。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190504004224.png" alt="在本地仓库查看" title="在本地仓库查看"></p><p>在 <code>GitHub</code> 的仓库中查看，图片全部推送。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190504004216.png" alt="在 GitHub 的仓库中查看" title="在 GitHub 的仓库中查看"></p><p>任意打开一篇博客，里面的图片已经可以全部正常显示，只不过有一些太大的图片【超过 1MB 的】加载速度有点慢，还可以接受。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>weibo</tag>
        <tag>GitHub</tag>
        <tag>image</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Valine 给 Hexo 博客添加评论系统</title>
    <url>/2019032001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>我的博客已经搭建得差不多了，一些配置也固定下来了，最近重点一直在补充博客内容，把以前的笔记都整理出来。然后有一天我就想，好像总感觉少点什么，发现评论这个功能是没有的。以前是为了追求简洁的风格，而且评论这个功能不稳定，主要是评论系统不好选择，很多都关闭了。思前想后，考虑了好几天，最终还是决定先加上评论功能，实验一阵子，看看有没有必要，后续再决定是取消还是继续，反正也就是改一下配置就行了，没有多大工作量。接下来查了一下当前还活着的评论系统的种类，最后选择了 <strong>Valine</strong> 这个评论系统。它不需要登录，无后台管理，非常简洁，比较符合我追求的理念。参考相关内容：<a href="https://github.com/xCss/Valine" target="_blank" rel="noopener">https://github.com/xCss/Valine</a> 、<a href="https://valine.js.org" target="_blank" rel="noopener">https://valine.js.org</a> 、<a href="https://leancloud.cn" target="_blank" rel="noopener">https://leancloud.cn</a> 。</p><a id="more"></a><h1 id="注册帐号创建应用"><a href="# 注册帐号创建应用" class="headerlink" title="注册帐号创建应用"></a>注册帐号创建应用 </h1><blockquote><p>Valine 诞生于 2017 年 8 月 7 日，是一款基于 Leancloud 的快速、简洁且高效的无后端评论系统。</p></blockquote><p> 所以，第一步就需要注册 <code>Leancloud</code> 账号，然后才能申请应用的 <code>appid</code> 和 <code>appkey</code>。注册过程我就不赘述了，和注册普通的账号一样，官网地址：<a href="https://leancloud.cn" target="_blank" rel="noopener">https://leancloud.cn</a> 。接下来重点来了，需要申请免费的应用【有钱的话也可以购买收费的版本】，这里面有一些需要注意的地方，否则最后评论的时候没有效果，会导致 <code>Leancloud</code> 后台接收不到评论数据。</p><p>1、登录 <code>Leancloud</code> 系统，进入系统的控制台，然后创建应用。<br>从主页进入控制台 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d797qim2j21hc0rvq6j.jpg" alt="从主页进入控制台" title="从主页进入控制台"></p><p> 创建应用，我这里已经创建好一个应用了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d79ng997j21hc0q974s.jpg" alt="创建应用" title="创建应用"></p><p>2、填写、选择应用的参数，这里需要填写应用的名字，选择开发版本【免费版本，限制请求并发数】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d79uhbrqj21hc0q9q4e.jpg" alt="填写、选择应用的参数" title="填写、选择应用的参数"></p><p>3、创建完成后，进入设置详情页面。<br>点击齿轮，进入设置详情页面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d79z1cf8j21hc0q9mxq.jpg" alt="进入设置详情页面" title="进入设置详情页面"></p><p>在设置详情页面里面，选择 <strong>设置 -&gt; 应用 Key</strong>，就可以看到应用的 <code>appid</code> 和 <code>appkey</code>，这 2 个字符串要记下来，等一下在 <code>Hexo</code> 里面配置的时候有用。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7a30cpmj21hc0q9jt5.jpg" alt="查看应用 Key" title="查看应用 Key"></p><p>4、在 <strong>存储 -&gt; 数据 </strong>里面查看默认的 <code>Class</code> 信息，有一些默认的 <code>Class</code>，例如 <code>_User</code>、<code>_File</code>、<code>_Role</code> 等，这些都用不到，而 <code>Hexo</code> 的评论功能需要一个名称为 <code>Comment</code> 的 <code>Class</code>，现在发现没有这个 <code>Class</code>，要不要手动配置一个呢。其实不用担心，经过我的测试 <code>Hexo</code> 会自动生成这个 <code>Class</code>，所以不需要自己手动配置了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7agpw2ij21hc0q9gnc.jpg" alt="查看 Class 信息" title="查看 Class 信息"></p><p>5、在 <strong>设置 -&gt; 安全中心 </strong>，把 <strong>文件上传、短信服务、推送服务、实时通信 </strong>这几个服务全部关闭，因为用不到。然后需要特别注意的就是 <strong>Web 安全域名 </strong>这一个选项，里面一定要填写自己站点的域名，并且带上端口号，例如 <code>http</code> 请求的默认端口就是 80，<code>https</code> 请求的默认端口就是 443。这里如果没有配置好，评论的时候也会失败的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7amoctcj21hc0rv76n.jpg" alt="设置 Web 安全域名" title="设置 Web 安全域名"></p><h1 id="配置 -Hexo- 参数"><a href="# 配置 -Hexo- 参数" class="headerlink" title="配置 Hexo 参数"></a>配置 Hexo 参数 </h1><p> 上一步骤已经把 <code>Leancloud</code> 里面的应用申请好了，并且设置了重要的选项，获取到 <code>appid</code> 和 <code>appkey</code>，接下来配置 <code>Hexo</code> 就简单多了。打开 <code>Hexo</code> 主题的配置文件 <strong>_config.yml</strong>，搜索一下 <code>Valine</code>，找到默认配置【这是因为 <code>Hexo</code> 已经自动集成了 <code>Valine</code> 评论系统，不需要安装什么，如果没有请升级 <code>Hexo</code> 版本】。</p><p>默认是关闭的，把配置更改如下图，更为详细内容参考：<a href="https://valine.js.org/configuration.html" target="_blank" rel="noopener">https://valine.js.org/configuration.html</a> 。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7at81uyj20ku0b0dgq.jpg" alt="Hexo 配置" title="Hexo 配置"></p><p>主要配置的内容如下【重点是 <code>appid</code>、<code>appkey</code>、<code>placeholder</code>，至于验证、邮件提醒就按照自己的需要来配置吧】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">valine:</span><br><span class="line">  # 开启 Valine 评论 </span><br><span class="line">  enable: true</span><br><span class="line">  # 设置应用 id 和 key</span><br><span class="line">  appid: CCCJixxxxxxXXXxxxXXXX000-gzGzo000</span><br><span class="line">  appkey: AA1RXXXXXhPXXXX00F0XXXJSq</span><br><span class="line">  # mail notifier , https://github.com/xCss/Valine/wiki</span><br><span class="line">  # 关闭提醒与验证 </span><br><span class="line">  notify: false</span><br><span class="line">  verify: false</span><br><span class="line">  # 文本框占位文字 </span><br><span class="line">  placeholder: 没有问题吗？</span><br><span class="line">  # 需要填写的信息字段 </span><br><span class="line">  meta: [&apos;nick&apos;,&apos;mail&apos;]</span><br><span class="line">  # 默认头像 </span><br><span class="line">  avatar: wavatar</span><br><span class="line">  # 每页显示的评论数 </span><br><span class="line">  pageSize: 10</span><br></pre></td></tr></table></figure><p>这里面我发现一个问题，就是有一些配置项不生效，例如：<strong>meta</strong>、<strong>avatar</strong>，我也不知道是 <code>Hexo</code> 的问题还是 <code>Valine</code> 的问题，我也不懂，就先不管了，因为不影响评论这个功能。</p><p>另外还有一个就是评论的时候总会强制检验邮箱和 <code>url</code> 的规范性，如果没填或者填的不规范就弹框提示，我不知道怎么取消，只好在在 <code>GitHub</code> 提了一个 <code>Issue</code>，详见：<a href="https://github.com/xCss/Valine/issues/168" target="_blank" rel="noopener">https://github.com/xCss/Valine/issues/168</a> ，但是作者一直没回。等了几天，作者回复了，说是我的 <code>Valine</code> 版本太低，让我升级。我看了本地的 <code>Valine</code> 的版本，已经是 <code>v1.3.5</code> 了，然后我就怀疑可能是 <code>Hexo</code> 的版本问题，但是我自己做了很多自定义的配置，改了很多 <code>css</code>、<code>js</code> 文件，不能随便升级，等以后有时间做一个大版本的升级，再好好整理。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7da6215j20u30fsdgb.jpg" alt="强制检验邮箱和 url 的规范性" title="强制检验邮箱和 url 的规范性"></p><p>那怎么才能让博客文章的底部显示评论对话框呢，其实很简单，什么都不用做，<code>Hexo</code> 默认是给每个页面都开启评论的【前提是在 <code>Hexo</code> 的配置文件中开启了一种评论系统】。它背后的配置就是 <code>Markdown</code> 文件的 <code>comments</code> 属性，默认设置是 <code>true</code>，所以不用配置了，如果非要配置也可以，如下图。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7dge614j20e408c0sy.jpg" alt="配置底部显示评论对话框" title="配置底部显示评论对话框"></p><p>此外，还需要注意，如果博客还有除正文内容之外的页面存在，例如关于、分类、标签，要把他们的 <code>Markdown</code> 文件的 <code>comments</code> 属性设置为 <code>false</code>，否则这些页面在展示的时候也会有评论的功能出现，总不能让别人随便评论吧。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7djunr3j20no03iq2r.jpg" alt="取消一些不该有评论的页面" title="取消一些不该有评论的页面"></p><h1 id="测试效果"><a href="# 测试效果" class="headerlink" title="测试效果"></a>测试效果 </h1><p> 打开任意一篇博客文章，可以看到底部已经有评论的文本框了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7e6uw4mj20uk0o2q3s.jpg" alt="查看文章的评论文本框" title="查看文章的评论文本框"></p><p>试着填写内容，评论一下，可以看到评论列表的内容。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7e3f5njj20ta0q3750.jpg" alt="文章的评论列表" title="文章的评论列表"></p><p>好了，此时可以再回到 <code>Leancloud</code> 系统，看一下评论数据吧。直接在 <strong>存储 -&gt; 数据 -&gt;Comment</strong> 里面，可以看到已经有评论数据了。由于 <code>Valine</code> 是无后端的评论系统，所以数据直接被存储到了 <code>Leancloud</code> 系统的数据库表里面，看看就行了，不方便管理。如果评论数据很多，为了更方便管理评论数据，能收到更友好的邮件通知提醒，可以使用 <code>Valine-Admin</code> 来实现，我暂时先不用。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7dzjwhgj21hc0q9jt1.jpg" alt="Leancloud 系统的评论数据" title="Leancloud 系统的评论数据"></p><p>经过几天的测试，可以看到应用的请求量统计信息。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1d7dvlarqj21hc0rwt9f.jpg" alt="Leancloud 系统的应用请求量" title="Leancloud 系统的应用请求量"></p><h1 id="附加 -Valine-Admin- 进行评论数据管理"><a href="# 附加 -Valine-Admin- 进行评论数据管理" class="headerlink" title="附加 Valine-Admin 进行评论数据管理"></a>附加 Valine-Admin 进行评论数据管理 </h1><p> 这个插件我现在先不使用，因为还不知道评论数据会怎么样呢，等以后如果确实有需要再考虑增加，参考项目：<br><a href="https://github.com/zhaojun1998/Valine-Admin" target="_blank" rel="noopener">https://github.com/zhaojun1998/Valine-Admin</a> 。</p><h1 id="后记"><a href="# 后记" class="headerlink" title="后记"></a>后记 </h1><h2 id="版本问题"><a href="# 版本问题" class="headerlink" title="版本问题"></a> 版本问题 </h2><p> 还记得我上面提到的 <code>Valine</code> 版本过低，导致评论的时候总会强制检验邮箱和 <code>url</code> 的规范性这个现象。经过一段时间的观察，以及 2019-06-21 爆发的 <code>leanCloud</code> 域名误被封禁事件，导致彻底无法评论，我终于找到了升级 <code>Valine</code> 版本的方法，只要直接更改主题的 <code>swig</code> 脚本文件，具体路径在 <code>themes/next/layout/_third-party/comments/valine.swig</code>，把里面的旧版本的 <code>js</code> 引用移除【有 2 个文件引用】，改为新版本的 <code>js</code> 引用。</p><p>注意，作者特意在官网说明最新版本的 <code>Valine</code> 只需要引用一个 <code>unpkg</code> 库的 <code>Valine.min.js</code> 文件即可，其它的不再需要【我升级到当时最新的版本 <code>v1.3.7</code>】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190712012449.png" alt="升级新版本 Valine 配置" title="升级新版本 Valine 配置"></p><p>升级完成后，再去评论区看看，不会再强制验证邮箱和 <code>url</code>，而且会收集显示评论用户的操作系统、浏览器信息，同时右下角也新增了 <code>Valine</code> 的版本信息，可以更为清晰地看到版本。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190712012457.png" alt="升级 Valine 后查看最新的评论区" title="升级 Valine 后查看最新的评论区"></p><h2 id="绑定域名"><a href="# 绑定域名" class="headerlink" title="绑定域名"></a>绑定域名 </h2><p> 从 2019 年 10 月 1 日起，<code>leancloud</code> 针对没有绑定自有域名的应用停止某些服务，包含存储、即时通讯、云函数，参考 <code>leancloud</code> 官方发送的通知：<a href="https://leancloudblog.com/mandatory-domain-config" target="_blank" rel="noopener">leancloud 绑定自己的域名 </a> 。</p><p> 官方通知 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191010013431.png" alt="官方通知" title="官方通知"></p><p> 当然，如果不想绑定自有域名，也可以使用国际版，针对存储的数据，可以把数据迁移过去。使用国内版导出数据，再使用国际版导入数据，然后把应用中的 <code>appid</code>、<code>appkey</code> 替换为新的即可，这个操作在 <code>leancloud</code> 的通知中也有涉及。</p><p>注意，这个导出功能、导入功能的设计有点奇怪，导出功能在 <strong>设置 -&gt; 数据导出 </strong>，导入功能在具体的应用里面，例如我打开我的 <code>blog.playpi.org</code> 应用，找到 <strong>存储 -&gt; 数据 -&gt; 数据导入 </strong>即可操作。</p><p>数据导出功能演示 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191010013455.png" alt="数据导出功能" title="数据导出功能"></p><p> 数据导入功能演示 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191010013501.png" alt="数据导入功能" title="数据导入功能"></p><p> 这些数据实际上是格式化的 <code>JSON</code> 文本文件，使用文本编辑器打开后可以看到详细内容，如果想对内容做修改的话，直接修改保存即可，然后再导入。</p><p>此外，还要注意一点，导出数据只能在 <strong>中午 12 点之前 </strong>操作，会发送到邮箱一个压缩包。</p><p>如果使用了国际版后，遇到评论无法显示的问题，报错：<br><code>Code : undefined [410 GET https://avoscloud.com/1.1/classes/Comment]</code>，这是 <code>Valine</code> 的 <code>bug</code>，需要升级至 <code>v1.3.10</code> 解决，参考 <code>GitHub</code> 讨论的 <code>issue</code>：<a href="https://github.com/xCss/Valine/issues/194" target="_blank" rel="noopener">194</a> 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191010020925.png" alt="显示异常" title="显示异常"></p><p>这个 <code>bug</code> 的核心就是 <code>Valine</code> 没有考虑到 <code>LeanCloud</code> 的多个域名，华北、华东、国际站点的域名都不一样，而 <code>Valine</code> 统一默认是 <code>avoscloud.com</code>，这就导致不能支持某些地区的站点。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Valine</tag>
        <tag>评论系统</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 http 接口删除 Elasticsearch 集群的索引</title>
    <url>/2019082101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在工作中遇到需要定期关闭、删除 <code>Elasticsearch</code> 集群索引的需求，关闭索引或者删除索引是一个很简单的操作，直接向 <code>Elasticsearch</code> 集群发送一个请求即可。而且，为了实现批量删除，可以一次性发送多个索引名称，使用逗号分隔即可，甚至可以使用通配符【需要 <code>Elasticsearch</code> 集群的相关设置开启】，会直接删掉满足通配符条件的索引。</p><p>本文基于最简单的一个场景：单个索引的关闭、删除，使用 <code>Java</code> 编程语言、<code>HTTP</code> 接口，尝试关闭、删除 <code>Elasticsearch</code> 集群的索引，属于入门级别，开发环境基于 <code>Elasticsearch v1.7.5</code>，这是一个很旧的版本，<code>JDK v1.8</code>。</p><a id="more"></a><p>首先声明，本文内容是基于 <code>Elasticsearch v1.7.5</code>，这是一个很旧的版本，目前各个公司应该只有在一些历史遗留的项目中使用，一般大家都会使用 <code>v5.x</code>、<code>v6.x</code> 之类的版本了。此外，在 <code>v6.x</code> 及以上版本取消了索引 <code>type</code> 的概念，在那个场景下可以随便删除一个索引，而不用再考虑单个索引 <code>index</code> 下面存在的多个 <code>type</code> 的情况，没有误删除的风险。</p><h1 id="背景介绍"><a href="# 背景介绍" class="headerlink" title="背景介绍"></a>背景介绍 </h1><p> 我的目的只有两个：关闭索引、删除索引，是不是很简单的问题。</p><p>回归到我的具体业务，其实就是由于历史数据的积压，创建了很多个索引，而这些数据平时又没有用处，特别是比较久远的数据，根本不会有人用到，留着它们纯属浪费磁盘空间。</p><p>仔细分析、调研，对于最近几个月的数据，还会有一些价值，偶尔有人翻看，其实可以先关闭索引，如果确实有人需要，再临时打开。但是对于已经存在一年以上的数据，不会有人用到，可以说是无人关心、无人问津，这种数据对应的索引就应该被删除，不需要保留。</p><p>那么为了实现这个需求，可以写一个定时程序来处理。</p><h1 id="技术分析"><a href="# 技术分析" class="headerlink" title="技术分析"></a>技术分析 </h1><p> 根据以上的想法，我去查看了 <code>Elasticsearch</code> 的官方文档，发现有非常简单的 <code>HTTP</code> 接口可以使用，我也决定使用它。但是需要注意，在 <code>Elasticsearch</code> 中只能删除整个 <code>index</code>，而不能只是删除 <code>index</code> 下面的某个 <code>type</code>。也就是说只要对某个 <code>index</code> 执行删除操作，则此 <code>index</code> 下面的所有 <code>type</code> 都会被一起删除，所以这是一个有点危险的操作，读者需要慎重执行，千万不要只想着 <strong>一顿操作猛如虎 </strong>，最终沦落为 <strong>不领工资快跑路 </strong>的境地，或者造成 <strong>明天去一趟财务室 </strong>的严重后果。</p><p>参考官方文档内容如下：</p><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/indices-delete-index.html" target="_blank" rel="noopener">indices-delete-index</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/1.7/indices-open-close.html" target="_blank" rel="noopener">indices-open-close</a></li></ul><p>看文档很明显，我需要使用三个 <code>HTTP</code> 接口，请读者继续往下看。</p><h2 id="删除索引"><a href="# 删除索引" class="headerlink" title="删除索引"></a>删除索引 </h2><p> 删除索引，使用 <code>curl -XDELETE http://localhost:9200/your_index</code> 接口即可，把主机地址、端口号、索引名称更换成实际的取值即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190823232341.png" alt="删除索引文档" title="删除索引文档"></p><p>如果想一次性删除多个索引，可以传入多个索引名称，使用逗号连接，例如：<code>index1,index2,index3</code>，这样就可以一次性删除，但是索引也不能太多，我在自己的集群测试，只能传入 20 个，再多会被忽略，不会被删除。</p><p>当然，为了方便用户使用，<code>Elasticsearch</code> 也是支持通配符的，例如使用：<br><code>curl -XDELETE http://localhost:9200/_all</code>、<br><code>curl -XDELETE http://localhost:9200/*</code><br>就可以把所有的索引删除。其中，<code>_all</code>、<code>*</code> 就是通配符，匹配所有的索引名称，显然这是一个极度危险的操作，如果做了真的是只能 <strong>删库跑路 </strong>。</p><p>另外还有一种比较安全的通配符，就是前缀匹配，例如使用 <code>curl -XDELETE http://localhost:9200/test-*</code> 就可以把以 <code>test-</code> 开头的索引删除，不会删除不满足这个匹配条件的索引。</p><p>当然，是有办法可以避免这种潜在的危险操作，那就是关闭通配符的功能，在 <code>Elasticsearch</code> 的配置文件 <code>elasticsearch.yml</code> 中，有一个 <code>action.destructive_requires_name=true</code> 参数，控制着 <code>_all</code>、<code>*</code> 这两个通配符的开启还是关闭【配置为 true 表示拒绝通配符，只能匹配特定的索引名称】。</p><p>除了直接更改配置文件，需要重启 <code>Elasticsearch</code> 集群，也可以通过 <strong>动态变更参数 </strong>接口来改变这个参数的取值，这样就不用重启集群。但是，这一特性需要 <code>v2.x</code> 以上的版本才会支持，参考官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.1/cluster-update-settings.html" target="_blank" rel="noopener">cluster-update-settings</a> 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190823232359.png" alt="动态更新配置文档" title="动态更新配置文档"></p><p>以下使用配置举例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl XPUT http://localhost:9200/_cluster/settings -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    永久生效 </span><br><span class="line">    &quot;persistent&quot; : &#123;</span><br><span class="line">        &quot;action.destructive_requires_name&quot; : true</span><br><span class="line">    &#125;,</span><br><span class="line">    本次生效，重启集群后失效 </span><br><span class="line">    &quot;transient&quot; : &#123;</span><br><span class="line">        &quot;iaction.destructive_requires_name&quot; : true </span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>其实仔细想想，关闭通配符可以保证数据安全，但是却给操作带来了一定的麻烦，这个需要读者自己权衡。</p><h2 id="开启关闭索引"><a href="# 开启关闭索引" class="headerlink" title="开启关闭索引"></a>开启关闭索引 </h2><p> 开启、关闭索引的接口比较简单，如下：</p><ul><li>开启索引，<code>curl -XPOST http://localhost:9200/your_index/_open</code></li><li>关闭索引，<code>curl -XPOST http://localhost:9200/your_index/_close</code></li></ul><p>把主机地址、端口号、索引名称更换成实际的取值即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190823232821.png" alt="开启关闭索引文档" title="开启关闭索引文档"></p><p>这里的通配符使用方式与上面的一致，不再赘述。</p><h1 id="代码实现"><a href="# 代码实现" class="headerlink" title="代码实现"></a>代码实现 </h1><p> 技术分析完毕，开始使用代码实现，这样就可以在服务器起一个定时程序，用来定时关闭一些索引，定时删除一些索引，以后只需要定期检查有无误操作即可。</p><p>代码逻辑比较简单，使用参数封装 <code>HTTP</code> 请求，然后发送给 <code>Elasticsearch</code> 集群，再解析返回的数据，来判断操作是否成功。</p><p>代码示例我已经放在 <code>GitHub</code> 上面，仅供参考：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-elasticsearch/src/main/java/org/playpi/study/client" target="_blank" rel="noopener">CleanEsClusterClient.java</a> ，搜索 <strong>CleanEsClusterClient</strong> 类即可，此外，核心的处理类是 <strong>EsClusterUtil</strong>，里面封装了主要逻辑。</p><p>下面使用删除索引的 <code>HTTP</code> 请求处理来展示一下代码示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 删除指定的索引 </span><br><span class="line">     * 索引可以批量传入，使用逗号分隔即可 </span><br><span class="line">     *</span><br><span class="line">     * @param hostport</span><br><span class="line">     * @param indexName</span><br><span class="line">     * @param useSsl    是否使用 https 协议 </span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">public static Boolean deleteIndex (String hostport, String indexName, Boolean useSsl) &#123;</span><br><span class="line">	String url = &quot;http://&quot; + hostport + &quot;/&quot; + indexName;</span><br><span class="line">	String resultStr = HttpUtil.getHttpResult (url, null, HttpUtil.HTTP_METHOD.DELETE, useSsl);</span><br><span class="line">	Map&lt;String, Object&gt; resultMap = new Gson ().fromJson (resultStr, Map.class);</span><br><span class="line">	if (null != resultMap &amp;&amp; Boolean.valueOf (resultMap.getOrDefault (&quot;acknowledged&quot;, false).toString ())) &#123;</span><br><span class="line">		return true;</span><br><span class="line">	&#125;</span><br><span class="line">	return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190823234735.png" alt="删除索引代码示例" title="删除索引代码示例"></p><p>可以看到只有几行代码，其中 <code>HttpUtil</code> 是一个工具类，也可以在 <code>GitHub</code> 项目中搜索。</p><h1 id="使用命令发送请求"><a href="# 使用命令发送请求" class="headerlink" title="使用命令发送请求"></a>使用命令发送请求 </h1><p> 演示完了代码，下面演示使用 <code>curl</code> 命令的方式来操作 <code>Elasticsearch</code> 集群，与 <code>Java</code> 代码发送 <code>HTTP</code> 请求的效果是一样的，我这里只是简单演示关闭索引的操作。</p><p>使用如下命令向我的 <code>Elasticsearch</code> 集群发送一个关闭索引的请求：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPOST http://dev2:9200/test-index-v2/_close</span><br></pre></td></tr></table></figure><p>发送成功后，可以看到返回结果，关闭成功：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&quot;acknowledged&quot;:true&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190823234220.png" alt="发送命令返回结果" title="发送命令返回结果"></p><p>去 <code>Elasticsearch</code> 集群看一下索引的状态，索引 <code>test-index-v2</code> 的确已经被关闭了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190823234312.png" alt="v2 索引被关闭" title="v2 索引被关闭"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Java</tag>
        <tag>HTTP</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title>使用海龟绘图绘制一些植物</title>
    <url>/2019110201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在 2019 年 10 月 1 日的时候，我尝试使用海龟绘图绘制了一面五星红旗，参考我的另外一篇博文：<a href="https://www.playpi.org/2019100101.html">使用海龟绘图绘制一面五星红旗 </a> ，我觉得挺好玩的，还想进一步了解一下相关知识。后来，我又探索了一些绘图内容，发现可以绘制一些植物，例如树木、花草，核心就是要定义好绘制曲线。本文记录几个常见的植物：樱花树、火树银花、玫瑰花。</p><a id="more"></a><p> 提前声明，下文中涉及的 <code>Python</code> 脚本已经被我上传至 <code>GitHub</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypipython/tree/master/iplaypipython/20191102" target="_blank" rel="noopener">绘制植物脚本 </a> ，脚本命名使用英文单词作为前缀。</p><h1 id="樱花树"><a href="# 樱花树" class="headerlink" title="樱花树"></a> 樱花树 </h1><p> 画樱花树的整体思路就是先绘制樱花树，再绘制地上的落叶。</p><p>其中，绘制樱花树使用了递归的方式，从主干开始绘制，绘制主干完成后分为左右两侧的枝干，不停递归绘制，对于长度比较长的枝干，仍旧按照主干的方式绘制，直到长度比较短的枝干，作为树枝末端存在，会有不同的颜色、粗细。</p><p>代码示例如下，里面包含了注释，很容易就能看懂：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding=utf-8</span><br><span class="line"># 画一棵樱花树（模拟）</span><br><span class="line"># 导入 turtle 模块 </span><br><span class="line">import turtle</span><br><span class="line"># 导入 random 模块，每次绘制的樱花树形状随机 </span><br><span class="line">import random</span><br><span class="line">from turtle import *</span><br><span class="line">from time import sleep</span><br><span class="line"></span><br><span class="line"># 画樱花的躯干，传入躯干长度、画布 </span><br><span class="line"># 这里面会有递归调用 </span><br><span class="line"># 先画主干，然后递归画树枝，树枝越来越短，颜色会随机生成 </span><br><span class="line">def draw_tree (branchLen, t):</span><br><span class="line">    sleep (0.0005)</span><br><span class="line">    if branchLen &gt; 3:</span><br><span class="line">        # 末端的树枝 </span><br><span class="line">        if 8 &lt;= branchLen &lt;= 12:</span><br><span class="line">            # 随机生成画笔的颜色，用来画末端的树枝 </span><br><span class="line">            if random.randint (0,2) == 0:</span><br><span class="line">                # 白色 </span><br><span class="line">                t.color (&apos;snow&apos;)</span><br><span class="line">            else:</span><br><span class="line">                # 淡珊瑚色 </span><br><span class="line">                t.color (&apos;lightcoral&apos;)</span><br><span class="line">            # 画笔的线条粗细 </span><br><span class="line">            t.pensize (branchLen / 3)</span><br><span class="line">        elif branchLen &lt; 8:</span><br><span class="line">            if random.randint (0,1) == 0:</span><br><span class="line">                t.color (&apos;snow&apos;)</span><br><span class="line">            else:</span><br><span class="line">                t.color (&apos;lightcoral&apos;) # 淡珊瑚色 </span><br><span class="line">            t.pensize (branchLen / 2)</span><br><span class="line">        else:</span><br><span class="line">            # 树干的颜色赭 (zhě) 色、粗细 6</span><br><span class="line">            t.color (&apos;sienna&apos;)</span><br><span class="line">            t.pensize (branchLen / 10)</span><br><span class="line">        # 向前移动 branchLen 个像素 </span><br><span class="line">        t.forward (branchLen)</span><br><span class="line">        # 随机生成右转的角度 </span><br><span class="line">        a = 1.5 * random.random ()</span><br><span class="line">        t.right (20 * a)</span><br><span class="line">        # 递归画樱花树 </span><br><span class="line">        b = 1.5 * random.random ()</span><br><span class="line">        draw_tree (branchLen - 10 * b, t)</span><br><span class="line">        # 左转，递归画樱花树 </span><br><span class="line">        t.left (40 * a)</span><br><span class="line">        draw_tree (branchLen - 10 * b, t)</span><br><span class="line">        # 画笔回正方向，向前移动 </span><br><span class="line">        t.right (20 * a)</span><br><span class="line">        t.up ()</span><br><span class="line">        t.backward (branchLen)</span><br><span class="line">        t.down ()</span><br><span class="line"> </span><br><span class="line"># 掉落的花瓣，传入个数、画布 </span><br><span class="line">def draw_petal (m, t):</span><br><span class="line">    # 循环绘制 m 个花瓣 </span><br><span class="line">    for i in range (m):</span><br><span class="line">        # 生成随机的移动像素个数，a 用来控制左右的移动，b 用来控制上下的移动 </span><br><span class="line">        # a 大一点，b 小一点，总体可以让花瓣看起来有透视立体感 </span><br><span class="line">        a = 200 - 400 * random.random ()</span><br><span class="line">        b = 10 - 20 * random.random ()</span><br><span class="line">        # 以下就是到达花瓣位置 </span><br><span class="line">        # 提起画笔 </span><br><span class="line">        t.up ()</span><br><span class="line">        # 向前移动 b 个像素 </span><br><span class="line">        t.forward (b)</span><br><span class="line">        # 左转 90 度角度 </span><br><span class="line">        t.left (90)</span><br><span class="line">        # 向前移动 a 个像素 </span><br><span class="line">        t.forward (a)</span><br><span class="line">        # 放下画笔 </span><br><span class="line">        t.down ()</span><br><span class="line">        # 淡珊瑚色，花瓣的颜色 </span><br><span class="line">        t.color (&apos;lightcoral&apos;)</span><br><span class="line">        # 以下是绘制一个花瓣 </span><br><span class="line">        # 绘制一个圆 </span><br><span class="line">        t.circle (1)</span><br><span class="line">        # 以下就是回到中心点 </span><br><span class="line">        # 提起画笔 </span><br><span class="line">        t.up ()</span><br><span class="line">        # 向后移动 a 个像素 </span><br><span class="line">        t.backward (a)</span><br><span class="line">        # 右转 90 度角度 </span><br><span class="line">        t.right (90)</span><br><span class="line">        # 向后移动 b 个像素 </span><br><span class="line">        t.backward (b)</span><br><span class="line"></span><br><span class="line">def draw_cherry ():</span><br><span class="line">    # 海龟绘图区域 </span><br><span class="line">    t = turtle.Turtle ()</span><br><span class="line">    # 画布 </span><br><span class="line">    w = turtle.Screen ()</span><br><span class="line">    # 设置大小，4 个参数：宽度、高度、起始值 x 轴、起始值 y 轴 </span><br><span class="line">    w.setup (1000, 600, 200, 100)</span><br><span class="line">    # 设置背景为小麦颜色 </span><br><span class="line">    w.bgcolor (&apos;wheat&apos;)</span><br><span class="line">    # 隐藏画笔 </span><br><span class="line">    t.hideturtle ()</span><br><span class="line">    # 获取屏幕，并追踪 </span><br><span class="line">    t.getscreen ().tracer (5, 0)</span><br><span class="line">    t.left (90)</span><br><span class="line">    t.up ()</span><br><span class="line">    t.backward (200)</span><br><span class="line">    t.down ()</span><br><span class="line">    # 1、画樱花的躯干 </span><br><span class="line">    draw_tree (60, t)</span><br><span class="line">    # 2、画掉落的花瓣 </span><br><span class="line">    draw_petal (200, t)</span><br><span class="line">    # 3、点击退出 </span><br><span class="line">    w.exitonclick ()</span><br><span class="line"></span><br><span class="line"># 程序入口 </span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    print (&apos; 开始绘制樱花树 & apos;)</span><br><span class="line">    draw_cherry ()</span><br><span class="line">    print (&apos; 结束绘制樱花树 & apos;)</span><br><span class="line">    # input (&apos; 暂停，等待输入（输入任意内容按回车键可退出）：&apos;)</span><br></pre></td></tr></table></figure><p>运行结果如下，由于角度是随机生成的，所以每次运行结果都会不一样：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191105000726.png" alt="运行结果 1" title="运行结果 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191105000732.png" alt="运行结果 2" title="运行结果 2"></p><h1 id="火树银花"><a href="# 火树银花" class="headerlink" title="火树银花"></a>火树银花 </h1><p> 绘制火树银花的思路和上面的樱花树一致，只不过火树银花这个名字比较酷，树枝没有区分粗细，只区分长度、颜色，整个画面采用黑色背景，看起来非常闪耀。</p><p>需要注意的是，运行一次耗时比较长，大概需要 4-5 分钟。</p><p>代码内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># !/usr/bin/python3</span><br><span class="line"># -*-coding:UTF-8-*-</span><br><span class="line"># 火树银花 </span><br><span class="line"></span><br><span class="line"># 导入海龟作图模块 </span><br><span class="line">import turtle</span><br><span class="line"># 导入随机数模块 </span><br><span class="line">import random as rm</span><br><span class="line"></span><br><span class="line"># 角度 </span><br><span class="line">angle = [15, 5, 10, 20, 25, 30]</span><br><span class="line"># 颜色数组，多种颜色供绘制时随机选择，青、红、粉、蓝、绿、黄 </span><br><span class="line">color = [&apos;yellow&apos;, &apos;green&apos;, &apos;blue&apos;, &apos;red&apos;, &apos;pink&apos;, &apos;cyan&apos;]</span><br><span class="line"></span><br><span class="line"># 绘制树干，传入长度、画布对象 </span><br><span class="line"># 绘制思路：根据长度的不同，生成的角度不同，树干会分为 2 个树枝，然后树枝再递归分叉 </span><br><span class="line"># 直到树枝的长度过小，变为树枝末梢，不再分叉 </span><br><span class="line">def draw_tree (branch_len, t, cr):</span><br><span class="line">    # 树干颜色 </span><br><span class="line">    t.color (cr)</span><br><span class="line">    # 设置画笔的粗细 </span><br><span class="line">    t.pensize (1)</span><br><span class="line">    # 随机选择颜色，不等于树干颜色，用于分叉树枝 </span><br><span class="line">    new_color = color [:]</span><br><span class="line">    new_color.remove (cr)</span><br><span class="line">    new_cr = rm.choice (new_color)</span><br><span class="line">    # 随机转动角度，用于分叉树枝 </span><br><span class="line">    ag1 = rm.choice (angle)</span><br><span class="line">    ag2 = rm.choice (angle)</span><br><span class="line">    # 分叉树枝的长度，默认等于树干的长度 </span><br><span class="line">    new_branch_len = branch_len</span><br><span class="line">    # 分叉树枝的长度重新计算，越来越短 </span><br><span class="line">    if branch_len &gt; 120:</span><br><span class="line">        new_branch_len = branch_len - 20</span><br><span class="line">    elif branch_len &gt;= 60:</span><br><span class="line">        new_branch_len = branch_len - 15</span><br><span class="line">    elif branch_len &gt;= 20:</span><br><span class="line">        new_branch_len = branch_len - 10</span><br><span class="line">    else:</span><br><span class="line">        new_branch_len = branch_len - 5</span><br><span class="line">    # 开始绘制 </span><br><span class="line">    if 10 &gt;= branch_len:</span><br><span class="line">        # 树枝太短，无需绘制，递归结束 </span><br><span class="line">        pass</span><br><span class="line">    else:</span><br><span class="line">        # 向前移动，绘制树干 </span><br><span class="line">        t.forward (branch_len)</span><br><span class="line">        # 右转指定角度 1，分叉 </span><br><span class="line">        t.right (ag1)</span><br><span class="line">        # 递归画树干，可以理解成子树 </span><br><span class="line">        draw_tree (new_branch_len, t, new_cr)</span><br><span class="line">        # 左转指定角度 2，分叉 </span><br><span class="line">        t.left (ag1 + ag2)</span><br><span class="line">        draw_tree (new_branch_len, t, new_cr)</span><br><span class="line">        # 角度回正，右转指定角度 2</span><br><span class="line">        t.right (ag2)</span><br><span class="line">        # 恢复颜色并后退 </span><br><span class="line">        t.color (cr)</span><br><span class="line">        t.backward (branch_len)</span><br><span class="line"></span><br><span class="line"># 开始绘制整棵树 </span><br><span class="line">def draw_fire_cilver ():</span><br><span class="line">    t = turtle.Turtle ()</span><br><span class="line">    w = turtle.Screen ()</span><br><span class="line">    # 设置背景为黑色 </span><br><span class="line">    w.bgcolor (&apos;black&apos;)</span><br><span class="line">    # 设置弹框大小，4 个参数：宽度、高度、起始值 x 轴、起始值 y 轴 </span><br><span class="line">    w.setup (1200, 800, 200, 50)</span><br><span class="line">    # 加快速度 </span><br><span class="line">    t.speed (10)</span><br><span class="line">    # 调整画笔的位置，开始的位置在中间偏下方 </span><br><span class="line">    t.left (90)</span><br><span class="line">    t.up ()</span><br><span class="line">    t.backward (400)</span><br><span class="line">    t.down ()</span><br><span class="line">    # 跟踪画笔，可以看到整个绘制轨迹 </span><br><span class="line">    turtle.tracer (5)</span><br><span class="line">    # 垂直位置绘制 1 棵，左右边再各绘制 3 棵，共 7 棵 </span><br><span class="line">    t.left (15)</span><br><span class="line">    for i in range (0,7):</span><br><span class="line">        # 绘制 1 棵，右转 5 度 </span><br><span class="line">        print (&apos;==== 绘制第 [&apos; + str (i + 1) + &apos;] 棵树 & apos;)</span><br><span class="line">        draw_tree (150, t, &apos;cyan&apos;)</span><br><span class="line">        t.right (5)</span><br><span class="line">    # 单机退出 </span><br><span class="line">    w.exitonclick ()</span><br><span class="line"></span><br><span class="line"># 主程序入口 </span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print (&apos; 开始绘制火树银花 & apos;)</span><br><span class="line">    draw_fire_cilver ()</span><br><span class="line">    print (&apos; 结束绘制火树银花 & apos;)</span><br><span class="line">    # input (&apos; 暂停，等待输入（输入任意内容按回车键可退出）：&apos;)</span><br></pre></td></tr></table></figure><p>运行结果如下图，由于角度、颜色也是随机生成的，所以每次运行结果是不一致的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191105001116.png" alt="运行结果" title="运行结果"></p><p>在网络上找到的示例，看起来更好看一些。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191105001233.png" alt="网络上找到的示例" title="网络上找到的示例"></p><h1 id="玫瑰花"><a href="# 玫瑰花" class="headerlink" title="玫瑰花"></a>玫瑰花 </h1><p> 玫瑰花比较有意思，会涉及到非规则图形，花瓣的形状怎么绘制、绿叶的形状怎么绘制等。</p><p>简单思路：</p><ul><li>先绘制花瓣的边框，包括填充颜色 </li><li> 再绘制花瓣中的线条，凸显出花瓣的层次 </li><li> 绘制花枝主干 </li><li> 绘制两片绿叶，包括绿叶的枝条 </li></ul><p> 代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 导入海龟绘图模块 </span><br><span class="line">import turtle as t</span><br><span class="line"></span><br><span class="line"># 定义一个曲线绘制函数 </span><br><span class="line"># 思路就是画多个小圆弧，构成曲线 </span><br><span class="line"># n 表示画多少次圆弧，n 越大画的曲线越长 </span><br><span class="line"># r 表示圆弧半径，r 越大则曲线越平滑 </span><br><span class="line"># d=1 则是左弯的圆弧，d=-1 则是右弯的圆弧（由于屏幕的分辨率不同，有时候看不出来明显的弯度）</span><br><span class="line">def degree_curve (n, r, d=1):</span><br><span class="line">    for i in range (n):</span><br><span class="line">        t.left (d)</span><br><span class="line">        # r 是半径，abs (d) 是夹角 </span><br><span class="line">        t.circle (r, abs (d))</span><br><span class="line"></span><br><span class="line"># 绘制玫瑰花 </span><br><span class="line">def draw_rose (s):</span><br><span class="line">    # 设置画笔速度 </span><br><span class="line">    t.speed (100)</span><br><span class="line">    # 提起画笔，移动到指定位置 </span><br><span class="line">    t.penup ()</span><br><span class="line">    t.goto (0, 900 * s)</span><br><span class="line">    # 放下画笔 </span><br><span class="line">    t.pendown ()</span><br><span class="line"></span><br><span class="line">    # 开始填充，并绘制花朵形状 </span><br><span class="line">    t.begin_fill ()</span><br><span class="line">    # 起步花蕊的曲线，30 度圆弧，一层椭圆下侧 </span><br><span class="line">    t.circle (200 * s, 30)</span><br><span class="line">    # 左弯曲线，60 次半径为 10 的圆弧，一层椭圆右侧 </span><br><span class="line">    degree_curve (60, 50 * s)</span><br><span class="line">    # 和起步花蕊的曲线对称，30 度圆弧 </span><br><span class="line">    t.circle (200 * s, 30)</span><br><span class="line">    # 左弯曲线，4 次半径为 20 的圆弧，为了调整角度 </span><br><span class="line">    degree_curve (4, 100 * s)</span><br><span class="line">    # 50 度圆弧，一层椭圆上侧 </span><br><span class="line">    t.circle (200 * s, 50)</span><br><span class="line">    # 左弯曲线，50 次半径为 10 的圆弧，一层椭圆左侧下侧 </span><br><span class="line">    degree_curve (50, 50 * s)</span><br><span class="line">    # 65 度圆弧，一层椭圆下侧 </span><br><span class="line">    t.circle (350 * s, 65)</span><br><span class="line">    # 左弯曲线，40 次半径为 14 的圆弧，二层椭圆右侧 </span><br><span class="line">    degree_curve (40, 70 * s)</span><br><span class="line">    # 50 度圆弧，二层椭圆右侧上侧 </span><br><span class="line">    t.circle (150 * s, 50)</span><br><span class="line">    # 右弯曲线，20 次半径为 10 的圆弧，二层椭圆上侧 </span><br><span class="line">    degree_curve (20, 50 * s, -1)</span><br><span class="line">    # 60 度圆弧，二层椭圆上侧 </span><br><span class="line">    t.circle (400 * s, 60)</span><br><span class="line">    # 右弯曲线，18 次半径为 10 的圆弧，二层椭圆左侧 </span><br><span class="line">    degree_curve (18, 50 * s)</span><br><span class="line">    # 前进 125，直线，二层椭圆左侧连接处 </span><br><span class="line">    t.fd (250 * s)</span><br><span class="line">    # 右转 150 度 </span><br><span class="line">    t.right (150)</span><br><span class="line">    # 12 度圆弧，顺时针画圆，右弯曲线 </span><br><span class="line">    t.circle (-500 * s, 12)</span><br><span class="line">    # 左转 140 度 </span><br><span class="line">    t.left (140)</span><br><span class="line">    # 110 度圆弧，左侧花瓣边缘 </span><br><span class="line">    t.circle (550 * s, 110)</span><br><span class="line">    # 左转 27 度 </span><br><span class="line">    t.left (27)</span><br><span class="line">    # 100 度圆弧，右侧花瓣边缘 </span><br><span class="line">    t.circle (650 * s, 100)</span><br><span class="line">    # 左转 130 度 </span><br><span class="line">    t.left (130)</span><br><span class="line">    # 20 度圆弧，顺时针画圆 </span><br><span class="line">    t.circle (-300 * s, 20)</span><br><span class="line">    # 右转 123 度 </span><br><span class="line">    t.right (123)</span><br><span class="line">    # 57 度圆弧，连接到二层椭圆右侧 </span><br><span class="line">    t.circle (220 * s, 57)</span><br><span class="line">    # 至此图形封闭，颜色填充完成 </span><br><span class="line">    t.end_fill ()</span><br><span class="line"></span><br><span class="line">    # 绘制花枝形状，包括勾勒花瓣中间的线条 </span><br><span class="line">    # 左转 120 度 </span><br><span class="line">    t.left (120)</span><br><span class="line">    # 前进 140</span><br><span class="line">    t.fd (280 * s)</span><br><span class="line">    # 左转 115 度 </span><br><span class="line">    t.left (115)</span><br><span class="line">    # 33 度圆弧，连接到右侧花瓣边缘 </span><br><span class="line">    t.circle (300 * s, 33)</span><br><span class="line">    # 左转 180 度 </span><br><span class="line">    t.left (180)</span><br><span class="line">    # 33 度圆弧，顺时针，为了回到上一步画圆弧之前的位置 </span><br><span class="line">    t.circle (-300 * s, 33)</span><br><span class="line">    # 右弯曲线，70 次半径为 113 的圆弧，右侧花瓣线条 </span><br><span class="line">    degree_curve (70, 225 * s, -1)</span><br><span class="line">    # 104 度圆弧，右侧花瓣线条 </span><br><span class="line">    t.circle (350 * s, 104)</span><br><span class="line">    # 左转 90 度 </span><br><span class="line">    t.left (90)</span><br><span class="line">    # 105 度圆弧，左侧花瓣线条 </span><br><span class="line">    t.circle (200 * s, 105)</span><br><span class="line">    # 63 度弧度，顺时针，左侧花瓣线条，至此花瓣线条完成 </span><br><span class="line">    t.circle (-500 * s, 63)</span><br><span class="line">    # 提起画笔，移动到指定位置，花瓣与花枝连接处 </span><br><span class="line">    t.penup ()</span><br><span class="line">    t.goto (170 * s, -30 * s)</span><br><span class="line">    # 放下画笔 </span><br><span class="line">    t.pendown ()</span><br><span class="line">    # 左转 160 度，朝向调整为朝下 </span><br><span class="line">    t.left (160)</span><br><span class="line">    # 左弯曲线，20 次半径为 1250 的圆弧，花枝 </span><br><span class="line">    degree_curve (20, 2500 * s)</span><br><span class="line">    # 右弯曲线，220 次半径为 125 的圆弧，花枝 </span><br><span class="line">    degree_curve (220, 250 * s, -1)</span><br><span class="line"></span><br><span class="line">    # 下面开始绘制 2 片绿叶 </span><br><span class="line">    # 绘制一个绿色叶子，上方的 </span><br><span class="line">    t.fillcolor (&apos;green&apos;)</span><br><span class="line">    # 提起画笔移动到指定位置，叶尖 </span><br><span class="line">    t.penup ()</span><br><span class="line">    t.goto (670 * s, -180 * s)</span><br><span class="line">    t.pendown ()</span><br><span class="line">    # 右转 140 度，调整角度 </span><br><span class="line">    t.right (140)</span><br><span class="line">    # 开始填充 </span><br><span class="line">    t.begin_fill ()</span><br><span class="line">    # 120 度弧度，绿叶上侧 </span><br><span class="line">    t.circle (300 * s, 120)</span><br><span class="line">    # 左转 60 度 </span><br><span class="line">    t.left (60)</span><br><span class="line">    # 120 度弧度，绿叶下侧 </span><br><span class="line">    t.circle (300 * s, 120)</span><br><span class="line">    # 完成填充 </span><br><span class="line">    t.end_fill ()</span><br><span class="line">    t.penup ()</span><br><span class="line">    # 移动到绿叶枝条起始处 </span><br><span class="line">    t.goto (180 * s, -550 * s)</span><br><span class="line">    t.pendown ()</span><br><span class="line">    # 右转 85 度 </span><br><span class="line">    t.right (85)</span><br><span class="line">    # 40 度圆弧，绿叶枝条 </span><br><span class="line">    t.circle (600 * s, 40)</span><br><span class="line">    </span><br><span class="line">    # 绘制另一个绿色叶子，下方的 </span><br><span class="line">    # 提笔，移动到叶尖 </span><br><span class="line">    t.penup ()</span><br><span class="line">    t.goto (-150 * s, -1000 * s)</span><br><span class="line">    t.pendown ()</span><br><span class="line">    t.begin_fill ()</span><br><span class="line">    # 右转 120 度，调整角度 </span><br><span class="line">    t.rt (120)</span><br><span class="line">    # 115 度圆弧，叶子下侧 </span><br><span class="line">    t.circle (300 * s, 115)</span><br><span class="line">    # 左转 75 度 </span><br><span class="line">    t.left (75)</span><br><span class="line">    # 100 度弧度，叶子上侧 </span><br><span class="line">    t.circle (300 * s, 100)</span><br><span class="line">    t.end_fill ()</span><br><span class="line">    t.penup ()</span><br><span class="line">    # 移动到绿叶枝条起始处 </span><br><span class="line">    t.goto (430 * s, -1070 * s)</span><br><span class="line">    t.pendown ()</span><br><span class="line">    # 右转 30 度，调整角度 </span><br><span class="line">    t.right (30)</span><br><span class="line">    # 35 度圆弧，右弯，叶子枝条 </span><br><span class="line">    t.circle (-600 * s, 35)</span><br><span class="line">    # 等待退出 </span><br><span class="line">    t.exitonclick ()</span><br><span class="line"></span><br><span class="line"># 程序入口 </span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    print (&apos; 开始绘制玫瑰花 & apos;)</span><br><span class="line">    # 比例设定 </span><br><span class="line">    s = 0.2</span><br><span class="line">    # 设置弹窗大小 </span><br><span class="line">    t.setup (500 * 5 * s, 750 * 5 * s)</span><br><span class="line">    # 背景颜色，小麦色 </span><br><span class="line">    t.bgcolor (&apos;wheat&apos;)</span><br><span class="line">    # 设置画笔颜色，黑色 </span><br><span class="line">    t.pencolor (&quot;black&quot;)</span><br><span class="line">    # 设置填充颜色为红色，绘制花朵 </span><br><span class="line">    t.fillcolor (&quot;red&quot;)</span><br><span class="line">    draw_rose (s)</span><br><span class="line">    print (&apos; 结束绘制玫瑰花 & apos;)</span><br><span class="line">    # input (&apos; 暂停，等待输入（输入任意内容按回车键可退出）：&apos;)</span><br></pre></td></tr></table></figure><p>这里面的重点就是 <code>degree_curve (n, r, d=1)</code> 方法，它是为了绘制不规则图形而定义的。此外用的次数比较多的就是海龟绘图内置的 <code>circle</code> 方法，用来绘制标准的圆弧。</p><p>运行结果如下图，包含花瓣、绿叶。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191117003518.png" alt="玫瑰花运行结果" title="玫瑰花运行结果"></p><h1 id="参考"><a href="# 参考" class="headerlink" title="参考"></a>参考</h1><p><code>Python</code> 官方文档：<a href="https://docs.python.org/zh-cn/3/library/turtle.html" target="_blank" rel="noopener">Python3 文档说明</a></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Turtle</tag>
        <tag>cherry</tag>
        <tag>tree</tag>
        <tag>rose</tag>
      </tags>
  </entry>
  <entry>
    <title>关于 Spark 或者 mapreduce 的累加器</title>
    <url>/2017043001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在 <code>Spark</code> 和 <code>Hadoop</code> 的 <code>MapReduce</code> 中都有累加器的概念，顾名思义，累加器就是用来做累加【或者累减】使用的，有时候为了统计某些值，在程序中埋入指标，这样在程序运行中、运行后都可以清晰观察到统计指标，还能辅助检查程序的问题。在 <code>Spark</code>、<code>MapReduce</code> 中，它们的使用方式尽管有一点点不同的地方，甚至在 <code>Spark</code> 的不同版本中使用方式也会不一致，但也算是大同小异。本文简单记录在 <code>Spark</code>、<code>MapReduce</code> 中累加器的使用，并补充说明一些重要的坑，<code>Spark</code> 环境基于 <code>v1.6.2</code>，<code>Hadoop</code> 环境基于 <code>v2.7.1</code> 。</p><a id="more"></a><h1 id="累加器基础概念"><a href="# 累加器基础概念" class="headerlink" title="累加器基础概念"></a>累加器基础概念 </h1><p> 在 <code>Spark</code> 任务中，如果想要在 <code>Task</code> 运行的过程中统计某些指标，例如处理了多少数据量、过滤了多少数据量，使用普通的变量是不行的，会有并发的问题。此时，累加器就可以出场了，使用方式简单，统计结果准确。</p><p>只要在代码中指定了累加器，并在 <code>Task</code> 中使用它，通过 <code>Action</code> 算子触发后，在 <code>Spark</code> 任务运行中或者运行完成后，都可以观察到累计器的值。</p><p>例如在 <code>Spark</code> 任务运行的过程中，通过 <code>SparkUI</code> 可以观察累加器的取值变化，在 <code>Stages</code> 标签页中选择带有累加器的某一个 <code>Stage</code>，查看详情，就可以看到在 <code>Accumulators</code> 指标列表中，列出了所有累加器的名字和取值。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714001039.png" alt="在 SparkUI 中查看任务的累加器" title="在 SparkUI 中查看任务的累加器"></p><p>而在 <code>Hadoop</code> 的 <code>MapReduce</code> 中，累加器的用法也是一样，不同的是，在 <code>MapReduce</code> 的调度系统 <code>Yarn</code> 中，无法观察到累加器的取值变化，只能等待 <code>MapReduce</code> 运行完成【其实也可以，需要开启 <code>HistoryServer</code> 服务，见下文的介绍】，才能在输出日志中查看累加器的最终取值。而且这是自动统计打印出来的，不需要手动输出。</p><p>下面详细介绍累加器的使用方式。</p><h1 id="累加器的使用"><a href="# 累加器的使用" class="headerlink" title="累加器的使用"></a>累加器的使用 </h1><h2 id="在 -Spark- 中的使用"><a href="# 在 -Spark- 中的使用" class="headerlink" title="在 Spark 中的使用"></a> 在 Spark 中的使用 </h2><p> 首先说明一下，注意不同版本的影响，使用方式会不一致，我下面列出的例子都是基于 <code>Spark v1.6.2</code>，例如在 <code>Spark v2.x</code> 的版本中，初始化累加器的方式就改变了一些，在此不再赘述。</p><p><code>Spark</code> 提供的 <code>Accumulator</code>，主要用于多个节点【Excutor】对同一个变量进行共享性的操作。<code>Accumulator</code> 只提供了累加的功能【调用 add () 方法】，给我们提供了多个 <code>Task</code> 对一个变量并行操作的功能。但是 <code>Task</code> 只能对 <code>Accumulator</code> 进行累加操作，不能读取它的值，只有 <code>Driver</code> 端的程序可以读取 <code>Accumulator</code> 的值【调用 <code>value ()</code> 方法】。</p><h3 id="代码接口"><a href="# 代码接口" class="headerlink" title="代码接口"></a>代码接口 </h3><p> 为了使用累加器，首先要有上下文对象，对于 <code>Java</code> 的接口来说就是 <code>JavaSparkContext</code>，然后利用上下文对象创建累加器。下面列出几个简单的示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JavaSparkContext jsc = initJsc ();</span><br><span class="line">final Accumulator&lt;Integer&gt; totalAcc = jsc.accumulator (0, &quot;total&quot;);</span><br><span class="line">final Accumulator&lt;Integer&gt; saveTotalAcc = jsc.accumulator (0, &quot;saveTotal&quot;);</span><br><span class="line">final Accumulator&lt;Integer&gt; defaultAcc = jsc.accumulator (0);</span><br><span class="line">final Accumulator&lt;Double&gt; doubleAcc = jsc.doubleAccumulator (0);</span><br><span class="line">final Accumulator&lt;Integer&gt; intAcc = jsc.intAccumulator (0);</span><br></pre></td></tr></table></figure><p>代码片段截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714002724.png" alt="创建累加器代码片段" title="创建累加器代码片段"></p><p>这里把累加器的修饰符定义为 <code>final</code> 是有必要的，因为在 <code>Spark</code> 的 <code>Function</code> 中使用时，内部匿名类会要求变量必须为 <code>final</code> 类型的。</p><p>应该尽量为累加器命名【唯一标识】，这样在查看时才能区分是哪个累加器。</p><p>此外，除了普通的数值型累加器，还有集合型累加器，或者用户可以自定义累加器，只要实现特定的接口即可：<code>Accumulator</code>，然后通过 <code>JavaSparkContext</code> 对象进行注册，在此不再赘述。</p><p>创建完成后，就可以使用了，在自定义实现的 <code>Function</code> 中，可以使用累加器进行累加操作，代码片段如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">totalAcc.add (1);</span><br><span class="line">saveTotalAcc.add (1);</span><br></pre></td></tr></table></figure><p>代码片段截图如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714003706.png" alt="使用累加器代码片段" title="使用累加器代码片段"></p><p>注意一点，在 <code>Function</code> 中对累加器只能增加，不能取值，如果在 <code>Spark</code> 的 <code>RDD</code> 中试图取出累加器的值，<code>Spark</code> 任务会抛出异常而失败。</p><p>因为累加器，顾名思义，就是用来累加的，只能在 <code>Spark</code> 任务运行中【Task 端】进行累加，而且用户不用担心并发的问题，但是想要使用代码获取累加器的取值，只能等待 <code>Spark</code> 任务运行完成后，才能在 <code>Driver</code> 端进行取值操作。使用代码取值代码片段如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">System.out.println (&quot;====total:&quot; + totalAcc.value ());</span><br><span class="line">System.out.println (&quot;====saveTotal:&quot; + saveTotalAcc.value ());</span><br></pre></td></tr></table></figure><p>代码片段截图如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714004227.png" alt="累加器取值代码片段" title="累加器取值代码片段"></p><h3 id="前端界面查看"><a href="# 前端界面查看" class="headerlink" title="前端界面查看"></a>前端界面查看 </h3><p> 而如果有一个需求就是要在某时刻查看累加器的值，或者说需要实时查看累加器的值，能不能实现呢，当然可以，这就需要 <code>SparkUI</code> 出场了。</p><p>在提交 <code>Spark</code> 任务时，创建 <code>JavaSparkContext</code> 对象成功后，注意观察输出日志，会发现有一个重要的链接信息出现：SparkUI 的地址。当然，如果已经知道了自己所使用的 <code>Yarn</code> 或者 <code>Standalone</code> 集群的信息，就不需要关心这个日志了，直接打开浏览器就可以查看了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714004850.png" alt="在日志中查看 SparkUI 的地址" title="在日志中查看 SparkUI 的地址"></p><p>在上面的截图中，可以看到重要的一行信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">16:50:10 [main] INFO ui.SparkUI:58: Started SparkUI at http://192.168.10.99:4041</span><br></pre></td></tr></table></figure><p>这个就是 <code>SparkUI</code> 的地址，直接在浏览器中打开，就可以看到这个 <code>Spark</code> 任务的运行状态，其它的信息我在这里不关心，直接选择 <code>Stages</code> 标签页，可以看到下面有一个 <code>Stages</code> 列表，里面是运行中或者运行完成的 <code>Stage</code>：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714005348.png" alt="在 SparkUI 中查看 Stages" title="在 SparkUI 中查看 Stages"></p><p>选择一个带有累加器的 <code>Stage</code>，查看详细信息，可以看到 <code>Executor</code>、<code>Tasks</code>、<code>Accumulators</code> 等信息，在这里重点关注 <code>Accumulators</code> 的信息：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714005708.png" alt="在 SparkUI 中查看 Accumulators" title="在 SparkUI 中查看 Accumulators"></p><p>可以看到，我这里有 2 个累加器：<code>total</code>、<code>saveTotal</code>，它们的取值分别为 70552、70552。根据我的代码逻辑，这表示我的 <code>Spark</code> 任务已经处理了 70552 条数据，并且没有过滤掉 1 条数据，全部写出到文件。</p><h3 id="奇技淫巧"><a href="# 奇技淫巧" class="headerlink" title="奇技淫巧"></a>奇技淫巧 </h3><p> 如果需要使用累加器进行减法操作，可行吗，当然，把累加器的累加数值改为负数即可。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">totalAcc.add (-1);</span><br><span class="line">saveTotalAcc.add (-1);</span><br></pre></td></tr></table></figure><h2 id="在 -MapReduce- 中的使用"><a href="# 在 -MapReduce- 中的使用" class="headerlink" title="在 MapReduce 中的使用"></a>在 MapReduce 中的使用 </h2><p> 在 <code>MapReduce</code> 中使用累加器的方法就很简单了，不需要初始化，直接通过枚举类型 <code>Enum</code> 定义累加器的唯一标识，然后在 <code>Map</code> 或者 <code>Reduce</code> 中，利用 <code>Context</code> 上下文对象对累加器进行操作，例如增加指定数值。代码示例如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">context.getCounter (MREnum.MAP_READ).increment (1);</span><br><span class="line">if (result == null || result.isEmpty ()) &#123;</span><br><span class="line">	context.getCounter (MREnum.MAP_FILTER).increment (1);</span><br><span class="line">	return;</span><br><span class="line">&#125;</span><br><span class="line">String pk = new String (result.getRow ());</span><br><span class="line">if (StringUtil.isNullOrEmpty (pk)) &#123;</span><br><span class="line">	context.getCounter (MREnum.MAP_FILTER).increment (1);</span><br><span class="line">	return;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码片段截图如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714013323.png" alt="使用累加器代码片段" title="使用累加器代码片段"></p><p>使用累加器的核心代码就是：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">context.getCounter (MREnum.MAP_FILTER).increment (1);</span><br></pre></td></tr></table></figure><p>其中，<code>Context</code> 就是 <code>MapReduce</code> 中的上下文对象，<code>MREnum.MAP_FILTER</code> 是自定义的枚举类型，每个累加器对应一个。</p><p><code>MapReduce</code> 任务完成后，不需要手动输出累加器的取值，<code>Hadoop</code> 框架会自动统计输出各种指标，当然也包括累加器的取值。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190714013755.png" alt="累加器取值输出" title="累加器取值输出"></p><p>可以从上图中看到有 5 个累加器：<code>DONE</code>、<code>READ</code>、<code>REDUCE</code>、<code>SHUFFLE</code>、<code>WRITE</code>，它们的取值都是千万级别的数字。</p><p>此外，在 <code>Yarn</code> 等调度系统中无法查看 <code>MapReduce</code> 任务的累加器取值变化，~~ 这是一个遗憾～～。</p><p>以下为 2020-04-07 更新内容，可以通过 <code>Tracking UI</code> 查看累加器的取值。</p><h3 id="前端页面查看"><a href="# 前端页面查看" class="headerlink" title="前端页面查看"></a>前端页面查看 </h3><p> 在 <code>Tracking UI</code> 的页面中【前提是要开启 <code>HistoryServer</code> 服务】，可以看到左上角 <code>Job</code> 下有一个 <code>Counters</code> 选项，打开它就可以查看累加器了。除了基本的内置累加器，还有自定义累加器，这里看到的内容和日志中输出的一致。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200407220450.png" alt="MapReduce 查看 Counters" title="MapReduce 查看 Counters"></p><h1 id="注意踩坑"><a href="# 注意踩坑" class="headerlink" title="注意踩坑"></a>注意踩坑</h1><p>1、前面已经说过，使用累加器时，只能在 <code>Spark</code> 任务运行中【Task 端】进行累加，然后等待 <code>Spark</code> 任务运行完成后，才能在 <code>Driver</code> 端进行取值操作。如果强行在 <code>Task</code> 中对累加器进行取值，<code>Spark</code> 任务会抛出异常而失败。</p><p>2、在 <code>Spark</code> 中，由于累加器是在 <code>Task</code> 中进行的，所以针对 <code>RDD</code> 的 <code>Transform</code> 操作【例如 <code>map</code>、<code>filter</code>】是不会触发累加器的执行的，必须是 <code>Action</code> 操作【例如 <code>count</code>】才会触发。所以如果读者发现自己的程序中输出的累加器取值不正确，看看是不是这个原因。</p><p>3、正是因为 2 的原因，用户可能会进行多次 <code>Action</code> 操作后，发现累加器的数值不对，远远大于正确的数值，然后懵了。这种现象是正常的，属于人为误操作，因此用户一定要正确使用累加器，控制好 <code>Action</code> 操作，或者及时使用 <code>cache ()</code> 方法，这样可以断开与前面 <code>DataSet</code> 的血缘关系，保证累加器只被执行一次。</p><p>4、通过 2 也可以发现一个问题，如果 <code>Spark</code> 任务的某个 <code>Task</code> 反复执行了多次【Spark 的容错性，例如某个 <code>Task</code> 失败重试了多次之后才成功】，那累加器进行累加时会不会重复计算。当然会重复计算，这也是一个坑，为了避免这个坑，尽量把对累加器的操作放在 <code>Action</code> 算子中，这样就可以保证累加器被操作一次。</p><p>5、在创建累加器时，如果没有指定累加器的名字，那么只能在程序中通过代码操作累加器，而在 <code>SparkUI</code> 中无法看到累加器的取值。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
        <tag>Java</tag>
        <tag>MapReduce</tag>
        <tag>Accumulator</tag>
      </tags>
  </entry>
  <entry>
    <title>关于  httpcore 的 Maven 依赖冲突问题解决</title>
    <url>/2019042201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天，又遇到一个 Maven 冲突的问题，这种问题我遇到的多了，每次都是因为项目依赖管理混乱或者为新功能增加依赖之后影响了旧功能，这次就是因为后者，新增加的依赖的传递依赖覆盖了原有的依赖，导致了问题的产生。大家如果搜索我的博客，搜索关键词 maven 或者 mvn，应该可以看到好几篇类似的文章，每次的情况都略有不同，每次解决问题的过程也是很崩溃。不过，每次崩溃之后都是一阵喜悦，毕竟感觉自己的经验又扩充了一些，以后遇到此类问题可以迅速解决。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 写了一个 mapReduce 程序从 HBase 读取数据，写入到 Elasticsearch 中，整体的框架是从别的项目复制过来的，自己重写了处理逻辑以及环境相关的参数，但是跑起来的时候，map 过程很顺利，几百个 task 全部成功完成，但是 reduce 过程直接挂了，几十个 task 全部失败，重试了还是失败。</p><p>我只能去查看日志，去 Hadoop 监控界面，看到对应任务的报错日志如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-04-22 16:01:30,469 ERROR [main] com.datastory.banyan.spark.ScanFlushESMRV2$FlushESReducer: org/apache/http/message/TokenParser</span><br><span class="line">java.lang.NoClassDefFoundError: org/apache/http/message/TokenParser</span><br><span class="line">	at org.apache.http.client.utils.URLEncodedUtils.parse (URLEncodedUtils.java:280)</span><br><span class="line">	at org.apache.http.client.utils.URLEncodedUtils.parse (URLEncodedUtils.java:237)</span><br><span class="line">	at org.apache.http.client.utils.URIBuilder.parseQuery (URIBuilder.java:111)</span><br><span class="line">	at org.apache.http.client.utils.URIBuilder.digestURI (URIBuilder.java:181)</span><br><span class="line">	at org.apache.http.client.utils.URIBuilder.&lt;init&gt;(URIBuilder.java:91)</span><br><span class="line">	at org.apache.http.client.utils.URIUtils.rewriteURI (URIUtils.java:185)</span><br><span class="line">	at org.apache.http.impl.nio.client.MainClientExec.rewriteRequestURI (MainClientExec.java:494)</span><br><span class="line">	at org.apache.http.impl.nio.client.MainClientExec.prepareRequest (MainClientExec.java:529)</span><br><span class="line">	at org.apache.http.impl.nio.client.MainClientExec.prepare (MainClientExec.java:156)</span><br><span class="line">	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.start (DefaultClientExchangeHandlerImpl.java:125)</span><br><span class="line">	at org.apache.http.impl.nio.client.InternalHttpAsyncClient.execute (InternalHttpAsyncClient.java:129)</span><br><span class="line">	at org.elasticsearch.client.RestClient.performRequestAsync (RestClient.java:343)</span><br><span class="line">	at org.elasticsearch.client.RestClient.performRequestAsync (RestClient.java:325)</span><br><span class="line">	at org.elasticsearch.client.RestClient.performRequestAsync (RestClient.java:268)</span><br><span class="line">	at org.elasticsearch.client.RestHighLevelClient.performRequestAsync (RestHighLevelClient.java:445)</span><br><span class="line">	at org.elasticsearch.client.RestHighLevelClient.performRequestAsyncAndParseEntity (RestHighLevelClient.java:423)</span><br><span class="line">	at org.elasticsearch.client.RestHighLevelClient.bulkAsync (RestHighLevelClient.java:206)</span><br><span class="line">	at com.datastory.banyan.client.es.ESBulkProcessor.lambda$new$0 (ESBulkProcessor.java:154)</span><br><span class="line">	at org.elasticsearch.action.bulk.Retry$RetryHandler.execute (Retry.java:230)</span><br><span class="line">	at org.elasticsearch.action.bulk.Retry.withAsyncBackoff (Retry.java:87)</span><br><span class="line">	at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute (BulkRequestHandler.java:138)</span><br><span class="line">	at org.elasticsearch.action.bulk.BulkProcessor.execute (BulkProcessor.java:350)</span><br><span class="line">	at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded (BulkProcessor.java:341)</span><br><span class="line">	at org.elasticsearch.action.bulk.BulkProcessor.internalAdd (BulkProcessor.java:276)</span><br><span class="line">	at org.elasticsearch.action.bulk.BulkProcessor.add (BulkProcessor.java:259)</span><br><span class="line">	at org.elasticsearch.action.bulk.BulkProcessor.add (BulkProcessor.java:255)</span><br><span class="line">	at org.elasticsearch.action.bulk.BulkProcessor.add (BulkProcessor.java:241)</span><br><span class="line">	at com.datastory.banyan.client.es.ESBulkProcessor.addIndexRequest (ESBulkProcessor.java:237)</span><br><span class="line">	at com.datastory.banyan.spark.ScanFlushESMRV2$FlushESReducer.reduce (ScanFlushESMRV2.java:212)</span><br><span class="line">	at com.datastory.banyan.spark.ScanFlushESMRV2$FlushESReducer.reduce (ScanFlushESMRV2.java:158)</span><br><span class="line">	at org.apache.hadoop.mapreduce.Reducer.run (Reducer.java:171)</span><br><span class="line">	at org.apache.hadoop.mapred.ReduceTask.runNewReducer (ReduceTask.java:627)</span><br><span class="line">	at org.apache.hadoop.mapred.ReduceTask.run (ReduceTask.java:389)</span><br><span class="line">	at org.apache.hadoop.mapred.YarnChild$2.run (YarnChild.java:168)</span><br><span class="line">	at java.security.AccessController.doPrivileged (Native Method)</span><br><span class="line">	at javax.security.auth.Subject.doAs (Subject.java:422)</span><br><span class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs (UserGroupInformation.java:1709)</span><br><span class="line">	at org.apache.hadoop.mapred.YarnChild.main (YarnChild.java:162)</span><br></pre></td></tr></table></figure><p>截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2brjd9bl2j210d0j9q4k.jpg" alt="异常日志信息" title="异常日志信息"></p><p>看到关键部分：<strong>java.lang.NoClassDefFoundError: org/apache/http/message/TokenParser</strong>，表面看是类未定义，但是真实情况是什么还要继续探索，例如依赖缺失、依赖冲突导致的类不匹配等。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><h2 id="初步分析"><a href="# 初步分析" class="headerlink" title="初步分析"></a> 初步分析 </h2><p> 先搜索类 <strong>TokenParser</strong> 吧，看看能不能搜索到，在 IDEA 中搜索，我的环境是使用 <strong>ctrl + shift + t</strong> 快捷键，搜索之后发现存在这个类，记住对应的 jar 包坐标以及版本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.httpcomponents:httpcore:jar:4.3.2</span><br></pre></td></tr></table></figure><p>这里需要注意一点，如果你的项目是由多个子项目聚合而成的，此时使用 IDEA 的搜索功能并不准确，会搜索出来其它子项目的同名依赖，从而误导你的视线，所以还是使用依赖分析插件比较好，例如：depedency，下面也会讲到。</p><p>既然类已经存在，说明有极大可能是依赖冲突导致的 <strong>NoClassDefFoundError</strong>。继续从错误日志中寻找蛛丝马迹，看到 <strong>at org.apache.http.client.utils.URLEncodedUtils.parse (URLEncodedUtils.java:280)</strong> 这里，接着搜索类 <strong>URLEncodedUtils</strong> 并查看第 280 行的 <strong>parse</strong> 方法。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.httpcomponents:httpclient:jar:4.5.2</span><br></pre></td></tr></table></figure><p>上面是依赖坐标以及版本，看到这里有经验的工程师已经可以发现问题所在了：两个同类型的依赖 jar 包版本差别太大，这里暂且不分析。</p><p>接着查看源码：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2brkjzrvrj20v50djt9j.jpg" alt="URLEncodedUtils 源码" title="URLEncodedUtils 源码"></p><p>好，到这里已经把基本情况分析清楚了，程序异常里面的 <strong>NoClassDefFoundError</strong> 并不是类缺失，所以没有报错 <strong>ClassNotFound</strong>。根本原因是类版本不对，导致 <strong>URLEncodedUtils</strong> 找不到自己需要的特定版本的类，尽管有一个同名的低版本的类存在，但是对于 Java 虚拟机来说这是完全不同的两个类，这也是容易误导人的地方。</p><p>再延伸一下话题，如果真的是类不存在，使用 IDEA 查看源码时会显示红色字体提示的，如图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2brle6hgjj20zc0ieq49.jpg" alt="类不存在错误提示" title="类不存在错误提示"></p><h2 id="详细分析"><a href="# 详细分析" class="headerlink" title="详细分析"></a>详细分析 </h2><p> 接下来就使用依赖分析插件 <strong>dependency</strong> 来分析这两个 jar 包的来源以及版本差异，在项目的根目录执行 <strong>mvn dependency:tree -Dverbose &gt; tree.txt</strong> ，把依赖树信息重定向到 tree.txt 文件中，里面的 -Dverbose 参数可以使我们更为清晰地看到版本冲突的 jar 包以及实际使用的 jar 包。</p><p>找到 httpclient 和 httpcore 的来源，依赖树片段截取如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO] +- com.company.commons3:ds-commons3-es-rest:jar:1.2:compile</span><br><span class="line">[INFO] |  +- org.apache.httpcomponents:httpclient:jar:4.5.2:compile</span><br><span class="line"></span><br><span class="line">...... 省略 </span><br><span class="line"></span><br><span class="line">[INFO] |  +- org.apache.httpcomponents:httpasyncclient:jar:4.0.2:compile</span><br><span class="line">[INFO] |  |  +- org.apache.httpcomponents:httpcore:jar:4.3.2:compile</span><br><span class="line">[INFO] |  |  +- (org.apache.httpcomponents:httpcore-nio:jar:4.3.2:compile - omitted for duplicate)</span><br><span class="line">[INFO] |  |  +- (org.apache.httpcomponents:httpclient:jar:4.3.5:compile - omitted for conflict with 4.5.2)</span><br><span class="line">[INFO] |  |  \- (commons-logging:commons-logging:jar:1.1.3:compile - omitted for duplicate)</span><br></pre></td></tr></table></figure><p>可以看到 <strong>httpclient</strong> 来自于 <strong>ds-commons3-es-rest</strong>，版本为 4.5.2，而 <strong>httpcore</strong> 来自于 <strong>httpasyncclient</strong>，版本为 4.3.2。</p><p>特别注意：<strong>httpasyncclient</strong> 里面还有一个 4.3.5 版本的 <strong>httpclient</strong> 由于版本冲突被忽略了，这也是导致问题的元凶。</p><p>依赖树片段截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2brlwy34ij210404e74q.jpg" alt="依赖树片段 1" title="依赖树片段 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2brm3rutxj211508h0tr.jpg" alt="依赖树片段 2" title="依赖树片段 2"></p><p>到这里已经可以知道问题所在了，<strong>httpclient</strong>、<strong>httpcore</strong> 这两个依赖的版本差距太大，前者 4.5.2，后者 4.3.2，导致前者的类 URLEncodedUtils 在调用后者的类 TokenParser 时，找不到满足条件的版本，于是抛出异常：NoClassDefFoundError。</p><h2 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案 </h2><p> 那这个问题也是很容易解决的，指定版本接近的两个依赖即可，但是还是要根据实际情况而来。本来最简单的方案就是移除所有相关依赖，然后在 pom.xml 中显式地指定这两个依赖的版本。但是这么做太简单粗暴了，因为这两个依赖不是一级依赖，而是传递依赖，不必手动管理。所以要适当地移除某一些传递依赖，保留另一些传递依赖，让它们不要交叉出现。</p><p>我的做法就是移除 <strong>ds-commons3-es-rest</strong> 里面的传递依赖，保持 <strong>httpasyncclient</strong> 里面的传递依赖，这样它们的版本号接近，而且是同一个依赖里面传递的，基本不可能出错。</p><p>pom.xml 配置如图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2brnorbdej211p0amaaq.jpg" alt="修复后的 pom 配置" title="修复后的 pom 配置"></p><p>httpclient 的小版本号是可以比 httpcore 高一点的，继续查看依赖树，可以看到 httpclient 的版本为 4.3.5，httpcore 的版本为 4.3.2。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2brntqakfj20rp021aa1.jpg" alt="修复后的 http 依赖版本号" title="修复后的 http 依赖版本号"></p><h2 id="引申插件"><a href="# 引申插件" class="headerlink" title="引申插件"></a>引申插件 </h2><p> 除了 dependency 插件外，还有另外一个插件也非常好用：enforcer，插件的坐标如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 帮助分析依赖冲突的插件，可以在编译时期找到依赖问题 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.1&lt;/version&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;id&gt;enforce-ban-duplicate-classes&lt;/id&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;goal&gt;enforce&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;!-- 设置规则，否则没法检查 --&gt;</span><br><span class="line">                &lt;rules&gt;</span><br><span class="line">                    &lt;!-- 检查重复类 --&gt;</span><br><span class="line">                    &lt;banDuplicateClasses&gt;</span><br><span class="line">                        &lt;!-- 忽略一些类 --&gt;</span><br><span class="line">                        &lt;ignoreClasses&gt;</span><br><span class="line">                            &lt;ignoreClass&gt;javax.*&lt;/ignoreClass&gt;</span><br><span class="line">                            &lt;ignoreClass&gt;org.junit.*&lt;/ignoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.aspectj.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.jboss.netty.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.apache.juli.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.apache.commons.logging.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.apache.log4j.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.objectweb.asm.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.parboiled.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.apache.xmlbeans.xml.stream.*&lt;/ingoreClass&gt;</span><br><span class="line">                            &lt;ingoreClass&gt;org.json.JSONString&lt;/ingoreClass&gt;</span><br><span class="line">                        &lt;/ignoreClasses&gt;</span><br><span class="line">                        &lt;!-- 除了上面忽略的类，检查所有的类 --&gt;</span><br><span class="line">                        &lt;findAllDuplicates&gt;true&lt;/findAllDuplicates&gt;</span><br><span class="line">                    &lt;/banDuplicateClasses&gt;</span><br><span class="line">                    &lt;!-- JDK 在 1.8 以上 --&gt;</span><br><span class="line">                    &lt;requireJavaVersion&gt;</span><br><span class="line">                        &lt;version&gt;1.8.0&lt;/version&gt;</span><br><span class="line">                    &lt;/requireJavaVersion&gt;</span><br><span class="line">                    &lt;!-- Maven 在 3.0.5 以上 --&gt;</span><br><span class="line">                    &lt;requireMavenVersion&gt;</span><br><span class="line">                        &lt;version&gt;3.0.5&lt;/version&gt;</span><br><span class="line">                    &lt;/requireMavenVersion&gt;</span><br><span class="line">                &lt;/rules&gt;</span><br><span class="line">                &lt;fail&gt;true&lt;/fail&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">    &lt;!-- 官方的默认规则 --&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;extra-enforcer-rules&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.0-beta-6&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><p>这个插件需要配置在 pom.xml 中，并且绑定 Maven 的生命周期，默认是绑定在 compile 上面，然后需要给 enforcer 配置一些规则，例如检查重复的类。接着在编译期间，enforcer 插件就会检验项目的依赖中所有的类【可以设置忽略容器中的类，例如作用域为 provided 的依赖包】，如果有重复的类，就会报错，编译不会通过。</p><p>注意，这个插件除了可以检查依赖、类的冲突【通过设置规则 rule 来实现】，还可以设置一些其它的开发规范，例如规定 JDK 版本、开发系统环境必须为 Windows、使用的 Maven 版本等等。此外，官方也提供了一些规则列表可以参考：<a href="http://maven.apache.org/enforcer/enforcer-rules/index.html" target="_blank" rel="noopener">http://maven.apache.org/enforcer/enforcer-rules/index.html</a> ，而且还有 API 允许我们自定义规则，非常灵活。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><h2 id="抽象总结"><a href="# 抽象总结" class="headerlink" title="抽象总结"></a> 抽象总结 </h2><p> 总结一下现象，其实就是项目本来依赖了 B 包，B 包里面有传递依赖包 1、包 2，由于包 1、包 2 都来自于 B 包，所以版本差别不大，很适配。包 1 的类调用包 2 的类很顺利，不会有问题。</p><p>后来由于其它功能需要，项目又加入了 A 包，此时没有注意到 A 包里面也有包 1，而且比 B 包里面的包 1 版本高，这本来不是问题，只是潜在风险。但是，编译打包时 A 包里面的包 1 把 B 包里面的包 1 覆盖了，包 2 仍旧是来自于 B 包，这就出问题了，风险变成灾难了。当程序运行时包 1 需要调用包 2，由于版本差别过大，找不到符合条件的类了，抛出异常：NoClassDefFoundError。</p><p>这里面的验证机制浅显地描述就是每个类都会有自己的序列化编号，如果有严格要求同版本依赖的类，调用方法时会严格验证。</p><h2 id="关于编译的疑问"><a href="# 关于编译的疑问" class="headerlink" title="关于编译的疑问"></a>关于编译的疑问 </h2><p> 到这里，读者会有疑问，为什么编译不报错，能顺利通过呢？其实从上面就能看到答案了，这种依赖包之间相互引用的类，类是存在的，只是版本不一致而已，编译时并不能检测出来。如果是你自己写的类源码，引用了别的依赖包的类，同时对版本要求严格的话，编译是一定会报错的。</p><p>但是，如果你提前知道了是哪个类，一般不可能知道，只有报错了才会知道，而且会有不止一个类，这也是令人头疼的地方。</p><p>如果进一步分析异常信息，发现它归属于 ERROR，并不是运行时异常，更不用谈编译时异常了，这种错误和 OutOfMemoryError 类似，是虚拟机运行时出现问题，比较严重。</p><h2 id="感悟"><a href="# 感悟" class="headerlink" title="感悟"></a>感悟 </h2><p> 找到这种问题的原因是没有什么难度的，一眼就可以看出来是依赖冲突。但是解决过程可谓是难度极大，而且可以让人崩溃，对于初学者来说可以放弃了，折腾三天可能都不会有结果的。特别在依赖庞大的情况下，几百个依赖包，几百 M 大小，这时候找起来特别麻烦，有时候改动了一点会影响到其它的依赖，引起连锁反应，可能问题还没解决，又引发了其它问题。</p><p>所以，在项目开发的初始阶段，一定要管理好项目的依赖，并且在依赖变更时要一起讨论，否则后患无穷。</p><p>此外，在解决依赖冲突的过程中，有 2 个插件工具很好用：dependency、enforcer。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>httpcore</tag>
        <tag>maven</tag>
        <tag>dependency</tag>
        <tag>enforcer</tag>
      </tags>
  </entry>
  <entry>
    <title>分别 是为了再次相聚</title>
    <url>/2019032702.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>这是我还在大学读书的时候，有一年过年回家，组织了高中同班同学的聚会，其实主要目的就是一起吃个饭，玩半天，交流一下。我还隐隐约约记得当时提前约好了十几个人，然后到了当天早上再确认的时候，只有八个人能来了，刚好凑一桌。那次一别，以后再也没见过，只在微信上聊过，大家天各一方，有的求学做科研，有的成家立业。而如今，当我碰巧再拾起这段文字的时候，只觉得沙流指尖，微风拂面。</p><p>当然，我再也写不出这么稚嫩的、无病呻吟的文字了，因为现在整天在写代码，我的思维也变化了很多。</p><p>最近三年，在工作环境中经历了多次的相聚离别，现在年后又是离职大潮，刚好整理出这篇旧笔记，提醒自己的成长之路。</p><a id="more"></a><h1 id="开篇"><a href="# 开篇" class="headerlink" title="开篇"></a>开篇 </h1><p> 我应该算是一个善感的人，但不多愁。此时努力寻找记忆中的碎片，感受那些我能看到的瞬间，尝试从记忆中寻找值得书写的部分，以作想念。</p><p>每次只要有久违的聚会，之前我都会想象见面时的情景，以及每个人的样子，认为这样能追寻到由于长时间不见面而淡去的亲切感。同时内心也会积聚起来丰富的情感，构思出许多可以表达的文字，藏在心底，待到意兴浓的时候说出来。</p><h1 id="相聚"><a href="# 相聚" class="headerlink" title="相聚"></a>相聚 </h1><p> 我记得那天早晨起的特别早，是假期中最早的一次，可能是内心的激动，亦或是天气转暖，也可能是因为我定了三个闹钟。出发的时候由于出现了三个不在我计划中的意外，导致我的出发时间比我预计的晚了一个小时，这已经使我的内心感到些许急躁。后来在路上没想到会堵车，又耽搁了 20 分钟，望着拥挤的车流，我再也按捺不住急躁的内心，便直接下车走完了最后一段路，到达的时候已经是中午 12 点了。</p><p>在路上有点风，微风拂面，我能感觉到微微颤抖，为自己没有围围巾而感到后悔，这可是冬天，温度只有几摄氏度。可是到了集合地点太阳都出来了，阳光明媚，冬风和煦，的确是个好天气，相当适合聚会，内心的寒冷一扫而空。</p><p>走到集合的地点，那是一个破旧的学校操场，我曾在这里度过一年光阴，扶了扶眼镜，向四周望了望，看到在操场旁的屋檐下，他们正在打桌球。毕竟两年多没见过面了，他们的样子在我脑海中渐渐模糊，此时努力搜寻，看着一张张熟悉又陌生的脸庞，心中情感翻涌，暗暗对着他们的名字，辛福感扑面而来。但准备好的话一句也没有说出口，这就是我的性格，见了面在一起比什么语言都美好，直接加入他们，我想这也是最好的表达。</p><p>快速从脑海中搜索记忆，在我仔细看来，大家仍然是高中的模样，没有怎么变化，还是那么青春，还是那么快乐，没有老练，没有隔阂，脸上洋溢着年少时的单纯感，都像这个年龄应该有的样子。</p><p>我装出很「酷」的样子，至少我是这么认为，可毕竟长时间没有打过桌球了，手生，出杆结果总是不尽人意，我总感觉自己处于尴尬的境地，可是仍然装出不在乎的样子，说几句玩笑话，淡淡一笑，希望没人看到，说到底还是生疏了。</p><p>本应该可以去吃饭了，但大家兴致未尽，在「混乱」的状态下又玩了几十分钟，随着黑色八号球的入袋，结束了应该有的结局，已经过了午饭的时间。说实话，此时我已经饥肠辘辘，但大家看起来都很亢奋，兴奋喜悦的表情洋溢于脸，在说笑中集体寻找吃饭的地点。</p><p>八个年轻人一起走在马路上，蹦蹦跳跳，三两成堆，不时对旁边的人吐露心声，开着不着边际的玩笑，说着没心没肺的笑话。此时我的脑海中浮现出一幅和谐美好的画面，也必将印在我的心底。</p><p>走走停停，说说笑笑，乘坐免费的公交，不多时便到达了新建落成的七彩世界，映入眼帘的是花花绿绿的色彩，心情豁然开朗，已经做好了吃喝的准备。进入大楼入口，乘坐电梯，直奔饮食区域。</p><p>首先寻找最佳的位置，足够容纳八个人入座，围在一起，谈笑风生。我实在是饿坏了，便独自一人去点了一碗面，首先尝尝咸淡。没想到我等了一会儿，他们大部分人都来了，都要吃面，那就点吧。七七八八大家议论了一番，各自点了一碗面。</p><p>等待上面的过程中，几个男生又去点了一些副食，女生去点了饮品，相互搭配，应该足够果腹了。东西上齐后，本想随心所欲，大快朵颐，可是不知怎么的，先前的食欲减小了，不过以我的大饭量还是能消耗很多食物的。</p><p>吃饭的过程就是吃饭的过程。</p><p>吃饱喝足之后，大家聊了一会儿，有人提议打牌，反正闲着没事儿干，打就开打。本来准备去购买纸牌的，没想到王飞的书包里居然带着这玩意儿，看来他那书包里面装着很多现金也是真的了。</p><p>打牌真的是体力活也是脑力活，不仅需要工于计算，还需要相互配合，可是牌不好什么都白搭。在这个过程，我可以说是遭遇了打牌生涯的滑铁卢，无论怎么样打，都是输牌。当然，值得说明的是，输牌并不是因为牌技不好，而是因为牌不好，就算什么都算出来了也打不赢，这不能怪我。</p><p>身为理科生，我清楚地知道这只是概率问题，风水会轮流转，但为了缓解气氛，我也可以承认这可能是人品的问题。况且竟然牌从头到尾一直不好，想想这也是一个小概率事件，我不得不承认可能确实和我的人品有一点关系。</p><p>输输输……</p><p>输了牌，就会有惩罚，惩罚过后，换了一波人继续打。可是万万没想到，我这一门虽然换了人打，牌还是不好，虽然比我打的时候好了那么一点点，仍然是稳输不赢，牌差的简直令人发指。打牌成绩的最顶峰也就是赢了一个而已，很快又变成负数了，真是令人伤悲。</p><h1 id="分别"><a href="# 分别" class="headerlink" title="分别"></a>分别 </h1><p> 不知不觉中，在说说笑笑、打打闹闹的氛围下过去了几个小时，天也已经快黑了，是时候该分别了，各自回家，要不然有些人恐怕赶不上末班车了（十八线小县城过了六点就没车了）。而后大家收拾东西，开始动身，临走时总要合照一张吧。<br>合照一没有我 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nqcm23mj22kg1g0qrf.jpg" alt="合照一没有我" title="合照一没有我"></p><p> 合照二没有我 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nq6tdiuj22kg1g0e39.jpg" alt="合照二没有我" title="合照二没有我"></p><p> 每一张照片，王飞的脖子和头看起来很奇怪，我没法挑出效果更好的了。第一张解丰的全身没有入镜，当然，这怪我，是我拍的。请看下面零散的几张照片，当时的红米手机拍照效果也就这样了，每张照片的大小只有 800KB 左右。<br>大家闲聊 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nqg2uudj22kg1g01gn.jpg" alt="大家闲聊" title="大家闲聊"></p><p> 二位在比划啥 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nqk8fcij22kg1g0e5h.jpg" alt="二位在比划啥" title="二位在比划啥"></p><p> 二位正经的样子 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nqnctgmj21g02kgav7.jpg" alt="二位正经的样子" title="二位正经的样子"></p><p> 正经人 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nrb50u6j22kg1g0qrd.jpg" alt="正经人" title="正经人"></p><p> 这里面有我 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nqqosy6j22kg1g0nlw.jpg" alt="这里面有我" title="这里面有我"></p><p> 这是干啥 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g22nreufvtj21g02kgnl7.jpg" alt="这是干啥" title="这是干啥"></p><p> 下了楼，大家一起往车站行走，途中许梦宇有事首先分别，王继雪顺车回家第二个分别。剩下的六人继续走在繁华的街头，沿着热闹的商铺，趁着剩下不多的时间聊天说笑。</p><p>本来是一段很短的路程，我们却走了很长时间，可能大家心里都想着多聊一会儿吧，才故意放慢了脚步。当然，最终这也导致了我错过了回家的末班车。</p><p>到了车站，大家又聊了一会儿，当作告别的寒暄。我不得不乘坐另外一辆车，和李欢一起，只是到达离家还有十多公里的永兴街上，然后让家里的亲人来接。</p><h1 id="结尾"><a href="# 结尾" class="headerlink" title="结尾"></a>结尾 </h1><p>「天下没有不散的宴席」，这句老话大家都知道，可大概只有经历过的人才能理解其中蕴含着的意义吧。时间总是很快，最终的时刻总要分别。</p><p> 分别，是为了再次相聚。</p><p>下一次再相聚会是什么时候呢？</p><p>下一次再相聚大家会变吗？</p><p>静静等待着再次相聚。</p><p>哦，对了，我离开家乡去学校的那天，火车开动的时候，家乡飘起了小雪。后来火车远离家乡的时候，听说雪已经很大了，可惜我没有见到。</p><p>是为记。</p><p>2015 年 02 月 26 日 </p><p> 鹏飞</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>游玩</category>
      </categories>
      <tags>
        <tag>聚会</tag>
        <tag>利辛一中</tag>
      </tags>
  </entry>
  <entry>
    <title>利用阿里云申请免费的 SSL 证书</title>
    <url>/2019030401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在搭建博客的过程中，一开始是全部使用 <code>GitHub</code>，因为这样做就什么也不用考虑了，例如主机、带宽、<code>SSL</code> 证书，全部都交给 <code>GitHub</code> 了，自己唯一需要做的就是写 <code>Markdown</code> 文档。但是，后来发现 <code>GitHub</code> 把百度爬虫给禁止了，也就是百度爬虫爬取不到 <code>GitHub</code> 的内容，导致我的站点没有被百度收录。后来为了专门给百度爬虫搭建一条线路，自己搭建了一个镜像服务，也就是和 <code>GitHub</code> 上面的内容一模一样站点，是专门给百度爬虫使用的。而且，为了测试方便，在 <code>DNSPod</code> 中还增加了一条 <code>blog</code> 二级域名的解析记录，<code>blog</code> 的访问全导向自己的镜像，这样就可以方便观察部署是否成功。后来还把百度爬虫的 <code>www</code> 访问通过 <code>CNANE</code> 跳转到 <code>blog</code> 去，这样就不用单独再搞一个 <code>www</code> 了，因为挺麻烦的【域名解析线路问题、测试问题、证书确认问题，都挺麻烦】。而在这个过程中，就产生了使用阿里云申请免费的 <code>SSL</code> 证书这一流程【有效期一年】，记录下来给大家参考。</p><a id="more"></a><h1 id="注册阿里云、开启实名认证"><a href="# 注册阿里云、开启实名认证" class="headerlink" title="注册阿里云、开启实名认证"></a>注册阿里云、开启实名认证 </h1><p> 这个步骤就不多说了，需要证书总得注册一个帐号吧，也方便后续管理。此外，国内的证书服务商都要求实名认证，这个也没办法。如果不想实名认证，可以使用开源的 <a href="https://letsencrypt.org" target="_blank" rel="noopener">Lets Encrypt</a> ，只不过有效期只能是 3 个月，也就是说每隔 3 个月就要更新一次，<code>GitHub Pages</code> 使用的就是它。阿里云的官网链接：<a href="https://www.aliyun.com" target="_blank" rel="noopener">https://www.aliyun.com</a> 。</p><h1 id="购买 -SSL- 证书"><a href="# 购买 -SSL- 证书" class="headerlink" title="购买 SSL 证书"></a>购买 SSL 证书 </h1><p>1、在阿里云系统找到关于 <code>SSL</code> 证书的服务，<strong> 产品与服务 </strong>-&gt;<strong> 安全（云盾）</strong>-&gt;<strong>SSL 证书（应用安全）</strong>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4q5ikmnj21hc0q9gp7.jpg" alt="SSL 证书（应用安全）" title="SSL 证书（应用安全）"></p><p>2、进入后，点击右上角的 <strong> 购买证书 </strong>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4qkt3cwj21hc0q9tal.jpg" alt="购买证书" title="购买证书"></p><p>3、按照我截图中的步骤 1、2、3 选择，这里需要注意，这个免费的选项隐藏的很深，直接勾选是不会出现的，要按照我标识的步骤来勾选才行，这里看到出现的费用很贵不用害怕，等一下接着选择对了就会免费的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4qvpk2wj21hc0q9775.jpg" alt="正确的选择流程" title="正确的选择流程"></p><p>最终选择 <strong>免费型 DV SSL</strong>，按照我下图中的选项，可以看到费用是 0 元。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4r9iriij21hc0q9gob.jpg" alt="免费型 DV SSL" title="免费型 DV SSL"></p><p>选择后，下单即可，虽然要走购买流程，但是是不用付钱的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4rjfjm2j21hc0q9jtw.jpg" alt="下单完成" title="下单完成"></p><h1 id="绑定证书信息、等待审核"><a href="# 绑定证书信息、等待审核" class="headerlink" title="绑定证书信息、等待审核"></a>绑定证书信息、等待审核 </h1><p>1、下单完成后开始 <strong> 申请 </strong>，这里的 <strong>申请 </strong>的意思是申请使用它，要填写一些基本的信息，包括个人信息和网站信息，后续还需要验证身份，看你有没有权限管理你配置的网站。如果不申请 <strong>使用 </strong>，证书其实就一直闲置在那里。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4rvewbsj21hc0q9jti.jpg" alt="申请使用证书" title="申请使用证书"></p><p>填写个人信息，主要就是我个人的联系方式。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4s5trvij21hc0q9dho.jpg" alt="填写个人信息" title="填写个人信息"></p><p>填写网站信息，由于我使用的是自己的服务器上面搭建的 Web 服务，既没有使用阿里云也没有使用其它云服务，所以我选择了 <strong>文件验证 </strong>，即需要把验证文件上传到我的域名对应的目录下面，用来证明这个站点是我管理的。当然，验证通过后，这个文件可以删除。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4serk53j21hc0q9q58.jpg" alt="文件验证" title="文件验证"></p><p>2、填写完成后，会生成一个文件 <code>fileauthor.txt</code>，我需要把这个文件下载下来，然后上传到我的服务器对应的目录中，才能点击 <strong>验证 </strong>按钮，如果通过了，说明这个站点就是我管理的，也就是一个权限验证。</p><p>由于在验证 <code>www</code> 证书对应的文件的时候，需要把 <code>fileauthor.txt</code> 文件上传到服务器，但是由于在 <code>DNSPod</code> 中设置的域名解析是解析到 <code>GitHub</code> 的【没有专门针对阿里的设置】，所以总是验证失败。后来就干脆临时把所有的 <code>www</code> 解析都指向我自己的服务器，等通过了验证再改回去，整个过程很是折腾。折腾了一大圈，最后还发现了更简单的方法，直接放弃 <code>www</code> 证书的申请，在 <code>DNSPod</code> 中把百度的流量通过 <code>CNAME</code> 直接引到 <code>blog</code> 上面去就行了，这样只要维护一个 <code>blog</code> 的 <code>Web</code> 服务就行了。这样只需要增加一条解析，而且 <code>blog</code> 的证书验证过程也方便简单。</p><p><code>DNSPod</code> 解析示例 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4srjg4xj21hc0q9ac4.jpg" alt="DNSPod 解析示例" title="DNSPod 解析示例"></p><p> 在这个过程中，我还发现验证过程需要一定的时间，一开始显示失败，但是不告诉我原因，还以为是自己的服务器的问题，重试了多种方法，包括重启 <code>Web</code> 服务。我等了十几分钟，证书就莫名其妙审核通过了，然后还发送了短信通知【到这里我猜测阿里云的 <code>Web</code> 界面显示的内容是滞后的，短信通知的内容才是实时的】。</p><p>此外，如果是验证失败，先刷新一下网页，可能就成功了。如果还不行，需要注意一下是不是主机被墙了，阿里云无法访问；或者主机文件的读取权限没有放开。</p><p>证书申请成功，可以使用了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4t1jlj7j21hc0q9mz2.jpg" alt="证书申请成功" title="证书申请成功"></p><h1 id="下载证书、上传到自己的服务器"><a href="# 下载证书、上传到自己的服务器" class="headerlink" title="下载证书、上传到自己的服务器"></a>下载证书、上传到自己的服务器 </h1><p> 下载证书、上传到自己的服务器这一步骤就不多说了，主要就是复制粘贴的工作。着重要说一下 <code>Nginx</code> 的配置，主要就是 <code>server</code> 属性的配置，由于我把 <code>www</code>、<code>blog</code> 这 2 个二级域名都保留了，所以需要分开配置。其实，这里配置的 <code>www</code> 的二级域名根本没有用，因为不会有流量过来的，重在测试证书的安装。<code>Nginx</code> 的配置内容参考【2 个子域名分开配置，有 2 份 <code>SSL</code> 证书】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  www.playpi.org;</span><br><span class="line">    access_log   /site/iplaypi.github.io.http-www-access.log  main;</span><br><span class="line">    rewrite ^/(.*)$ https://www.playpi.org/$1 permanent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  blog.playpi.org;</span><br><span class="line">    access_log   /site/iplaypi.github.io.http-blog-access.log  main;</span><br><span class="line">    rewrite ^/(.*)$ https://blog.playpi.org/$1 permanent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">    listen 443 ssl;# 监听端口 </span><br><span class="line">    server_name www.playpi.org;# 域名 </span><br><span class="line">    access_log   /site/iplaypi.github.io.https-www-access.log  main;</span><br><span class="line">    root         /site/iplaypi.github.io;</span><br><span class="line">    ssl_certificate /site/1884603_www.playpi.org.pem;# 证书路径 </span><br><span class="line">    ssl_certificate_key /site/1884603_www.playpi.org.key;#key 路径 </span><br><span class="line">    ssl_session_cache shared:SSL:1m;# 储存 SSL 会话的缓存类型和大小 </span><br><span class="line">    ssl_session_timeout 5m;# 配置会话超时时间 </span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;# 为建立安全连接，服务器所允许的密码格式列表 </span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_prefer_server_ciphers on;# 依赖 SSLv3 和 TLSv1 协议的服务器密码将优先于客户端密码 </span><br><span class="line">    #减少点击劫持 </span><br><span class="line">    add_header X-Frame-Options DENY;</span><br><span class="line">    #禁止服务器自动解析资源类型 </span><br><span class="line">    add_header X-Content-Type-Options nosniff;</span><br><span class="line">    #防 XSS 攻击 </span><br><span class="line">    add_header X-Xss-Protection 1;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl;# 监听端口 </span><br><span class="line">    server_name blog.playpi.org;# 域名 </span><br><span class="line">    access_log   /site/iplaypi.github.io.https-blog-access.log  main;</span><br><span class="line">    root         /site/iplaypi.github.io;</span><br><span class="line">    ssl_certificate /site/1883927_blog.playpi.org.pem;# 证书路径 </span><br><span class="line">    ssl_certificate_key /site/1883927_blog.playpi.org.key;#key 路径 </span><br><span class="line">    ssl_session_cache shared:SSL:1m;# 储存 SSL 会话的缓存类型和大小 </span><br><span class="line">    ssl_session_timeout 5m;# 配置会话超时时间 </span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;# 为建立安全连接，服务器所允许的密码格式列表 </span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_prefer_server_ciphers on;# 依赖 SSLv3 和 TLSv1 协议的服务器密码将优先于客户端密码 </span><br><span class="line">    #减少点击劫持 </span><br><span class="line">    add_header X-Frame-Options DENY;</span><br><span class="line">    #禁止服务器自动解析资源类型 </span><br><span class="line">    add_header X-Content-Type-Options nosniff;</span><br><span class="line">    #防 XSS 攻击 </span><br><span class="line">    add_header X-Xss-Protection 1;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>配置完成后重启 <code>Nginx</code>【使用 <code>nginx -s reload</code>】，去浏览器查看证书信息，看到有效期一年。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4tirwwkj20f00gdwfk.jpg" alt="去浏览器查看证书信息" title="去浏览器查看证书信息"></p><p>打开链接，看到左上角的小绿锁，好了，网站是经过验证的了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r4tu5l57j21hl0rr0wt.jpg" alt="打开链接" title="打开链接"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>https</tag>
        <tag>阿里云</tag>
        <tag>SSL证书</tag>
        <tag>Lets Encrypt</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Elasticsearch 中一个字段支持的最大字符数</title>
    <url>/2017061401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近在项目中遇到一个异常，写入数据到 <code>Elasticsearch</code> 中，报错：<code>max_bytes_length_exceeded_exception</code>。这个其实和 <code>Elasticsearch</code> 的字段长度限制有关，本文就回顾一下在 <code>Elasticsearch</code> 中一个字段支持的最大字符数。</p><p>本文涉及的开发环境：<code>Elasticsearch v5.6.8</code>，读者需要注意 <strong>字符数 </strong>、<strong> 字节数 </strong>这两个基本概念的区别。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在业务中发现漏数，查看后台的任务日志，发现异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ERROR ESBulkProcessor: &#123;&quot;index&quot;:&quot;your_index&quot;,&quot;type&quot;:&quot;your_type&quot;,&quot;id&quot;:&quot;b20ddaf126908506024aed6698b50214&quot;,&quot;cause&quot;:&#123;&quot;type&quot;:&quot;exception&quot;,&quot;reason&quot;:&quot;Elasticsearch exception [type=illegal_argument_exception, reason=Document contains at least one immense term in field=\&quot;author.raw\&quot; (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: &apos;[-24, -87, -71, -25, -74, -83, -24, -128, -107, -17, -68, -113, -27, -113, -80, -27, -116, -105, -27, -96, -79, -27, -80, -114, 32, -27, -120, -111, -28, -70]...&apos;, original message: bytes can be at most 32766 in length; got 98345]&quot;,&quot;caused_by&quot;:&#123;&quot;type&quot;:&quot;exception&quot;,&quot;reason&quot;:&quot;Elasticsearch exception [type=max_bytes_length_exceeded_exception, reason=max_bytes_length_exceeded_exception: bytes can be at most 32766 in length; got 98345]&quot;&#125;&#125;,&quot;status&quot;:400&#125;</span><br><span class="line">17/06/14 18:07:04 ERROR ESBulkProcessor: bulk [76 : 1560506824519] 527 request - 526 response</span><br><span class="line">17/06/14 19:05:36 ERROR ESBulkProcessor: &#123;&quot;index&quot;:&quot;your_index&quot;,&quot;type&quot;:&quot;your_type&quot;,&quot;id&quot;:&quot;cc36f925a9281389cb50b194cf590108&quot;,&quot;cause&quot;:&#123;&quot;type&quot;:&quot;exception&quot;,&quot;reason&quot;:&quot;Elasticsearch exception [type=illegal_argument_exception, reason=Document contains at least one immense term in field=\&quot;author.raw\&quot; (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: &apos;[-27, -112, -77, -25, -112, -115, -27, -112, -101, -26, -114, -95, -24, -88, -86, -27, -96, -79, -27, -80, -114, 35, 34, 44, 34, 112, 117, 98, 116, 105]...&apos;, original message: bytes can be at most 32766 in length; got 94724]&quot;,&quot;caused_by&quot;:&#123;&quot;type&quot;:&quot;exception&quot;,&quot;reason&quot;:&quot;Elasticsearch exception [type=max_bytes_length_exceeded_exception, reason=max_bytes_length_exceeded_exception: bytes can be at most 32766 in length; got 94724]&quot;&#125;&#125;,&quot;status&quot;:400&#125;</span><br></pre></td></tr></table></figure><p>可以看到，使用 <code>bulk</code> 方式，在数据写入 <code>Elasticsearch</code> 时遇到异常，如果一个字段的类型是 <code>keyword</code>，而实际写入数据时指定了一个非常长的文本值，会报错：<code>illegal_argument_exception</code>、<code>max_bytes_length_exceeded_exception</code>，整个文档写入失败并返回异常【注意，会过滤掉当前整个文档，即整条数据不能被写入，而如果字段的字节长度小于等于 32766，文档是可以被写入的，但是这个字段可能不会被索引，参考下面的 <code>ignore_above</code> 参数】。</p><p>更详细的信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">whose UTF8 encoding is longer than the max length 32766</span><br></pre></td></tr></table></figure><p><code>author.raw</code> 取值的字节数超过了 32766，无法写入，综合上述异常信息，表明 <code>author.raw</code> 字段定义为 <code>keyword</code>，而实际写入数据时文本长度过大，字节数达到 94724【大概率是脏数据】。</p><p>注意，这里的无法写入是针对整个文档，即整条数据无法成功写入 <code>Elasticsearch</code>。</p><h1 id="问题分析"><a href="# 问题分析" class="headerlink" title="问题分析"></a>问题分析 </h1><p> 对于这种超长的值，如果简单的把字段设置为 <code>keyword</code> 类型肯定是不行的。</p><p>解决方法就是对这种长文本的字段不能定义为 <code>keyword</code>，而应该定义为分析类型，即 <code>text</code>，并指定必要的分析器。</p><p>那如果这个字段本身就应该定义为 <code>keyword</code> 类型，而实际中存在少量的脏数据，这种超长的内容是可以忽略的，那就给这个字段指定一个最长字符数，例如 200 字符，在写入前判断一下长度，超过则移除或者截断，不要让这种超长的文本进入写 <code>Elasticsearch</code> 的流程。毕竟这种超长文本写入到一个 <code>keyword</code> 类型的字段中，对于 <code>Elasticsearch</code> 是不友好的，底层的 <code>Lucene</code> 也无法支持，而且哪怕写入了，对于使用者来说也没有意义【要进行全文检索才是有意义的】。</p><h2 id="禁止索引"><a href="# 禁止索引" class="headerlink" title="禁止索引"></a>禁止索引 </h2><p> 当然，对于长度不超过 32766 字节的 <code>keyword</code> 类型字段值，如果太长也没有意义，例如几百几千个字符【对应的字节数可能是几千几万】，而 <code>Elasticsearch</code> 原生也支持对 <code>keyword</code> 类型的字段设置禁止索引的长度上限，超过一定的字符数【前提是不超过 32766 字节】则当前字段不能被索引，但是字段的数据还是能写入的，它就是 <code>ignore_above</code> 参数，下面举例说明。</p><p>设置 <code>name_ignore</code> 字段为 <code>keyword</code> 类型，并指定 <code>ignore_above</code> 为 8，表示最大可以索引 8 个字符的长度。同理，设置 <code>name</code> 字段为 <code>keyword</code> 类型，并指定 <code>ignore_above</code> 为 32，表示最大可以索引 32 个字符的长度。</p><p>注意，<code>ignore_above</code> 参数限制的是字符数，具体字节数要根据实际内容转换，如果内容中都是字母、数字，则字符数就是字节数，但是当内容中大多数是中文、韩文，则字节数等于字符数乘以 4。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /my-index-post/_mapping/post</span><br><span class="line">&#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name_ignore&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">        &quot;ignore_above&quot;: 8</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /my-index-post/_mapping/post</span><br><span class="line">&#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">        &quot;ignore_above&quot;: 32</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>写入 2 条数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/post/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot; 名称过长会被过滤名称过长会被过滤 & quot;,</span><br><span class="line">  &quot;name_ignore&quot;: &quot; 名称过长会被过滤名称过长会被过滤 & quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my-index-post/post/2</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot; 名称过长会被过滤名称过长会被过滤 & quot;,</span><br><span class="line">  &quot;name_ignore&quot;: &quot; 名称过长会被过滤名称过长会被过滤 & quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看一下数据，2 条数据都成功写入 <code>Elasticsearch</code> 中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;_id&quot;: [</span><br><span class="line">              &quot;1&quot;,</span><br><span class="line">              &quot;2&quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200305213903.png" alt="查看 2 条数据" title="查看 2 条数据"></p><p>可以看到字段信息都完整，那设置了 <code>name_ignore</code> 参数的用处是什么呢，在于是否 <strong>索引 </strong>，我们加上精确匹配来查询一下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查不到数据 </span><br><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;_id&quot;: [</span><br><span class="line">              &quot;1&quot;,</span><br><span class="line">              &quot;2&quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;name_ignore&quot;: [</span><br><span class="line">              &quot; 名称过长会被过滤名称过长会被过滤 & quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 可以查到数据 </span><br><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;_id&quot;: [</span><br><span class="line">              &quot;1&quot;,</span><br><span class="line">              &quot;2&quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: [</span><br><span class="line">              &quot; 名称过长会被过滤名称过长会被过滤 & quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200305213928.png" alt="查不到数据" title="查不到数据"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200305213935.png" alt="可以查到数据" title="可以查到数据"></p><p>可以发现，使用 <code>name_ignore</code> 字段做精确匹配时查不到数据，而使用 <code>name</code> 字段却可以，说明 <code>Elasticsearch</code> 在写入 <code>name_ignore</code> 字段的值时没有对超过 8 个字符的做索引，只是简单的存储，也就无法查询。</p><p>官方说明：</p><blockquote><p>Strings longer than the ignore_above setting will not be indexed or stored.</p></blockquote><h1 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h1><p>1、一个字段被设置为 <code>keyword</code> 类型，遇到很长的大段内容写入后【超过 32766 个字节】，抛出字节数过大异常，整条数据无法写入。</p><p>2、搜索超过 <code>ignore_above</code> 设定长度的字段，无法命中数据【因为在写入时没有做索引，但是字段的值仍旧保留】。</p><p>3、写入数据时，内容的字符数超过 <code>ignore_above</code> 的限制，整条数据仍旧可以入库【包含当前字段】，只是内容不会被索引，在查询命中这条数据时字段对应的值仍旧可以返回。</p><p>4、如果不设置 <code>ignore_above</code> 的值，默认为 256 个字符，但是记住这个值首先受限于 <code>keyword</code> 类型的限制，并不能无限大。</p><h2 id="引申说明"><a href="# 引申说明" class="headerlink" title="引申说明"></a> 引申说明 </h2><p>1、由于 <code>keyword</code> 的长度限制，<code>keyword</code> 类型的最大支持的长度为 32766 个字节，注意如果是 <code>UTF-8</code> 类型的字符【占用 1-4 个字节】，也就能支持 8000 个左右【如果都是数字、字母则会长一点】，也就是说 <code>term</code> 精确匹配的最大支持长度为 8000 个 <code>UTF-8</code> 个字符【而实际上这么长在应用中是没有意义的】。</p><p>2、两种类型的区别：</p><ul><li><code>text</code> 类型：没有最大长度限制，支持分词、全文检索，不支持聚合、排序，因此适合大字段存储，例如文章详情</li><li><code>keyword</code> 类型：最大字节数为 32766，如果使用 <code>UTF-8</code> 编码，最大字符数粗略估计可以使用最大字节数除以 4，支持精确匹配，支持聚合、排序，适合精确字段匹配，例如：<code>url</code>、姓名、性别</li></ul><p> 官方说明：</p><blockquote><p>This option is also useful for protecting against Lucene’s term byte-length limit of 32766.<br>The value for ignore_above is the character count, but Lucene counts bytes. If you use UTF-8 text with many non-ASCII characters, you may want to set the limit to 32766 / 4 = 8191 since UTF-8 characters may occupy at most 4 bytes.</p></blockquote><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>1、官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/ignore-above.html" target="_blank" rel="noopener">ignore-above</a> 。</p><p>2、字段的 <code>ignore_above</code> 可以变更，类型不会变更，不会影响已经存储的内容【使用 <code>put</code> 接口，参考官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/indices-put-mapping.html" target="_blank" rel="noopener">indices-put-mapping</a>】，只会影响以后写入的内容，因为字段类型并没有变化，只是限制了写入长度。</p><p>3、设置时取值为数值，例如 6、16 等，注意它表示的是字符数，不是字节数，所以如果数据都是字母、数字最大就可以设置为 32766，但是当数据是中文、韩文时最大只能设置为 8000 了。</p><p>4、如果需要同一个字段存在多种类型，可以使用 <code>multi-fields</code> 特性，参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/multi-fields.html" target="_blank" rel="noopener">multi-fields</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>bulk</tag>
        <tag>keyword</tag>
        <tag>ignore_above</tag>
      </tags>
  </entry>
  <entry>
    <title>常用正则表达式列表</title>
    <url>/2018121401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>正则表达式是一种匹配模式，在日常学习或者工作中，如果善于使用正则表达式，可以大大提高效率。特别是在文本处理方面，使用正则表达式与不使用的效率可谓天壤之别。当然，如果确实没有使用的场景，了解一下正则表达式的知识点也是有好处的，可以从归纳总结的角度思考问题。本文首先概述一下正则表达式的基本知识点，再记录一些常用的正则表达式，以便查用。</p><a id="more"></a><h1 id="正则表达式的概念"><a href="# 正则表达式的概念" class="headerlink" title="正则表达式的概念"></a>正则表达式的概念 </h1><p> 正则表达式【regular expression】描述了一种匹配字符串的 <strong>模式 </strong>【pattern】，其本身是一个 <strong>字符串 </strong>，由 <strong>普通字符 </strong>、<strong> 元字符 </strong>组成。</p><p>通俗点说，正则表达式就是一种人为定义的规则，用来匹配字符串，一般有三种作用：</p><ul><li>可以检查一个字符串中是否含有某种子串，例如判断微博内容中是否包含微博话题 </li><li> 将字符串中某种子串替换掉，例如替换微博内容中的话题为空白 </li><li> 从某个字符串中抽取某种子串，例如从微博内容中抽取话题 </li></ul><p> 正则表达式是非常简单而强大的，学会之后，除了能提高效率，还会给你带来绝对的成就感。所以，在此，要了解上面的概念并记住这几个名词：<strong> 模式 </strong>、<strong> 字符串 </strong>、<strong> 普通字符 </strong>、<strong> 元字符 </strong>。</p><h1 id="正则表达式的入门语法"><a href="# 正则表达式的入门语法" class="headerlink" title="正则表达式的入门语法"></a>正则表达式的入门语法 </h1><p> 正则表达式的语法很简单，本质就是一个字符串，所以任意一个字符串就是一个正则表达式，但是为了保证这个字符串有意义、有实际用处，还是要遵循正则表达式的语法规范，下面就列举一些常见的语法规范。</p><h2 id="基本字符"><a href="# 基本字符" class="headerlink" title="基本字符"></a>基本字符 </h2><p><code>[]</code>：中括号表达式，表示集合<br><code>()</code>：子表达式<br><code>{}</code>：限定符表达式，用来限定次数<br><code>|</code>：多个选项中的一个，即或的逻辑关系，满足其一即可<br><code>.</code>：点号，表示除去换行符【\n】之外的任意字符<br><code>\</code>：转义字符，用来转义特殊字符</p><h2 id="定位符"><a href="# 定位符" class="headerlink" title="定位符"></a> 定位符 </h2><p><code>^</code>：开始位置<br><code>$</code>：结束位置</p><h2 id="限定符"><a href="# 限定符" class="headerlink" title="限定符"></a> 限定符 </h2><p><code>*</code>：匹配 0 次或多次<br><code>+</code>：匹配 1 次或多次<br><code>?</code>：匹配 0 次或 1 次<br><code>{n}</code>：匹配确定的 n 次<br><code>{n,}</code>：至少匹配 n 次<br><code>{n,m}</code>：最少匹配 n 次且最多匹配 m 次</p><h2 id="转义字符"><a href="# 转义字符" class="headerlink" title="转义字符"></a> 转义字符 </h2><p> 除了表示特殊的字符，匹配元字符都需要使用 </p><p><code>\r</code>：回车符<br><code>\n</code>：换行符<br><code>\s</code>：匹配任何空白字符，包括空格、制表符、换页符，等价于 [\f\n\r\t\v]<br><code>\d</code>：匹配一个数字字符，等价于 [0-9]<br><code>\w</code>：匹配字母、数字、下划线，等价于 [A-Za-z0-9_]</p><h2 id="普通字符"><a href="# 普通字符" class="headerlink" title="普通字符"></a> 普通字符 </h2><p> 元字符之外的字符都是普通字符，即 1-4 之外的所有字符【当然，1-4 中没有列出完整的元字符】，例如标点符号、中文字、英文字母、数字等都是普通字符。</p><p>其实，平时大家都会用到的一个功能就涉及到正则表达式：在文件管理器中根据关键词搜索文件，虽然输入的只是一个普通的字符串，但是文件管理器会把它作为正则表达式来搜索，只要文件名称包含指定的字符串，就会命中【而不是说文件名一定要等于指定的字符串】。</p><h1 id="常用模式举例"><a href="# 常用模式举例" class="headerlink" title="常用模式举例"></a>常用模式举例 </h1><p> 这里所说的模式，其实就是一条规范的正则表达式，具有实际的用处。</p><p>座机号码：<code>\d {3}-\d {8}|\d {4}-\d {7,8}</code><br>网址链接：<code>(https?|ftp|file)://[-A-Za-z0-9+&amp;@#/%?=~_|!:,.;]+[-A-Za-z0-9+&amp;@#/%=~_|]</code><br>微博表情【[] 里包含 1 到 8 个中文、字母】：<code>\[[\u4e00-\u9fa5A-Za-z]{1,8}\]</code><br>微博话题：<code>#[^@&lt;&gt;#&quot;&amp;&#39;\r\n\t]{1,49}#</code>，不考虑复杂情况使用 <code>#[^#]{1,49}#</code> 也可以<br> 微博用户昵称【中文、数字、字母、横线、下划线的组合，2-30 个字符】：<code>@[\u4e00-\u9fa5A-Z0-9a-z_-]{2,30}</code><br>所有的小写字母：<code>[a-z]</code><br>所有的大写字母：<code>[A-Z]</code><br>所有的字母：<code>[a-zA-Z]</code><br>所有的数字、句号、减号：<code>[0-9\.\-]</code><br>中文：<code>[\u4e00-\u9fa5]</code>，利用了转义字符与 Unicode 编码 <br> 除了小写字母以外的所有字符：<code>[^a-z]</code><br>除了双引号【“】和单引号【’】之外的所有字符：<code>[^\”\&#39;]</code><br>整数：<code>^\-?[0-9]+$</code><br>小数：<code>^[-]?[0-9]+(\.[0-9]+)?$</code><br>一个数字：<code>\d</code>，或者 <code>[0-9]</code><br>单词 yeah 连续出现一次以上：<code>(yeah)+</code></p><p>其它正则表达式可以参考菜鸟工具里面的列表：<a href="https://c.runoob.com/front-end/854" target="_blank" rel="noopener">https://c.runoob.com/front-end/854</a> 。</p><h1 id="在线学习网站以及使用演示"><a href="# 在线学习网站以及使用演示" class="headerlink" title="在线学习网站以及使用演示"></a>在线学习网站以及使用演示 </h1><p> 看的再多，懂得再多，不使用很快也就忘记了，所以切记：熟能生巧。下面就使用微博内容的例子来演示正则表达式的入门级别使用。</p><h2 id="使用在线工具"><a href="# 使用在线工具" class="headerlink" title="使用在线工具"></a>使用在线工具 </h2><p>1、<a href="https://tool.oschina.net/regex" target="_blank" rel="noopener">https://tool.oschina.net/regex</a><br>2、<a href="https://regex101.com" target="_blank" rel="noopener">https://regex101.com</a> 【需要翻墙，注意程序语言的选择，选择 ECMAScript，如果使用过程中有红色填充就表示出错警告】<br>3、正则表达式可视化网站，帮你把正则表达式转为形象的流程图：<a href="https://regexper.com" target="_blank" rel="noopener">regexper</a></p><p> 假如有一篇微博，内容为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 我分享了一张图片，来自 #腾讯动漫# 我分享了一张图片，来自 #腾讯动漫# http://t.cn/RDFUnja http://t.cn/zT8RAls //@狮鸢 LionGlede2018:[笑 cry] 哈哈哈哈哈换肚子疼 //@果子狸爬大树: [允悲]//@飞船叔叔：呵呵哈哈哈太乖了 //@Suhero-D-Ace: 笑昏 //@土豆动漫：真・睡蒙了 [允悲]//@妖妖小精: [允悲]//@M 大王叫我来巡山：这书包咋这么硬呢 [允悲][good]</span><br></pre></td></tr></table></figure><p>演示几个匹配操作：</p><p>1、抽取微博内容中的话题：<code>#[^@&lt;&gt;#&quot;&amp;&#39;\r\n\t]{1,49}#</code><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190605005658.png" alt="截图示例 - 抽取话题有 2 个匹配" title="截图示例 - 抽取话题有 2 个匹配"></p><p>2、抽取微博内容中的表情：<code>\[[\u4e00-\u9fa5A-Za-z]{1,8}\]</code><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190605005739.png" alt="截图示例 - 抽取表情有 6 个匹配" title="截图示例 - 抽取表情有 6 个匹配"></p><p>3、判断是否以【我分享了一张图片，来自】开头：<code>^ 我分享了一张图片，来自.*</code><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190605005804.png" alt="截图示例 - 判断以某句话开头有 1 个匹配" title="截图示例 - 判断以某句话开头有 1 个匹配"></p><p>当然，使用 <code>^(我分享了一张图片，来自).*</code> 更为准确 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190605005830.png" alt="截图示例 - 判断以某句话开头有 1 个匹配" title="截图示例 - 判断以某句话开头有 1 个匹配"></p><p>4、抽取微博内容中的链接：<code>(https?|ftp|file):\/\/[-A-Za-z0-9+&amp;@#/%?=~_|!:,.;]+[-A-Za-z0-9+&amp;@#/%=~_|]</code><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190605005855.png" alt="截图示例 - 抽取网址链接有 2 个匹配" title="截图示例 - 抽取网址链接有 2 个匹配"></p><p>5、抽取微博内容中的用户昵称：<code>@[\u4e00-\u9fa5A-Z0-9a-z_-]{2,30}</code><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190605005905.png" alt="截图示例 - 抽取昵称有 7 个匹配" title="截图示例 - 抽取昵称有 7 个匹配"></p><h2 id="总结"><a href="# 总结" class="headerlink" title="总结"></a> 总结 </h2><p> 使用正则表达式之前需要先归纳总结，找到需要匹配的内容的规律，然后才能着手写正则表达式【即模式】，接着才能测试验证正则表达式是否准确。</p><p>还需要注意一点，在不同的编程语言中，对于某些特殊的字符需要转义，例如双引号、单引号、反斜杠等，还有些符号需要额外特殊处理，例如在 PHP 中，中文编码需要使用形如 <code>\x {4e00}-\x {9fa5A}</code> 的格式。</p><h1 id="在文本编辑器中使用"><a href="# 在文本编辑器中使用" class="headerlink" title="在文本编辑器中使用"></a>在文本编辑器中使用 </h1><p> 平时处理文本文件时，有时候需要查找替换指定的内容、删除指定的内容、统计指定的内容出现的次数等等。如果这里指定的内容只是具体的字符串【例如在内容中查找：爱国敬业】，用不到正则表达式，但是如果指定的内容是一种规则，无法给出具体的表示【例如在内容中查找网址链接，并不是指某一条具体的网址链接】，那就需要正则表达式出场了。</p><h2 id="文本编辑器推荐"><a href="# 文本编辑器推荐" class="headerlink" title="文本编辑器推荐"></a>文本编辑器推荐 </h2><p>1、不要使用 Windows 自带的记事本，原因：编码支持差、效率低、扩展功能弱。<br> 举例：【联通】乱码问题、打开 11MB 大小的日志文件会卡住 </p><p>2、推荐 Notepad++、Sublimetext、EmEditor 等文本编辑器<br>Notepad++ 官网：<a href="https://notepad-plus-plus.org" target="_blank" rel="noopener">https://notepad-plus-plus.org</a><br>Sublimetext 官网：<a href="https://www.sublimetext.com" target="_blank" rel="noopener">https://www.sublimetext.com</a><br>【打不开进镜像网站：<a href="http://www.sublimetextcn.com" target="_blank" rel="noopener">http://www.sublimetextcn.com</a> 】</p><p>3、此外还有一些收费的工具，例如：Ultraedit、EditPlus 等，不再介绍</p><h2 id="实际演示"><a href="# 实际演示" class="headerlink" title="实际演示"></a> 实际演示 </h2><p> 使用 Sublimetext 工具，继续使用上述的微博内容，操作演示，更多功能请自行探索：</p><p>1、查找替换表情，批量操作【需要开启正则模式】<br>查找【Ctrl + F】，或者在 <strong>查找 </strong>下拉列表中选择 <strong>查找匹配值 </strong><br> 查找替换【Ctrl + H】，或者在 <strong>查找 </strong>下拉列表中选择 <strong>替换匹配值 </strong><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190605013756.png" alt="SublimeText 查找替换表情" title="SublimeText 查找替换表情"></p><p>2、统计网址链接个数，在左下角可以看到命中个数【需要开启正则模式】<br> 查找【Ctrl + F】，或者在 <strong>查找 </strong>下拉列表中选择 <strong>查找匹配值 </strong></p><p>3、打开大文件，操作流畅【打开 11MB 的 log 文件】</p><p>4、查看设置文件编码<br> 在 <strong>文件 </strong>-&gt; <strong>保存 </strong>编码中选择 </p><p>5、同时修改多处内容，Multiple Selections【Ctrl+D】</p><p>6、列模式编辑【Ctrl + Shift + L，配合 Shift 多选内容】</p><p> 此外，有的版本显示文件名会乱码，显示方格，需要在 <strong>首选项 </strong>-&gt; <strong>设置 - 用户 </strong>中添加配置项：<code>&quot;dpi_scale&quot;: 1.0</code> ，即可正常显示。</p><p>使用 EmEditor 工具：</p><p>使用 EmEditor 打开 10 万数据量的大文件，这是一款针对 csv 文件专门设计的工具，几十万数据量不在话下，只要电脑内存够用，打开几个 GB 的 csv 文件也很轻松，而 Excel 遇到几万的数据量基本就卡住，无法操作了。</p><p>1、打开大文件，内容搜索、文件切分、编码设置 </p><p>2、缺点，不能像 Excel 那么灵活进行筛选统计分析</p><h1 id="后记"><a href="# 后记" class="headerlink" title="后记"></a> 后记 </h1><p> 有一次遇到一个需求，使用正则表达式处理，逻辑很简单，一开始我处理时，直接写了一个嵌套很多层 <code>.</code>、<code>+</code>、<code>*</code> 等符号的正则表达式，结果出现了无限循环，电脑主机的 CPU 持续保持在 100%，十几个小时仍在匹配，这种肯定不能使用，我在另外一篇博客中有介绍：<a href="https://www.playpi.org/2018120201.html">一条正则表达式引发的惨案 </a> ，有兴趣的可以看一下。</p><p> 接着我在下面列出一个看似很简单的正则表达式，但是却可以进入无限循环。</p><p>正则表达式：<br><code>^([hH][tT]{2}[pP]:\/\/|[hH][tT]{2}[pP][sS]:\/\/)(([A-Za-z0-9-~]+).)+([A-Za-z0-9-~\\\\/])+$</code></p><p>匹配内容：<br><code>http://www.fapiao.com/dddp-web/pdf/download?request=6e7JGxxxxx4ILd-kExxxxxxxqJ4-CHLmqVnenXC692m74H38sdfdsazxcUmfcOH2fAfY1Vw__%5EDadIfJgiEf</code></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title>微博 url mid 相互转换算法实现 - Java 版本</title>
    <url>/2018122001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>对微博数据有了解的人都知道，一条微博内容对应有唯一的微博 <code>url</code>，同时对微博官方来说，又会生成一个 <code>mid</code>，<code>mid</code> 就是一条微博的唯一标识【就像 <code>uid</code> 是微博用户的唯一标识一样】，也类似于人的身份证号。其实，微博 <code>url</code> 里面有一串看起来无意义的字符【由字母、数字组成，6-9 个字符长度，当然以后也可能会变长】，可以和 <code>mid</code> 互相转换，本文就根据理论以及 <code>Java</code> 版本的实现，讲解微博 <code>url</code> 与 <code>mid</code> 的互相转换过程。</p><a id="more"></a><p>注意，为了确保多个 <code>id</code> 字段的定义不混乱，本文先约束好 <code>mid</code>、<code>uid</code>、<code>url</code>、<code>id</code>、<code>murl</code> 的概念：</p><ul><li><code>mid</code>，一条微博拥有一个独立的标识，由微博官方生成【也可以理解为 <code>mobile id</code>，可以和 <code>murl</code> 转换】，可以和 <code>id</code> 互相转换，例如：<code>4404101091169383</code>【由 <code>I1IGF4Ud1</code> 转换】</li><li><code>url</code>，指一条微博的链接，里面包含了 <code>uid</code>、<code>id</code>，格式如：<code>https://weibo.com/uid/id</code>，例如：<code>https://weibo.com/3086148515/I1IGF4Ud1</code></li><li><code>uid</code>，指一个微博用户的唯一标识，由微博官方生成，通过 <code>https://weibo.com/u/uid</code> 可以打开微博个人主页，例如：<code>https://weibo.com/u/3086148515</code></li><li><code>id</code>，指 <code>url</code> 中标识微博的那部分，可以和 <code>mid</code> 互相转换，例如：<code>I1IGF4Ud1</code></li><li><code>murl</code>，即 <code>mobile url</code>，移动端 <code>url</code>，格式：<code>https://m.weibo.cn/status/id</code>、<code>https://m.weibo.cn/status/mid</code>，专为客户端设计，适合使用手机、平板的浏览器打开，排版显示友好，如果使用电脑的浏览器打开，排版显示不友好，例如：<code>https://m.weibo.cn/status/I1IGF4Ud1</code>、<code>https://m.weibo.cn/status/4404101091169383</code></li></ul><h1 id="数据示例"><a href="# 数据示例" class="headerlink" title="数据示例"></a>数据示例 </h1><p> 为了让读者直观地了解这些概念的不同，下面我将列举一些微博链接、<code>id</code> 的示例，并且给出截图，希望读者看到后可以明白上面约束规范的含义。当然，对于对微博数据非常熟悉的读者来说，可以跳过这个小节，直接看下一小节的转换代码。</p><p>1、通过 <code>id</code>、<code>uid</code> 构造的 <code>url</code>，打开微博内容，示例：<code>https://weibo.com/3086148515/I1IGF4Ud1</code> ，其中，<code>3086148515</code> 是 <code>uid</code>，<code>I1IGF4Ud1</code> 是 <code>id</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112021749.png" alt="通过微博 url 打开" title="通过微博 url 打开"></p><p>这种格式的 <code>url</code> 可以在网页端通过点击微博的发表时间获取，如下图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112022115.png" alt="点击发表时间获取 url" title="点击发表时间获取 url"></p><p>2、通过 <code>uid</code> 打开微博用户的首页，示例：<code>https://weibo.com/u/3086148515</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112022621.png" alt="uid 打开首页" title="uid 打开首页"></p><p>这里需要注意一点，有时候微博用户会设置个性名称，输入上述链接会跳转到另外一个链接，但是打开的内容一定是个人首页【当然也可以直接打开】，例如：<code>https://weibo.com/playpi</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112022613.png" alt="uid 跳转打开首页" title="uid 跳转打开首页"></p><p>3、通过 <code>id</code>、<code>mid</code> 构造的 <code>murl</code> 打开微博内容，示例：<code>https://m.weibo.cn/status/I1IGF4Ud1</code>、<code>https://m.weibo.cn/status/4404101091169383</code>，当然这种内容不适合在 <code>PC</code> 端的浏览器打开，排版不好。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112022925.png" alt="通过 id 构造 murl" title="通过 id 构造 murl"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112022938.png" alt="通过 mid 构造 murl" title="通过 mid 构造 murl"></p><h1 id="转换代码"><a href="# 转换代码" class="headerlink" title="转换代码"></a>转换代码 </h1><p> 提前说明，下文中涉及的代码已经被我上传至 <code>GitHub</code>：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-common-core/src/main/java/org/playpi/study/util" target="_blank" rel="noopener">WeiboUtil</a> ，读者可以提前下载查看。</p><p>此外，还有一份 <code>Python</code> 版本的代码，读者可以参考我的另外一篇博客：<a href="https://www.playpi.org/2018071801.html">微博 id mid 相互转换算法实现 - Python 版本 </a> 。</p><p> 好，言归正传，下面开始讲述关于转换代码的部分，主要是关于 <code>id</code>、<code>mid</code> 转换的，其它的内容不会赘述，读者可以参考代码，使用单元测试用例进行测试也可以。</p><p>注意，涉及到的 62 进制表示从 0 到 9、从 <code>a</code> 到 <code>z</code>、从 <code>A</code> 到 <code>Z</code> 一共 62 个字符。</p><p>1、<code>id</code> 转为 <code>mid</code> 的思路，例如：<code>I1IGF4Ud1</code>，有 9 个字符，从后开始以 4 个字符为单位进行拆分，拆分为：<code>I</code>、<code>1IGF</code>、<code>4Ud1</code>，然后再分别把它们转为 62 进制对应的 10 进制数值，得到：<code>44</code>、<code>0410109</code>【不足 7 位在前面补 0】、<code>1169383</code>。紧接着再拼接所有的结果，得到最终的 <code>mid</code>：<code>4404101091169383</code>。</p><p>主要代码逻辑如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * id 转化成 mid 的值 </span><br><span class="line">     *</span><br><span class="line">     *</span><br><span class="line">     * @param id</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">public static String id2mid (String id) &#123;</span><br><span class="line">	String mid = &quot;&quot;;</span><br><span class="line">	String k = id.toString ().substring (3, 4);</span><br><span class="line">	// 用于第四位为 0 时的转换 </span><br><span class="line">	if (!k.equals (&quot;0&quot;)) &#123;</span><br><span class="line">		for (int i = id.length () - 4; i &gt; -4; i = i - 4) &#123;</span><br><span class="line">			// 分别以四个为一组 </span><br><span class="line">			int offset1 = i &lt; 0 ? 0 : i;</span><br><span class="line">			int offset2 = i + 4;</span><br><span class="line">			String str = id.toString ().substring (offset1, offset2);</span><br><span class="line">			str = str62to10 (str);</span><br><span class="line">			//String 类型的转化成十进制的数 </span><br><span class="line">			// 若不是第一组，则不足 7 位补 0</span><br><span class="line">			if (offset1 &gt; 0) &#123;</span><br><span class="line">				while (str.length () &lt; 7) &#123;</span><br><span class="line">					str = &apos;0&apos; + str;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			mid = str + mid;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		for (int i = id.length () - 4; i &gt; -4; i = i - 4) &#123;</span><br><span class="line">			int offset1 = i &lt; 0 ? 0 : i;</span><br><span class="line">			int offset2 = i + 4;</span><br><span class="line">			if (offset1 &gt; -1 &amp;&amp; offset1 &lt; 1 || offset1 &gt; 4) &#123;</span><br><span class="line">				String str = id.toString ().substring (offset1, offset2);</span><br><span class="line">				str = str62to10 (str);</span><br><span class="line">				// 若不是第一组，则不足 7 位补 0</span><br><span class="line">				if (offset1 &gt; 0) &#123;</span><br><span class="line">					while (str.length () &lt; 7) &#123;</span><br><span class="line">						str = &apos;0&apos; + str;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				mid = str + mid;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				String str = id.toString ().substring (offset1 + 1, offset2);</span><br><span class="line">				str = str62to10 (str);</span><br><span class="line">				// 若不是第一组，则不足 7 位补 0</span><br><span class="line">				if (offset1 &gt; 0) &#123;</span><br><span class="line">					while (str.length () &lt; 7) &#123;</span><br><span class="line">						str = &apos;0&apos; + str;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				mid = str + mid;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return mid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、<code>mid</code> 转为 <code>id</code> 的思路，例如：<code>4404101091169383</code>，有 18 个字符，从后开始以 7 个字符为单位进行拆分，拆分为：<code>44</code>、<code>410109</code>【前面有 0 的直接去除】、<code>1169383</code>，然后再分别把它们转为 10 进制数值对应的 62 进制字符串，得到：<code>I</code>、<code>1IGF</code>、<code>4Ud1</code>。紧接着再拼接所有的结果，得到最终的 <code>id</code>：<code>I1IGF4Ud1</code>。</p><p>主要代码逻辑如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * mid 转换成 id</span><br><span class="line">     *</span><br><span class="line">     * @param mid</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">public static String mid2id (String mid) &#123;</span><br><span class="line">	String url = &quot;&quot;;</span><br><span class="line">	for (int j = mid.length () - 7; j &gt; -7; j = j - 7) &#123;</span><br><span class="line">		// 以 7 个数字为一个单位进行转换 </span><br><span class="line">		int offset3 = j &lt; 0 ? 0 : j;</span><br><span class="line">		int offset4 = j + 7;</span><br><span class="line">		// String l = mid.substring (mid.length () - 14, mid.length () - 13);</span><br><span class="line">		if ((j &gt; 0 &amp;&amp; j &lt; 6) &amp;&amp; (mid.substring (mid.length () - 14, mid.length () - 13).equals (&quot;0&quot;) &amp;&amp; mid.length () == 19)) &#123;</span><br><span class="line">			String num = mid.toString ().substring (offset3 + 1, offset4);</span><br><span class="line">			num = int10to62 (Integer.valueOf (num));</span><br><span class="line">			// 十进制转换成 62 进制 </span><br><span class="line">			url = 0 + num + url;</span><br><span class="line">			if (url.length () == 9) &#123;</span><br><span class="line">				url = url.substring (1, url.length ());</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			String num = mid.toString ().substring (offset3, offset4);</span><br><span class="line">			num = int10to62 (Integer.valueOf (num));</span><br><span class="line">			url = num + url;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return url;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、以上内容运行单元测试后结果截图如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112031006.png" alt="单元测试结果" title="单元测试结果"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><h2 id="其它编程语言实现"><a href="# 其它编程语言实现" class="headerlink" title="其它编程语言实现"></a> 其它编程语言实现 </h2><p> 关于 <code>mid</code>、<code>id</code> 转换的方法，有一个 <code>Python</code> 语言的版本，参考我的另外一篇博客：<a href="https://www.playpi.org/2018071801.html">微博 id mid 相互转换算法实现 - Python 版本 </a> 。</p><h2 id="微博图床"><a href="# 微博图床" class="headerlink" title="微博图床"></a> 微博图床 </h2><p> 本站点一开始使用的图床工具就是微博图床，很好用，免费，速度快，可以上传高清图片，后来听说被黑产人员恶意使用，已经开启了防盗链，只留下了几个接口用来钓鱼。有兴趣的读者可以参考我的另外几篇博客：<a href="https://www.playpi.org/2019042701.html">解决微博图床防盗链的问题 </a> 、<a href="https://www.playpi.org/2019050201.html"> 使用 Java 代码迁移微博图床到 GitHub 图床 </a> 。</p><p> 图片上传微博图床后，得到一个图片链接，根据这个微博图床链接，也可以提取用户的 <code>uid</code>，进一步就能找到这个用户。</p><p>提取的逻辑是：使用链接中文件名的前 8 个字符，将 16 进制转为 10 进制的数值，得到的数字就是 <code>uid</code>【当然，现在也有例外，应该是 8 位 16 进制存满了，所以出现了 005、006、007 等以 00 数字开头的文件名，那也不用着急，它们其实是 62 进制的字符，也同样转为 10 进制的数值即可】。</p><p>我这里有一份 <code>JavaScript</code> 示例代码，代码已经被我上传至 <code>GitHub</code>：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/bin/20181220" target="_blank" rel="noopener">extractUid.js</a> ，读者可以查看，内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function idx (c) &#123;</span><br><span class="line">    c = c.charCodeAt ();</span><br><span class="line">    if (c &gt;= 48 &amp;&amp; c &lt;= 57) return c - 48;</span><br><span class="line">    if (c &gt;= 97 &amp;&amp; c &lt;= 122) return c - 97 + 10;</span><br><span class="line">    return c - 56 + 36;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function extractUid (url) &#123;</span><br><span class="line">    url = url.replace (/\.\w+$/g, &apos;&apos;);</span><br><span class="line">    // 提取文件名 </span><br><span class="line">    var hash = url.match (/[0-9a-zA-Z]&#123;32&#125;$/);</span><br><span class="line">    if (hash === null) return &apos;&apos;;</span><br><span class="line">    // 截取前 8 位 </span><br><span class="line">    hash = hash [0].slice (0, 8);</span><br><span class="line">    var uid = 0;</span><br><span class="line">    // 16 进制或者 62 进制 </span><br><span class="line">    if (hash [0] == &apos;0&apos; &amp;&amp; hash [1] == &apos;0&apos;) k = 62;</span><br><span class="line">    else k = 16;</span><br><span class="line">    // 每一个数字都转为 10 进制 </span><br><span class="line">    for (i = 0; i &lt; 8; i++) uid = uid * k + idx (hash [i]);</span><br><span class="line">    return uid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>例如我这里上传一张图片到微博图床，链接：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https://wx3.sinaimg.cn/mw1024/b7f2e3a3gy1gakhzzxtmtj20fu0l4dku.jpg</span><br></pre></td></tr></table></figure><p>然后使用上述转换代码可以获取上传图片对应的 <code>uid</code>，进而就可以找到这个微博用户。运行结果是：<code>3086148515</code>，那么这个微博用户的微博首页就是：<code>https://weibo.com/u/3086148515</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20200112193012.png" alt="微博图床链接抽取 uid" title="微博图床链接抽取 uid"></p><p>简单分析一下，文件名是：<code>b7f2e3a3gy1gakhzzxtmtj20fu0l4dku.jpg</code>，前 8 个字符是：<code>b7f2e3a3</code>，把它由 16 进制转为 10 进制，得到：<code>3086148515</code>，与上面的结果一致。</p><p>不过微博图床在 2019 年 9 月份已经开启防盗链了，即图片链接通过外站打不开，只能在新浪站内打开。</p><h2 id="微博短链接"><a href="# 微博短链接" class="headerlink" title="微博短链接"></a>微博短链接 </h2><p> 微博短链接是微博官方提供的网址压缩功能产生的一种只包含少量字符的短网址，例如：<a href="https://weibo.com/3086148515/I1IGF4Ud1" target="_blank" rel="noopener">https://weibo.com/3086148515/I1IGF4Ud1</a> ，压缩后为：<a href="http://t.cn/A6vvAcHP" target="_blank" rel="noopener">http://t.cn/A6vvAcHP</a> 。这样的话，发微博时链接占用更少的字符长度。如果发微博时，内容中带了链接，例如视频地址、淘宝店地址，会被自动压缩为短链接。微博短链接可以直接在浏览器中访问，会被微博的网址解析服务器转换为原来的正常链接再访问。</p><p>各大公司都已经提供短链接服务，例如百度、新浪、谷歌，短链接的优点是字符个数比较少，一般在 10 个以内，例如新浪的短网址可以把字符个数控制在 8 个以内【域名 <code>t.cn</code> 是单字符 <code>t</code>】。</p><p>日常大家见到的应用主要有 2 个地方：一个是微博内容中的网址，例如视频网址、电商商品网址，都会被压缩为 8 个字符以内，这样可以减少微博内容的长度【当然微博内容已经不再限制 140 个字符的长度，但是微博评论还是限制的，使用短网址减少字符的使用，何乐而不为】；另外一个就是邮件中的附件网址、图片网址，一般也都是短链接的形式。</p><p>有兴趣的读者可以参考我的另外一篇博客：<a href="https://www.playpi.org/2018101501.html">微博 URL 短网址生成算法 - Java 版本</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>微博url</tag>
        <tag>微博mid</tag>
      </tags>
  </entry>
  <entry>
    <title>微博电影文稿备份</title>
    <url>/2019010101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>元旦是个好日子，在一年之始，我整理硬盘文件夹的过程中，发现了很多电影的资料，都是以前下载的，有的看过有的没看过。突发奇想，有些觉得好看的电影可以保留下来，剪辑部分片段发到微博，也可以用来记录自己曾经看过那些电影，本文记录随微博发送的文稿，防止被删。</p><a id="more"></a><h1 id="双旗镇刀客"><a href="# 双旗镇刀客" class="headerlink" title="双旗镇刀客"></a>双旗镇刀客 </h1><p>《双旗镇刀客》，是一部 1991 年的武侠动作片，获奖很多，豆瓣评分 8.1，好于 95% 的武侠片，好于 92% 的动作片。但是，这部电影里面几乎没有打斗的场面，也没有动作大场面，但依然削弱不了它的武侠内涵。</p><p> 仅有的几个决斗场面全部都是一对一，看不到出招、闪躲、反杀，细节全部使用蒙太奇的手法表现，只能听到一声风声、一声刀声、一声剑声，然后胜败已分，没有嘶喊、没有大动作，非常干净利落。</p><p>视频截取的片段（01:20:07 到 01:23:03）是最后一刀仙和孩哥决斗的场面。对了，你们能认出饰演这一刀仙的演员是谁吗？</p><p>–《双旗镇刀客》：粗粝、苦难、鲁莽的平民式的武侠片。</p><h1 id="扫毒"><a href="# 扫毒" class="headerlink" title="扫毒"></a>扫毒 </h1><p> 扫毒片段之一（01:22:06 到 01:32:16）：泰国一战回来，过了很久，马昊天【刘青云 饰演】、张子伟【张家辉 饰演】、苏建秋【古天乐 饰演】第一次见面，他们并不知道张子伟还活着，看一下大家的反映，三大影帝同场飙戏。</p><p>扫毒片段之二（01:36:30 到 01:46:42）：三兄弟在天台见面，交换人质，然后引发枪战。这一段也是张家辉的鬼畜视频的素材，台词是：五年，五年，你知道这五年我怎么过的吗？你知道吗？【见视频 3 分 38 秒处】</p><h1 id="那山那人那狗"><a href="# 那山那人那狗" class="headerlink" title="那山那人那狗"></a>那山那人那狗 </h1><p> 那山那人那狗，是一部 1999 年的电影，讲述的是儿子（刘烨 饰演）高考落榜不得已回到大山中的家后，做了大半辈子山村邮递员的父亲（滕汝骏 饰演）提前退休，安排儿子接下自己的工作。儿子上班第一天，父亲千叮咛万嘱咐之后仍不放心，带上长年在其左右的忠实老狗（老二）决定陪儿子再走一趟送信之旅。</p><p>在这趟旅途之中，父子由于长期隔膜一开始默默不语，后来渐渐打开了话匣子，对彼此有了更深一层的认识和了解，故事自然真实、扣人心弦。</p><p>以下截取的 11 分钟片段（00:51:52 到 01:03:04）是很重要的一场戏，父子两人一同过河，然后共同休息聊天，在这个过程中，父子的情感逐渐加深了。</p><h1 id="倚天屠龙记之魔教教主"><a href="# 倚天屠龙记之魔教教主" class="headerlink" title="倚天屠龙记之魔教教主"></a>倚天屠龙记之魔教教主 </h1><p> 这是一部 1993 年的武侠片：《倚天屠龙记之魔教教主》，看看这武打场面，动作发挥，虽然当时科技不发达，资源不足，但是拍出来的电影仍然很经典。再看看现在，科技发达了，资金充足，但是动作戏只是做做样子，实在看不下去。</p><p>截取的 7 分钟片段（01:04:22 到 01:11:24）是围攻光明顶的场面，张无忌出场以及打戏过程，动作非常流畅、到位。</p><h1 id="叶问外传：张天志"><a href="# 叶问外传：张天志" class="headerlink" title="叶问外传：张天志"></a>叶问外传：张天志 </h1><p> 作为《叶问》系列影片，电影《叶问外传：张天志》延续了《叶问 3》的故事，讲述了同为咏春传人的张天志在比武惜败叶问后，决意放下功夫，远离江湖纷争。但面对接踵而至的连番挑衅，面对家国大义遭受的恶意侵犯，决定重拾咏春惩戒毒贩，「以武之道」捍卫民族道义尊严的故事。</p><p>电影虽然总体评分不高，但是里面的打戏还是值得看的。以下截取的 3 分钟片段（00:08:40 到 00:11:54）是电影开场的矛盾冲突过程以及打戏场面，动作流利，拳拳到肉。</p><h1 id="屏住呼吸"><a href="# 屏住呼吸" class="headerlink" title="屏住呼吸"></a>屏住呼吸 </h1><p>《屏住呼吸》是一部 2016 年的电影，豆瓣评分 7.0，好于 63% 的惊悚片，好于 82% 的恐怖片。讲述的是三位惯偷（洛奇、艾利克斯、摩尼）潜入一位退伍老兵的家里，老兵因为女儿的车祸获取了巨额赔偿金，他们想偷取这笔钱，从此金盆洗手。</p><p> 三人潜入了老兵位于底特律的如同鬼宅一般的老房子中，整个社区只有他一个人居住，没想到却就此打开了地狱的大门。老兵拥有着高于常人的嗅觉和听力，以及极为敏捷的行动力，很快就发现了三名不速之客的行踪。在他的枪口之下，一行人犹如瓮中之鳖，无处可逃。在紧张而又激烈的追逃之中，洛奇和艾利克斯误打误撞跌落到了地下室中，却因此发现了一个可怕的秘密。</p><p>以下截取的 14 分钟视频片段（00:24:51 到 00:39:15）是三人刚刚潜入住宅，本以为被迷晕的老兵却突然出现，及其凶狠地打死小偷一人，去检查保险箱又恰巧被洛奇看到密码，接着他们小偷二人偷取巨额现金准备逃跑。整个过程真的让人屏住呼吸，时刻感觉到危险，此时已经不是偷东西那么简单了，自己的生命已经快保不住了。</p><h1 id="无间道"><a href="# 无间道" class="headerlink" title="无间道"></a>无间道 </h1><p>《无间道》是一部 2003 年的悬疑犯罪剧情片，获得金马奖最佳剧情片，金像奖最佳电影，豆瓣评分 9.1，好于 99% 的犯罪片，好于 98% 的剧情片。</p><p>1991 年，香港黑帮三合会会员刘健明（刘德华 饰演）听从老大韩琛（曾志伟 饰演）的吩咐，加入警察部队成为黑帮卧底，韩琛许诺刘健明会帮其在七年后晋升为见习督察。1992 年，警察训练学校优秀学员陈永仁（梁朝伟 饰演）被上级要求深入到三合会做卧底，终极目标是成为韩琛身边的红人。2002 年，两人都不负重望，也都身背重压，但是刘健明渐想成为一个真正的好人，而陈永仁则盼着尽快回归警察的身份。 在后续的较量中，逐渐暴露出双方均有卧底的事实，引发双方高层清除内鬼的决心。命运迥异又相似的刘健明和陈永仁开始在无间道的旅程中接受严峻考验。</p><p> 以下截取的 7 分钟片段（01:29:28 到 01:36:04），是结局的天台见面，台词、配乐、镜头都很经典，最后的 2 个卧底双双命丧枪口，令人唏嘘。</p><p>经典台词对话如下：</p><p>刘建明：给我一个机会。<br>陈永仁：怎么给你机会。<br>刘建明：我以前没得选，我现在想做一个好人。<br>陈永仁：好啊，跟法官说，看给不给你做好人。<br>刘建明：那就是要我死。<br>陈永仁：对不起，我是警察。<br>刘建明：谁知道？</p><h1 id="毒液：致命守护者"><a href="# 毒液：致命守护者" class="headerlink" title="毒液：致命守护者"></a>毒液：致命守护者 </h1><p>《毒液：致命守护者》是一部 2018 年的科幻、动作、惊悚电影，又名毒魔、猛毒，豆瓣评分 7.2，好于 69% 的科幻片，好于 69% 的动作片。</p><p> 剧情简介：艾迪是一位深受观众喜爱的新闻记者，和女友安妮相恋多年，彼此之间感情十分要好。安妮是一名律师，接手了生命基金会的案件，在女友的邮箱里，艾迪碰巧发现了基金会老板德雷克不为人知的秘密。为此，艾迪不仅丢了工作，女友也离他而去。之后，生命基金会的朵拉博士找到了艾迪，希望艾迪能够帮助她阻止德雷克疯狂的罪行。在生命基金会的实验室里，艾迪发现了德雷克进行人体实验的证据，并且在误打误撞之中被外星生命体毒液附身。回到家后，艾迪和毒液之间形成了共生关系，他们要应对的是德雷克派出的一波又一波杀手。</p><p>以下截取的 10 分钟片段（00:50:25 到 01:00:55），是艾迪和毒液共生时第一次遇到德雷克派出的杀手的情景，双方产生了激烈的打斗，此时可以看到艾迪和毒液完美的共生关系。</p><h1 id="剑雨"><a href="# 剑雨" class="headerlink" title="剑雨"></a>剑雨 </h1><p>《剑雨》是一部 2010 年的武侠、动作电影，豆瓣评分 7.1，好于 58% 的武侠片，好于 66% 的动作片。这部电影由吴宇森监制，有人称它是《卧虎藏龙》之后最好的武侠片。</p><p> 剧情简介：八百年前，竺人达摩来至中原弘法，其死后尸体被人盗取并分为两部分。传说拿到达摩尸体的人能练成绝世武功，因此江湖上风波骤起。时有转轮王（王学圻 饰演）操控的黑石杀手集团，转轮王率徒众夜袭藏匿半具达摩尸首的首辅张海端（李庆祥 饰演）宅邸，但是他的手下细雨（林熙蕾 饰演）却带着残尸绝走江湖，致令转轮王发出江湖追杀令，引出一阵血雨腥风。为避追杀，细雨易容，更名曾静（杨紫琼 饰演），逃亡期间结识了木讷善良的江阿生（郑宇成 饰演）。一段时间相处，二人渐渐萌生感情，更喜结连理。但是江湖恩怨，怎可轻易了结，后续引发了一系列复仇的情节。</p><p>截取的 9 分钟片段（01:19:06 到 01:28:15），是曾静被黑石集团追杀，受伤后归家昏厥，而江阿生此时不得不重新拿起剑与敌人厮杀的场景。这一段打斗堪称精彩，使用兵器剑，动作流畅，很符合吴宇森的暴力美学。</p><p>精彩对白：<br>1、我愿是你杀的最后一人。<br>2、我愿化身石桥，受那五百年风吹，五百年日晒，五百年雨淋，只求她从桥上走过。</p><h1 id="网络谜踪"><a href="# 网络谜踪" class="headerlink" title="网络谜踪"></a>网络谜踪 </h1><p>《网络谜踪》是一部 2018 年的悬疑、惊悚、犯罪电影，豆瓣评分高达 8.6，好于 96% 的悬疑片，好于 96% 的犯罪片，又名人肉搜寻、人肉搜索、搜索、屏幕搜索。</p><p> 影片讲述的是工程师大卫・金一直引以为傲的 16 岁乖女玛戈特突然失踪，前来调查此案的警探怀疑女儿离家出走。不满这一结论的父亲为了寻找真相，独自展开调查，他打开了女儿的笔记本电脑，用社交软件开始寻找破案线索，大卫必须在女儿消失之前，沿着她在虚拟世界的足迹找到她。最后经历了各种挫折，总算找到了真相，可惜女儿已经被害离世。没想到，最终在女儿的遗体告别仪式上，父亲又发现了不可告人的秘密，事情得到大反转。</p><p>整个电影的镜头大部分时间都是由录像、监控、视频、新闻画面组成，反正全部是电子屏幕，很少有摄像机直接拍摄的场景，但是正是由于这样，才体现出整个过程的悬疑、惊悚的效果。</p><p>看似牢不可破的密码，跳转几次邮箱就可破译；看似无比相熟的女儿，连吸食大麻都未曾知。本来代表身份的头像，竟是无需版权的图库模特；本来孤立寡言的女孩，却在直播软件里袒露心扉。最亲近的女儿却比密码还难破译，最沉默的女孩却比模特还健谈，面前提供海量信息的屏幕，当你在凝视它，它也在吞食你。</p><p>以下截取的 15 分钟片段（00:42:09 到 00:57:26），是父亲根据女儿在社交网站上的图片、视频发现了女儿的可能去处，并没有一味地听从被 “分配” 过来的警探的建议，没想到真的找到了女儿的遗物和沉入湖底的汽车，这也给警察的搜索带来了方向。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>微博电影</tag>
        <tag>文稿备份</tag>
      </tags>
  </entry>
  <entry>
    <title>注册 Facebook Twitter Tumblr 遇到的问题</title>
    <url>/2018020101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在这个地球上，有很多好用的工具或者网站被封了，在中国大陆地区无法访问，如果需要使用它们，首要的问题就是翻墙。然而，事情没有那么简单，有时候可以翻出去了，但是在使用的过程中还会遇到奇怪的问题，每一步都不好走。本文记录注册使用 Facebook、Twitter、Tumblr 等社交账号时可能遇到的问题、解决的办法，给自己留一个备份，同时也能给大家带去一些方便。</p><a id="more"></a><p>提前说明，需要翻墙的读者，可以使用浏览器插件或者一些免费的工具，但是大多数都不够稳定，如果想要稳定的方式，最好还是自己搭建梯子。我这里有一个硬核教程【需要一点点技术，或者找一个懂技术的人，10 分钟可以搞定】，自己搭建 <code>shadowsocks</code>，手把手教学，图文并茂，顺便把客户端的使用方式也记录下来，参考我的另外一篇博文：<a href="https://www.playpi.org/2018111601.html">使用 Vultr 搭建 Shadowsocks（VPS 搭建 SS）</a> 。当然，这种方式肯定不是免费的，租用云服务器每月需要一定的钱，但是也不多，几美元足够，如果几个人合伙使用的话，平摊费用算下来也不多。</p><h1 id="Facebook"><a href="#Facebook" class="headerlink" title="Facebook"></a>Facebook</h1><p>待整理。</p><h1 id="Twitter"><a href="#Twitter" class="headerlink" title="Twitter"></a>Twitter</h1><p>以下内容中涉及到的操作环境、截图示例都是基于 Web 版的 Twitter，没有使用手机客户端。</p><h2 id="注册"><a href="# 注册" class="headerlink" title="注册"></a>注册 </h2><p> 注册 Twitter 帐号，首先需要一个邮箱帐号，或者手机号，进入注册首页，进行信息填写 <a href="https://twitter.com/i/flow/signup" target="_blank" rel="noopener">注册页 </a>，填写完成后，接下来也就是常规流程，发送短信验证码、语音验证码、邮箱激活链接等，基本没什么问题。</p><h2 id="绑定手机号问题"><a href="# 绑定手机号问题" class="headerlink" title="绑定手机号问题"></a> 绑定手机号问题 </h2><p> 由于我选择的是 Google 邮箱注册，注册完成之后可以正常登录，但是进入不了主页面，就被绑定手机号页面拦截了，<strong> 一直提示需要添加一个手机号 </strong>，要不然就停留在当前页面，什么也做不了，除非退出。那这个就是坑人了，登录之后卡在那里，什么都看不了，只能退出，那我还注册帐号干什么。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxerje8k7wj20p00exglz.jpg" alt="Add a phone number" title="Add a phone number"></p><p>接着我就按照提示，绑定手机号吧，但是，诡异的问题再次出现，我使用自己的手机号进行绑定时，提示错误：<code>由于技术问题，无法完成当前的请求，请重试【Due to a technical issue, we couldn&#39;t complete this request. Please try again.】</code>。</p><p>我是不相信 <code>Twitter</code> 能有什么技术问题，我只能怀疑是中国的手机号无法进行绑定，当然只是猜测。于是上网搜索了一下资料，发现果然是这个原因，铺天盖地的结果展现在搜索引擎的搜索列表中，很多人都遇到了这个问题。</p><p>再看看，一些过来人都建议一开始直接使用手机号注册，不要使用邮箱注册，就不会有这个问题了。唉，一开始不知道，接下来没有办法了，只能尝试寻找可行的办法，毕竟邮箱已经注册过了，不想浪费。</p><h2 id="绑定手机号解决方案尝试"><a href="# 绑定手机号解决方案尝试" class="headerlink" title="绑定手机号解决方案尝试"></a>绑定手机号解决方案尝试 </h2><p> 官方说法是当前帐号疑似是机器人【不是一个真实的人类】，所以被冻结了，必须添加一个可用的手机号，用来接收验证码，才能证明当前帐号是人为注册的，才能进行接下来的操作。那这样看起来很好办，想办法找一个可以使用的手机号接收验证码，或者能不能通过和客服沟通人工解封呢？</p><h3 id="利用浏览器调试工具"><a href="# 利用浏览器调试工具" class="headerlink" title="利用浏览器调试工具"></a>利用浏览器调试工具 </h3><p> 利用 Chrome 浏览器的开发者工具更改下拉列表的值，把日本的编号 81 改为 86，应用在页面上，从而伪造手机号码的所属国家编码，看看能不能收到验证码。<strong> 实际操作发现不行，所以大家不要使用这种方式，没有用，请使用第二种邮件申诉的方式，亲测可以使用，并且已经帮助好几个人成功注册激活 </strong>。没有用的原因在于 Twitter 验证的时候还是会重新刷新下拉列表，把国家编码更新。</p><p>具体操作为：在 Chrome 浏览器的对应页面，按下键盘的 F12 按键，就可以打开调试工具【或者点击鼠标的右键，选择检查】，在 <code>Elements</code> 选项中可以看到源代码，更改表单里面的下拉列表的值，即可，需要一点点技术知识。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxertxa23qj21260p6myi.jpg" alt="更改下拉列表内容" title="更改下拉列表内容"></p><h3 id="邮件申诉"><a href="# 邮件申诉" class="headerlink" title="邮件申诉"></a>邮件申诉 </h3><p> 首先声明，<strong> 推荐大家使用这种方式来解封、激活帐号 </strong>，我自己使用有效，而且已经帮助过好几个人解决了问题，基本在 24 小时内可以解决问题【节假日不知道客服上不上班】。</p><p>去帮助中心，找客服，发送申诉邮件，内容解释说明你是一个真实的人，现在注册帐号被冻结了，请求解封。Twitter 帮助中心网址：<a href="https://help.twitter.com/en" target="_blank" rel="noopener">Twitter 帮助中心 </a> ，在帮助中心选择 <code>Contact us</code>，进一步选择 <code>View all support topics</code> 。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxes1ihmuqj21hc0p6q49.jpg" alt="Contact us" title="Contact us"></p><p> 进入选择页面后，进一步选择 <code>Suspended or locked account</code>，表示对冻结或者锁定的帐号进行申诉处理。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxes4iubaqj212y0p6jsx.jpg" alt="Suspended or locked account" title="Suspended or locked account"></p><p>最终进入的页面就是这样的：<a href="https://help.twitter.com/forms/general?subtopic=suspended" target="_blank" rel="noopener">申诉信息填写 </a> ，可以开始填写申诉信息了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxes6m6189j219e0p6gmv.jpg" alt="申诉信息填写" title="申诉信息填写"></p><p> 这里面最主要的内容就是问题描述，请描述清楚你的问题，另外设备的选择按照自己的实际情况填写，全名和手机号也按照实际情况填写。此外，注意填写信息前需要登录帐号【虽然卡在验证页面，也要保持登录状态】，否则页面是锁定状态，无法填写任何信息。而且，登录后，大部分信息都是自动填充完成的，无需手动一个一个填写，只需要填写重要的几项内容即可。</p><p>例如我填写的问题描述，仅供参考：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Account suspended.Could not unsuspend it through phone number.Pls help to unsuspend the account.Thanks.</span><br></pre></td></tr></table></figure><p>提交后会收到一封由 Twitter 官方技术支持【Twitter Support <a href="mailto:&#115;&#x75;&#112;&#112;&#111;&#x72;&#116;&#x40;&#x74;&#119;&#x69;&#116;&#x74;&#101;&#x72;&#x2e;&#99;&#x6f;&#109;" target="_blank" rel="noopener">&#115;&#x75;&#112;&#112;&#111;&#x72;&#116;&#x40;&#x74;&#119;&#x69;&#116;&#x74;&#101;&#x72;&#x2e;&#99;&#x6f;&#109;</a>】发送的邮件【邮件基本是秒回，肯定是系统自动回复】，告诉你应该怎么做，邮件内容如下截图。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxesj53y9zj215s0llgn7.jpg" alt="Twitter 技术支持邮件" title="Twitter 技术支持邮件"></p><p>但是看内容也看不出来什么，只是表明说你的帐号疑似是机器人帐号，需要绑定手机号码，后面列出来一系列的步骤。其实我也是想做这一步的，但是奈何中国的手机号码不支持，仔细看最后一句话：<strong> 如果还有问题，可以直接回复此邮件并说明问题详细 </strong>，好，机会来了。</p><p>接下来我又回复了一封邮件，说明自己遇到的问题，内容大概如下，解释说明自己是一个真实的人，但是由于手机号码是中国的，无法接收到验证码，请求人工解决：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Hello,</span><br><span class="line">  I try in this way,But i am in China,i can not receive messages.</span><br><span class="line">  I am a human indeed,and my phone number is +86 1********06.</span><br><span class="line">  best wishes.</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxeso1yjgrj21870e3my0.jpg" alt="回复邮件" title="回复邮件"></p><p>接下来就是等待官方的回复了，由于是客服人工操作的，或者系统审核，速度比较慢，需要等好几个小时，希望晚上睡一觉后明天会有好消息。</p><p>在等待了一夜后，又过了半天时间【总共大概 17 个小时】，收到了 Twitter 官方的回复，说我的帐号已经解冻，并解释了原因。这次回复等待了这么长时间，不像上次申诉回复那么快，说明很大可能是人工审核的，然后解冻了你的帐号，再回复这封通知邮件给我。</p><p>不管怎样，帐号可以使用了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxfnvviw2gj21dk0n7mzb.jpg" alt="官方解冻邮件回复" title="官方解冻邮件回复"></p><p>接下来为了保证不被封号，最好重新设置一下昵称，并且填写一些必要的信息：<strong> 用户名【id】、头像、生日、国家、描述 </strong>等，也可以关注一些其他推主。</p><p>更改用户名在 <code>Settings and Privacy</code> 里面，由于用户名是唯一的【和 GitHub 的策略一样】，所以常用的都被别人注册过了，自己要注意寻找，如果遇到更改失败的情况，会显示用户名被占用，再换一个试试。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxfp8312wuj216i0p6gnu.jpg" alt="更改用户名" title="更改用户名"></p><p>更改 <strong>昵称、头像、背景墙、描述 </strong>等，在 <code>Profile</code> 里面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxfpeugi9zj218p0p6wi6.jpg" alt="更改基本信息" title="更改基本信息"></p><p>流程总结：</p><p>1、此篇博文只针对使用 Google 邮箱注册的情况，注册后帐号被冻结，什么也做不了，绑定手机号又说不支持，只能通过申诉来解决【如果一开始注册时使用的就是手机号，应该没有问题】；<br>2、申诉的目的是为了解冻帐号，但是官方是自动回复，让绑定手机号，此时又回到了原地；<br>3、在步骤 2 的基础上可以直接回复邮件【邮件中有提示】，说明遇到的问题，等待将近一天就行了；【如果没有步骤 2，直接给官方技术支持发邮件，应该是不行的】<br>4、步骤 3 官方回复的邮件中，问题已经解决，并提示说不要回复此邮件；【回复了应该也没人理】</p><h1 id="Tumblr"><a href="#Tumblr" class="headerlink" title="Tumblr"></a>Tumblr</h1><p>待整理。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Facebook</tag>
        <tag>Twitter</tag>
        <tag>Tumblr</tag>
      </tags>
  </entry>
  <entry>
    <title>记录一个 Kafka 错误：OffsetOutOfRangeException</title>
    <url>/2017060101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在使用 <code>Kafka</code> 的过程中，某一天项目中莫名其妙出现了一个异常信息：<br><code>kafka.common.OffsetOutOfRangeException</code><br>项目的业务场景是使用 <code>SparkStreaming</code> 消费 <code>Kafka</code> 数据，进一步进行 <strong>ETL 处理 </strong>，没有复杂的逻辑。平时一切正常运行，某一天我想在测试环境测试一下更新的逻辑代码，就出现了这个问题，导致整个进程任务失败。本文记录分析问题、解决问题的过程，运行环境基于 <code>Kafka v0.8.2.1</code>，<code>Spark v1.6.2</code>、<code>spark-streaming v2.10</code>，其它版本的内容会与这个版本存在部分不一致的地方，我会特殊说明。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 某一天我修改了项目的代码，在本地连接测试环境，开始测试，出现以下异常信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Caused by: kafka.common.OffsetOutOfRangeException</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0 (Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance (NativeConstructorAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance (DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance (Constructor.java:423)</span><br><span class="line">	at java.lang.Class.newInstance (Class.java:442)</span><br><span class="line">	at kafka.common.ErrorMapping$.exceptionFor (ErrorMapping.scala:86)</span><br><span class="line">	at org.apache.spark.streaming.kafka.KafkaRDD$KafkaRDDIterator.handleFetchErr (KafkaRDD.scala:184)</span><br><span class="line">	at org.apache.spark.streaming.kafka.KafkaRDD$KafkaRDDIterator.fetchBatch (KafkaRDD.scala:193)</span><br><span class="line">	at org.apache.spark.streaming.kafka.KafkaRDD$KafkaRDDIterator.getNext (KafkaRDD.scala:208)</span><br><span class="line">	at org.apache.spark.util.NextIterator.hasNext (NextIterator.scala:73)</span><br><span class="line">	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext (Wrappers.scala:29)</span><br><span class="line">	at com.datastory.banyan.v3.consumer.BaseRhinoDirectConsumerV3$1.call (BaseRhinoDirectConsumerV3.java:81)</span><br><span class="line">	at com.datastory.banyan.v3.consumer.BaseRhinoDirectConsumerV3$1.call (BaseRhinoDirectConsumerV3.java:72)</span><br><span class="line">	at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply (JavaRDDLike.scala:225)</span><br><span class="line">	at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply (JavaRDDLike.scala:225)</span><br><span class="line">	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$33.apply (RDD.scala:920)</span><br><span class="line">	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$33.apply (RDD.scala:920)</span><br><span class="line">	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply (SparkContext.scala:1858)</span><br><span class="line">	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply (SparkContext.scala:1858)</span><br><span class="line">	at org.apache.spark.scheduler.ResultTask.runTask (ResultTask.scala:66)</span><br><span class="line">	at org.apache.spark.scheduler.Task.run (Task.scala:89)</span><br><span class="line">	at org.apache.spark.executor.Executor$TaskRunner.run (Executor.scala:227)</span><br><span class="line">	... 3 more</span><br></pre></td></tr></table></figure><p>项目中的异常信息本来有很多行，但是关键的就是这部分内容，关键异常信息截图如下。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728180827.png" alt="异常信息截图" title="异常信息截图"></p><p>重点就看 <code>Caused by: kafka.common.OffsetOutOfRangeException</code> 这一句即可，可以明显看出问题所在：<strong> 下标越界 </strong>，下一步开始分析问题、解决问题。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><h2 id="分析"><a href="# 分析" class="headerlink" title="分析"></a> 分析 </h2><p> 原因既然是 <strong>下标越界 </strong>，就要先搞清楚 <code>Kafka</code> 在什么场景下会出现这个异常。</p><p>通过查看源代码得知，这是 <code>Kafka topic</code> 的 <code>offset</code> 下标越界异常，对应我这个场景，就是 <code>Spark</code> 任务在消费 <code>Kafka topic</code> 的数据时，指定的下标不在 <strong>有效数据 </strong>范围之内。</p><p>有点看不明白？的确，此处有必要插入一些基本知识点。<strong> 消费者 </strong>客户端在消费处理 <code>Kafka topic</code> 的数据时，会有一个 <strong>偏移量 </strong>【取值是数字】记录已经消费数据的位置，也可以说是下标，称之为 <code>offset</code>，并同步更新到 <code>Zookeeper</code> 中。[^1] 如果 <strong>消费者 </strong>客户端在消费中途出问题而停止，等下一次消费时会从上一次中断的 <strong>偏移量 </strong>位置开始继续消费数据，[^2] 这样就可以避免重复消费数据，节约资源。</p><p>以上注解 1、注解 2：</p><p>[^1]: 注意，<code>Kafka v0.9.0.x</code> 以及之后的版本不再是这个策略，不再使用 <code>Zookeeper</code> 存储，改成存储到 <code>kafka</code> 的 <code>broker</code> 节点上面，更方便管理。</p><p>[^2]: 注意，这里的消费策略是通过参数 <code>auto.offset.reset</code> 设置的，从上一次中断的位置继续消费数据只是消费策略选择之一，取值 <code>smallest</code>。另外，<code>Kafka v0.7.x</code> 以及之前的版本这个参数曾经的名称为：<code>autooffset.reset</code>。这个参数的取值在 <code>v.0.9.0.x</code> 以及之后的版本也更名为：<code>earliest</code>、<code>latest</code>、<code>none</code>。</p><p>接着回到正题，如果发生 <strong>下标越界 </strong>现象，说明 <code>Zookeeper</code> 中保存 <strong>消费者 </strong>的 <code>offset</code> 的值小于 <code>topic</code> 中存在的最早的 <code>message</code> 的 <code>offset</code> 值，即 <code>zookeeper_offset &lt; 最早_offset</code>。</p><p>这就导致 <strong>消费者 </strong>程序运行时需要消费的数据在 <code>Kafka topic</code> 中并不存在，进而引发异常的发生。表面上是因为消费的 <code>Zookeeper</code> 缓存信息不正确，实际上是因为 <code>Kafka</code> 的数据过期被清除了，下面我将使用 <code>Kafka</code> 自带的命令来一一验证。</p><h2 id="验证"><a href="# 验证" class="headerlink" title="验证"></a>验证 </h2><p> 先查看 <strong>消费者 </strong>的消费进度信息，指定 <code>Zookeeper</code> 主机、消费 <code>group</code> 组名、<code>topic</code> 名称，使用命令：<code>bin/kafka-consumer-offset-checker.sh --zookeeper zkhost:2181 --group consumer_group_name --topic topic_name</code>。</p><p>查看消费进度，可以看到 <code>offset</code> 是 0，表示从头开始消费，<code>logSize</code> 是 10044740，表示 <code>Kafka topic</code> 已经生产了这么多数据。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728180912.png" alt="查看消费进度" title="查看消费进度"></p><p>从上图可以看出 <code>topic</code> 的 <strong>消费者 </strong>只有 1 个消费组分区，为了保险起见，再验证一下这个 <code>topic</code> 的分区数是怎样的，使用命令：<code>bin/kafka-topics.sh --describe --zookeeper zkhost:2181 --topic topic_name</code>。</p><p>查看分区数，可以看到只有 1 个分区，编号为 0 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728180936.png" alt="查看分区数" title="查看分区数"></p><p>综上截图，可以得出总结，<strong> 消费者 </strong>程序是从下标 0 开始消费数据，也就是从头开始，而 <code>topic</code> 的数据已经生产了 1000 多万。那么，读者就会怀疑，这种情况下怎么可能会 <strong>下标越界 </strong>呢，0 就是开始的位置，还怎么越界。除非 <code>topic</code> 当前的数据量为 0，而不是 1000 多万。</p><p>我思考了一下，上述的结论是基于 <code>Zookeeper</code> 的缓存信息得到的，如果 <code>Kafka topic</code> 里面真的有数据存在，的确不可能下标越界。但是，此处还会有另外一种情况，如果 <code>Kafka</code> 里面的数据已经过期了【<code>Kafka</code> 有相关的参数可以设置过期策略】，那就会找不到数据，则报错 <strong>下标越界 </strong>。</p><p>再结合我的业务场景，由于我的 <strong>消费者 </strong>程序给消费组重新定义了名字【使用 <code>group.id</code> 参数】，所以会从头消费【<code>offset</code> 为 0】，但是测试环境的 <code>Kafka topic</code> 里面的数据极有可能是很久之前的，从创建 <code>topic</code> 开始到现在累积了 1000 多万数据，大量数据由于过期策略已经被清除了，现在肯定找不到。</p><p>接下来去查看 <code>Kafka broker</code> 服务的相关配置：过期策略、数据存储位置，在 <code>kafka broker</code> 的安装目录查看 <code>conf/server.properties</code> 配置文件，验证我的猜测。</p><p>首先查看名称为 <code>log.retention.*</code> 的相关参数，看看设置的值是什么：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728181003.png" alt="查看 Kafka 过期策略" title="查看 Kafka 过期策略"></p><p>可以看到，相关参数设置的值是 <code>log.retention.hours=48</code>，也就是说数据的有效期是 48 小时，过期会自动清理，而 <code>log.retention.bytes=-1</code> 表示不限制数据空间大小，即不会因为数据占用空间太大而删除。</p><p>那么，<code>Kafka topic</code> 里面的数据是不是真的不在了呢，让我一探究竟，继续从配置文件中查看数据存储目录，参数名称为：<code>log.dirs</code> 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728181036.png" alt="查看 Kafka 数据存储位置" title="查看 Kafka 数据存储位置"></p><p>可以看到，数据与索引存储在 <code>/kafka-logs</code> 目录，进入目录，找到指定的 <code>topic</code>、<code>partition</code> 对应的目录，我这里是 <code>/kafka-logs/topic_name-partition_number</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728181046.png" alt="查看 Kafka 数据文件" title="查看 Kafka 数据文件"></p><p>可以从上图看到目录里面有 2 个文件，分别是数据文件：<code>00000000000010044740.log</code>、索引文件：<code>00000000000010044740.index</code>。通过查看文件空间大小，发现数据文件的大小的是 0B，什么意思呢，表示没有数据，看来数据已经全部过期而且都被清理掉了。</p><p>至此，验证了我全部的分析猜测，下面可以简单复现一下这个异常现象。</p><h2 id="重现异常"><a href="# 重现异常" class="headerlink" title="重现异常"></a>重现异常 </h2><p>1、修改配置文件，把过期时间设置为 3 分钟：<code>log.retention.minutes=3</code>，然后重启 <code>Kafka</code> 服务。<br>2、使用 <code>Kafka producer</code> 生产一批数据，100 条，并等待 3 分钟，数据由于过期会被清理。<br>3、启动 <code>SparkStreaming</code> 消费程序处理数据，出现异常。<br>4、使用 <code>Kafka</code> 命令查看 <strong> 消费者 </strong>消费进度信息，<code>offset</code> 是 0，<code>logSize</code> 是 100 。<br>5、去 <code>Zookeeper</code> 里面查看 <code>zk_offset</code> 的值，是 0 。</p><p>复现异常，现象完全一致，至此问题原因找到。</p><p>总结一下：我这里的 <code>Kafka topic</code> 已经生产了 1000 多万的数据，但是旧数据由于过期被清理，而且全部被清理掉了。然而 <code>Zookeeper</code> 中的 <code>Kafka topic</code> 信息仍旧保留，<strong> 消费者 </strong>程序从头消费的时候，实际上已经获取不到 <code>Kafka topic</code> 的真实数据，所以一定会有异常。</p><h2 id="解决"><a href="# 解决" class="headerlink" title="解决"></a>解决 </h2><p> 那怎么办呢，如果 <code>Kafka topic</code> 继续生产数据，我的 <strong>消费者 </strong>程序怎么才能消费到新数据呢？</p><p>其实还是有办法的，最简单的就是不要使用新的消费组名【<code>group.id</code> 参数指定】，如果能继续使用以前的消费组名，并且以前已经把数据消费处理完了，那么它的 <code>offset</code> 也就是最大的值。此时如果继续消费数据，是从最大的 <strong>偏移量 </strong>位置开始消费的，即只会消费最新生产的数据，不会有 <strong>下标越界 </strong>的异常出现。</p><p>但是，如果非要使用新的消费组名称，并且也想从最新生产的数据开始消费【从头再重复消费 1000 多万数据太浪费资源】，有没有办法呢。当然也有，可以手动在 <code>Zookeeper</code> 查询一下消费者的 <strong>偏移量 </strong>，主要查看当前消费组对某个 <code>Kafka topic</code> 的消费 <strong>偏移量 </strong>，然后根据实际情况重置即可。</p><p>先登录 <code>Zookeeper</code> 服务，在指定目录查看消费者的 <strong>偏移量 </strong>，需要指定消费组名称、<code>topic</code> 名称，使用命令：<code>get /consumers/consumer_group_name/offsets/topic_name/0</code> 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728181432.png" alt="查看消费分区偏移量" title="查看消费分区偏移量"></p><p>可以看到当前取值是 0，接着重置消费者的 <strong>偏移量 </strong>，使用命令：<br><code>set /consumers/consumer_group_name/offsets/topic_name/0 10044740</code> 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728181441.png" alt="重置消费分区偏移量" title="重置消费分区偏移量"></p><p>我把它重置为最大值，接下来再测试消费程序就会从最新生产的数据开始消费。</p><p>好了，接下来就成功运行了。</p><h1 id="总结备注"><a href="# 总结备注" class="headerlink" title="总结备注"></a>总结备注 </h1><h2 id="不同版本之间的参数差异"><a href="# 不同版本之间的参数差异" class="headerlink" title="不同版本之间的参数差异"></a> 不同版本之间的参数差异 </h2><p> 本文是基于低版本的 <code>Kafka</code> 进行分析问题的：<code>v0.8.2.1</code>，关于里面的参数信息可以参考官网：<br><a href="https://kafka.apache.org/082/documentation.html#consumerconfigs" target="_blank" rel="noopener">Kafka-v0.8.2-configuration</a> 。</p><p>其中，<code>auto.offset.reset</code> 这个参数【<code>v0.7.x</code> 之前参数名称为 <code>autooffset.reset</code>】的解释说明如图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190729204654.png" alt="低版本 auto.offset.reset 参数说明" title="低版本 auto.offset.reset 参数说明"></p><p>原文如下：</p><blockquote><p>What to do when there is no initial offset in ZooKeeper or if an offset is out of range:</p><ul><li><code>smallest</code> : automatically reset the offset to the smallest offset</li><li><code>largest</code> : automatically reset the offset to the largest offset</li><li><code>anything else</code>: throw exception to the consumer</li></ul></blockquote><p>参数含义的总结归纳：</p><ul><li><code>smallest</code>：当各分区下有已提交的 <code>offset</code> 时，从提交的 <code>offset</code> 开始消费；无提交的 <code>offset</code> 时，从头开始消费 </li><li><code>largest</code>：当各分区下有已提交的 <code>offset</code> 时，从提交的 <code>offset</code> 开始消费；无提交的 <code>offset</code> 时，从该分区下新产生的数据开始消费</li><li><code>anything else</code>：<code>topic</code> 各分区都存在已提交的 <code>offset</code> 时，从 <code>offset</code> 后开始消费；只要有一个分区不存在已提交的 <code>offset</code>，则抛出异常信息</li></ul><p> 关于 <code>v0.7.x</code> 版本的参数信息参考官网：<br><a href="https://kafka.apache.org/07/documentation/#configuration" target="_blank" rel="noopener">Kafka-v0.7.x-configuration</a> 。</p><p>其中，<code>autooffset.reset</code> 这个参数名称和以后的都不一样，解释说明如图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728181607.png" alt="低版本 autooffset.reset 参数说明" title="低版本 autooffset.reset 参数说明"></p><p>原文如下：</p><blockquote><ul><li><code>smallest</code>: automatically reset the offset to the smallest offset available on the broker.</li><li><code>largest</code> : automatically reset the offset to the largest offset available on the broker.</li><li><code>anything else</code>: throw an exception to the consumer.</li></ul></blockquote><p>至于高版本的配置信息，也可以参考官网：<br><a href="https://kafka.apache.org/090/documentation.html#consumerconfigs" target="_blank" rel="noopener">Kafka-v0.9.0.x-configuration</a> 。</p><p>其中，<code>auto.offset.reset</code> 这个参数的解释说明如图，自从 <code>v0.9.0.x</code> 版本之后，它的取值已经变化。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190728190054.png" alt="高版本 auto.offset.reset 参数说明" title="高版本 auto.offset.reset 参数说明"></p><p>原文如下：</p><blockquote><p>What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server (e.g. because that data has been deleted):</p><ul><li><code>earliest</code>: automatically reset the offset to the earliest offset.</li><li><code>latest</code>: automatically reset the offset to the latest offset.</li><li><code>none</code>: throw exception to the consumer if no previous offset is found for the consumer’s group.</li><li><code>anything else</code>: throw exception to the consumer.</li></ul></blockquote><h2 id="消费者信息存储位置"><a href="# 消费者信息存储位置" class="headerlink" title="消费者信息存储位置"></a>消费者信息存储位置 </h2><p><strong> 消费者 </strong>信息存储位置的问题，新版本【v0.9.x 以及之后】不存储在 <code>Zookeeper</code> 了，转而存到 <code>Kafka</code> 的 <code>broker</code> 节点。如果有 <strong>消费者 </strong>启动，那么这个 <strong>消费者 </strong>的组名和它要消费的那个 <code>topic</code> 的 <code>offset</code> 信息就会被记录在 <code>broker</code> 节点上。</p><h2 id="关于偏移量的另一个常见异常"><a href="# 关于偏移量的另一个常见异常" class="headerlink" title="关于偏移量的另一个常见异常"></a>关于偏移量的另一个常见异常 </h2><p> 关于偏移量 <code>offset</code> 的问题，还有一个常见异常：<code>numRecords must not be negative</code>，它主要是由删除 <code>Kafka topic</code> 后又新建同名的 <code>topic</code> 引起的。根本原因在于删除 <code>topic</code> 后没有把 <code>Zookeeper</code> 中的 <strong>消费者 </strong>的信息也一同删除，导致遗留的 <strong>消费者 </strong>的信息在新建同名后 <code>topic</code> 被作为当前 <code>topic</code> 的 <strong>消费者 </strong>的信息，如果此时启动一个消费程序，在计算 <code>numRecords</code> 的时候会出现负数的情况【0 减去 old_offset】，接着就会抛出这个异常。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>SparkStreaming</tag>
        <tag>Zookeeper</tag>
        <tag>Kafka</tag>
        <tag>OffsetOutOfRangeException</tag>
      </tags>
  </entry>
  <entry>
    <title>记录一次 AbstractMethodError 异常</title>
    <url>/2019070401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>场景描述：在某一天我觉得我的 Java 项目的依赖太冗余了，决定删除一些无用的依赖，让整个项目瘦身，以后打包发布的时候也更快速、节省时间。</p><p>接着我按照自己的经验，把大部分依赖全部删除，此时编译会报一些错误，这是必然的，但是我不担心，根据报错信息把缺失的依赖再一个一个添加进来即可。忙活了一阵，终于解决了所有的报错，编译、打包一气呵成，不再有错误，看了一下打包后的文件大小，足足比原先小了 30%，我略感满意。</p><p>但是此时我仍旧悬着一颗心，因为编译、打包成功不代表什么，后面的运行才是大问题，运行时往往会暴露一些隐藏的问题。而且项目里面有好几个功能，只要有一个功能运行失败那就说明依赖还是有问题，改造不成功。【千万不要以为编译、打包成功就万事大吉了，运行时的异常才是大问题，一定要有未雨绸缪的准备】</p><p>果然，刚启动第一个功能就出现了我想象中的异常信息：<code>java.lang.AbstractMethodError</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 异常突然出现，我差点就懵了，昨天还好好的，今天怎么就这样了，程序又不是女朋女，不可能说变就变。此时，我又想起了一个段子，程序员的一般心里活动：运行失败了，这 TM 怎么可能会失败呢？运行成功了，这 TM 怎么就成功了呢？</p><p>作为一名资深的工程师，我还是决定试试，看看能不能走个狗屎运，于是我在本机、测试环境、正式环境分别做了测试，发现都是报一样的错误，接着我就意识到问题的严重性，不能再心存侥幸，要拿出我真实的技术来说话了。</p><p>前面的处理方式就像重启系统一样，只不过是碰运气的方式，我连报错信息都没有仔细看，接下来就要认真处理了。</p><p>既然报错了，那就耐心查看，<strong> 办法总比困难多 </strong>。下面列出完整的错误信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-07-04_20:05:26 [main] INFO yarn.Client:58: Application report for application_1561431414509_0020 (state: ACCEPTED)</span><br><span class="line">2019-07-04_20:05:26 [shuffle-server-2] ERROR server.TransportRequestHandler:191: Error sending result RpcResponse&#123;requestId=5206989806485258134, body=NioManagedBuffer&#123;buf=java.nio.HeapByteBuffer [pos=0 lim=47 cap=47]&#125;&#125; to dev6/172.18.5.206:55124; closing connection</span><br><span class="line">java.lang.AbstractMethodError</span><br><span class="line">	at io.netty.util.ReferenceCountUtil.touch (ReferenceCountUtil.java:73)</span><br><span class="line">	at io.netty.channel.DefaultChannelPipeline.touch (DefaultChannelPipeline.java:107)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:810)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:723)</span><br><span class="line">	at io.netty.handler.codec.MessageToMessageEncoder.write (MessageToMessageEncoder.java:111)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0 (AbstractChannelHandlerContext.java:738)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:730)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:816)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:723)</span><br><span class="line">	at io.netty.handler.timeout.IdleStateHandler.write (IdleStateHandler.java:302)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0 (AbstractChannelHandlerContext.java:738)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:730)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.access$1900 (AbstractChannelHandlerContext.java:38)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write (AbstractChannelHandlerContext.java:1089)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write (AbstractChannelHandlerContext.java:1136)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run (AbstractChannelHandlerContext.java:1078)</span><br><span class="line">	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute (AbstractEventExecutor.java:163)</span><br><span class="line">	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks (SingleThreadEventExecutor.java:403)</span><br><span class="line">	at io.netty.channel.nio.NioEventLoop.run (NioEventLoop.java:462)</span><br><span class="line">	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run (SingleThreadEventExecutor.java:858)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190704232421.png" alt="报错日志" title="报错日志"></p><p>其中，重点只需要看这几行内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-07-04_20:05:26 [shuffle-server-2] ERROR server.TransportRequestHandler:191: Error sending result RpcResponse&#123;requestId=5206989806485258134, body=NioManagedBuffer&#123;buf=java.nio.HeapByteBuffer [pos=0 lim=47 cap=47]&#125;&#125; to dev6/172.18.5.206:55124; closing connection</span><br><span class="line">java.lang.AbstractMethodError</span><br><span class="line">	at io.netty.util.ReferenceCountUtil.touch (ReferenceCountUtil.java:73)</span><br><span class="line">	at io.netty.channel.DefaultChannelPipeline.touch (DefaultChannelPipeline.java:107)</span><br></pre></td></tr></table></figure><p>我定睛一瞧，<code>AbstractMethodError</code> 这种异常类型我还没见过，这怎么行，抓紧去查了 Java 的官方文档，查过之后，才明白这个异常的含义。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190704232219.png" alt="AbstractMethodError 文档" title="AbstractMethodError 文档"></p><p>官方定义内容如下：</p><blockquote><p>Thrown when an application tries to call an abstract method. Normally, this error is caught by the compiler; this error can only occur at run time if the definition of some class has incompatibly changed since the currently executing method was last compiled.</p></blockquote><p>大概意思就是说 Java 程序在 <strong>运行时 </strong>发现 <strong>方法的定义 </strong>与 <strong>编译时 </strong>的不一致，怎么会有这种现象呢，最大的可能也就是依赖冲突了，至于为何造成冲突，还需要进一步检查。</p><p>我又回过头去仔细看一下这个功能的前后逻辑，很简单，只是使用 <code>Spark</code> 处理 <code>HDFS</code> 里面的数据，然后把处理结果再写回到 <code>HDFS</code>，实际运行时处理的数据量也不大，看起来不会有功能性的问题。而且，前不久这个功能还运行的好好的，只在我重构更改后才起不来的，原因基本可以定位在依赖方面：冲突、缺失。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 顺着依赖冲突这个突破点看下去，可能是因为我在清理依赖时把某个依赖清除掉了，然后又自己添加一个不同版本的，导致与原先的依赖版本不匹配。而且看到异常信息里面都是和 <code>netty</code> 有关的，可以猜测可能是 <code>netty</code> 的相关依赖出问题了。</p><p>接着再多看一点点异常信息，还发现有一些额外的有效信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-07-04_20:05:23 [main] INFO spark.SecurityManager:58: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set (Administrator, dota); users with modify permissions: Set (Administrator, dota)</span><br><span class="line">2019-07-04_20:05:23 [main] INFO yarn.Client:58: Submitting application 20 to ResourceManager</span><br><span class="line">2019-07-04_20:05:23 [main] INFO impl.YarnClientImpl:274: Submitted application application_1561431414509_0020</span><br><span class="line">2019-07-04_20:05:24 [main] INFO yarn.Client:58: Application report for application_1561431414509_0020 (state: ACCEPTED)</span><br><span class="line">2019-07-04_20:05:24 [main] INFO yarn.Client:58: </span><br><span class="line">	 client token: N/A</span><br><span class="line">	 diagnostics: N/A</span><br><span class="line">	 ApplicationMaster host: N/A</span><br><span class="line">	 ApplicationMaster RPC port: -1</span><br><span class="line">	 queue: default</span><br><span class="line">	 start time: 1562241921232</span><br><span class="line">	 final status: UNDEFINED</span><br><span class="line">	 tracking URL: http://dev6:8088/proxy/application_1561431414509_0020/</span><br><span class="line">	 user: dota</span><br><span class="line">2019-07-04_20:05:29 [main] INFO yarn.Client:58: Application report for application_1561431414509_0020 (state: ACCEPTED)</span><br><span class="line">2019-07-04_20:05:30 [main] INFO yarn.Client:58: Application report for application_1561431414509_0020 (state: ACCEPTED)</span><br><span class="line">2019-07-04_20:05:31 [main] INFO yarn.Client:58: Application report for application_1561431414509_0020 (state: ACCEPTED)</span><br><span class="line">2019-07-04_20:05:32 [main] INFO yarn.Client:58: Application report for application_1561431414509_0020 (state: FAILED)</span><br><span class="line">2019-07-04_20:05:32 [main] INFO yarn.Client:58: </span><br><span class="line">	 client token: N/A</span><br><span class="line">	 diagnostics: Application application_1561431414509_0020 failed 2 times due to AM Container for appattempt_1561431414509_0020_000002 exited with  exitCode: 10</span><br><span class="line">For more detailed output, check application tracking page:http://dev6:8088/cluster/app/application_1561431414509_0020Then, click on links to logs of each attempt.</span><br><span class="line">Diagnostics: Exception from container-launch.</span><br><span class="line">Container id: container_e19_1561431414509_0020_02_000001</span><br><span class="line">Exit code: 10</span><br><span class="line">Stack trace: ExitCodeException exitCode=10: </span><br><span class="line">	at org.apache.hadoop.util.Shell.runCommand (Shell.java:576)</span><br><span class="line">	at org.apache.hadoop.util.Shell.run (Shell.java:487)</span><br><span class="line">	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute (Shell.java:753)</span><br><span class="line">	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer (DefaultContainerExecutor.java:212)</span><br><span class="line">	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call (ContainerLaunch.java:303)</span><br><span class="line">	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call (ContainerLaunch.java:82)</span><br><span class="line">	at java.util.concurrent.FutureTask.run (FutureTask.java:266)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br></pre></td></tr></table></figure><p>从上文的日志信息来看，程序的 <code>Driver</code> 端已经提交了 <code>Spark</code> 任务到 <code>Yarn</code> 集群，然后 <code>Yarn</code> 集群分配了资源，但是在后续的通信过程中，不知道哪里出问题了，导致通信中断，进而导致 <code>Spark</code> 任务失败。</p><p>结合上面我猜测的和 <code>netty</code> 依赖有关，那就从这里入手吧，先把项目的依赖树梳理出来，使用 <code>mvn dependency:tree &gt; tree.txt</code>，把依赖树的信息保存在文件 <code>tree.txt</code> 中，然后在依赖树信息中搜索 <code>netty</code>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190704232242.png" alt="搜索 netty 关键字" title="搜索 netty 关键字"></p><p>可以看到关于 <code>netty</code> 依赖的信息。</p><p>再全局搜索一下项目中的类【在 Windows 下使用 Eclipse 模式的快捷键 <code>Ctrl + Shift + t</code>】，异常信息对应的那个类：<code>ReferenceCountUtil</code>，可以看到存在两个同名的类：类名称一致【都是 ReferenceCountUtil】，包名称一致【都是 io.netty.util】，只不过对应的 jar 包依赖不一致，一个是 <code>io.netty:netty-common:4.1.13.Final.jar</code>【这个是我的 org.elasticsearch.client:transport:5.5.0 传递依赖过来的】，另一个是 <code>io.netty:netty-all:4.0.29.Final.jar</code>【这个是 Spark 自带的，只不过我重新指定了版本】，这两个类肯定会冲突的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190704232137.png" alt="搜索 ReferenceCountUtil 类" title="搜索 ReferenceCountUtil 类"></p><p>解决办法很简单，直接去除多余的依赖即可，但是要注意去除后会不会引发其它的依赖缺失问题。我在我的项目里面移除了所有的 <code>io.netty:netty-*</code> 依赖，这些依赖也是传递过来的，版本都为 <code>v4.1.13</code>，如下图：</p><p>如果不全部移除而是选择只移除 <code>netty-common</code>，还会有问题，因为这些依赖之间也互相依赖，看 <code>common</code> 这个命名就知道了，这就是：<strong> 一荣俱荣，一损俱损 </strong>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190718231720.png" alt="移除所有的 netty 传递依赖" title="移除所有的 netty 传递依赖"></p><p>我把这些依赖移除后，<code>netty</code> 相关的依赖冲突就没有问题了，但是又遇到了一个小问题：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.ClassNotFoundException: org.elasticsearch.spark.rdd.EsPartition</span><br></pre></td></tr></table></figure><p><code>Spark</code> 任务正常启动后，运行过程中出现了上述错误，导致 <code>Spark</code> 任务失败，乍一看是类缺失。但是如果在项目中搜索的话，也能搜索到这个类，是不是觉得很奇怪。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190718233540.png" alt="搜索缺失的 ESPartition 类" title="搜索缺失的 ESPartition 类"></p><p>其实不要多想，这个是典型的 <code>Yarn/Spark</code> 集群环境问题，项目中使用的 jar 包【特定版本的，我这里是：org.elasticsearch.client:transport:jar:5.5.0】在集群环境中没有，如果切换一个集群环境中存在版本就可以了【例如 v5.6.8】。或者一定要使用这个版本的话，就把这个 jar 包复制到 <code>Yarn/Spark</code> 集群环境每台机器的 <code>lib</code> 库中去。但是一般情况下，公司的环境是统一的，会避免使用多版本的依赖，以免引起一连串的未知冲突问题，浪费大家的时间。</p><p>在实际生产环境中，可能还会遇到一个更加糟糕的问题，即项目本身的依赖非常混乱，并且有大量的重复，可能去除一个还有一个，会造成大量重复的工作，所以在查看依赖树时可以使用 <code>-Dverbose</code> 参数，完整的命令：<code>mvn dependency:tree -Dverbose &gt; tree.txt</code>，把原始的所有传递依赖全部列出来，这样就可以对症操作，一次性把所有依赖移除。</p><p>当然，会有人觉得这样操作也是很麻烦，能不能来个插件，直接配置一下即可，至于去除的操作过程我也不关心，只要能帮我去除就行。当然，这对于想偷懒并提高效率的技术人员来说是必备的，这个东西就是插件 <code>maven-shade-plugin</code>。</p><p>在 <code>configuration</code> 里面配置 <code>artifactSet -&gt; excludes -&gt; exclude -&gt; jar 包坐标 </code> 即可。</p><p> 但是要注意，插件要使用高版本的：<code>v3.1.0</code>，我一开始使用的是 <code>v2.4.3</code>，怎么配置都无效，搞了半天发现低版本不支持。此外，还要注意 JDK 的版本也要 <code>v1.8+</code>，这样才能保证使用其它的特性，例如打包压缩：<code>&lt;minimizeJar&gt;true&lt;/minimizeJar&gt;</code>。使用这个参数可以自动把无用的依赖 jar 排除掉，给代码瘦身，同时也节约打包时间，非常好用。我的 jar 在使用打包压缩参数后，由原本的 313MB 被压缩到了 191MB，压缩率超过 30%，我觉得非常好用。</p><p>此外，<code>maven-shade-plugin</code> 插件是一款非常优秀的插件，最常用的莫过于 <strong>影子别名 </strong>功能，对于复杂的依赖冲突解决有奇效。例如对于上面的依赖冲突问题，可以不用找原因一点一点解决，直接使用 <strong>影子别名 </strong>功能把传递依赖的 <code>netty</code> jar 包改个名字即可，这样它们就可以共存了，简单粗暴却有奇效。推荐大家使用，这里不再赘述。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p> 总结一下问题，就是同名的类存在了不同版本的 jar 包中，等到运行的时候，Java 虚拟机发现异常，便抛出异常信息，停止运行程序。</p><p>此外，在没有十足的把握或者时间人力不充足的情况下，千万不要想着重构代码，后果你不一定能承担，带来的好处可能大于带来的灾难，这也叫 <strong>好心办坏事 </strong>。</p><p>再回顾一下，我这个问题是 <code>Spark</code> 任务运行在 <code>Yarn</code> 集群上面才发现的，如果使用 <code>local</code> 模式运行 <code>Spark</code> 任务是不会有问题的。所以当时出问题后我也是疑惑，反复测试了好几次才敢确认，主要是因为使用 <code>Yarn</code> 模式时，同时也会使用集群中提供的 jar 包依赖，如果项目本身打包时又打进了相同的 jar 包，就极有可能引发冲突【版本不一致，而且 <code>netty</code> 包的冲突本身就是一个大坑】。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Java</tag>
        <tag>netty</tag>
        <tag>AbstractMethodError</tag>
      </tags>
  </entry>
  <entry>
    <title>记录一次关于 log4j 的 ClassNotFoundException 异常</title>
    <url>/2019073001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>本来一个正常的 <code>Java</code> 项目，某一次运行的时候发现了一个异常：<br><code>java.lang.ClassNotFoundException: org.apache.log4j.DailyRollingFileAppender</code>，<br>我觉得很奇怪，这种常用的类怎么可能会缺失。但是，<strong> 代码之多，无奇不有 </strong>，遇到这种奇怪的问题也是检验我技术高低的良机，看我怎么步步排查，找到问题所在。本文开发环境基于 <code>Java v1.8+</code>、<code>Spark v1.6.x</code>、<code>Maven v3.5.x</code> 。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 场景描述：一个常规的 <code>Java</code> 项目，单线程处理数据，一直以来都正常运行，某一天我做了小小的代码改动，接着运行就报错。</p><p>错误日志信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log4j:ERROR Could not instantiate class [org.apache.log4j.DailyRollingFileAppender].</span><br><span class="line">java.lang.ClassNotFoundException: org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">	at java.net.URLClassLoader.findClass (URLClassLoader.java:381)</span><br><span class="line">	at java.lang.ClassLoader.loadClass (ClassLoader.java:424)</span><br><span class="line">	at sun.misc.Launcher$AppClassLoader.loadClass (Launcher.java:338)</span><br><span class="line">	at java.lang.ClassLoader.loadClass (ClassLoader.java:357)</span><br><span class="line">	at java.lang.Class.forName0 (Native Method)</span><br><span class="line">	at java.lang.Class.forName (Class.java:264)</span><br><span class="line">	at org.apache.log4j.helpers.Loader.loadClass (Loader.java:178)</span><br><span class="line">	at org.apache.log4j.helpers.OptionConverter.instantiateByClassName (OptionConverter.java:317)</span><br><span class="line">	at org.apache.log4j.helpers.OptionConverter.instantiateByKey (OptionConverter.java:120)</span><br><span class="line">	at org.apache.log4j.PropertyConfigurator.parseAppender (PropertyConfigurator.java:629)</span><br><span class="line">	at org.apache.log4j.PropertyConfigurator.parseCategory (PropertyConfigurator.java:612)</span><br><span class="line">	at org.apache.log4j.PropertyConfigurator.configureRootCategory (PropertyConfigurator.java:509)</span><br><span class="line">	at org.apache.log4j.PropertyConfigurator.doConfigure (PropertyConfigurator.java:415)</span><br><span class="line">	at org.apache.log4j.PropertyConfigurator.doConfigure (PropertyConfigurator.java:441)</span><br><span class="line">	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure (OptionConverter.java:468)</span><br><span class="line">	at org.apache.log4j.LogManager.&lt;clinit&gt;(LogManager.java:122)</span><br><span class="line">	at org.slf4j.impl.Log4jLoggerFactory.getLogger (Log4jLoggerFactory.java:64)</span><br><span class="line">	at org.slf4j.LoggerFactory.getLogger (LoggerFactory.java:285)</span><br><span class="line">	at org.slf4j.LoggerFactory.getLogger (LoggerFactory.java:305)</span><br><span class="line">	at com.xxx.yyy.client.hbase.HBaseUtils.&lt;clinit&gt;(HBaseUtils.java:36)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804183345.png" alt="错误日志片段截图" title="错误日志片段截图"></p><p>错误日志很多，主要看这一行信息：<br><code>java.lang.ClassNotFoundException: org.apache.log4j.DailyRollingFileAppender</code>，<br>找不到 <code>DailyRollingFileAppender</code> 这个类，即类缺失。显然，这不可能是代码改动引起的问题，这种情况可能是虚拟机没有加载到类，或者加载了多个版本不一致的类导致冲突。</p><p>查了很多网上的相同问题，都说是依赖包缺失，但是我觉得不太可能，因为这个 <code>Java</code> 项目中的其它模块都能正常使用【使用多个 <code>Maven</code> 模块管理整个 <code>Java</code> 项目，它们的环境一致】，于是想办法验证一下。</p><p>先在 <code>Java</code> 项目中搜索类，可以看到能搜索到，说明不会缺失【此处不考虑打包过程中移除的情况】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804183506.png" alt="全局搜索类" title="全局搜索类"></p><p>再使用 <code>mvn dependency:tree</code> 生成依赖树信息，在依赖树信息中搜索查看，也能看到关于 <code>slf4j</code> 的两个依赖包以及关于 <code>log4j</code> 的一个依赖包，说明没有缺失。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO] |  |  +- org.slf4j:slf4j-api:jar:1.7.10:compile</span><br><span class="line">[INFO] |  |  +- org.slf4j:slf4j-log4j12:jar:1.7.10:compile</span><br><span class="line">...</span><br><span class="line">[INFO] +- log4j:log4j:jar:1.2.12:compile</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804183531.png" alt="查看 slf4j 相关类" title="查看 slf4j 相关类"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804183539.png" alt="查看 log4j 相关类" title="查看 log4j 相关类"></p><p>根据上面的操作分析，依赖没有缺失，而且，从搜索结果看只有一个类，从依赖树信息中看也没有多版本冲突，此时看似陷入了僵局。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><p> 我努力回想改动了什么代码或者配置才会导致这个问题，使用 <code>Git</code> 查一下，通过查看提交历史记录，发现了一处微小的改动，在 <code>Maven</code> 子模块的 <code>pom.xml</code> 文件中。这也是造成这个问题的罪魁祸首，下面详细说明。</p><p>其实，此时需要考虑一个问题，本机查看的项目代码和打包后的可能不一样，比如冲突问题导致的版本选择，或者插件造成的部分无效依赖被移除等原因会造成前后差异。</p><p>我也一直在回想我改动了什么代码或者配置，才触发了这个问题，果然，通过 <code>Git</code> 的提交记录找到了蛛丝马迹。</p><p>通过仔细的对比，发现了问题所在，原来在 <code>pom.xml</code> 文件中，使用了 <code>maven-shade-plugin</code> 插件进行依赖瘦身，导致将 <code>slf4j</code>、<code>log4j</code> 相关的依赖全部被移除。归根结底，还是因为我在代码中没有使用 <code>slf4j</code>、<code>log4j</code> 的相关类【但是在父类中使用了】，<code>maven-shade-plugin</code> 插件误以为这两个依赖都是无用的，就全部移除了。等到程序启动运行的时候，发现找不到相关的类了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804183620.png" alt="shade 插件配置" title="shade 插件配置"></p><p><code>pom.xml</code> 配置信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- shade 构件，打包时可以：包含依赖构件，重命名包名避免冲突，移除特定的类避免冲突 --&gt;</span><br><span class="line">&lt;!-- 具体参考:http://maven.apache.org/plugins/maven-shade-plugin/--&gt;</span><br><span class="line">&lt;!-- &lt;minimizeJar&gt;true&lt;/minimizeJar&gt; 可以自动移除无用的类，瘦身 jar 包 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;3.1.0&lt;/version&gt;</span><br><span class="line">  &lt;executions&gt;</span><br><span class="line">    &lt;execution&gt;</span><br><span class="line">      &lt;!-- 绑定 Maven 的 package 阶段 --&gt;</span><br><span class="line">      &lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">      &lt;goals&gt;</span><br><span class="line">        &lt;goal&gt;shade&lt;/goal&gt;</span><br><span class="line">      &lt;/goals&gt;</span><br><span class="line">      &lt;!-- 详细配置项 --&gt;</span><br><span class="line">      &lt;configuration&gt;</span><br><span class="line">        &lt;!-- 自动移除无用的依赖，坑：项目没用到 slf4j, 但是依赖的父类用到，却被移除 --&gt;</span><br><span class="line">        &lt;!--&lt;minimizeJar&gt;true&lt;/minimizeJar&gt;--&gt;</span><br><span class="line">        &lt;!-- 将指定文件以 append 方式加入到构建的 jar 包中 --&gt;</span><br><span class="line">        &lt;transformers&gt;</span><br><span class="line">          &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt;</span><br><span class="line">            &lt;resource&gt;reference.conf&lt;/resource&gt;</span><br><span class="line">          &lt;/transformer&gt;</span><br><span class="line">        &lt;/transformers&gt;</span><br><span class="line">        &lt;!-- 过滤匹配到的文件 --&gt;</span><br><span class="line">        &lt;filters&gt;</span><br><span class="line">          &lt;filter&gt;</span><br><span class="line">            &lt;artifact&gt;*:*&lt;/artifact&gt;</span><br><span class="line">            &lt;excludes&gt;</span><br><span class="line">              &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;</span><br><span class="line">              &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;</span><br><span class="line">              &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;</span><br><span class="line">            &lt;/excludes&gt;</span><br><span class="line">          &lt;/filter&gt;</span><br><span class="line">        &lt;/filters&gt;</span><br><span class="line">        &lt;!-- 附加所有构件，并指定后缀名，与主程序 jar 包区分开 --&gt;</span><br><span class="line">        &lt;shadedArtifactAttached&gt;true&lt;/shadedArtifactAttached&gt;</span><br><span class="line">        &lt;shadedClassifierName&gt;jar-with-dependencies&lt;/shadedClassifierName&gt;</span><br><span class="line">      &lt;/configuration&gt;</span><br><span class="line">    &lt;/execution&gt;</span><br><span class="line">  &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><p>其中，<code>&lt;minimizeJar&gt;true&lt;/minimizeJar&gt;</code> 这个配置决定了打包的依赖保留还是移除，我把它配置为 <code>true</code>，打包时会自动帮我移除无用的依赖包，其中包括 <code>log4j</code>、<code>slf4j</code>，也就导致了本文开头的问题。</p><p>看来，<code>maven-shade-plugin</code> 插件的依赖瘦身功能，还是要慎用，像今天这种情况就很是莫名其妙，只能靠细心、靠经验来发现问题、解决问题，如果是别人的代码还真难发现。</p><p>解决方法很简单，只要把这个配置移除【或者设置为 <code>false</code>】，问题就解决了。还有另外一种解决方式，在代码中显式使用 <code>log4j</code> 的相关类，其实真实是使用 <code>slf4j</code> 里面的实现类，这样打包时 <code>maven-shade-plugin</code> 插件则不会移除相关的类。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p> 在这种 <code>ClassNotFoundException</code> 异常现象的分析过程中，可以借助一款工具：<a href="https://alibaba.github.io/arthas" target="_blank" rel="noopener">Arthas（阿尔萨斯）</a> ，这是一款由 <strong>阿里巴巴 </strong>开源的一款 <code>Java</code> 诊断工具，深受开发者喜爱。</p><p>它可以解决类似如下的问题：</p><ul><li>这个类从哪个 <code>jar</code> 包加载的？为什么会报各种类相关的 <code>Exception</code>？</li><li>我改的代码为什么没有执行到？难道是我没 <code>commit</code>？分支搞错了？</li><li>遇到问题无法在线上 <code>debug</code>，难道只能通过加日志再重新发布吗？</li><li>线上遇到某个用户的数据处理有问题，但线上同样无法 <code>debug</code>，线下无法重现！</li><li>是否有一个全局视角来查看系统的运行状况？</li><li>有什么办法可以监控到 <code>JVM</code> 的实时运行状态？</li></ul><p>比如针对我这个场景，我就可以快速查到 <code>DailyRollingFileAppender</code> 这个类有没有被虚拟机加载，以及从哪个 <code>jar</code> 包加载的。可以快速发现：虚拟机中并没有加载这个类，这个时候就可以断定类缺失，然后转换思路去查为什么类缺失。如果在项目中搜索、查看依赖树信息都没有发现类缺失的迹象，就可以怀疑是不是打包过程中被移除了，甚至可以怀疑是不是上传了错误的 <code>jar</code> 包去执行程序。</p><p>这样就可以一步一步、有理有据地分析问题，直到解决问题，不至于全程懵逼，靠经验与猜测去碰运气。显然，解决问题的过程肯定是目的明确而且高效的。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Maven</tag>
        <tag>log4j</tag>
        <tag>slf4j</tag>
        <tag>ClassNotFoundException</tag>
        <tag>DailyRollingFileAppender</tag>
        <tag>maven-shade-plugin</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 自动安装 Shadowsocks 脚本</title>
    <url>/2019082801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>以前我整理过一篇博客，详细叙述了如何自己搭建梯子，图文并茂，可以参见：<a href="https://www.playpi.org/2018111601.html">使用 Vultr 搭建 Shadowsocks（VPS 搭建 SS）</a> 。里面有涉及到购买一台云服务器后该如何操作：初始化环境、安装 <code>Shadowsocks</code>、配置参数、安装防火墙、启动服务、检查服务状态等等步骤。</p><p>虽然过程很详细，只要几个命令就可以完成 <code>Shadowsocks</code> 服务的搭建，但是对于没有技术基础又不想折腾的读者来说，还是有点困难。所以我把安装过程整理成一个自动化的 <code>Shell</code> 脚本，读者下载下来之后，直接运行即可，在运行过程中如果需要询问交互，例如填写密码、端口号等，读者直接填写即可，或者直接使用默认的设置。</p><a id="more"></a><p>首先说明，使用这个自动化 <code>Shell</code> 脚本，零基础的读者也可以自行安装 <code>Shadowsocks</code>，整个安装过程不到五分钟，非常友好而高效，运行脚本后慢慢等待即可，当然别忘记填写必要信息。</p><p>本脚本已经被我上传至 <code>GitHub</code>，读者可以下载查看并使用：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/bin/20190828" target="_blank" rel="noopener">auto_deploy_shadowsocks.sh</a> ，需要注意的是，这个自动化 <code>Shell</code> 脚本只针对 <code>CentOS 7x64</code> 操作系统有效，其它操作系统我没有测试，不保证能用。所以为了稳妥起见，请读者还是参考我上面给出的那篇博客来创建云主机。</p><h1 id="自动化安装"><a href="# 自动化安装" class="headerlink" title="自动化安装"></a>自动化安装 </h1><p> 下载 <code>GitHub</code> 上面的脚本时，如果有类似 <code>Shell</code> 的环境，就不用浏览器下载了，在 <code>Shell</code> 中可以直接使用 <code>wget</code> 命令下载，使用如下命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/iplaypi/iplaypistudy/master/iplaypistudy-normal/src/bin/20190828/auto_deploy_shadowsocks.sh</span><br></pre></td></tr></table></figure><p>下载下来后接着直接运行即可，使用 <code>sh auto_deploy_shadowsocks.sh</code> 。</p><p>下面简单描述自动化脚本的思路：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、提示用户输入端口号、密码，并读取输入，没有输入则使用默认值 </span><br><span class="line">2、利用端口号、密码，生成 /etc/shadowsocks.json 配置文件 </span><br><span class="line">3、安装 shadowsocks 以及其它组件：m2crypto、pip、firewalld</span><br><span class="line">4、启动防火墙，开启必要的端口 </span><br><span class="line">5、检测当前是否有运行的 shadowsocks 服务，有则杀死 </span><br><span class="line">6、后台启动 shadowsocks 服务 </span><br><span class="line">7、输出部署成功的信息，如果部署失败，需要进一步查看日志文件 </span><br><span class="line">8、处理 server 酱通知 </span><br></pre></td></tr></table></figure><p>脚本内容整理如下，重要的地方已经注释清楚【这里要特别注意脚本中的换行符号，一律使用 <code>\\n</code> 的形式，否则会引起错误】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># 注意本脚本中的换行符号，一律使用 \n 的形式，否则会引起错误 </span><br><span class="line"># 日志路径，如果安装失败需要查看日志，是否有异常 / 报错信息 </span><br><span class="line">export log_path=/etc/auto_deploy_shadowsocks.log</span><br><span class="line"># 设置端口号，从键盘接收参数输入，默认为 2018,-e 参数转义开启高亮显示 </span><br><span class="line">echo -n -e &apos;\033 [36mPlease enter PORT [2018 default]:\033 [0m&apos;</span><br><span class="line">read port</span><br><span class="line">if [! -n &quot;$port&quot;];then</span><br><span class="line">    echo &quot;port will be set to 2018&quot;</span><br><span class="line">    port=2018</span><br><span class="line">else</span><br><span class="line">    echo &quot;port will be set to $port&quot;</span><br><span class="line">fi</span><br><span class="line"># 设置密码，从键盘接收参数输入，默认为 pengfeivpn,-e 参数转义开启高亮显示 </span><br><span class="line">echo -n -e &apos;\033 [36mPlease enter PASSWORD [pengfeivpn default]:\033 [0m&apos;</span><br><span class="line">read pwd</span><br><span class="line">if [! -n &quot;$pwd&quot;];then</span><br><span class="line">    echo &quot;password will be set to 123456&quot;</span><br><span class="line">    pwd=pengfeivpn</span><br><span class="line">else</span><br><span class="line">    echo &quot;password will be set to $pwd&quot;</span><br><span class="line">fi</span><br><span class="line"># 创建 shadowsocks.json 配置文件，只开一个端口，server 可以是 0.0.0.0</span><br><span class="line">echo &quot;****************start generate /etc/shadowsocks.json&quot;</span><br><span class="line">cat&gt;/etc/shadowsocks.json&lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;server&quot;:&quot;0.0.0.0&quot;,</span><br><span class="line">    &quot;server_port&quot;:$port,</span><br><span class="line">    &quot;local_address&quot;: &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;local_port&quot;:1080,</span><br><span class="line">    &quot;password&quot;:&quot;$pwd&quot;,</span><br><span class="line">    &quot;timeout&quot;:300,</span><br><span class="line">    &quot;method&quot;:&quot;aes-256-cfb&quot;,</span><br><span class="line">    &quot;fast_open&quot;: false</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">echo &quot;****************start install shadowsocks and other tools&quot;</span><br><span class="line"># 安装 shadowsocks / 防火墙，携带 - y 参数表示自动同意安装，无需交互询问 </span><br><span class="line"># 日志全部输出到上面指定的日志文件中 </span><br><span class="line">echo &quot;&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;********************************&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;start deploy shadowsocks,date is:&quot;$(date +% Y-% m-% d-% X) &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;********************************&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;******************start install m2crypto&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">ret=`yum install -y m2crypto python-setuptools &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">echo &quot;&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;******************start install pip&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">ret=`easy_install pip &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">echo &quot;&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;******************start install shadowsocks&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">ret=`pip install shadowsocks &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">echo &quot;&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;******************start install firewalld&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">ret=`yum install -y firewalld &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">echo &quot;&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;******************start start firewalld&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">ret=`systemctl start firewalld &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">echo &quot;&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line">echo &quot;******************start reload firewall&quot; &gt;&gt; $&#123;log_path&#125;</span><br><span class="line"># 开启端口 </span><br><span class="line">ret=`firewall-cmd --permanent --zone=public --add-port=22/tcp &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">ret=`firewall-cmd --permanent --zone=public --add-port=$port/tcp &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">ret=`firewall-cmd --reload &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">echo &quot;****************start check shadowsocks&quot;</span><br><span class="line"># 如果有相同功能的进程则先杀死，$? 表示上个命令的退出状态，或者函数的返回值 </span><br><span class="line">ps -ef | grep ssserver | grep shadowsocks | grep -v grep</span><br><span class="line">if [$? -eq 0];then</span><br><span class="line">    ps -ef | grep ssserver | grep shadowsocks | awk &apos;&#123; print $2 &#125;&apos; | xargs kill -9</span><br><span class="line">fi</span><br><span class="line"># 后台启动，-d 表示守护进程 </span><br><span class="line">/usr/bin/ssserver -c /etc/shadowsocks.json -d start</span><br><span class="line"># 启动成功 </span><br><span class="line">if [$? -eq 0];then</span><br><span class="line"># 获取本机 ip 地址 </span><br><span class="line">ip=`ip addr | grep &apos;state UP&apos; -A2 | tail -n1 | awk &apos;&#123;print $2&#125;&apos; | cut -f1 -d &apos;/&apos;`</span><br><span class="line">clear</span><br><span class="line">cat&lt;&lt;EOF</span><br><span class="line">***************Congratulation!*****************</span><br><span class="line">shadowsocks deployed successfully!</span><br><span class="line"></span><br><span class="line">IP:$ip</span><br><span class="line">PORT:$port</span><br><span class="line">PASSWORD:$pwd</span><br><span class="line">METHOD:aes-256-cfb</span><br><span class="line"></span><br><span class="line">*****************JUST ENJOY IT!****************</span><br><span class="line">EOF</span><br><span class="line"># 建议开启 server 酱自动通知，推送到微信，就可以直接复制信息转发给别人了 </span><br><span class="line"># 不开启请把以下内容注释掉，注释内容持续到 & apos;server 酱通知完成 & apos;</span><br><span class="line"># 关于 server 酱的使用请参考:https://sc.ftqq.com</span><br><span class="line"># 注意 server_key 不要泄露，泄漏后可以去官网重置 </span><br><span class="line">echo &quot;************** 开始处理 server 酱通知 & quot;</span><br><span class="line">server_key=SCU60861T303e1c479df6cea9e95fc54d210232565d7dbbf075750</span><br><span class="line"># 传输 2 个参数:text/desp,desp 使用 markdown 语法 (注意换行符要使用 2 个换行)</span><br><span class="line">cat&gt;./shadowsocks_msg.txt&lt;&lt;EOF</span><br><span class="line">text=shadowsocks 服务部署启动完成 </span><br><span class="line">&amp;desp=</span><br><span class="line">- IP 地址：$ip</span><br><span class="line"></span><br><span class="line">- 端口号：$port</span><br><span class="line"></span><br><span class="line">- 密码：$pwd</span><br><span class="line"></span><br><span class="line">- 加密方式：aes-256-cfb</span><br><span class="line">EOF</span><br><span class="line">curl -X POST --data-binary @./shadowsocks_msg.txt  https://sc.ftqq.com/$server_key.send</span><br><span class="line">echo &quot;&quot;</span><br><span class="line">echo &quot;**************server 酱通知处理完成 & quot;</span><br><span class="line"># 失败 </span><br><span class="line">else</span><br><span class="line">clear</span><br><span class="line">cat&lt;&lt;EOF</span><br><span class="line">**************Failed,retry please!*************</span><br><span class="line"></span><br><span class="line">cat /etc/ss.log to get something you need.</span><br><span class="line"></span><br><span class="line">**************Failed,retry please!*************</span><br><span class="line">EOF</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>执行脚本的输出信息如下【我手动设置端口号为 2019，密码使用默认值】，表示安装完成：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@playpi ~]# sh auto_deploy_shadowsocks.sh </span><br><span class="line">Please enter PORT [2018 default]:2019</span><br><span class="line">port will be set to 2019</span><br><span class="line">Please enter PASSWORD [pengfeivpn default]:</span><br><span class="line">password will be set to 123456</span><br><span class="line">****************start generate /etc/shadowsocks.json</span><br><span class="line">****************start install shadowsocks and other tools</span><br><span class="line">****************start check shadowsocks</span><br><span class="line">root     13980     1  0 11:07 ?        00:00:00 /usr/bin/python/usr/bin/ssserver -c /etc/shadowsocks.json -d start</span><br><span class="line">INFO: loading config from /etc/shadowsocks.json</span><br><span class="line">2019-09-29 11:09:29 INFO     loading libcrypto from libcrypto.so.10</span><br><span class="line">started</span><br><span class="line">***************Congratulation!*****************</span><br><span class="line">shadowsocks deployed successfully!</span><br><span class="line"></span><br><span class="line">IP:45.32.79.20</span><br><span class="line">PORT:2019</span><br><span class="line">PASSWORD:pengfeivpn</span><br><span class="line">METHOD:aes-256-cfb</span><br><span class="line"></span><br><span class="line">*****************JUST ENJOY IT!****************</span><br><span class="line">************** 开始处理 server 酱通知 </span><br><span class="line">&#123;&quot;errno&quot;:0,&quot;errmsg&quot;:&quot;success&quot;,&quot;dataset&quot;:&quot;done&quot;&#125;</span><br><span class="line">**************server 酱通知完成 </span><br><span class="line">[root@playpi ~]#</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190929211341.png" alt="自动安装成功" title="自动安装成功"></p><p>同时，<code>server</code> 酱也接收到通知，可以很方便地直接转发给需要的人了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190929211352.png" alt="server 酱的通知" title="server 酱的通知"></p><h1 id="自动更换端口重启"><a href="# 自动更换端口重启" class="headerlink" title="自动更换端口重启"></a>自动更换端口重启 </h1><p> 在使用 <code>Shadowsocks</code> 的时候，有时候会遇到一个问题，端口被封了【<code>ip</code> 被封另外说，只能销毁主机新建】，特别是国家严厉管控非法 <code>VPN</code> 的时候，当然我这是属于误封，因为我只是用来学习、测试接口，这时候解决办法也简单，尝试更换一个端口即可。</p><p>步骤其实很简单，停止服务、更改配置文件、开启新端口、重启服务，但是作为一个追求效率的人，我还是想把操作简化一下，最好敲下一行命令等着就行【执行脚本的前提是 <code>Shadowsocks</code> 以及相关工具已经安装完成】。</p><p>其实把前面的步骤稍微整理一下，就变成了一个简单的脚本，直接执行即可。脚本已经被我上传至 <code>GitHub</code>，在 <code>Shell</code> 中可以直接使用 <code>wget</code> 命令下载，使用如下命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/iplaypi/iplaypistudy/master/iplaypistudy-normal/src/bin/20190828/auto_restart_shadowsocks.sh</span><br></pre></td></tr></table></figure><p>下载下来后接着直接运行即可，使用 <code>sh auto_restart_shadowsocks.sh</code> 。</p><p>下面简单描述自动化脚本的思路：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、提示用户输入端口号、密码，并读取输入，没有输入则使用默认值 </span><br><span class="line">2、利用端口号、密码，生成 /etc/shadowsocks.json 配置文件 </span><br><span class="line">3、启动防火墙，开启必要的端口（`Shadowsocks` 以及相关工具无需再安装）</span><br><span class="line">4、使用 stop 停止 shadowsocks 服务 </span><br><span class="line">5、再次检测当前是否有运行的 shadowsocks 服务，有则杀死 </span><br><span class="line">6、后台启动 shadowsocks 服务 </span><br><span class="line">7、输出部署成功的信息，如果部署失败，需要进一步查看日志文件 </span><br><span class="line">8、处理 server 酱通知 </span><br></pre></td></tr></table></figure><p>脚本内容整理如下，重要的地方已经注释清楚【这里要特别注意脚本中的换行符号，一律使用 <code>\\n</code> 的形式，否则会引起错误】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># 注意本脚本中的换行符号，一律使用 \n 的形式，否则会引起错误 </span><br><span class="line"># 日志路径，如果安装失败需要查看日志，是否有异常 / 报错信息 </span><br><span class="line">export log_path=/etc/auto_restart_shadowsocks.log</span><br><span class="line"># 设置端口号，从键盘接收参数输入，默认为 2018,-e 参数转义开启高亮显示 </span><br><span class="line">echo -n -e &apos;\033 [36mPlease enter PORT [2018 default]:\033 [0m&apos;</span><br><span class="line">read port</span><br><span class="line">if [! -n &quot;$port&quot;];then</span><br><span class="line">    echo &quot;port will be set to 2018&quot;</span><br><span class="line">    port=2018</span><br><span class="line">else</span><br><span class="line">    echo &quot;port will be set to $port&quot;</span><br><span class="line">fi</span><br><span class="line"># 设置密码，从键盘接收参数输入，默认为 pengfeivpn,-e 参数转义开启高亮显示 </span><br><span class="line">echo -n -e &apos;\033 [36mPlease enter PASSWORD [pengfeivpn default]:\033 [0m&apos;</span><br><span class="line">read pwd</span><br><span class="line">if [! -n &quot;$pwd&quot;];then</span><br><span class="line">    echo &quot;password will be set to pengfeivpn&quot;</span><br><span class="line">    pwd=pengfeivpn</span><br><span class="line">else</span><br><span class="line">    echo &quot;password will be set to $pwd&quot;</span><br><span class="line">fi</span><br><span class="line"># 创建 shadowsocks.json 配置文件，只开一个端口，server 可以是 0.0.0.0</span><br><span class="line">echo &quot;****************start generate /etc/shadowsocks.json&quot;</span><br><span class="line">cat&gt;/etc/shadowsocks.json&lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;server&quot;:&quot;0.0.0.0&quot;,</span><br><span class="line">    &quot;server_port&quot;:$port,</span><br><span class="line">    &quot;local_address&quot;: &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;local_port&quot;:1080,</span><br><span class="line">    &quot;password&quot;:&quot;$pwd&quot;,</span><br><span class="line">    &quot;timeout&quot;:300,</span><br><span class="line">    &quot;method&quot;:&quot;aes-256-cfb&quot;,</span><br><span class="line">    &quot;fast_open&quot;: false</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">echo &quot;****************start open port&quot;</span><br><span class="line"># 开启端口 </span><br><span class="line">ret=`firewall-cmd --permanent --zone=public --add-port=$port/tcp &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line">ret=`firewall-cmd --reload &gt;&gt; $&#123;log_path&#125; 2&gt;&amp;1`</span><br><span class="line"># 正常停掉 shadowsocks 服务 </span><br><span class="line">echo &quot;****************start stop shadowsocks&quot;</span><br><span class="line">/usr/bin/ssserver -c /etc/shadowsocks.json -d stop</span><br><span class="line">echo &quot;****************start check shadowsocks&quot;</span><br><span class="line"># 如果有相同功能的进程则先杀死，$? 表示上个命令的退出状态，或者函数的返回值 </span><br><span class="line">ps -ef | grep ssserver | grep shadowsocks | grep -v grep</span><br><span class="line">if [$? -eq 0];then</span><br><span class="line">    ps -ef | grep ssserver | grep shadowsocks | awk &apos;&#123; print $2 &#125;&apos; | xargs kill -9</span><br><span class="line">fi</span><br><span class="line"># 后台启动，-d 表示守护进程 </span><br><span class="line">/usr/bin/ssserver -c /etc/shadowsocks.json -d start</span><br><span class="line"># 启动成功 </span><br><span class="line">if [$? -eq 0];then</span><br><span class="line"># 获取本机 ip 地址 </span><br><span class="line">ip=`ip addr | grep &apos;state UP&apos; -A2 | tail -n1 | awk &apos;&#123;print $2&#125;&apos; | cut -f1 -d &apos;/&apos;`</span><br><span class="line">clear</span><br><span class="line">cat&lt;&lt;EOF</span><br><span class="line">***************Congratulation!*****************</span><br><span class="line">shadowsocks restart successfully!</span><br><span class="line"></span><br><span class="line">IP:$ip</span><br><span class="line">PORT:$port</span><br><span class="line">PASSWORD:$pwd</span><br><span class="line">METHOD:aes-256-cfb</span><br><span class="line"></span><br><span class="line">*****************JUST ENJOY IT!****************</span><br><span class="line">EOF</span><br><span class="line"># 建议开启 server 酱自动通知，推送到微信，就可以直接复制信息转发给别人了 </span><br><span class="line"># 不开启请把以下内容注释掉，注释内容持续到 & apos;server 酱通知完成 & apos;</span><br><span class="line"># 关于 server 酱的使用请参考:https://sc.ftqq.com</span><br><span class="line"># 注意 server_key 不要泄露，泄漏后可以去官网重置 </span><br><span class="line">echo &quot;************** 开始处理 server 酱通知 & quot;</span><br><span class="line">server_key=SCU60861T303e1c479df6cea9e95fc54d210232565d7dbbf075750</span><br><span class="line"># 传输 2 个参数:text/desp,desp 使用 markdown 语法 (注意换行符要使用 2 个换行)</span><br><span class="line">cat&gt;./shadowsocks_msg.txt&lt;&lt;EOF</span><br><span class="line">text=shadowsocks 服务更换端口重新启动完成 </span><br><span class="line">&amp;desp=</span><br><span class="line">- IP 地址：$ip</span><br><span class="line"></span><br><span class="line">- 端口号：$port</span><br><span class="line"></span><br><span class="line">- 密码：$pwd</span><br><span class="line"></span><br><span class="line">- 加密方式：aes-256-cfb</span><br><span class="line">EOF</span><br><span class="line">curl -X POST --data-binary @./shadowsocks_msg.txt  https://sc.ftqq.com/$server_key.send</span><br><span class="line">echo &quot;&quot;</span><br><span class="line">echo &quot;**************server 酱通知处理完成 & quot;</span><br><span class="line"># 失败 </span><br><span class="line">else</span><br><span class="line">clear</span><br><span class="line">cat&lt;&lt;EOF</span><br><span class="line">**************Failed,retry please!*************</span><br><span class="line"></span><br><span class="line">cat /etc/ss.log to get something you need.</span><br><span class="line"></span><br><span class="line">**************Failed,retry please!*************</span><br><span class="line">EOF</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>执行脚本的输出信息如下【需要手动设置新的端口号，我设置为 2020，密码仍旧使用默认值】，表示重启完成：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@playpi ~]# sh auto_restart_shadowsocks.sh </span><br><span class="line">Please enter PORT [2018 default]:2020</span><br><span class="line">port will be set to 2020</span><br><span class="line">Please enter PASSWORD [pengfeivpn default]:</span><br><span class="line">password will be set to pengfeivpn</span><br><span class="line">****************start generate /etc/shadowsocks.json</span><br><span class="line">****************start open port</span><br><span class="line">****************start stop shadowsocks</span><br><span class="line">INFO: loading config from /etc/shadowsocks.json</span><br><span class="line">stopped</span><br><span class="line">****************start check shadowsocks</span><br><span class="line">INFO: loading config from /etc/shadowsocks.json</span><br><span class="line">2019-10-02 10:53:17 INFO     loading libcrypto from libcrypto.so.10</span><br><span class="line">started</span><br><span class="line">***************Congratulation!*****************</span><br><span class="line">shadowsocks restart successfully!</span><br><span class="line"></span><br><span class="line">IP:45.32.79.20</span><br><span class="line">PORT:2020</span><br><span class="line">PASSWORD:pengfeivpn</span><br><span class="line">METHOD:aes-256-cfb</span><br><span class="line"></span><br><span class="line">*****************JUST ENJOY IT!****************</span><br><span class="line">************** 开始处理 server 酱通知 </span><br><span class="line">&#123;&quot;errno&quot;:0,&quot;errmsg&quot;:&quot;success&quot;,&quot;dataset&quot;:&quot;done&quot;&#125;</span><br><span class="line">**************server 酱通知处理完成 </span><br><span class="line">[root@playpi ~]#</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191002185742.png" alt="重启成功" title="重启成功"></p><p>同时，<code>server</code> 酱也接收到通知，可以很方便地直接转发给需要的人了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191002185749.png" alt="server 酱的通知" title="server 酱的通知"></p><h1 id="监控服务"><a href="# 监控服务" class="headerlink" title="监控服务"></a>监控服务 </h1><p> 鉴于国家管控越来越严格，有时候会误伤到我们的 <code>VPS</code>，毕竟我只是用来学习技术、测试接口，没有做什么违法的事，有时候突然挂掉了我也不知道，直到需要用到的时候才发现已经挂掉了，这时候还要去折腾，重启甚至更换 <code>ip</code>，影响心情，也影响做事的效率。</p><p>那么有没有可能做一个简单的监控服务，每隔一段时间检测一下服务是否正常，如果不正常则发送通知。如果连续多次不正常，则发送通知提醒更换端口重启；如果是 <code>ip</code> 被封，此时重启没有用了，应该发送通知，提醒重新更换主机。</p><p>使用 <code>Shell</code> 可以做一个简化的版本，脚本已经被我上传至 <code>GitHub</code>，在 <code>Shell</code> 中可以直接使用 <code>wget</code> 命令下载，使用如下命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/iplaypi/iplaypistudy/master/iplaypistudy-normal/src/bin/20190828/auto_monitor_shadowsocks.sh</span><br></pre></td></tr></table></figure><p>下载下来后接着直接运行即可，使用 <code>sh auto_monitor_shadowsocks.sh</code> 。</p><p>当然，这个监控脚本是要放在常用的主机上面运行，或者是在自己的电脑后台运行，但是为了确保一直后台运行，还是放在远程服务器上比较好，例如公司的公共服务器、阿里云主机等，这样就可以一直运行并监控【确保运行在家庭的网络环境中或者公司的网络环境中，否则监控结果没有意义】。</p><p>下面简单描述自动化脚本的思路：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、执行脚本时输入 ip、端口号、周期，然后每隔指定时间按照如下流程检测一次 </span><br><span class="line">2、使用 ping 检测 ip 是否可用 </span><br><span class="line">3、如果 ip 不可用，通过 server 酱通知；如果 ip 可用，进一步检测端口是否可用 </span><br><span class="line">4、如果端口不可用，记录并通过 server 酱通知；如果端口可用，不做操作 </span><br><span class="line">5、步骤 4 中如果端口不可用连续超过 3 次，才发送通知 </span><br><span class="line">6、如果更换了 ip 或者端口，此监控脚本需要重启，从头重新开始检测 </span><br></pre></td></tr></table></figure><p>脚本内容整理如下，重要的地方已经注释清楚【这里要特别注意脚本中的换行符号，一律使用 <code>\\n</code> 的形式，否则会引起错误】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># 脚本接收 3 个参数:ip/port/ 执行周期 (默认 10 分钟), 切记放在后台运行 </span><br><span class="line"># 注意本脚本中的换行符号，一律使用 \n 的形式，否则会引起错误 </span><br><span class="line"># 日志路径，如果安装失败需要查看日志，是否有异常 / 报错信息 </span><br><span class="line"># 最少 2 个参数，否则直接退出 </span><br><span class="line">if [2 -gt $#];then</span><br><span class="line">  echo &quot;must enter ip and port&quot;</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br><span class="line">ip=$1</span><br><span class="line">port=$2</span><br><span class="line">log_path=/etc/auto_monitor_shadowsocks.log</span><br><span class="line"># 设置执行周期，默认 10 分钟，如果参数有指定则使用 </span><br><span class="line">circle_time=$3</span><br><span class="line">if [-z $circle_time];then</span><br><span class="line">  circle_time=10m</span><br><span class="line">fi</span><br><span class="line">echo &quot;ip will be set to [$ip],port will be set to [$port],circle_time will be set to [$circle_time]&quot;</span><br><span class="line"># 变量，标记是否通知以及通知内容 </span><br><span class="line">notice=0</span><br><span class="line">notice_msg=&quot;&quot;</span><br><span class="line"># 变量，标记 ip / 端口的失败次数 </span><br><span class="line">ip_fail_num=0</span><br><span class="line">port_fail_num=0</span><br><span class="line"># while 循环 </span><br><span class="line">while :</span><br><span class="line">do</span><br><span class="line">  # 查看 ip 是否正常 </span><br><span class="line">  ping=`ping -c 1 $ip |grep loss |awk &apos;&#123;print $6&#125;&apos; |awk -F &quot;%&quot; &apos;&#123;print $1&#125;&apos;`</span><br><span class="line">  # ip 不可用 </span><br><span class="line">  if [$ping -eq 100];then</span><br><span class="line">    ip_fail_num=`expr $ip_fail_num + 1`</span><br><span class="line">    echo ping [$ip] at $(date +% Y-% m-% d% t% X) fail &gt;&gt; $log_path</span><br><span class="line">    notice=1</span><br><span class="line">    notice_msg=`echo ping [$ip] at $(date +% Y-% m-% d% t% X) 失败，累计次数：[$ip_fail_num]，请更换主机 `</span><br><span class="line">    #ip 可用 </span><br><span class="line">  else</span><br><span class="line">    echo ping [$ip] at $(date +% Y-% m-% d% t% X) ok &gt;&gt; $log_path</span><br><span class="line">    ip_fail_num=0</span><br><span class="line">    # 接着判断端口是否可用，使用 nc 工具，超时时间为 20 秒 </span><br><span class="line">    `nc -v -z -w 20 $ip $port`</span><br><span class="line">    # 端口不可用 </span><br><span class="line">    if [0 -ne $?];then</span><br><span class="line">      port_fail_num=`expr $port_fail_num + 1`</span><br><span class="line">      echo nc [$ip:$port] at $(date +% Y-% m-% d% t% X) fail &gt;&gt; $log_path</span><br><span class="line">      if [$port_fail_num -gt 3];then</span><br><span class="line">        notice=1</span><br><span class="line">        notice_msg=`echo nc [$ip:$port] at $(date +% Y-% m-% d% t% X) 失败，累计次数：[$port_fail_num]，请更换端口 `</span><br><span class="line">      fi</span><br><span class="line">    # 端口可用 </span><br><span class="line">    else</span><br><span class="line">      echo nc [$ip:$port] at $(date +% Y-% m-% d% t% X) ok &gt;&gt; $log_path</span><br><span class="line">      port_fail_num=0</span><br><span class="line">    fi</span><br><span class="line">  fi</span><br><span class="line"># 建议开启 server 酱自动通知，推送到微信 </span><br><span class="line"># 不开启请把以下内容注释掉，注释内容持续到 & apos;server 酱通知完成 & apos;</span><br><span class="line"># 关于 server 酱的使用请参考:https://sc.ftqq.com</span><br><span class="line"># 注意 server_key 不要泄露，泄漏后可以去官网重置 </span><br><span class="line">if [1 -eq $notice];then</span><br><span class="line">  echo &quot;************** 开始处理 server 酱通知 & quot; &gt;&gt; $log_path</span><br><span class="line">  server_key=SCU60861T303e1c479df6cea9e95fc54d210232565d7dbbf075750</span><br><span class="line">  # 传输 2 个参数:text/desp,desp 使用 markdown 语法 (注意换行符要使用 2 个换行)</span><br><span class="line">cat&gt;./shadowsocks_msg.txt&lt;&lt;EOF</span><br><span class="line">text=shadowsocks 定时监控服务消息 </span><br><span class="line">&amp;desp=</span><br><span class="line">$notice_msg</span><br><span class="line">EOF</span><br><span class="line">  curl -X POST --data-binary @./shadowsocks_msg.txt https://sc.ftqq.com/$server_key.send &gt;&gt; $log_path</span><br><span class="line">  echo &quot;&quot; &gt;&gt; $log_path</span><br><span class="line">  echo &quot;**************server 酱通知处理完成 & quot; &gt;&gt; $log_path</span><br><span class="line">  notice=0</span><br><span class="line">  notice_msg=&quot;&quot;</span><br><span class="line">fi</span><br><span class="line">sleep $circle_time</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>执行脚本后，每隔 10 分钟检测一下 <code>ip</code> 或者端口是否可以正常访问。如果正常什么都不做；如果端口不正常则记录，如果端口连续 3 次不正常则发送故障报告，提醒更换端口；如果 <code>ip</code> 不正常则发送故障报告，提醒更换主机。</p><p>下面列举一些 <code>server</code> 酱的通知示例。</p><p>端口连续不可用。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191003005805.png" alt="端口连续不可用" title="端口连续不可用"></p><p><code>ip</code> 不可用。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20191003005759.png" alt="ip 不可用" title="ip 不可用"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注</h1><p>1、Server 酱的使用有限制，每天限制 1000 条信息，所以千万不能写个死循环狂发信息，会被拉黑的。</p><p>2、使用 <code>wget</code> 下载文件时，如果本地文件已经存在，会自动新建一个文件，文件很多，有时候会显得很乱，如果想覆盖下载，可以使用 <code>-N</code> 参数，或者使用 <code>-O your_file_name</code> 参数指定本地文件名。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>shadowsocks</tag>
        <tag>firewalld</tag>
        <tag>Shadowsocks</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 分析器使用入门指南</title>
    <url>/2017082001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p><code>ElasticSearch</code> 是一个基于 <code>Lucene</code> 构建的开源、分布式、<code>RESTful</code> 搜索引擎，能够达到实时搜索，并且稳定、可靠、快速。而其中最常用的全文检索【<code>match</code> 匹配】功能，在很多场景都有应用，这当然离不开分析器【<code>Analyzer</code>】，本文简单总结一下相关内容，入门级别。开发环境基于 <code>v5.6.8</code>。</p><a id="more"></a><h1 id="初识分析器"><a href="# 初识分析器" class="headerlink" title="初识分析器"></a>初识分析器 </h1><p> 首先需要先了解一下分析器的概念，以及与此相关的几个术语。</p><p>做全文检索前就需要对文档分析、建索引，其中从文档中提取词元【<code>Token</code>】的算法称为分词器【<code>Tokenizer</code>】，在分词前预处理字符串的算法称为字符过滤器【<code>Character Filter</code>】，进一步处理词元的算法称为词元过滤器【<code>Token Filter</code>】，最后得到词【<code>Term</code>，最小单元，决定着搜索时能否命中】。而这整个分析流程以及对应的算法称为分析器【<code>Analyzer</code>】，我们对文档的某个字段可以指定分析器，以达到我们全文检索的需求。</p><p>这里注意，我们在日常口语中会把 <code>Analyzer</code> 称为分词器，例如给某个字段指定一个分词器，这其实是有误导的【因为分词器只是分析器中的一个重要的组成部分】。</p><p>文档包含词的数量称为词频【<code>Frequency</code>】，搜索引擎会建立词与文档的索引，称为 <strong>倒排索引 </strong>【<code>Inverted Index</code>】，这是 <code>ElasticSearch</code> 中的基本概念。</p><p>下面使用一张图片来简单描述一下分析器的分析流程，更加直观：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200220223915.png" alt="分析器流程" title="分析器流程"></p><p><code>Analyzer</code> 按顺序做三件事：</p><ol><li>使用 <code>CharacterFilter</code> 过滤字符，可以添加、删除或更改字符来转换字符流，一个分析器可以有多个字符过滤器；</li><li>使用 <code>Tokenizer</code> 分词，接收字符流，将其分解成单独的词元，并输出词元流，一个分析器只能有一个分词器；</li><li>使用 <code>TokenFilter</code> 过滤词元，接收词元流，并可以添加、删除或修改词元，不允许更改每个词元的位置或字符偏移量，一个分析器可有多个 <code>TokenFilter</code> 过滤器，并按顺序应用。</li></ol><p>关于词【<code>Term</code>】，我们也会称之为单词，为了避免歧义，本文统一称之为词。</p><p><code>Elasticsearch</code> 默认提供了多种 <code>CharacterFilter</code>、<code>Tokenizer</code>、<code>TokenFilter</code>、<code>Analyzer</code>【可以直接使用的分析器】，当然，我们也可以下载第三方的 <code>Analyzer</code> 组件，或者根据业务场景开发自定义的组件。</p><p>官网链接如下：</p><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-charfilters.html" target="_blank" rel="noopener">CharacterFilter</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html" target="_blank" rel="noopener">Tokenizer</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html" target="_blank" rel="noopener">TokenFilter</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html" target="_blank" rel="noopener">Analyzer</a></li></ul><p><code>Elasticsearch</code> 中的 <code>Analyzer</code> 一般会提供一些配置，我们按照需要使用，如 <code>standard Analyzer</code> 提供了 <code>stop_words</code> 停用词过滤配置，这样我们就可以提供一些噪音词【例如特定行业数据中可能有歧义的词，不想被分析器输出为词元】，用于分析时剔除。</p><p>官方介绍：</p><blockquote><p>The standard analyzer divides text into terms on word boundaries, as defined by the Unicode Text Segmentation algorithm. It removes most punctuation, lowercases terms, and supports removing stop words.</p></blockquote><p>下面列举一个简单示例，为 <code>standard Analyzer</code> 添加 <code>stop_words</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /my-index-post/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;standard&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;standard&quot;,</span><br><span class="line">          &quot;stop_words&quot;: [&quot;is&quot;, &quot;a&quot;, &quot;ha&quot;, &quot;aha&quot;]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上我们就构造了名为 <code>standard</code> 的 <code>standard Analyzer</code> 类型的带停用词列表的分析器。</p><p>还有其它更多的分析器请读者参考上面的官方文档，例如 <code>Whitespace Analyzer</code>，即空格分析器，遇到任何空格字符时都会将文本分为多个词元，并且不会把词元转换为小写字母【区分大小写】。</p><h1 id="自定义分析器"><a href="# 自定义分析器" class="headerlink" title="自定义分析器"></a>自定义分析器 </h1><p> 通过上面的讲解，我们发现也可以通过 <code>Setting API</code> 来构造组合自定义的 <code>Analyzer</code>，此时需要我们指定 <code>Character Filter</code>、<code>Tokenizer</code>、<code>Token Filter</code> 等基础规则组件。读者可以参考官网示例：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-custom-analyzer.html" target="_blank" rel="noopener">analysis-custom-analyzer</a> 。</p><p>请看以下例子：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my-index-post/_settings</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;index&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;custom_analyzer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;custom&quot;,</span><br><span class="line">          &quot;char_filter&quot;: [&quot;html_strip&quot;],</span><br><span class="line">          &quot;tokenizer&quot;: &quot;standard&quot;,</span><br><span class="line">          &quot;filter&quot;: [&quot;lowercase&quot;, &quot;stop&quot;]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们构造了一个名称为 <code>custom_analyzer</code> 的分析器，其中 <code>type</code> 用来告诉 <code>Elasticsearch</code> 我们要自定义一个分析器，<code>char_filter</code> 指定了 <code>Character Filter</code>，<code>tokenizer</code> 指定了 <code>Tokenizer</code>，<code>filter</code> 指定了 <code>Token Filter</code>。</p><p>根据我们的设置，它会完成以下流程：</p><ol><li>使用 <code>html_strip</code> 字符过滤器，移除 <code>html</code> 标签；</li><li>使用 <code>standard</code> 分词器，进行分词；</li><li>使用 <code>lowercase</code> 词元过滤器，把大写字母转为小写字母；</li><li>使用 <code>stop</code> 词元过滤器，过滤掉停用词。</li></ol><p>这样我们的自定义分析器就构造完成，可以根据名称使用它了。</p><p>注意，创建自定义分析器之前，需要先关闭索引，创建成功后再打开，否则无法创建成功。</p><h1 id="实战演示"><a href="# 实战演示" class="headerlink" title="实战演示"></a>实战演示 </h1><h2 id="设置字段的分析器"><a href="# 设置字段的分析器" class="headerlink" title="设置字段的分析器"></a> 设置字段的分析器 </h2><p> 首先说明，在创建索引时，我们针对特殊的字段都会指定分析器，例如内容、标题这种长文本，需要全文检索。因此，我们在配置 <code>_mapping</code> 时，就可以指定分析器了，可以为单个字段指定，也可以使用动态模版指定【更加灵活】。</p><p>下面为示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT http://localhost:9202/my-index-post/_mapping/post/</span><br><span class="line">&#123;</span><br><span class="line">    &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;title&quot;: &#123;</span><br><span class="line">                &quot;mapping&quot;: &#123;</span><br><span class="line">                    &quot;analyzer&quot;: &quot;custom_analyzer&quot;,</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;match&quot;: &quot;*_title&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;content&quot;: &#123;</span><br><span class="line">                &quot;mapping&quot;: &#123;</span><br><span class="line">                    &quot;analyzer&quot;: &quot;custom_analyzer&quot;,</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;match&quot;: &quot;*_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;title&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;analyzer&quot;: &quot;custom_analyzer&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;content&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;analyzer&quot;: &quot;custom_analyzer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 <code>dynamic_templates</code> 指定了动态模版，字段名称满足 <code>*_title</code>、<code>*_content</code> 模版都会被设置为 <code>custom_analyzer</code> 分析器。</p><p>而在 <code>properties</code> 中，直接设置了 <code>title</code>、<code>content</code> 这两个字段的分析器为 <code>custom_analyzer</code>。</p><p>此外，如果希望对一个字段使用多种分析器，这样就可以得到不同的分析结果，也是可行的，利用 <code>multi-fields</code> 特性，其实是生成了多个子字段，参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-fields.html" target="_blank" rel="noopener">multi-fields</a> 。</p><p>下面为示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT http://localhost:9202/my-index-post/_mapping/post/</span><br><span class="line">&#123;</span><br><span class="line">    &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;title&quot;: &#123;</span><br><span class="line">                &quot;mapping&quot;: &#123;</span><br><span class="line">                    &quot;analyzer&quot;: &quot;custom_analyzer&quot;,</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                    &quot;fields&quot;: &#123;</span><br><span class="line">                        &quot;text1&quot;: &#123;</span><br><span class="line">                            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                            &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;text2&quot;: &#123;</span><br><span class="line">                            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                            &quot;analyzer&quot;: &quot;english&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;match&quot;: &quot;*_title&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;content&quot;: &#123;</span><br><span class="line">                &quot;mapping&quot;: &#123;</span><br><span class="line">                    &quot;analyzer&quot;: &quot;custom_analyzer&quot;,</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                    &quot;fields&quot;: &#123;</span><br><span class="line">                        &quot;text1&quot;: &#123;</span><br><span class="line">                            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                            &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;text2&quot;: &#123;</span><br><span class="line">                            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                            &quot;analyzer&quot;: &quot;english&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;match&quot;: &quot;*_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;title&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;analyzer&quot;: &quot;custom_analyzer&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">                &quot;text1&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                    &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;text2&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                    &quot;analyzer&quot;: &quot;english&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;content&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;analyzer&quot;: &quot;custom_analyzer&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">                &quot;text1&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                    &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;text2&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                    &quot;analyzer&quot;: &quot;english&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>利用 <code>fields</code> 属性，再分别添加 <code>text1</code>、<code>text2</code> 两个字段，并且指定不同的分析器，需要查询时指定字段名为 <code>title</code>、<code>title.text1</code>、<code>title.text2</code> 即可。</p><h2 id="查询"><a href="# 查询" class="headerlink" title="查询"></a>查询 </h2><p> 查询时也可以指定分析器，这样的话本次查询生成的词是单独的规则，可能无法匹配到索引数据时生成的词。如果不配置，则默认与索引数据时的分析器一致，这也符合用户的使用习惯，因为基本不会有人特别去指定查询的分析器。</p><p>注意，给搜索指定分析器后，实际是对指定的文本进行分析后产生词，用这些词去匹配数据文档中的字段，例如指定文本 <code>iPhone8</code> 搜索，如果指定使用 <code>standard</code> 分析器，文本会被分析为 <code>iphone8</code>，而如果索引数据使用的是 <code>wordsEN</code> 分析器【<code>iPhone8</code> 被分析为 <code>iphone</code>、<code>8</code>】，会造成无法命中。</p><p>利用 <code>analyzer</code> 属性指定：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;content&quot;:&#123;</span><br><span class="line">        &quot;query&quot;: &quot;，&quot;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200221004431.png" alt="查询数据指定 standard 无结果" title="查询数据指定 standard 无结果"></p><p>我这里 <code>content</code> 字段配置的分析器是 <code>wordsEN</code>，索引数据时会保留标点符号，而使用 <code>standard</code> 分析器查询时，由于 <code>standard</code> 分析器移除了标点符号，那么此时的词等价于空串了，所以无法命中数据。</p><p>换一个分析器查询，就可以查到数据了：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;content&quot;:&#123;</span><br><span class="line">        &quot;query&quot;: &quot;，&quot;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;wordsEN&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200221004501.png" alt="查询数据指定 wordsEN 有结果" title="查询数据指定 wordsEN 有结果"></p><p>下面再举一个典型的例子，虽然指定的文本在数据中并没有出现，但是通过指定查询的分析器【查询时会过滤掉标点符号】，也可以命中数据。</p><p>想查询 <code>着，我 </code> 这个短语，如果是正常的情况，<code> 着</code>、<code>我 </code> 应该出现在两个短句中，但是通过指定分析器 <code>standard</code>，就可以把逗号移除，从而命中带有 <code> 着我 </code> 的数据【这也改变了本来的查询含义，即人理解的含义，更多参考后面的 <strong> 误解 </strong>小节】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;content&quot;:&#123;</span><br><span class="line">        &quot;query&quot;: &quot; 着，我 & quot;,</span><br><span class="line">        &quot;type&quot;: &quot;phrase&quot;, </span><br><span class="line">        &quot;slop&quot;: 0,</span><br><span class="line">        &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200222142332.png" alt="典型例子" title="典型例子"></p><p>此外还有一种配置方法，除了可以给字段配置索引数据时的分析器，还可以给字段指定查询时的分析器，利用 <code>search_analyzer</code> 属性【如果不配置则默认与索引数据时的分析器一致，如果用户查询时又手动指定了分析器则使用用户指定的，读者可以看上面的例子】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /my-index-post/_mapping/post</span><br><span class="line">&#123;</span><br><span class="line">  &quot;post&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;title&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;english&quot;,</span><br><span class="line">        &quot;search_analyzer&quot;: &quot;standard&quot; </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="不同分析器的效果"><a href="# 不同分析器的效果" class="headerlink" title="不同分析器的效果"></a>不同分析器的效果 </h2><p> 对于集群已经安装的分析器，可以直接使用，利用 <code>_analyze</code> 接口即可，可以方便测试分析效果。下面使用文本 <code>出发，123，let&#39;s go！来自 iPhone8 的客户端。</code> 演示，这段文本里面包含了中文、标点符号、数字、小写单词、大写字母，很具有代表性。</p><p>发送请求：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 出发，123，let&apos;s go！来自 iPhone8 的客户端。&quot;,</span><br><span class="line">  &quot;analyzer&quot;:&quot;wordsEN&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> 指定索引也可以 </span><br><span class="line">POST my-index-post/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 出发，123，let&apos;s go！来自 iPhone8 的客户端。&quot;,</span><br><span class="line">  &quot;analyzer&quot;:&quot;wordsEN&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 出 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 0,</span><br><span class="line">      &quot;end_offset&quot;: 1,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 发 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 1,</span><br><span class="line">      &quot;end_offset&quot;: 2,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;，&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 2,</span><br><span class="line">      &quot;end_offset&quot;: 3,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;123&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 3,</span><br><span class="line">      &quot;end_offset&quot;: 6,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;，&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 6,</span><br><span class="line">      &quot;end_offset&quot;: 7,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 4</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;let&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 7,</span><br><span class="line">      &quot;end_offset&quot;: 10,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 5</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;&apos;&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 10,</span><br><span class="line">      &quot;end_offset&quot;: 11,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 6</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;s&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 11,</span><br><span class="line">      &quot;end_offset&quot;: 12,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 7</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; &quot;,</span><br><span class="line">      &quot;start_offset&quot;: 12,</span><br><span class="line">      &quot;end_offset&quot;: 13,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 8</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;go&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 13,</span><br><span class="line">      &quot;end_offset&quot;: 15,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 9</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;！&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 15,</span><br><span class="line">      &quot;end_offset&quot;: 16,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 10</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 来 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 16,</span><br><span class="line">      &quot;end_offset&quot;: 17,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 11</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 自 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 17,</span><br><span class="line">      &quot;end_offset&quot;: 18,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 12</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;iphone&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 18,</span><br><span class="line">      &quot;end_offset&quot;: 24,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 13</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;8&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 24,</span><br><span class="line">      &quot;end_offset&quot;: 25,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 14</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 的 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 25,</span><br><span class="line">      &quot;end_offset&quot;: 26,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 15</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 客 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 26,</span><br><span class="line">      &quot;end_offset&quot;: 27,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 16</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 户 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 27,</span><br><span class="line">      &quot;end_offset&quot;: 28,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 17</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 端 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 28,</span><br><span class="line">      &quot;end_offset&quot;: 29,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 18</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;。&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 29,</span><br><span class="line">      &quot;end_offset&quot;: 30,</span><br><span class="line">      &quot;type&quot;: &quot;word&quot;,</span><br><span class="line">      &quot;position&quot;: 19</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200221011959.png" alt="查看分析结果指定 wordsEN" title="查看分析结果指定 wordsEN"></p><p><code>wordsEN</code> 分析器把所有的字符全部保留了，把大写字母转为了小写字母，并且 <code>iPhone8</code> 被拆开为 <code>iphone</code> 和 <code>8</code>。</p><p>更换为 <code>standard</code> 分析器：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 出发，123，let&apos;s go！来自 iPhone8 的客户端。&quot;,</span><br><span class="line">  &quot;analyzer&quot;:&quot;standard&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 出 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 0,</span><br><span class="line">      &quot;end_offset&quot;: 1,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 发 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 1,</span><br><span class="line">      &quot;end_offset&quot;: 2,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;123&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 3,</span><br><span class="line">      &quot;end_offset&quot;: 6,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;NUM&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;let&apos;s&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 7,</span><br><span class="line">      &quot;end_offset&quot;: 12,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;go&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 13,</span><br><span class="line">      &quot;end_offset&quot;: 15,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 4</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 来 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 16,</span><br><span class="line">      &quot;end_offset&quot;: 17,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 5</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 自 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 17,</span><br><span class="line">      &quot;end_offset&quot;: 18,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 6</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;iphone8&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 18,</span><br><span class="line">      &quot;end_offset&quot;: 25,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 7</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 的 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 25,</span><br><span class="line">      &quot;end_offset&quot;: 26,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 8</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 客 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 26,</span><br><span class="line">      &quot;end_offset&quot;: 27,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 9</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 户 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 27,</span><br><span class="line">      &quot;end_offset&quot;: 28,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 10</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 端 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 28,</span><br><span class="line">      &quot;end_offset&quot;: 29,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 11</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200221011834.png" alt="查看分析结果指定 standard" title="查看分析结果指定 standard"></p><p>注意到，标点符号被剔除；缩写词 <code>let&#39;s</code> 没有拆开；<code>iPhone8</code> 被转为小写字母，但是字母、数字没有拆开。</p><p>这里可以留意到，尽管分析器剔除了一些字符，但是每个词的位置并没有变化，例如 <code>123</code> 的位置 <code>start_offset</code> 是 3，也就是在原文中的位置，并没有因为它前面的逗号被剔除而变为 2，这是很重要的。</p><p>另外，注意一下 <code>position</code> 的值，它才是词元的位置，由于过滤一些字符后，<code>position</code> 的值和 <code>*_offset</code> 值的对应关系变化了，这可能会引起一些误解，因为关系到搜索时的命中结果【指定步长 <code>slop</code> 的短语查询，下面会有特别记录，见 <strong>误解 </strong>小节】。</p><p>如果在一个索引中已经给某些字段指定了分析器，则可以直接查看赋值文本给这个字段后的分析结果。例如索引 <code>my-index-post</code> 中的 <code>content</code> 字段已经被设置分析器为 <code>wordsEN</code>，此时假如把 <code>content</code> 赋值为文本 <code>出发，123，let&#39;s go！来自 iPhone8 的客户端。</code>，看看分析结果。</p><p>此时不需要用 <code>analyzer</code> 指定分析器了，直接用 <code>field</code> 指定字段名即可：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 出发，123，let&apos;s go！来自 iPhone8 的客户端。&quot;,</span><br><span class="line">  &quot;field&quot;:&quot;content&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="分析结果的误解"><a href="# 分析结果的误解" class="headerlink" title="分析结果的误解"></a>分析结果的误解 </h2><p> 上面在 <strong>查询 </strong>小节已经举了一个查询时指定分析器，可能会改变查询原义【人理解的含义】的例子，即查询时指定分析器可能会改变指定内容的分析结果【<code>着，我 </code> 变成了 <code> 着我 </code>】，这会在一定情况下引起误解。</p><p> 同理，索引数据时指定的分析器也会改变分析的结果【部分字符会被移除，造成分析结果的词元位置变化】，例如以下示例。</p><p>使用上面的自定义分析器，把带 <code>html</code> 标签的文本内容过滤，分析出来词元结果，然后利用纯中文的词组再去查询，虽然查询条件中没有指定完全一样的文本【不带 <code>html</code> 标签】，但是也可以匹配命中。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;terms&quot;: &#123;</span><br><span class="line">            &quot;id&quot;: [</span><br><span class="line">              &quot;1&quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;match&quot;: &#123;</span><br><span class="line">            &quot;content_custom_analyzer&quot;: &#123;</span><br><span class="line">              &quot;query&quot;: &quot; 晚安 & quot;,</span><br><span class="line">              &quot;type&quot;: &quot;phrase&quot;,</span><br><span class="line">              &quot;slop&quot;: 0,</span><br><span class="line">              &quot;analyzer&quot;: &quot;custom_analyzer&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200226191451.png" alt="查询结果" title="查询结果"></p><p>这就是因为分析结果的词元中已经没有了 <code>html</code> 标签【注意看词元的位置 <code>position</code>】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot;exo&quot;,</span><br><span class="line">      &quot;start_offset&quot;: 1,</span><br><span class="line">      &quot;end_offset&quot;: 4,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 朴 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 6,</span><br><span class="line">      &quot;end_offset&quot;: 7,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 灿 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 7,</span><br><span class="line">      &quot;end_offset&quot;: 8,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 烈 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 8,</span><br><span class="line">      &quot;end_offset&quot;: 9,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 晚 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 10,</span><br><span class="line">      &quot;end_offset&quot;: 11,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 4</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot;: &quot; 安 & quot;,</span><br><span class="line">      &quot;start_offset&quot;: 24,</span><br><span class="line">      &quot;end_offset&quot;: 25,</span><br><span class="line">      &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot;: 5</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20200226191617.png" alt="对比文本可能会有误解" title="对比文本可能会有误解"></p><p>如果用户只是查看 <code>content_custom_analyzer</code> 字段的内容，就很容易造成误解，可能会发出 <strong>文本明明不一致怎么会命中了呢 </strong>的疑问，背后其实是分析器在起作用。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 需要注意，<code>Elasticsearch</code> 节点层面的默认分析器设置已经废弃，不支持了，也就是说在 <code>elasticsearch.yml</code> 中配置如下内容无效，并且会导致 <code>Elasticsearch</code> 节点启动失败：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">index:</span><br><span class="line">  analysis:                  </span><br><span class="line">    analyzer:</span><br><span class="line">      simple_analyzer:</span><br><span class="line">        type: standard</span><br></pre></td></tr></table></figure><p>有关说明如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Found index level settings on node level configuration.</span><br><span class="line"></span><br><span class="line">Since elasticsearch 5.x index level settings can NOT be set on the nodes</span><br><span class="line">configuration like the elasticsearch.yaml, in system properties or command line</span><br><span class="line"></span><br><span class="line">arguments.In order to upgrade all indices the settings must be updated via the</span><br><span class="line">/$&#123;index&#125;/_settings API. Unless all settings are dynamic all indices must be clo</span><br><span class="line">sed</span><br><span class="line">in order to apply the upgradeIndices created in the future should use index temp</span><br><span class="line">lates</span><br><span class="line">to set default values.</span><br></pre></td></tr></table></figure><p>因此，建议在索引层面动态设置，即使用索引模版针对某些字段设置【参考上面的 <strong>实战演示 </strong>中举例】。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>analyzer</tag>
        <tag>wordsEN</tag>
        <tag>standard</tag>
        <tag>english</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 常用 HTTP 接口</title>
    <url>/2018051401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>本文记录工作中常用的关于 <code>Elasticsearch</code> 的 <code>HTTP</code> 接口，以作备用，读者也可以参考，会持续补充更新。开发环境基于 <code>Elasticsearch v5.6.8</code>、<code>v1.7.5</code>、<code>v2.x</code>。</p><a id="more"></a><h1 id="集群状态"><a href="# 集群状态" class="headerlink" title="集群状态"></a>集群状态 </h1><h2 id="集群信息"><a href="# 集群信息" class="headerlink" title="集群信息"></a> 集群信息 </h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cluster/stats?pretty</span><br><span class="line">http://localhost:9200/_cat/nodes</span><br><span class="line">http://localhost:9200/_cat/indices</span><br><span class="line">http://localhost:9200/_cluster/state</span><br><span class="line">http://localhost:9200/_cat/aliases</span><br></pre></td></tr></table></figure><p> 可以看到整个集群的索引数、分片数、文档数、内存使用等等信息。</p><h2 id="健康状况"><a href="# 健康状况" class="headerlink" title="健康状况"></a>健康状况 </h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cat/health?v</span><br></pre></td></tr></table></figure><p> 可以看到分片数量，状态【红、黄、绿】。</p><h2 id="空间使用"><a href="# 空间使用" class="headerlink" title="空间使用"></a>空间使用 </h2><p> 查询每个节点的空间使用情况，预估数据大小：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cat/allocation?v</span><br></pre></td></tr></table></figure><h2 id="分片分布"><a href="# 分片分布" class="headerlink" title="分片分布"></a>分片分布 </h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cat/shards</span><br></pre></td></tr></table></figure><h2 id="索引状态"><a href="# 索引状态" class="headerlink" title="索引状态"></a> 索引状态 </h2><p> 可以看到索引的数据条数、磁盘大小、分片个数【可以使用别名】。</p><p>各项指标解释说明参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/indices-stats.html" target="_blank" rel="noopener">indices-stats</a> 。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/your_index/_stats</span><br></pre></td></tr></table></figure><h2 id="集群配置信息"><a href="# 集群配置信息" class="headerlink" title="集群配置信息"></a>集群配置信息 </h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cluster/settings?pretty</span><br></pre></td></tr></table></figure><p> 对于一些可以设置的参数，临时生效，对于集群的管理很有帮助。</p><p>例如节点黑名单：<code>cluster.routing.allocation.exclude._ip</code>，临时下线节点，类似于黑名单，分片不会往指定的主机移动，同时会把分片从指定的节点全部移除，最终可以下线该节点，可通过 <code>put transient</code> 设置临时生效。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPUT 127.0.0.1:9200/_cluster/settings -d &apos;&#123;</span><br><span class="line">    &quot;transient&quot; :&#123;</span><br><span class="line">        &quot;cluster.routing.allocation.exclude._ip&quot; : &quot;192.168.0.1&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>例如临时关闭分片重分配【开启时设置值为 <code>all</code>】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPUT 127.0.0.1:9200/_cluster/settings -d &apos;&#123;</span><br><span class="line">    &quot;transient&quot;: &#123;</span><br><span class="line">        &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>设置慢索引阈值，指定索引进行操作，可以使用通配符：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPUT 127.0.0.1:9200/your_index_*/_settings -d &apos;&#123;</span><br><span class="line">  &quot;index.indexing.slowlog.threshold.index.info&quot;: &quot;10s&quot;</span><br><span class="line">&#125;&apos;&apos;</span><br></pre></td></tr></table></figure><p>设置慢查询阈值方式类似：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPUT 127.0.0.1:9200/your_index_*/_settings -d &apos;&#123;</span><br><span class="line">  &quot;index.indexing.slowlog.threshold.search.info&quot;: &quot;10s&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>推迟索引分片的重新分配时间平【适用于 <code>Elasticsearch</code> 节点短时间离线再加入集群，提前设置好这个参数，避免从分片的复制移动，降低网络 <code>IO</code>】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /your_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5m&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以使用索引别名、通配符设置，这样就可以一次性设置多个索引，甚至全部的索引。</p><h2 id="热点线程"><a href="# 热点线程" class="headerlink" title="热点线程"></a>热点线程 </h2><p> 查看热点线程，可以判断热点线程是 <code>search</code>，<code>bulk</code>，还是 <code>merge</code> 类型，从而进一步分析是查询还是写入导致 <code>CPU</code> 负载过高。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_nodes/node0/hot_threads</span><br><span class="line"></span><br><span class="line">http://localhost:9200/_nodes/hot_threads</span><br></pre></td></tr></table></figure><h2 id="请求队列"><a href="# 请求队列" class="headerlink" title="请求队列"></a>请求队列 </h2><p> 查看请求队列情况，可以看到每种类型请求的积压情况：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cat/thread_pool?v</span><br></pre></td></tr></table></figure><h2 id="节点配置信息"><a href="# 节点配置信息" class="headerlink" title="节点配置信息"></a>节点配置信息 </h2><p> 可以查看节点的 <code>JVM</code> 配置、插件信息、队列配置等等。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_nodes/node_id</span><br><span class="line">http://localhost:9200/_nodes?pretty=true</span><br><span class="line">http://localhost:9200/_nodes/stats/thread_pool?pretty=true</span><br></pre></td></tr></table></figure><p>注意，<code>thread_pool</code> 线程池相关参数自从 <code>v5.x</code> 以后不支持动态设置【即通过 <code>put</code> 接口】，只能通过更改节点的配置文件并重启节点来操作，这也说明了这个参数是对于节点生效，不同配置的节点可以设置不同的值。</p><h2 id="使用堆内存大小"><a href="# 使用堆内存大小" class="headerlink" title="使用堆内存大小"></a>使用堆内存大小 </h2><p> 使用 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cat/fielddata</span><br></pre></td></tr></table></figure><p> 查看当前集群中每个数据节点上被 <code>fielddata</code> 所使用的堆内存大小。</p><p>此外还可以指定字段 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_cat/fielddata?v&amp;fields=uid&amp;pretty</span><br><span class="line">http://localhost:9200/_cat/fielddata/uid?v&amp;pretty</span><br></pre></td></tr></table></figure><p> 按照节点、索引来查询：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 按照索引、分片 </span><br><span class="line">http://localhost:9200/_stats/fielddata?fields=*</span><br><span class="line"></span><br><span class="line"> 按照节点 </span><br><span class="line">http://localhost:9200/_nodes/stats/indices/fielddata?fields=*</span><br><span class="line"></span><br><span class="line"> 按照节点、索引分片 </span><br><span class="line">http://localhost:9200/_nodes/stats/indices/fielddata?level=indices&amp;fields=*</span><br><span class="line">http://localhost:9200/_nodes/stats/indices/fielddata?level=indices&amp;fields=_uid</span><br></pre></td></tr></table></figure><h2 id="清理缓存"><a href="# 清理缓存" class="headerlink" title="清理缓存"></a>清理缓存 </h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl localhost:9200/index/_cache/clear?pretty&amp;filter=false&amp;field_data=true&amp;fields=_uid,site_name</span><br><span class="line"></span><br><span class="line"> 关于 `&amp;bloom=false` 参数的问题，要看当前 `Elasticsearch` 版本是否支持，`v5.6.x` 是不支持了。</span><br></pre></td></tr></table></figure><h1 id="分析器"><a href="# 分析器" class="headerlink" title="分析器"></a> 分析器 </h1><p> 可以查看不同分析器的分词结果，或者基于某个索引的某个字段查看分词结果。下面列举一些例子，其它更多的内容请读者参考另外一篇博客：<a href="https://www.playpi.org/2017082001.html">Elasticsearch 分析器使用入门指南 </a> 。</p><p> 查看集群安装的各种分词器效果，指定文本内容、分词器即可：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 行完成，是否成功请查看 ccc&quot;,</span><br><span class="line">  &quot;analyzer&quot;:&quot;wordsEN&quot;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 行完成，是否成功请查看 ccc&quot;,</span><br><span class="line">  &quot;analyzer&quot;:&quot;standard&quot;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 行完成，是否成功请查看 ccc&quot;,</span><br><span class="line">  &quot;analyzer&quot;:&quot;english&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看某个索引的某个字段的分词器效果【索引已经指定分词器，可以通过 <code>mapping</code> 查看】，指定索引名称、文本内容、字段名称，不要指定索引的 <code>type</code>，否则请求变为了新建文档：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;:&quot; 行完成，是否成功请查看 ccc&quot;,</span><br><span class="line">  &quot;field&quot;:&quot;content&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询时也可以指定分词器【不同分词器会影响返回的结果，例如 <code>standard</code> 分词器会过滤掉标点符号，所以查不到数据】，特别指定分词器即可。另外只能使用 <code>match</code>，不能使用 <code>match_phrase</code>。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;content&quot;:&#123;</span><br><span class="line">        &quot;query&quot;: &quot;，&quot;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="创建索引"><a href="# 创建索引" class="headerlink" title="创建索引"></a>创建索引 </h1><p> 创建带 <code>mapping</code> 的索引：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /my-index-post/</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index.number_of_shards&quot;: 3,</span><br><span class="line">    &quot;index.number_of_replicas&quot;: 1,</span><br><span class="line">    &quot;index.refresh_interval&quot;: &quot;30s&quot;,</span><br><span class="line">    &quot;index.routing.allocation.total_shards_per_node&quot;: 3</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;post&quot;: &#123;</span><br><span class="line">      &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;title1&quot;: &#123;</span><br><span class="line">            &quot;match&quot;: &quot;title&quot;,</span><br><span class="line">            &quot;match_mapping_type&quot;: &quot;*&quot;,</span><br><span class="line">            &quot;mapping&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">              &quot;analyzer&quot;: &quot;wordsEN&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建带 <code>mapping</code> 的 <code>type</code>【在索引已经存在的情况下】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /my-index-post/_mapping/post/</span><br><span class="line">&#123;</span><br><span class="line">    &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;title1&quot;: &#123;</span><br><span class="line">                &quot;mapping&quot;: &#123;</span><br><span class="line">                    &quot;analyzer&quot;: &quot;wordsEN&quot;,</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;match&quot;: &quot;title&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;title2&quot;: &#123;</span><br><span class="line">                &quot;mapping&quot;: &#123;</span><br><span class="line">                    &quot;analyzer&quot;: &quot;wordsEN&quot;,</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;match&quot;: &quot;*_title&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;avatar_url&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更新索引的 <code>mapping</code>【在索引、类型都已经存在的情况下】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /my-index-post/_mapping/post</span><br><span class="line">&#123;</span><br><span class="line">  &quot;post&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;title&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;english&quot;,</span><br><span class="line">        &quot;search_analyzer&quot;: &quot;standard&quot; </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="添加删除别名"><a href="# 添加删除别名" class="headerlink" title="添加删除别名"></a>添加删除别名 </h1><p> 给索引增加别名：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">  &quot;actions&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;add&quot;: &#123;</span><br><span class="line">        &quot;index&quot;: &quot;my-index-post&quot;,</span><br><span class="line">        &quot;alias&quot;: &quot;my-index-post-all&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>移除索引的别名：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">  &quot;actions&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;remove&quot;: &#123;</span><br><span class="line">        &quot;index&quot;: &quot;my-index-post&quot;,</span><br><span class="line">        &quot;alias&quot;: &quot;my-index-post-all&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="导入数据"><a href="# 导入数据" class="headerlink" title="导入数据"></a>导入数据 </h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 把文件中的数据导入索引，批量的形式 </span><br><span class="line"> 由于数据中可能存在一些特殊符号，所以使用文件的形式，in 为文件路径 </span><br><span class="line"> 文件内容格式，1 条数据需要包含 2 行内容，index 表示索引数据 </span><br><span class="line">&#123;&quot;index&quot;:&#123;&#125;&#125;</span><br><span class="line">JSON 原始数据 </span><br><span class="line"></span><br><span class="line">curl -XPOST &apos;http://localhost:9200/my-index-post/post/_bulk&apos; --data-binary @&quot;$in&quot;</span><br></pre></td></tr></table></figure><p><code>bulk</code> 接口，详情参考另外一篇博客：<a href="https://www.playpi.org/2019101701.html"> 使用 Elasticsearch 的 bulk 接口批量导入数据 </a> 。</p><h1 id="查询数据"><a href="# 查询数据" class="headerlink" title="查询数据"></a> 查询数据 </h1><h2 id="脚本查询"><a href="# 脚本查询" class="headerlink" title="脚本查询"></a> 脚本查询 </h2><p><code>Elasticsearch</code> 提供了脚本的支持，可以通过 <code>Groovy</code> 外置脚本【已经过时，<code>v6.x</code> 以及之后的版本，不建议使用】、内置 <code>painless</code> 脚本实现各种复杂的操作【类似于写逻辑代码，对数据进行 <code>ETL</code> 操作，需要集群配置开启】。</p><p> 以下是关于 <code>v2.x</code> 的说明：</p><blockquote><p>默认的脚本语言是 Groovy，一种快速表达的脚本语言，在语法上与 JavaScript 类似。它在 Elasticsearch v1.3.0 版本首次引入并运行在沙盒中，然而 Groovy 脚本引擎存在漏洞，允许攻击者通过构建 Groovy 脚本，在 Elasticsearch Java VM 运行时脱离沙盒并执行 shell 命令。<br>因此，在版本 v1.3.8、1.4.3 和 v1.5.0 及更高的版本中，它已经被默认禁用。此外，您可以通过设置集群中的所有节点的 config/elasticsearch.yml 文件来禁用动态 Groovy 脚本：script.groovy.sandbox.enabled: false，这将关闭 Groovy 沙盒，从而防止动态 Groovy 脚本作为请求的一部分被接受。</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Groovy 脚本 </span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;script&quot;: &#123;</span><br><span class="line">          &quot;script&quot;: &quot;doc [&apos;keywords&apos;].values.length == 2&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">painless 脚本 </span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;script&quot;: &#123;</span><br><span class="line">          &quot;script&quot;: &#123;</span><br><span class="line">            &quot;source&quot;: &quot;doc [&apos;keywords&apos;].values.length == 2&quot;,</span><br><span class="line">            &quot;lang&quot;: &quot;painless&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="日期桶聚合"><a href="# 日期桶聚合" class="headerlink" title="日期桶聚合"></a>日期桶聚合 </h2><p> 对日期格式的字段做桶聚合，可以使用 <code>interval</code> 设置桶间隔，使用 <code>extended_bounds</code> 设置桶边界，其它还可以设置时区、<code>doc</code> 过滤等。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;by_month&quot;: &#123;</span><br><span class="line">      &quot;date_histogram&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;publish_timestamp&quot;,</span><br><span class="line">        &quot;interval&quot;: &quot;day&quot;,</span><br><span class="line">        &quot;time_zone&quot;: &quot;+08:00&quot;,</span><br><span class="line">        &quot;format&quot;: &quot;yyyy-MM-dd&quot;,</span><br><span class="line">        &quot;min_doc_count&quot;: 100000,</span><br><span class="line">        &quot;extended_bounds&quot;: &#123;</span><br><span class="line">          &quot;min&quot;: &quot;2019-08-30&quot;,</span><br><span class="line">          &quot;max&quot;: &quot;2019-09-24&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>对于聚合结果不准的问题，可以增加参数，适当提高准确性。<code>size</code> 参数规定了最后返回的 <code>term</code> 个数【默认是 10 个】，<code>shard_size</code> 参数规定了每个分片上返回的个数【默认是 <code>size * 1.5 + 10</code>】，如果 <code>shard_size</code> 小于 <code>size</code>，那么分片也会按照 <code>size</code> 指定的个数计算。</p><p>聚合的字段可能存在一些频率很低的词条，如果这些词条数目比例很大，那么就会造成很多不必要的计算。因此可以通过设置 <code>min_doc_count</code> 和 <code>shard_min_doc_count</code> 来规定最小的文档数目，只有满足这个参数要求的个数的词条才会被记录返回。<code>min_doc_count</code>：规定了最终结果的筛选，<code>shard_min_doc_count</code>：规定了分片中计算返回时的筛选。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;aggs&quot;: &#123;</span><br><span class="line">  &quot;aggs_sentiment&quot;:&#123;</span><br><span class="line">    &quot;terms&quot;: &#123;</span><br><span class="line">      &quot;field&quot;: &quot;sentiment&quot;,</span><br><span class="line">      &quot;size&quot;: 10,</span><br><span class="line">      &quot;shard_size&quot;: 30,</span><br><span class="line">      &quot;min_doc_count&quot;: 10000,</span><br><span class="line">      &quot;shard_min_doc_count&quot;: 50</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="更新文档"><a href="# 更新文档" class="headerlink" title="更新文档"></a>更新文档 </h2><p> 指定部分字段进行更新，不影响其它字段【但是要注意，如果字段只是索引 <code>index</code> 而没有存储 <code>_source</code>，更新后会无法查询这个字段】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /my-index-user/user/0f42d65be1f5287e1c9c26e3728814aa/_update</span><br><span class="line">&#123;</span><br><span class="line">   &quot;doc&quot; : &#123;</span><br><span class="line">      &quot;friends&quot; : [&quot;98681482902&quot;,&quot;63639783663&quot;,&quot;59956667929&quot;]</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="自动缓存相关"><a href="# 自动缓存相关" class="headerlink" title="自动缓存相关"></a>自动缓存相关 </h2><p><code>terms lookup</code> 查询：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 自动缓存 </span><br><span class="line">POST my-index-post/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;terms&quot;: &#123;</span><br><span class="line">      &quot;user_item_id&quot;:&#123;</span><br><span class="line">          &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">          &quot;type&quot;: &quot;user&quot;,</span><br><span class="line">          &quot;id&quot;: &quot;0f42d65be1f5287e1c9c26e3728814aa&quot;,</span><br><span class="line">          &quot;path&quot;: &quot;friends&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 操作缓存的接口：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 关闭缓存 </span><br><span class="line">curl -XPOST &apos;localhost:9200/_cache/clear?filter_path=your_cache_key&apos;</span><br></pre></td></tr></table></figure><h2 id="多层嵌套反转桶聚合"><a href="# 多层嵌套反转桶聚合" class="headerlink" title="多层嵌套反转桶聚合"></a>多层嵌套反转桶聚合 </h2><p> 多层聚合查询，关于嵌套、反转，参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/nested-aggregation.html" target="_blank" rel="noopener">nested-aggregation</a> 。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST combine-paas-1003-index/2723-data/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;x&quot;: &#123;</span><br><span class="line">            &quot;aggs&quot;: &#123;</span><br><span class="line">                &quot;xx&quot;: &#123;</span><br><span class="line">                    &quot;aggs&quot;: &#123;</span><br><span class="line">                        &quot;xxx&quot;: &#123;</span><br><span class="line">                            &quot;aggs&quot;: &#123;</span><br><span class="line">                                &quot;xxxx_interaction_cnt&quot;: &#123;</span><br><span class="line">                                    &quot;sum&quot;: &#123;</span><br><span class="line">                                        &quot;field&quot;: &quot;2723_interaction_cnt&quot;</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;,</span><br><span class="line">                            &quot;reverse_nested&quot;: &#123;&#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;terms&quot;: &#123;</span><br><span class="line">                        &quot;field&quot;: &quot;Titan_sports.yundongerji&quot;,</span><br><span class="line">                        &quot;size&quot;: 100</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;nested&quot;: &#123;</span><br><span class="line">                &quot;path&quot;: &quot;Titan_sports&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;must&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;term&quot;: &#123;</span><br><span class="line">                        &quot;2723_is_noise&quot;: &#123;</span><br><span class="line">                            &quot;value&quot;: &quot; 否 & quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;size&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="统计个数聚合"><a href="# 统计个数聚合" class="headerlink" title="统计个数聚合"></a>统计个数聚合 </h2><p> 对于多篇文章，统计每个站点下面的作者个数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 多层嵌套以及特殊的聚合，每个 site_name 下面的作者个数统计 </span><br><span class="line">&#123;</span><br><span class="line">    &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;s&quot;: &#123;</span><br><span class="line">            &quot;aggs&quot;: &#123;</span><br><span class="line">                &quot;a&quot;: &#123;</span><br><span class="line">                    &quot;cardinality&quot;: &#123;</span><br><span class="line">                        &quot;field&quot;: &quot;author&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;terms&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;site_name&quot;,</span><br><span class="line">                &quot;size&quot;: 0</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;query&quot;: &#123;&#125;,</span><br><span class="line">    &quot;size&quot;: 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="存在查询"><a href="# 存在查询" class="headerlink" title="存在查询"></a>存在查询 </h2><p><code>exists</code>、<code>missing</code> 这两类查询在不同的版本之间使用方式不一致。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 存在、不存在判断条件，1.7.5 版本和 2.3.4 版本的方式不一样 </span><br><span class="line">-- 2.3.4：使用 exists、missing 关键字即可 </span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;exists&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;gender&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;missing&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;gender&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">-- 更高版本【v5.x 以及以上】的 ES 关键字 missing 已经被废弃，改为 must_not 和 exists 组合查询，以下有示例 </span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;must_not&quot;: &#123;</span><br><span class="line">                &quot;exists&quot;: &#123;</span><br><span class="line">                    &quot;field&quot;: &quot;user&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">-- 1.7.5：使用 filter 后再使用对应关键词，本质是一种过滤器 </span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;filtered&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;exists&quot;: &#123;</span><br><span class="line">          &quot;field&quot;: &quot;data_type&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">-- 此外，不同版本连接 ES 的 client 方式也不一样【tcp 连接，如果是 http 连接就不会有问题】，代码不能兼容，所以只能使用其中 1 种方式【在本博客中可以搜索到相关总结】</span><br></pre></td></tr></table></figure><h1 id="删除数据"><a href="# 删除数据" class="headerlink" title="删除数据"></a> 删除数据 </h1><p> 根据查询条件删除数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my-index-post/post/_delete_by_query/</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;terms&quot;: &#123;</span><br><span class="line">      &quot;id&quot;: [</span><br><span class="line">        &quot;1&quot;,</span><br><span class="line">        &quot;2&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，如果是低版本的 <code>Elasticsearch</code>，在 <code>1.x</code> 的版本中还可以使用发送 <code>DELETE</code> 请求的方式删除数据，容易引发一些操作失误，不建议使用。</p><p>更多内容参考：<a href="https://www.playpi.org/2018022401.html">Elasticsearch 根据查询条件删除数据的 API</a> 。</p><h1 id="索引关闭开启"><a href="# 索引关闭开启" class="headerlink" title="索引关闭开启"></a>索引关闭开启 </h1><p> 主要有两个接口：</p><ul><li>开启索引，<code>curl -XPOST http://localhost:9200/your_index/_open</code></li><li>关闭索引，<code>curl -XPOST http://localhost:9200/your_index/_close</code></li></ul><p>参考这篇博客的部分内容：<a href="https://www.playpi.org/2019082101.html">使用 http 接口删除 Elasticsearch 集群的索引 </a> 。</p><h1 id="迁移数据"><a href="# 迁移数据" class="headerlink" title="迁移数据"></a> 迁移数据 </h1><p> 迁移一个索引的数据到另外一个索引，切记需要提前创建好索引，包含 <code>mapping</code>，避免字段类型出问题：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-post&quot;,</span><br><span class="line">    &quot;type&quot;: &quot;post&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-post-bak&quot;,</span><br><span class="line">    &quot;type&quot;: &quot;post&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> 查看任务状态，取消任务 </span><br><span class="line"></span><br><span class="line">GET _tasks?detailed=true&amp;actions=*reindex</span><br><span class="line"></span><br><span class="line">POST _tasks/task_id:1/_cancel</span><br></pre></td></tr></table></figure><p>此外，参考：<a href="https://www.playpi.org/2020011601.html">Elasticsearch 的 Reindex API 详解 </a> ，里面包含了常见的参数使用方式，以及查看迁移任务进度、取消迁移任务的方式。</p><h1 id="移动分片"><a href="# 移动分片" class="headerlink" title="移动分片"></a> 移动分片 </h1><p> 需要先关闭 <code>rebalance</code>，再手动移动分片，否则由于手动迁移分片造成集群进行分片的重新分配，进而消耗 <code>IO</code>、<code>CPU</code> 资源。手动迁移分片完成之后，再打开 <code>rebalance</code>，让集群自行进行重新分配管理。</p><p>临时参数设置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 关闭 </span><br><span class="line">curl -XPUT &apos;localhost:9200/_cluster/settings&apos; -d</span><br><span class="line">&apos;&#123;</span><br><span class="line">  &quot;transient&quot;: &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"> 打开 </span><br><span class="line">curl -XPUT &apos;localhost:9200/_cluster/settings&apos; -d</span><br><span class="line">&apos;&#123;</span><br><span class="line">  &quot;transient&quot;: &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>分片的迁移使用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">move：移动分片 </span><br><span class="line">cancel：取消分片 </span><br><span class="line">allocate：重新分配分片 </span><br><span class="line"></span><br><span class="line">curl -XPOST &apos;localhost:9200/_cluster/reroute&apos; -d &apos;&#123;</span><br><span class="line">    &quot;commands&quot; : [&#123;</span><br><span class="line">        &quot;move&quot; :</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 0,</span><br><span class="line">              &quot;from_node&quot; : &quot;node1&quot;, &quot;to_node&quot; : &quot;node2&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">       &quot;cancel&quot; :</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 0, &quot;node&quot; : &quot;node1&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;allocate&quot; : &#123;</span><br><span class="line">              &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 1, &quot;node&quot; : &quot;node3&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"> 将分配失败的分片重新分配 </span><br><span class="line">curl -XGET &apos;localhost:9200/_cluster/reroute?retry_failed=true&apos;</span><br></pre></td></tr></table></figure><p>注意，<code>allocate</code> 命令还有一个参数，<code>&quot;allow_primary&quot; : true</code>，即允许该分片做主分片，但是这样可能会造成数据丢失【在不断写入数据的时候】，因此要慎用【如果数据在分配过程中是静态的则可以考虑使用】。</p><p>当然，手动操作需要在熟悉集群的 <code>API</code> 使用的情况下，例如需要获取节点、索引、分片的信息，不然的话不知道参数怎么填写、分片怎么迁移。此时可以使用 <code>Head</code>、<code>kopf</code>、<code>Cerebro</code> 等可视化工具进行查看，比较适合运维人员，而且，分片的迁移指挥工作也可以交给这些工具，只要通过鼠标点击就可以完成分片的迁移，很方便。</p><h1 id="验证"><a href="# 验证" class="headerlink" title="验证"></a>验证 </h1><p> 检验查询语句的合法性，不仅仅是满足 <code>JSON</code> 格式那么简单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /my-index-post/_validate/query?explain</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;content&quot;:&#123;</span><br><span class="line">        &quot;query&quot;: &quot;，&quot;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;wordsEN&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>检查分片分配的相关信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 不带任何参数执行该命令，会输出当前所有未分配分片的失败原因 </span><br><span class="line">curl -XGET &apos;localhost:9200/_cluster/allocation/explain</span><br><span class="line"></span><br><span class="line"> 该命令可查看指定分片当前所在节点以及分配到该节点的理由，和未分配到其他节点的原因 </span><br><span class="line">curl -XPOST &apos;localhost:9200/_cluster/reroute&apos; -d &apos;&#123;</span><br><span class="line">    &quot;index&quot;: &lt; 索引名 & gt;,</span><br><span class="line">    &quot;shard&quot;: &lt; 分片号 & gt;,</span><br><span class="line">    &quot;primary&quot;: true/false</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>HTTP</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase 错误之 NoClassDefFoundError：ProtobufUtil</title>
    <url>/2019093001.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>背景说明：通过 <code>dubbo</code> 部署一个服务，服务中的业务逻辑会查询 <code>HBase</code> 表的数据，但是 <code>dubbo</code> 服务在初始化注册时，<code>HBase</code> 初始化的过程中会报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.protobuf.ProtobufUtil</span><br></pre></td></tr></table></figure><p>本文涉及的开发环境，基于 <code>HBase v1.1.2</code>、<code>Zookeeper v3.4.6</code>、<code>dubbo v2.8.4</code>、<code>Hadoop v2.7.1</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 通过 <code>k8s</code> 多节点发布服务，但是只有在某一台机器上面出现错误【其它节点日志显示正常，也可以提供正常的服务】，发布后 <code>dubbo</code> 服务注册初始化时出现的错误如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-09-19_18:03:49 [http-nio-28956-exec-2-SendThread (192.168.20.101:2181)] INFO zookeeper.ClientCnxn:852: Socket connection established to 192.168.20.101/192.168.20.101:2181, initiating session</span><br><span class="line">2019-09-19_18:03:49 [http-nio-28956-exec-2-SendThread (192.168.20.101:2181)] INFO zookeeper.ClientCnxn:1235: Session establishment complete on server 192.168.20.101/192.168.20.101:2181, sessionid = 0x36af032f505e830, negotiated timeout = 90000</span><br><span class="line">2019-09-19_18:03:50 [http-nio-28956-exec-2] WARN hdfs.DFSUtil:689: Namenode for hdfs-cluster remains unresolved for ID nn1.  Check your hdfs-site.xml file to ensure namenodes are configured properly.</span><br><span class="line">2019-09-19_18:03:50 [http-nio-28956-exec-9] ERROR filter.ExceptionFilter:87:  [DUBBO] Got unchecked and undeclared exception which called by 10.200.0.2. service: com.yyy.zzz.service.es.weibo.IXxxService, method: search, exception: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.protobuf.ProtobufUtil, dubbo version: 2.8.4, current host: 127.0.0.1</span><br><span class="line">java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.protobuf.ProtobufUtil</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState (MetaTableLocator.java:482)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation (MetaTableLocator.java:167)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:598)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:579)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:558)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation (ZooKeeperRegistry.java:61)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta (ConnectionManager.java:1192)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1159)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.relocateRegion (ConnectionManager.java:1133)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta (ConnectionManager.java:1338)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1162)</span><br><span class="line">	at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.findAllLocationsOrFail (AsyncProcess.java:940)</span><br><span class="line">	at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.groupAndSendMultiAction (AsyncProcess.java:857)</span><br><span class="line">	at org.apache.hadoop.hbase.client.AsyncProcess$AsyncRequestFutureImpl.access$100 (AsyncProcess.java:575)</span><br><span class="line">	at org.apache.hadoop.hbase.client.AsyncProcess.submitAll (AsyncProcess.java:557)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.batch (HTable.java:933)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.batch (HTable.java:950)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:911)</span><br><span class="line">	at com.yyy.zzz.commons.search.reader.hbase.BaseHBaseReader.batchGet (BaseHBaseReader.java:94)</span><br><span class="line">	at com.yyy.zzz.commons.search.reader.hbase.weibo.WeiboContentHbaseReader.batchGet (WeiboContentHbaseReader.java:98)</span><br><span class="line">	at com.yyy.zzz.commons.search.searcher.AbstractBaseSearcher.getContent (AbstractBaseSearcher.java:269)</span><br><span class="line">	at com.yyy.zzz.commons.search.searcher.AbstractBaseSearcher.getInfo (AbstractBaseSearcher.java:188)</span><br><span class="line">	at com.yyy.zzz.runner.search.BaseSearchRunner.search (BaseSearchRunner.java:89)</span><br><span class="line">	at com.yyy.zzz.api.weibo.WeiboContentServiceImpl.search (WeiboContentServiceImpl.java:33)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.Wrapper3.invokeMethod (Wrapper3.java)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke (JavassistProxyFactory.java:46)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke (AbstractProxyInvoker.java:72)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke (InvokerWrapper.java:53)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke (ExceptionFilter.java:64)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke (MonitorFilter.java:75)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke (TimeoutFilter.java:42)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke (TraceFilter.java:78)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke (ContextFilter.java:70)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke (GenericFilter.java:132)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke (ClassLoaderFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke (EchoFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke (InvokerInvocationHandler.java:52)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.proxy1.search (proxy1.java)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">	at org.jboss.resteasy.core.MethodInjectorImpl.invoke (MethodInjectorImpl.java:137)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget (ResourceMethodInvoker.java:288)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:242)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:229)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:356)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:179)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service (ServletContainerDispatcher.java:220)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:56)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:51)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.rest.DubboHttpServer$RestHandler.handle (DubboHttpServer.java:86)</span><br><span class="line">	at com.alibaba.dubbo.remoting.http.servlet.DispatcherServlet.service (DispatcherServlet.java:64)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter (ApplicationFilterChain.java:291)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.doFilter (ApplicationFilterChain.java:206)</span><br><span class="line">	at org.apache.catalina.core.StandardWrapperValve.invoke (StandardWrapperValve.java:219)</span><br><span class="line">	at org.apache.catalina.core.StandardContextValve.invoke (StandardContextValve.java:106)</span><br><span class="line">	at org.apache.catalina.authenticator.AuthenticatorBase.invoke (AuthenticatorBase.java:504)</span><br><span class="line">	at org.apache.catalina.core.StandardHostValve.invoke (StandardHostValve.java:142)</span><br><span class="line">	at org.apache.catalina.valves.ErrorReportValve.invoke (ErrorReportValve.java:79)</span><br><span class="line">	at org.apache.catalina.core.StandardEngineValve.invoke (StandardEngineValve.java:88)</span><br><span class="line">	at org.apache.catalina.connector.CoyoteAdapter.service (CoyoteAdapter.java:534)</span><br><span class="line">	at org.apache.coyote.http11.AbstractHttp11Processor.process (AbstractHttp11Processor.java:1081)</span><br><span class="line">	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process (AbstractProtocol.java:658)</span><br><span class="line">	at org.apache.coyote.http11.Http11NioProtocol$Http11ConnectionHandler.process (Http11NioProtocol.java:222)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun (NioEndpoint.java:1566)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run (NioEndpoint.java:1523)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run (TaskThread.java:61)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br></pre></td></tr></table></figure><p>注意查看重点的内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-09-19_18:03:50 [http-nio-28956-exec-2] WARN hdfs.DFSUtil:689: Namenode for hdfs-cluster remains unresolved for ID nn1.  Check your hdfs-site.xml file to ensure namenodes are configured properly.</span><br><span class="line">java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.protobuf.ProtobufUtil</span><br></pre></td></tr></table></figure><p>第一行是 <code>hdfs</code> 无法解析 <code>HA</code> 的域名，应该是系统环境问题；第二行是 <code>HBase</code> 初始化环境失败，看起来像是缺失依赖包或者依赖包冲突导致的 <code>NoClassDefFoundError</code>。</p><p>同时还出现了未知主机名异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">com.yyy.zzz.exception.es.EsConnException: java.net.UnknownHostException: host40: Temporary failure in name resolution</span><br><span class="line">	at com.yyy.zzz.commons.infrastructure.client.EsClient.&lt;init&gt;(EsClient.java:46)</span><br><span class="line">	at com.yyy.zzz.commons.infrastructure.client.EsClient.getInstance (EsClient.java:57)</span><br><span class="line">	at com.yyy.zzz.commons.search.searcher.AbstractBaseSearcher.&lt;init&gt;(AbstractBaseSearcher.java:69)</span><br><span class="line">	at com.yyy.zzz.commons.search.searcher.weibo.WeiboContentSearcher.&lt;init&gt;(WeiboContentSearcher.java:14)</span><br><span class="line">	at com.yyy.zzz.commons.search.searcher.weibo.WeiboContentSearcher.getInstance (WeiboContentSearcher.java:22)</span><br><span class="line">	at com.yyy.zzz.runner.search.weibo.WeiboContentSearchRunner.&lt;init&gt;(WeiboContentSearchRunner.java:26)</span><br><span class="line">	at com.yyy.zzz.runner.search.weibo.WeiboContentSearchRunner.&lt;init&gt;(WeiboContentSearchRunner.java:20)</span><br><span class="line">	at com.yyy.zzz.api.weibo.WeiboContentServiceImpl.search (WeiboContentServiceImpl.java:32)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.Wrapper3.invokeMethod (Wrapper3.java)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke (JavassistProxyFactory.java:46)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke (AbstractProxyInvoker.java:72)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke (InvokerWrapper.java:53)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke (ExceptionFilter.java:64)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke (MonitorFilter.java:75)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke (TimeoutFilter.java:42)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke (TraceFilter.java:78)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke (ContextFilter.java:70)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke (GenericFilter.java:132)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke (ClassLoaderFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke (EchoFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke (InvokerInvocationHandler.java:52)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.proxy1.search (proxy1.java)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">	at org.jboss.resteasy.core.MethodInjectorImpl.invoke (MethodInjectorImpl.java:137)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget (ResourceMethodInvoker.java:288)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:242)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:229)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:356)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:179)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service (ServletContainerDispatcher.java:220)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:56)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:51)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.rest.DubboHttpServer$RestHandler.handle (DubboHttpServer.java:86)</span><br><span class="line">	at com.alibaba.dubbo.remoting.http.servlet.DispatcherServlet.service (DispatcherServlet.java:64)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter (ApplicationFilterChain.java:291)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.doFilter (ApplicationFilterChain.java:206)</span><br><span class="line">	at org.apache.catalina.core.StandardWrapperValve.invoke (StandardWrapperValve.java:219)</span><br><span class="line">	at org.apache.catalina.core.StandardContextValve.invoke (StandardContextValve.java:106)</span><br><span class="line">	at org.apache.catalina.authenticator.AuthenticatorBase.invoke (AuthenticatorBase.java:504)</span><br><span class="line">	at org.apache.catalina.core.StandardHostValve.invoke (StandardHostValve.java:142)</span><br><span class="line">	at org.apache.catalina.valves.ErrorReportValve.invoke (ErrorReportValve.java:79)</span><br><span class="line">	at org.apache.catalina.core.StandardEngineValve.invoke (StandardEngineValve.java:88)</span><br><span class="line">	at org.apache.catalina.connector.CoyoteAdapter.service (CoyoteAdapter.java:534)</span><br><span class="line">	at org.apache.coyote.http11.AbstractHttp11Processor.process (AbstractHttp11Processor.java:1081)</span><br><span class="line">	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process (AbstractProtocol.java:658)</span><br><span class="line">	at org.apache.coyote.http11.Http11NioProtocol$Http11ConnectionHandler.process (Http11NioProtocol.java:222)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun (NioEndpoint.java:1566)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run (NioEndpoint.java:1523)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run (TaskThread.java:61)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">Caused by: java.net.UnknownHostException: host40: Temporary failure in name resolution</span><br><span class="line">	at java.net.Inet6AddressImpl.lookupAllHostAddr (Native Method)</span><br><span class="line">	at java.net.InetAddress$2.lookupAllHostAddr (InetAddress.java:928)</span><br><span class="line">	at java.net.InetAddress.getAddressesFromNameService (InetAddress.java:1323)</span><br><span class="line">	at java.net.InetAddress.getAllByName0 (InetAddress.java:1276)</span><br><span class="line">	at java.net.InetAddress.getAllByName (InetAddress.java:1192)</span><br><span class="line">	at java.net.InetAddress.getAllByName (InetAddress.java:1126)</span><br><span class="line">	at java.net.InetAddress.getByName (InetAddress.java:1076)</span><br><span class="line">	at com.yyy.zzz.commons.infrastructure.client.EsClient.&lt;init&gt;(EsClient.java:43)</span><br><span class="line">	... 64 more</span><br></pre></td></tr></table></figure><p>同时，在之后的请求中，只要是转发到这个服务节点的请求，就会出现如下错误：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">com.yyy.zzz.exception.hbase.HBaseException: java.lang.reflect.InvocationTargetException</span><br><span class="line">Caused by: java.io.IOException: java.lang.reflect.InvocationTargetException</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection (ConnectionFactory.java:240)</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionManager.createConnection (ConnectionManager.java:433)</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionManager.createConnection (ConnectionManager.java:426)</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal (ConnectionManager.java:304)</span><br><span class="line">    at org.apache.hadoop.hbase.client.HTable.&lt;init&gt;(HTable.java:185)</span><br><span class="line">    at org.apache.hadoop.hbase.client.HTableFactory.createHTableInterface (HTableFactory.java:41)</span><br><span class="line">    ... 18 more</span><br></pre></td></tr></table></figure><p>通过排查代码，这个异常是在业务逻辑代码连接 <code>HBase</code> 表取数时出现的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hTableInterface.get (List&lt;Get&gt;)</span><br></pre></td></tr></table></figure><p>每一次连接 <code>HBase</code> 取数，都会有这个异常出现。</p><h1 id="问题排查"><a href="# 问题排查" class="headerlink" title="问题排查"></a>问题排查 </h1><p> 首先怀疑的是 <code>protobuf</code> 版本冲突问题，但是通过对比，发现只有一个确定版本的 <code>jar</code> 包，而且对比其它节点，并没有这个问题出现，最终否定了这个猜测。</p><p>接着尝试发送多次请求，查看日志，以下错误不再出现【也很合理，这些异常是在服务注册初始化时只出现一次】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.protobuf.ProtobufUtil</span><br><span class="line">com.yyy.zzz.exception.es.EsConnException: java.net.UnknownHostException: host40: Temporary failure in name resolution</span><br></pre></td></tr></table></figure><p>反而出现的全部是 <code>HBase</code> 取数异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">com.yyy.zzz.exception.hbase.HBaseException: java.lang.reflect.InvocationTargetException</span><br><span class="line">Caused by: java.io.IOException: java.lang.reflect.InvocationTargetException</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection (ConnectionFactory.java:240)</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionManager.createConnection (ConnectionManager.java:433)</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionManager.createConnection (ConnectionManager.java:426)</span><br><span class="line">    at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal (ConnectionManager.java:304)</span><br><span class="line">    at org.apache.hadoop.hbase.client.HTable.&lt;init&gt;(HTable.java:185)</span><br><span class="line">    at org.apache.hadoop.hbase.client.HTableFactory.createHTableInterface (HTableFactory.java:41)</span><br><span class="line">    ... 18 more</span><br></pre></td></tr></table></figure><p>更神奇的是，只在一台节点上面有问题，其它相同功能的节点没问题。</p><p>最终，通过运维排查，从 <code>NoClassDefFoundError</code> 以及 <code>UnknownHostException</code> 发现了异常原因：在某个时间点发布服务时，恰好此时机器负载过高，导致 <code>DNS</code> 解析异常，于是 <code>dubbo</code> 服务在注册时无法获取 <code>hdfs</code> 信息。而 <code>HBase</code> 在初始化时需要依赖 <code>hdfs</code> 上面的某个 <code>hbase.version</code> 文件【用来确定 <code>HBase</code> 的版本】，导致 <code>HBase</code> 在初始化时无法找到这个文件，也就无法确定版本，最终没有加载 <code>ProtobufUtil</code> 类文件。</p><p><code>hdfs-site.xml</code> 配置文件中的重要内容如下，<code>nn1</code> 节点无法被识别：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.namenodes.hdfs-cluster&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn1,nn2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><code>hbase-site.xml</code> 配置文件中的重要内容如下，对于 <code>HBase</code> 来说，这个 <code>hdfs</code> 路径里面存放着重要的信息，如果无法读取它也就无法成功初始化 <code>HBase</code> 环境：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://hdfs-cluster/apps/hbase/data&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>所以此后所有的请求需要连接 <code>HBase</code> 取数时，都会出现 <code>java.lang.reflect.InvocationTargetException</code> 异常。</p><p>这里会进一步引发一个严重的问题，由于 <code>dubbo</code> 服务在注册时出现问题没有退出，仍旧提供服务，但是这个服务是有问题的，每次需要连接 <code>HBase</code> 取数时都会出现异常，由于没有处理好异常，导致大量的 <code>Zookeeper</code> 连接没有关闭。</p><p>进一步导致当前机器的 <code>Zookeeper</code> 连接数接近 1000 个，严重影响了其它业务连接 <code>Zookeeper</code>，一律是等待、超时重试。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 找到问题原因，就很容易解决了，重启对应的服务，观察初始化日志，一切正常。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HBase</tag>
        <tag>Zookeeper</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>ItChat 系列 0 - 初识 ItChat</title>
    <url>/2019020701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>微信已经是我们日常生活中常用的 <code>APP</code> 之一，每天都离不开。作为掌握技术的理工科人员，有时候总想着是否可以利用微信的接口完成一些重复的工作，例如群发消息、自动回复、接入机器人自动聊天等。当然，这些都可以实现，而且只要是人工可以做到的事情，基本都可以做到自动化【前提是微信提供了对应的接口，反例就是自动收发红包不行，当然微信不会直接提供 <code>API</code> 接口，需要自己寻找】。本文就讲解为了做到这些，需要的入门知识点，主要就是利用 <code>ItChat</code> 工具【屏蔽了微信的 <code>API</code> 接口，简化了使用微信接口的过程，不懂技术的普通人也可以轻松掌握】，当然本文只是一个入门的例子而已【完成后对自己来说很实用而且有成就感】，后续会讲解更加深入与广泛的内容。本文基于 <code>Windows 7</code> 操作系统，<code>Python v2.7</code> 版本【为了兼容性与易维护性，我推荐使用 <code>Python v3.x</code> 版本】</p><a id="more"></a><h1 id="ItChat- 简介"><a href="#ItChat- 简介" class="headerlink" title="ItChat 简介"></a>ItChat 简介 </h1><p> 摘录官方文档描述：</p><blockquote><p>itchat 是一个开源的微信个人号接口，使用 python 调用微信从未如此简单；<br>使用不到三十行的代码，你就可以完成一个能够处理所有信息的微信机器人；<br>当然，该 api 的使用远不止一个机器人，更多的功能等着你来发现；<br>该接口与公众号接口 itchatmp 共享类似的操作方式，学习一次掌握两个工具；<br>如今微信已经成为了个人社交的很大一部分，希望这个项目能够帮助你扩展你的个人的微信号、方便自己的生活。</p></blockquote><p>当然，我是觉得上面的描述有一些语句不通顺，但是不影响我们理解作者的原意。</p><p>其实微信官方并没有提供详细的 <code>API</code> 接口，<code>ItChat</code> 是利用网页版微信收集了接口信息，然后独立封装一层，屏蔽掉底层的接口信息，提供一套简单的使用接口，方便使用者调用，这不仅提升了效率，还扩展了使用人群。</p><h1 id="使用入门"><a href="# 使用入门" class="headerlink" title="使用入门"></a>使用入门 </h1><p> 以下使用入门包括基础环境的安装、<code>itcaht</code> 的安装、代码的编写、实际运行，当然，为了避免赘述，不会讲解的很详细，如果遇到一些问题，自行利用搜索引擎解决。</p><h2 id="安装 -Python- 环境"><a href="# 安装 -Python- 环境" class="headerlink" title="安装 Python 环境"></a>安装 Python 环境 </h2><h3 id="下载 -Python"><a href="# 下载 -Python" class="headerlink" title="下载 Python"></a> 下载 Python</h3><p>去官网：<a href="https://www.python.org/downloads/windows" target="_blank" rel="noopener">https://www.python.org/downloads/windows</a> ，选择自己需要的版本，我这里选择 <code>Windows</code> 系统的版本【64 位操作系统】，<code>Python v2.7</code>【这是一个很古老的版本了，推荐大家使用 <code>v3.x</code> 版本】。</p><p>我选择的版本 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzcck7qfjj21hc0p6n0z.jpg" alt="Windows 系统 64 位" title="Windows 系统 64 位"></p><p> 下载过程就和下载普通的文件、视频等一样，根据网速的限制有快有慢。</p><h3 id="安装 -Python"><a href="# 安装 -Python" class="headerlink" title="安装 Python"></a>安装 Python</h3><p>就像安装普通程序一样，直接双击下载的程序文件，选择安装即可，这里就不再赘述详细的安装过程了；</p><p>如果你们的环境不是 <code>Windows 7</code> 系统的，可以自行使用搜索引擎搜索教程。</p><p>这里一定要注意安装的版本是否适配自己的操作系统【包括系统类型与系统位数】。</p><p>在 <code>Windows</code> 系统的 <strong>程序和功能 </strong>中查看已经安装完成的 <code>Python</code> 程序【2.7 版本，我是使用 <code>Anaconda2</code> 安装的，所以看起来有些不一样】：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzcbr6amhj20y80k5q5m.jpg" alt="windows 程序和功能" title="windows 程序和功能"></p><h3 id="配置环境变量"><a href="# 配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量 </h3><p> 如果这一步忽略了，使用 <code>Python</code> 或者 <code>Python</code> 自带的插件的时候【比如安装 <code>ItChat</code> 的时候就会用到 <code>pip</code> 工具】，会找不到应用程序，只能先进入到 <code>Python</code> 目录或者插件所在的目录再使用对应的工具【例如进入 <code>Python</code> 所在的目录或者 <code>pip</code> 所在的目录】，比较麻烦，所以在此建议大家配置一下环境变量。</p><p>配置环境变量的过程也不再赘述，大家自己利用搜索引擎获取，下图是基于 <code>Windows 7</code> 版本的配置截图示例。</p><p><strong>系统属性 </strong></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzcdqptjbj215o0ngtez.jpg" alt="系统属性" title="系统属性"></p><p><strong> 高级系统设置 </strong></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzcf7mux2j20fe0f7ta0.jpg" alt="高级系统设置" title="高级系统设置"></p><p><strong> 环境变量 </strong>，我这里编辑用户环境变量 <code>PATH</code> 的内容【如果不存在就新建，当然编辑系统环境变量 <code>PATH</code> 的内容也是可以的】，切记内容一定是英文格式下的，多个使用英文逗号分隔。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzcfp2cdvj20ei0e03zq.jpg" alt="环境变量" title="环境变量"></p><p><strong>用户环境变量 </strong>，我这里需要填写 2 条内容，使用英文逗号隔开【如果是直接安装的 <code>Python</code>，<code>pip</code> 和 <code>python</code> 应该在同一个路径下面，所以只需要 1 条就行了】</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzcg8856yj20ei0e0q4d.jpg" alt="用户环境变量" title="用户环境变量"></p><p>我的环境需要配置 2 条内容 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzcgokfnqj209501tmwy.jpg" alt="配置 2 条内容" title="配置 2 条内容"></p><p> 内容解释：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--pip 所在目录 </span><br><span class="line">D:\Anaconda2\Scripts\;</span><br><span class="line">--python 所在目录 </span><br><span class="line">D:\Anaconda2;</span><br></pre></td></tr></table></figure><h2 id="安装 -ItChat- 工具"><a href="# 安装 -ItChat- 工具" class="headerlink" title="安装 ItChat 工具"></a>安装 ItChat 工具 </h2><p> 在 <code>Python</code> 安装完成的情况下，才能进行接下来的操作，因为 <code>ItChat</code> 是基于 <code>Python</code> 环境运行的。为了验证 <code>Python</code> 是否正确安装，可以在命令行中输入 <code>python</code>，如果看到以下内容，就说明 <code>Python</code> 安装成功：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzfxmlh41j20n60873zj.jpg" alt="验证 Python" title="验证 Python"></p><p>接下来利用 <code>pip</code> 工具【<code>Python</code> 自带的】直接安装 <code>itchat</code>，非常简单，使用命令【如果 <code>pip</code> 命令不可用，请检查 <code>Python</code> 的安装目录是否存在 <code>pip.exe</code> 文件】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install itchat</span><br></pre></td></tr></table></figure><p>安装 <code>ItChat</code></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzfy2t8p5j20be016741.jpg" alt="itchat 安装命令" title="itchat 安装命令"></p><p>如果看到以下内容，说明 <code>ItChat</code> 安装成功：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzfyl5gcsj20n60a6t9e.jpg" alt="itchat 安装成功" title="itchat 安装成功"></p><h2 id="入门代码示例"><a href="# 入门代码示例" class="headerlink" title="入门代码示例"></a>入门代码示例 </h2><p> 一切准备就绪，接下来就可以写代码了，当然，入门代码非常简单实用（我会尽可能多的添加注释说明）：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># 从 python 环境中导入 itchat 包，re 正则表达式包 </span></span><br><span class="line"><span class="keyword">import</span> itchat, re</span><br><span class="line"><span class="comment"># 从 itchat.content 中导入所有类、常量 (例如代码中的 TEXT 其实就是 itchat.content.TEXT 常量)</span></span><br><span class="line"><span class="keyword">from</span> itchat.content <span class="keyword">import</span> *</span><br><span class="line"><span class="comment"># 导入时间包里面的 sleep 方法 </span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment"># 导入随机数包 </span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment"># 注册消息类型为文本 (即只监控文本消息，其它的例如语音 / 图片 / 表情包 / 文件都不会监控)</span></span><br><span class="line"><span class="comment"># 也就是说只有普通的文字微信消息才能触发以下的代码 </span></span><br><span class="line"><span class="comment"># isGroupChat=True 开启群聊模式，即只是监控群聊内容 (如果不开启就监控个人聊天，不监控群聊)</span></span><br><span class="line"><span class="meta">@itchat.msg_register ([TEXT], isGroupChat=True)</span></span><br><span class="line"><span class="comment"># @itchat.msg_register ([TEXT])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_reply</span><span class="params">(msg)</span>:</span></span><br><span class="line">    <span class="comment"># msg 是消息体，msg ['Text'] 用来获取消息内容 </span></span><br><span class="line">    <span class="comment"># 第一个单引号中的内容是关键词，使用正则匹配，可以自行更改 (我使用.* 表示任意内容), 如果使用中文注意 2.x 版本的 Python 会报错，需要 u 前缀 </span></span><br><span class="line">    message = msg [<span class="string">'Text'</span>]</span><br><span class="line">    print (message)</span><br><span class="line">    match = re.search (<span class="string">'.*'</span>, message)</span><br><span class="line">    <span class="comment"># match = re.search (u'年 | 春 | 快乐', message)</span></span><br><span class="line">    <span class="comment"># 增加睡眠机制，随机等待一定的秒数 (1-10 秒) 再回复，更像人类 </span></span><br><span class="line">    second = random.randint (<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line">    sleep (second)</span><br><span class="line">    <span class="keyword">if</span> match:</span><br><span class="line">      <span class="comment"># msg ['FromUserName'] 用来获取用户名，发送消息给对方 </span></span><br><span class="line">      from_user_name = msg [<span class="string">'FromUserName'</span>]</span><br><span class="line">	  print (from_user_name)</span><br><span class="line">      itchat.send ((<span class="string">'====test message'</span>), from_user_name)</span><br><span class="line">      <span class="comment"># 第一个单引号中的内容是回复的内容，可以自行更改 </span></span><br><span class="line"><span class="comment"># 热启动，退出一定时间内重新登录不需要扫码 (其实就是把二维码图片存下来，下次接着使用)</span></span><br><span class="line">itchat.auto_login (hotReload=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 开启命令行的二维码 </span></span><br><span class="line">itchat.auto_login (enableCmdQR=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 运行 </span></span><br><span class="line">itchat.run ()</span><br></pre></td></tr></table></figure><p>代码截图如下：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzh40wm8uj215v0lp0ve.jpg" alt="代码示例" title="代码示例"></p><h2 id="演示"><a href="# 演示" class="headerlink" title="演示"></a>演示 </h2><p> 登录扫码 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzfzy6tf8j21bm0oq76m.jpg" alt="运行代码扫码" title="运行代码扫码"></p><p> 登录成功 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzg0nho9pj20cq01sjr6.jpg" alt="登录成功" title="登录成功"></p><p> 群聊自动回复（正则是任意内容，所以总是会自动回复）<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzg1f8g7nj20u00rp0wd.jpg" alt="群聊自动回复" title="群聊自动回复"></p><p>退出 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzg1qzmewj20n604omy3.jpg" alt="退出" title="退出"></p><p> 重新登录继续聊天（由于开启了热启动，不需要重新扫码）<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzg26yztyj20n6084gmn.jpg" alt="重新登录" title="重新登录"></p><p>继续聊天 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzg2p3tnuj20u01mc7co.jpg" alt="继续聊天" title="继续聊天"></p><h2 id="小问题总结"><a href="# 小问题总结" class="headerlink" title="小问题总结"></a> 小问题总结 </h2><p>1、部分系统可能字幅宽度有出入，可以通过将 enableCmdQR 赋值为特定的倍数进行调整：<br></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如部分的 linux 系统，块字符的宽度为一个字符 (正常应为两字符), 故赋值为 2</span></span><br><span class="line">itchat.auto_login (enableCmdQR=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p></p><p>2、Python 2.7 版本的中文报错问题（在 Python 2.7 环境下使用中文需要额外注意，坑比较多）：<br> 例如代码中正则匹配带中文（由于编码问题导致无法匹配，或者会抛出异常）</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 正则搜索带中文，直接单引号在 Python 2.7 环境下是不行的 </span></span><br><span class="line">match = re.search (<span class="string">'年 | 春 | 快乐'</span>, message)</span><br></pre></td></tr></table></figure><p>实际运行时就会报错（报错信息如果不捕捉后台是看不到的）或者匹配结果不是想象中的（仅针对 Python 2.x 环境）</p><p>需要使用 u 前缀 </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 正则搜索带中文，直接单引号在 Python 2.7 环境下是不行的 </span></span><br><span class="line"><span class="comment"># 增加 u 前缀，表示 unicode 编码，才行 </span></span><br><span class="line">match = re.search (<span class="string">u'年 | 春 | 快乐'</span>, message)</span><br></pre></td></tr></table></figure><p>3、如果不开启热启动，每次重新登录时都会生成新的二维码，直接在 Wimdows 的命令行中，可能由于窗口太小显示不完整，此时需要拉伸一下命令行的窗口：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzg62t07ej20n60sctbf.jpg" alt="窗口拉伸" title="窗口拉伸"></p><p>4、有些人的电脑设置问题，命令行环境背景为白色，生成的二维码的颜色黑白色是相反的，导致扫码时无法识别，此时需要设置代码：<br></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认控制台背景色为暗色 (黑色)，若背景色为浅色 (白色)，可以将 enableCmdQR 赋值为负值 </span></span><br><span class="line">itchat.auto_login (enableCmdQR=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p></p><h2 id="接入机器人"><a href="# 接入机器人" class="headerlink" title="接入机器人"></a> 接入机器人 </h2><p> 一般读者做到上面的内容就算入门了，可以实现自动回复，并且关于 ItChat 也了解了一些，可以独自参考文档进行更加深入的开发了。但是，自动回复的内容毕竟太固定了，而且只能覆盖极少的内容，没办法实现真正的自动化。要想做到真正的自动化回复，机器人是少不了了，那么接下来讲解的就是如何接入一个第三方机器人，实现机器人自动回复。当然，代码内容也会稍显复杂，操作步骤也会稍显繁琐。</p><h3 id="接入机器人代码示例"><a href="# 接入机器人代码示例" class="headerlink" title="接入机器人代码示例"></a>接入机器人代码示例 </h3><p> 接入机器人时为了换种方式，先把群聊模式关闭，使用个人聊天监控模式（方便聊天内容的随意性，更能提现机器人的可用性）：<br></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@itchat.msg_register ([TEXT])</span></span><br></pre></td></tr></table></figure><p></p><p>还要导入网络请求相关的包：<br></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br></pre></td></tr></table></figure><p></p><p>需要使用图灵机器人的核心配置（注册图灵机器人的过程不在此赘述，官网链接：<a href="http://www.tuling123.com" target="_blank" rel="noopener">http://www.tuling123.com</a> ）：<br></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 封装一个根据内容调用机器人接口，返回回复的方法 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_response</span><span class="params">(msg)</span>:</span></span><br><span class="line">    <span class="comment"># 构造了要发送给服务器的数据 </span></span><br><span class="line">    apiUrl = <span class="string">'http://www.tuling123.com/openapi/api'</span></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'key'</span>    : APIKEY,</span><br><span class="line">        <span class="string">'info'</span>   : msg,</span><br><span class="line">        <span class="string">'userid'</span> : <span class="string">'wechat-robot'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.post (apiUrl, data=data).json ()</span><br><span class="line">        <span class="comment"># 字典的 get 方法在字典没有 'text' 值的时候会返回 None 而不会抛出异常 </span></span><br><span class="line">        <span class="keyword">return</span> r.get (<span class="string">'text'</span>)</span><br><span class="line">    <span class="comment"># 为了防止服务器没有正常响应导致程序异常退出，这里用 try-except 捕获了异常 </span></span><br><span class="line">    <span class="comment"># 如果服务器没能正常交互 (返回非 json 或无法连接), 那么就会进入下面的 return</span></span><br><span class="line">    <span class="keyword">except</span> Exception,err:</span><br><span class="line">        <span class="comment"># 打印一下错误信息 </span></span><br><span class="line">        print (err)</span><br><span class="line">        <span class="comment"># 将会返回一个 None</span></span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure><p></p><p>完整代码示例（代码会封装的更好，格式更加规范，易读）：<br></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># 从 python 环境中导入 itchat 包，requests 网络请求包 </span></span><br><span class="line"><span class="keyword">import</span> itchat, requests</span><br><span class="line"><span class="comment"># 从 itchat.content 中导入所有类、常量 (例如代码中的 TEXT 其实就是 itchat.content.TEXT 常量)</span></span><br><span class="line"><span class="keyword">from</span> itchat.content <span class="keyword">import</span> *</span><br><span class="line"><span class="comment"># 导入时间包里面的 sleep 方法 </span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment"># 导入随机数包 </span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment"># 机器人的 apikey</span></span><br><span class="line">APIKEY = <span class="string">'376cb2ca51d542c6b2e660f3c9ea3754'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 封装一个根据内容调用机器人接口，返回回复的方法 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_response</span><span class="params">(msg)</span>:</span></span><br><span class="line">    <span class="comment"># 构造了要发送给服务器的数据 </span></span><br><span class="line">    apiUrl = <span class="string">'http://www.tuling123.com/openapi/api'</span></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'key'</span>    : APIKEY,</span><br><span class="line">        <span class="string">'info'</span>   : msg,</span><br><span class="line">        <span class="string">'userid'</span> : <span class="string">'wechat-robot'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.post (apiUrl, data=data).json ()</span><br><span class="line">        <span class="comment"># 字典的 get 方法在字典没有 'text' 值的时候会返回 None 而不会抛出异常 </span></span><br><span class="line">        <span class="keyword">return</span> r.get (<span class="string">'text'</span>)</span><br><span class="line">    <span class="comment"># 为了防止服务器没有正常响应导致程序异常退出，这里用 try-except 捕获了异常 </span></span><br><span class="line">    <span class="comment"># 如果服务器没能正常交互 (返回非 json 或无法连接), 那么就会进入下面的 return</span></span><br><span class="line">    <span class="keyword">except</span> Exception,err:</span><br><span class="line">        <span class="comment"># 打印一下错误信息 </span></span><br><span class="line">        print (err)</span><br><span class="line">        <span class="comment"># 将会返回一个 None</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注册消息类型为文本 (即只监控文本消息，其它的例如语音 / 图片 / 表情包 / 文件都不会监控)</span></span><br><span class="line"><span class="comment"># 也就是说只有普通的文字微信消息才能触发以下的代码 </span></span><br><span class="line"><span class="comment"># isGroupChat=True 开启群聊模式，即只是监控群聊内容 (如果不开启就监控个人聊天，不监控群聊)</span></span><br><span class="line"><span class="comment"># @itchat.msg_register ([TEXT], isGroupChat=True)</span></span><br><span class="line"><span class="meta">@itchat.msg_register ([TEXT])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tuling_reply</span><span class="params">(msg)</span>:</span></span><br><span class="line">    <span class="comment"># msg 是消息体，msg ['Text'] 用来获取消息内容 </span></span><br><span class="line">    <span class="comment"># 第一个单引号中的内容是关键词，使用正则匹配，可以自行更改 (我使用.* 表示任意内容), 如果使用中文注意 2.x 版本的 Python 会报错，需要 u 前缀 </span></span><br><span class="line">    message = msg [<span class="string">'Text'</span>]</span><br><span class="line">    print (message)</span><br><span class="line">	<span class="comment"># 增加睡眠机制，随机等待一定的秒数 (1-10 秒) 再回复，更像人类 </span></span><br><span class="line">    second = random.randint (<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line">    sleep (second)</span><br><span class="line">    <span class="comment"># 为了保证在图灵 apikey 出现问题的时候仍旧可以回复，这里设置一个默认回复 </span></span><br><span class="line">    defaultReply = <span class="string">'I received:'</span> + message</span><br><span class="line">    <span class="comment"># 如果图灵 apikey 出现问题，那么 reply 将会是 None</span></span><br><span class="line">    reply = get_response (message)</span><br><span class="line">    <span class="comment"># a or b 的意思是，如果 a 有内容，那么返回 a, 否则返回 b</span></span><br><span class="line">    <span class="keyword">return</span> reply <span class="keyword">or</span> defaultReply</span><br><span class="line"><span class="comment"># 热启动，退出一定时间内重新登录不需要扫码 (其实就是把二维码图片存下来，下次接着使用)</span></span><br><span class="line">itchat.auto_login (hotReload=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 开启命令行的二维码 </span></span><br><span class="line">itchat.auto_login (enableCmdQR=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 运行 </span></span><br><span class="line">itchat.run ()</span><br></pre></td></tr></table></figure><p></p><p>代码截图（使用工具渲染了一下）：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzirq8uejj235s3xgu0x.jpg" alt="机器人接入代码" title="机器人接入代码"></p><h3 id="接入机器人演示"><a href="# 接入机器人演示" class="headerlink" title="接入机器人演示"></a>接入机器人演示 </h3><p> 演示一下，随便聊了几句：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzzislea0dj20u01mcgug.jpg" alt="图灵机器人聊天" title="图灵机器人聊天"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p>1、ItChat 项目 GitHub 地址：<a href="https://github.com/littlecodersh/itchat" target="_blank" rel="noopener">https://github.com/littlecodersh/itchat</a> ；</p><p>2、ItChat 项目说明文档：<a href="https://itchat.readthedocs.io/zh/latest" target="_blank" rel="noopener">https://itchat.readthedocs.io/zh/latest</a> ；</p><p>3、感谢微博科普博主 <a href="https://weibo.com/u/6969849160" target="_blank" rel="noopener"> 灵光灯泡 </a> 的科普视频 <a href="https://weibo.com/6969849160/HeLhjcKtA" target="_blank" rel="noopener">https://weibo.com/6969849160/HeLhjcKtA</a> 以及文档参考 <a href="https://shimo.im/docs/vCYHZ04LWTsugigR" target="_blank" rel="noopener"> 石墨文档</a> ；</p><p>4、Python 下载官网：<a href="https://www.python.org/downloads/windows" target="_blank" rel="noopener">https://www.python.org/downloads/windows</a> ，大家一定要选择与自己当前环境适配的版本（包括操作系统版本、Python 版本），环境变量最好配置一下；</p><p>5、图灵机器人官网：<a href="http://www.tuling123.com" target="_blank" rel="noopener">http://www.tuling123.com</a> ；</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>ItChat 系列</category>
      </categories>
      <tags>
        <tag>ItChat</tag>
        <tag>微信接口</tag>
        <tag>自定义接口</tag>
        <tag>自动回复</tag>
        <tag>微信机器人</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 之 kill 命令入门实践</title>
    <url>/2019042101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近在实际应用场景中，需要使用 <code>Linux</code> 系统的 <strong>kill</strong> 命令来控制程序的生命周期，例如 <strong>ctrl + c</strong>、<strong>ctrl + z</strong>、<strong>kill -9 pid</strong> 等，而这些命令在日常的工作当中也是非常常见的并且很好用。为了多了解一些 <code>Linux</code> 中信号常量的知识点，以及 <code>kill</code> 命令的基本原理，我整理了这一篇博客。</p><p>本文中涉及的 <code>c</code> 语言脚本已经被我上传至 <code>GitHub</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/bin/20190421" target="_blank" rel="noopener">signal 相关脚本 </a> ，脚本命名与下文中描述一致。</p><a id="more"></a><h1 id="基础知识"><a href="# 基础知识" class="headerlink" title="基础知识"></a> 基础知识 </h1><h2 id="信号"><a href="# 信号" class="headerlink" title="信号"></a> 信号 </h2><p> 根据 <code>kill</code> 的实际使用来初步了解一下信号的概念。</p><p>首先要清楚一个基本知识点：<code>kill</code> 命令只是用来向进程发送信号的，而不是直接杀死进程的，实际操控进程生命的仍旧是系统内核以及信号常量的规范动作【进程本身注册的信号动作：默认、忽略、捕捉自定义】。</p><blockquote><p>kill 命令使用户能够向进程发送信号，信号是发送给进程以中断进程并使其作出反应的信息。如果进程被设计为对发送给它的该类型信号作出反应，则它将作出反应；否则，该进程将终止。</p></blockquote><p>对于进程对信号做出正常反应的情况，例如对一个进程发送编号为 9 的信号，则该进程会终止。而对一个进程发送编号为 19 的信号【<code>SIGSTOP</code>】，则该进程会退到后台暂停，接着使用编号为 18 的信号【<code>SIGCONT</code>】可以激活进程继续运行【也可以直接使用 <code>fg /bg</code> 这一对命令】。</p><p>对于进程不能对信号做出反应而终止的情况，例如对一个进程发送编号为 10 的信号【<code>SIGUSR1</code>】，这个信号本来是给用户自定义的，而普通的进程没有被设计为对这个信号做出反应，因此进程将终止运行【另一方面，在 <code>PHP</code> 中，后台进程会对这个信号做出反应，是因为官方发布的程序实现了这个信号的指令，并为进程注册了这个信号】。</p><blockquote><p>对于 Linux 来说，实际上信号是软中断，许多重要的程序都需要处理信号。信号，为 Linux 提供了一种处理异步事件的方法。</p></blockquote><p>每个信号都有一个名字和编号，这些名字都以 <strong>SIG</strong> 开头，例如 <strong>SIGINT</strong>、<strong>SIGKILL</strong> 等等。信号定义在 <strong>signal.h</strong>【<code>/usr/include/asm/signal.h</code>】头文件中，信号编号都定义为正整数，从 1 开始。当然，也有编号为 0 的信号，但是它对于 kill 有特殊的应用。</p><p>使用 <strong>kill -l</strong> 可以查看所有的信号常量列表，其中，前面 32 个是基本的，后面 32 个是扩展的【做底层驱动开发时能用到】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518213523.png" alt="kill 命令查看信号常量" title="kill 命令查看信号常量"></p><h2 id="常用信号常量"><a href="# 常用信号常量" class="headerlink" title="常用信号常量"></a>常用信号常量 </h2><p> 以下列举一些常用的信号常量以及解释说明：</p><table><thead><tr><th style="text-align:center">信号编号 </th><th style="text-align:center"> 信号名称 </th><th style="text-align:center"> 信号解释 </th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">SIGHUP</td><td style="text-align:center"> 挂起信号【hang up】，终端断线，经常在退出系统前使用，会终止进程。但是，一般启动程序时为了让程序继续运行，会指定 nohup 就是为了不让程序接收挂起信号而终止，这样在退出系统时程序仍旧能正常运行 </td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">SIGINT</td><td style="text-align:center"> 中断【与键盘快捷键 ctrl + c 对应】，表示与键盘中断 </td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">SIGQUIT</td><td style="text-align:center"> 退出【与键盘快捷键 ctrl + \ 对应】</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">SIGKILL</td><td style="text-align:center">强制终止，程序必须终止【无需清除】，只有进程属主或者超级用户发出该命令时才起作用 </td></tr><tr><td style="text-align:center">15</td><td style="text-align:center">SIGTERM</td><td style="text-align:center"> 停止，要求进程自己退出【需要先清除】，所以可能停止失败，只有进程属主或者超级用户发出该命令时才起作用 </td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">SIGUSR1</td><td style="text-align:center"> 用户自定义信号 1</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">SIGSEGV</td><td style="text-align:center">段错误信号，在操作内存、硬盘资源出错时会出现，例如硬盘空间不足、内存读取无权限时 </td></tr><tr><td style="text-align:center">12</td><td style="text-align:center">SIGUSR2</td><td style="text-align:center"> 用户自定义信号 2</td></tr><tr><td style="text-align:center">18</td><td style="text-align:center">SIGCONT</td><td style="text-align:center">继续【与命令 fg/bg 对应，搭配 jobs 一起使用】</td></tr><tr><td style="text-align:center">19</td><td style="text-align:center">SIGSTOP</td><td style="text-align:center">暂停【与键盘快捷键 ctrl + z 对应】，可以使用信号 18 来继续运行，或者使用 fg/bg 来调度到前 / 后台继续运行【搭配 jobs 一起使用】</td></tr></tbody></table><p>也可以在 <code>Linux</code> 机器上面使用 <strong>man 7 signal</strong> 可以查看帮助文档，有更为详细的解释说明。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518213623.png" alt="man 7 signal 查看帮助文档" title="man 7 signal 查看帮助文档"></p><p>在所有的信号中，只有编号为 9 的信号【<code>SIGKILL</code>】才可以 <strong>无条件终止 </strong>进程，编号为 15 的信号【<code>SIGTERM</code>】也可以 <strong>停止 </strong>进程，但是可能终止失败。对于编号为 9 的信号【<code>SIGKILL</code>】和编号为 19 的信号【<code>SIGSTOP</code>】，进程无法选择忽略，必须做出反应，而对于其它的信号，进程都有权利选择忽略。</p><h2 id="信号处理动作详解"><a href="# 信号处理动作详解" class="headerlink" title="信号处理动作详解"></a>信号处理动作详解 </h2><p> 对于信号的处理有三种方式：忽略、捕捉、默认。</p><blockquote><p>忽略信号，大多数信号可以使用这个方式来处理，但是有两种信号不能被忽略：9 号【SIGKILL】、19 号【SIGSTOP】。因为这两个信号向内核和超级用户提供了 <strong>终止 </strong>和 <strong>停止 </strong>的 <strong>可靠 </strong>方法，如果被忽略了，那么这个进程就变成了没人能管理的的进程，显然这是内核设计者不希望看到的场景。</p></blockquote><blockquote><p>捕捉信号，需要告诉内核，程序希望如何处理某一种信号，其实就是写一个信号处理函数，里面写上自定义的处理逻辑，然后将这个函数告诉内核【注册函数】。当该信号产生时，由内核来调用用户的自定义函数，以此来实现某种信号的自定义处理。说到底，就是进程捕捉信号，自定义处理，不使用内核默认的处理方式。</p></blockquote><blockquote><p>系统默认动作，对于每个信号来说，系统都对应有默认的处理动作。当发生了该信号，系统会自动执行。不过，对系统来说，大部分的处理方式都比较粗暴，就是直接杀死该进程。</p></blockquote><h2 id="信号的实际使用"><a href="# 信号的实际使用" class="headerlink" title="信号的实际使用"></a>信号的实际使用 </h2><p> 以上把信号的基本概念了解清楚了，但是在实际中程序是怎么使用的呢？为了配合使用，必须有两方面程序：一是信号发送方【即负责发送信号的工具，例如 <code>kill</code> 就可以】，另一方是接收方【即能接收信号并且做出反应的程序，基本所有运行在 <code>Linux</code> 上的程序都可以】。</p><p>接下来就以 <code>c</code> 语言编程，写两个例子，模拟发送方【封装 <code>kill</code>】、接收方【信号处理函数注册】，来观察一下信号的实际应用。</p><h3 id="信号处理函数注册"><a href="# 信号处理函数注册" class="headerlink" title="信号处理函数注册"></a>信号处理函数注册 </h3><p> 信号处理函数的注册，使用入门版的接口，<code>signal</code> 函数原型如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*<span class="keyword">sighandler_t</span>)</span><span class="params">(<span class="keyword">int</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">sighandler_t</span> <span class="title">signal</span><span class="params">(<span class="keyword">int</span> signum, <span class="keyword">sighandler_t</span> handler)</span></span>;</span><br></pre></td></tr></table></figure><p>根据函数原型可以看出，由两部分组成，一个是真正处理信号的函数，另一个是注册函数。对于 <strong>sighandler_t signal (int signum, sighandler_t handler)</strong> 函数来说，<code>signum</code> 显然是信号的编号，<code>handler</code> 是处理函数的指针。同样地，在 <strong>typedef void (*sighandler_t)(int)</strong> 这个处理函数的原型中，有一个参数是 <code>int</code> 类型，显然也是信号的编号，在实现函数时要根据信号的编号进行不同的操作。</p><p>只需要实现真正的处理信号的方法即可，以下是示例【脚本文件名：<code>signal_test.c</code>】，信号处理只是打印，方便观察：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">handler</span><span class="params">(<span class="keyword">int</span> signum)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 处理函数只把接收到的信号编号打印出来 </span></span><br><span class="line">    <span class="keyword">if</span>(signum == SIGIO)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"SIGIO signal: % d\n"</span>, signum);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(signum == SIGUSR1)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"SIGUSR1 signal: % d\n"</span>, signum);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"error\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 忽略 SIGINT, 默认处理 SIGTERM, 其它信号不注册都会导致程序退出 </span></span><br><span class="line">    signal (SIGIO, handler);</span><br><span class="line">    signal (SIGUSR1, handler);</span><br><span class="line">    signal (SIGINT, SIG_IGN);</span><br><span class="line">    signal (SIGTERM, SIG_DFL);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"SIGIO=% d,SIGUSR1=% d,SIGINT=% d,SIGTERM=% d\n"</span>, SIGIO, SIGUSR1, SIGINT, SIGTERM);</span><br><span class="line">    <span class="comment">// 以下是无限循环 </span></span><br><span class="line">    <span class="keyword">for</span>(;;)&#123;</span><br><span class="line">        sleep (<span class="number">10000</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 <code>gcc</code> 编译器编译【如果 <code>Linux</code> 环境不带需要自行安装】：<code>gcc -o signal_test signal_test.c</code> ，然后就可以执行了：<code>./signal_test</code> 。</p><p>接着使用 <code>ctrl + c</code> 快捷键【被进程忽略】，使用 <code>kill</code> 命令发送 29 号信号【被接收并打印出来编号】、10 号信号【被接收并打印出来编号】、2 号【被接收并忽略】、15 号【被接收并按照系统默认动作停止进程】，具体看下面的两张图片。</p><p>使用 <code>kill</code> 命令发送信号 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518222351.png" alt="使用 kill 命令发送信号" title="使用 kill 命令发送信号"></p><p> 进程接收信号的处理方式 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518222402.png" alt="进程接收信号的处理方式" title="进程接收信号的处理方式"></p><p> 接着演示 <code>kill</code> 发送一个程序没有注册的信号 12 号【<code>SIGUSR2</code>】，可以观察到程序直接退出。</p><p><code>kill</code> 发送 12 号信号 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518223015.png" alt="kill 发送 12 号信号" title="kill 发送 12 号信号"></p><p> 进程直接退出 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518223037.png" alt="进程直接退出" title="进程直接退出"></p><h3 id="信号发送工具模拟"><a href="# 信号发送工具模拟" class="headerlink" title="信号发送工具模拟"></a> 信号发送工具模拟 </h3><p> 信号发送工具比较简易，其实就是模拟封装 <code>kill</code>，观察效果，先看一下 <code>kill</code> 函数的原型：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kill</span><span class="params">(<span class="keyword">pid_t</span> pid, <span class="keyword">int</span> sig)</span></span>;</span><br></pre></td></tr></table></figure><p>可以看到函数原型很简单，有两个参数，<code>pid</code> 是信号接受者的 <code>pid</code>，<code>sig</code> 是信号编号，接着就实现一个简单的脚本【脚本文件名：<code>signal_kill.c</code>】，里面直接调用 <code>kill</code> 函数，内容如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 接收的参数个数不足 </span></span><br><span class="line">    <span class="keyword">if</span>(<span class="number">3</span> != argc)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"[Arguments ERROR!]\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\tUsage:\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\t\t% s &lt;Target_PID&gt; &lt;Signal_Number&gt;\n"</span>, argv [<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> pid = atoi (argv [<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">int</span> sig = atoi (argv [<span class="number">2</span>]);</span><br><span class="line">    <span class="comment">// 这里增加一个对编号判断的逻辑 </span></span><br><span class="line">    <span class="keyword">if</span>(pid &gt; <span class="number">0</span> &amp;&amp; sig &gt; <span class="number">0</span>)&#123;</span><br><span class="line">        kill (pid, sig);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Target_PID or Signal_Number MUST bigger than 0!\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在此特殊说明一下，关于 <code>pid</code> 的取值范围，上述代码示例把 <code>pid</code> 限制在正整数，防止出错。其实 <code>pid</code> 的取值范围很广，各有特殊含义，请参考文末的备注。</p><p>使用 <code>gcc</code> 编译后【<code>gcc -o signal_kill signal_kill.c</code>】直接运行，观察能否把信号正常发送给运行的进程。</p><p>运行脚本发送信号 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518224421.png" alt="运行脚本发送信号" title="运行脚本发送信号"></p><p> 运行的进程可以正常接收到信号 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518224412.png" alt="运行的进程可以正常接收到信号" title="运行的进程可以正常接收到信号"></p><p> 经过观察，是可以的，至此信号函数的使用演示完成。</p><h1 id="操作实践"><a href="# 操作实践" class="headerlink" title="操作实践"></a>操作实践 </h1><p> 详细认识信号的基本知识后，接下来进行实践会更加知其所以然，那就回归到正题，我来使用 <code>kill</code> 命令进行实践操作一下，演示一下常用的信号以及处理效果。</p><p>在日常工作中，一般会使用信号 1、信号 3、信号 3、信号 9、信号 15，这五个比较常用，就不再演示，只是需要留意一下它们对应的键盘快捷键，信号 2 是 <code>ctrl + c</code>，信号 3 是 <code>ctrl + \</code> 。</p><p>我想重点演示一下信号 18、信号 19 以及 <code>bg、fg、jobs</code> 命令。</p><h2 id="演示"><a href="# 演示" class="headerlink" title="演示"></a>演示 </h2><p> 开启三个进程，分别使用 <code>ctrl + z</code> 命令暂停它们的运行，在暂停时输出的日志中会有 <code>Stopped</code> 标记，并且会有进程的编号分配，在方括号中的就是【有时候暂停时还会有 <strong>核心已转储 </strong>、<strong>core dumped</strong> 的提示】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518231714.png" alt="开启三个进程分别暂停" title="开启三个进程分别暂停"></p><p>使用 <code>jobs</code> 命令查看暂停的进程，此时每个进程会有编号，此时的三个进程分别是 2、3、4。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518231705.png" alt="jobs 查看暂停的进程" title="jobs 查看暂停的进程 v"></p><p>使用 <code>kill</code> 发送 18 号信号给编号为 4 的暂停进程，然后再次使用 <code>jobs</code> 命令查看，发现这个进程的状态已经由 <code>Stopped</code> 变为了 <code>Running</code>，说明这个进程继续运行了【但是是后台运行，没有占用终端】。</p><p>发送 18 号信号 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518232545.png" alt="发送 18 号信号" title="发送 18 号信号"></p><p> 编号为 4 的进程后台运行中 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518232554.png" alt="编号为 4 的进程后台运行中" title="编号为 4 的进程后台运行中"></p><p> 接着使用 <code>fg</code>、<code>bg</code> 命令把编号为 4 的进程调到前台运行、返回后台运行。此时可以发现，<code>fg</code>、<code>bg</code> 命令和信号 18 的作用是等价的，而且更为丰富，可以把进程在前台【占用终端】、后台【不占用终端】之间调换。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190518233026.png" alt="使用 fg、bg 命令" title="使用 fg、bg 命令"></p><h2 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h2><p> 总结一下：</p><p>对于正在运行的进程，并且等待终端的输入，此时如果使用 <strong>ctrl + c</strong> 就会导致进程退出，所以可以使用 <strong>ctrl + z</strong> 让进程暂停，并退到后台等待，此时终端被释放，可以继续输入命令。</p><p>接着可以使用 <strong>jobs</strong> 命令查看有哪些被暂停的进程【此时进程会有编号，从 1 开始】，可以使用 <strong>bg num</strong> 命令让第 <code>num</code> 个进程在后台运行，可以使用 <strong>fg num</strong> 让第 <code>num</code> 个进程在前台运行【继续占用终端】。当然，如果使用 <code>bg</code>、<code>fg</code> 时不加序号参数，则默认对最后一个进程操作。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><h2 id="段错误"><a href="# 段错误" class="headerlink" title="段错误"></a> 段错误 </h2><p> 在某一次的实际场景中，想从本地上传文件到远程服务器，具体的操作是登录远程服务器后，在终端中使用 <strong>lrz</strong> 命令【环境为 <code>CentOS</code> 系统，需要自行安装这个工具】，然后在弹出的文件浏览器中选择本地的文件。</p><p>在上传的过程中，刚刚开始没多久就报错：<strong> 段错误 (core dumped)</strong>【如果使用英文表示，为：<code>Segmentation fault</code>，后面括号里面的 <code>core dumped</code> 是核心已转储，在进程退出或者暂停时会出现】，紧接着上传进度中断，上传进程停止。</p><p>然后检查发现服务器上传文件指定目录的硬盘空间已经没有了，使用 <strong>df -h</strong> 命令查看，磁盘使用率 100%，所以无法再继续上传文件。</p><p>上面的错误： <strong>段错误 (core dumped)</strong>，我猜测可能是和信号 <strong>SIGSEGV</strong> 有关，下面就以 <code>c</code> 语言为基础写一个简单的例子，在代码中特意非法操作内存，让内核主动发送 <strong>SIGSEGV</strong> 信号给进程。</p><p>代码示例如下【脚本文件名：<code>seg_error.c</code>】，已经写好注释：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> *str = <span class="string">"hello"</span>;</span><br><span class="line">    <span class="comment">// 非法赋值，想改变字符串内存地址的字符串值，不被允许 </span></span><br><span class="line">    *str = <span class="string">'h'</span>; </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"% s\n"</span>, str);</span><br><span class="line">    <span class="comment">// 新定义字符串就可以 </span></span><br><span class="line">    <span class="keyword">char</span> *str2 = <span class="string">"world"</span>; </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"% s\n"</span>, str2);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 <code>gcc</code> 编译：<strong>gcc -o seg_error seg_error.c</strong>，然后运行：<strong>./seg_error</strong>，就可以发现报错：<strong>Segmentation fault</strong>。</p><p><code>Segmentation fault</code> 报错截图 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190521233505.png" alt="Segmentation fault 报错截图" title="Segmentation fault 报错截图"></p><p> 如果不确定是哪几行代码出了问题，可以简单调试一下，重新编译时加上 <strong>-g</strong> 参数，再使用 <code>gdb</code> 调试器工具：<strong>gdb seg_error</strong>，开启调试模式，然后输入 <strong>r</strong> 运行，接着就可以看到具体的报错信息以及报错位置。</p><p>从下图中可以看到，程序在运行中接收到 <strong>SIGSEGV</strong> 信号而退出，并抛出 <strong>Segmentation fault</strong> 错误信息，异常代码在第 6 行：<strong>*str = ‘h’;</strong>，这 1 行代码在非法操作内存【字符串是不可改变的量，被分配在内存区域的数据段，当向该只读数据区域进行写操作即为非法】，操作系统内核【<code>kernel</code>】会通过 <code>kill</code> 命令向进程发送编号为 11 的信号，即 <code>SIGSEGV</code>【段错误】信号，进程被内核终止。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190521234109.png" alt="Segmentation 调试" title="Segmentation 调试"></p><p>除了内核在检测到非法操作时发送这个信号给进程，如果我手动发送这个信号给进程会发生什么呢，不妨试一下。随便起动一个进程【我使用 <code>tail -f seg_error.c</code> 查看文件内容】，然后使用 <code>kill</code> 命令发送 <code>SIGSEGV</code> 信号给这个进程。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190521235126.png" alt="手动发送 SIGSEGV 信号给进程" title="手动发送 SIGSEGV 信号给进程"></p><p>可以从上图中看到，进程由于接收到 <strong>SIGSEGV</strong> 信号而退出。</p><h2 id="进程号取值"><a href="# 进程号取值" class="headerlink" title="进程号取值"></a>进程号取值 </h2><p> 在使用 <code>kill</code> 命令时，<code>pid</code> 参数就是系统给进程分配的编号，但是这个参数除了正常的正整数之外，其它的取值有各自特殊的含义。</p><ul><li>pid 大于 0，将信号发送给进程 id 为 pid 的进程 </li><li>pid 等于 0，将信号发送给与发送进程属于同一进程组的所有进程【即进程组 id 相等的进程】</li><li>pid 等于 - 1，将该信号发送给系统内所有的进程【前提是有发送信号权限的，并且不包括系统进程集中的进程】</li><li>pid 小于 - 1，将该信号发送给其进程组 id 等于 pid 绝对值的所有进程【针对进程组】</li></ul><h2 id="可靠信号与不可靠信号"><a href="# 可靠信号与不可靠信号" class="headerlink" title="可靠信号与不可靠信号"></a> 可靠信号与不可靠信号 </h2><p> 以上内容在讨论信号的知识点与实际演示时，都没有考虑到信号的可靠性问题，默认都是能送达的。但是，信号是区分可靠信号、不可靠信号的。</p><ul><li>不可靠信号，信号可能会丢失，而一旦信号丢失【多次信号不排队】，进程是无法接收这个信号的。Linux 的信号机制基本上是从 Unix 系统中继承过来的，早期 Unix 系统中的信号机制比较简单和原始，后来在实践中逐渐暴露出一些问题。因此，把那些建立在早期 Unix 信号机制上的信号叫做 <strong>不可靠信号 </strong>，信号值小于 SIGRTMIN【不同系统会有微小的差别，例如在 CentOS 中是 34】的信号都是不可靠信号。</li><li>可靠信号，也称为阻塞信号，当发送了一个阻塞信号，并且该信号的动作是系统默认动作或捕捉该信号，则信号从发出以后会一直保持未决的状态，直到该进程对此信号解除了阻塞，或将对此信号的动作更改为忽略。随着时间的发展，实践证明了有必要对信号的原始机制加以改进和扩充。所以，后来出现的各种 Unix 版本分别在这方面进行了研究，力图实现 <strong>可靠信号 </strong>。由于原来定义的信号已有许多应用，不好再做改动，最终只好又新增加了一些信号，并在一开始就把它们定义为可靠信号，这些信号支持排队，不会丢失，信号值的范围在 SIGRTMIN 和 SIGRTMAX 之间。同时，信号的发送和安装也出现了新版本：信号发送函数 sigqueue () 以及信号的安装函数 sigaction () 。</li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Linux 命令系列</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>kill</tag>
        <tag>jobs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 输出重定向的问题</title>
    <url>/2017050401.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近遇到一个好玩的事，在使用 <code>Linux</code> 命令执行任务【<code>Java</code> 程序或者 <code>Python</code> 程序】时，需要把输出内容日志重定向到文件中，并且保持任务后台执行，这样就可以继续执行其它的命令，不占用 <code>SSH</code> 工具的 <code>session</code>。而且，如果等不了任务的运行，直接退出 <code>SSH</code> 登录即可，任务会在后台继续执行，下次重新登录时可以继续查看任务的状态、分析日志的内容。这里面会涉及到输出重定向、设备文件、输出类型的概念，本文记录这个问题以及涉及的相关知识点。</p><a id="more"></a><h1 id="基础概念"><a href="# 基础概念" class="headerlink" title="基础概念"></a>基础概念 </h1><p> 首先，通过一个很常见的具体的例子来说明基础概念，让读者有一个深刻印象。在 <code>Linux</code> 机器上面运行程序的时候，很多人都很熟练地使用类似于 <code>nohup run_your_program &gt; /dev/null 2&gt;&amp;1 &amp;</code>，一些人一看就明白了，还有一些人可能会使用，但是不太了解什么意思。当然，大多数人肯定都查过，了解过相关知识，只不过有时候不在意它，久而久之就忘记了。下面我就以这个例子为样本分析各个符号的含义。</p><ul><li>起始的 <code>nohup</code> 和结尾的 <code>&amp;</code> 是一对命令，常常放在一起使用，表示让运行的进程忽略 <strong>SIGHUP</strong> 信号，并进入后台运行，这样就可以保证这个进程一直运行下去，不受用户退出、系统 <strong>SIGHUP</strong> 信号的影响 </li><li><code>run_your_program</code>，表示运行的程序命令，可以是 Java、Shell、Python、Go 等</li><li><code>&gt;</code>，表示 <strong> 重定向 </strong>，可以把输入或者输出重定向到一个地方，后面一般跟着的是文件 </li><li><code>&gt;</code> 重定向符号前面缺省了默认值 1，完整应该是 <code>1&gt;</code>，表示 <strong> 标准输出文件 </strong>，即 <code>stdout</code></li><li><code>/dev/null</code>，表示 <strong>空设备文件 </strong>，它是一个特殊的文件，表示什么都没有，它跟在重定向符号后面则表示把运行程序产生的 <strong>标准输出文件 </strong>重定向到空设备文件，即不会输出 <strong>标准输出文件 </strong>的内容 </li><li><code>2&gt;&amp;1</code>，根据前面的解释，这些符号可以放在一起理解，<code>2</code> 表示 <strong> 标准错误文件 </strong>，即 <code>stderr</code>，<code>&gt;</code> 仍旧是重定向，<code>&amp;1</code> 则表示重定向的文件和 1 一样，即把 <strong>标准错误文件 </strong>也重定向到 <code>/dev/null</code> 中，即不会输出 <strong>标准错误文件 </strong>的内容 </li></ul><p> 想必读者已经看明白了，上面的描述已经很清楚，但是有些地方我觉得还是需要再总结完善一下。</p><p>对于 <code>nohup</code> 与 <code>&amp;</code> 的使用，还需要了解一下控制信号、后台进程相关的知识点，这样才能知其然并且知其所以然。关于控制信号的知识点，可以参考我另外一篇博文：<a href="https://www.playpi.org/2019042101.html">Linux 之 kill 命令入门实践 </a> ，关于后台进程的知识点，也可以参考我另外一篇博文：<a href="https://www.playpi.org/2019051501.html">Linux 让进程在后台运行的几种方法</a> 。</p><p><code>1</code>、<code>2</code> 这 2 个数字，是文件描述符，都是有特殊含义的，<code>1</code> 是缺省值，其实还有一个 <code>0</code>。一般情况下，Linux/Unix 系统在启动进程时，会打开三个文件，由这三个文件描述符来表示，它们的具体含义如下：</p><ul><li> 标准输入文件，<code>stdin</code>，文件描述符为 0，进程默认从 <code>stdin</code> 读取数据，一般是从键盘输入读取 </li><li> 标准输出文件，<code>stdout</code>，文件描述符为 1，进程默认向 <code>stdout</code> 输出数据，一般是输出到终端界面 </li><li> 标准错误文件，<code>stderr</code>，文件描述符为 2，进程默认向 <code>stder</code> 输出错误数据【例如异常日志】，一般是输出到终端界面 </li></ul><p> 这里再多提一点，有时候读者还会见到 <code>&amp;&gt; /dev/null</code> 这种重定向的使用，这里的 <code>&amp;</code> 其实表示的是 <code>1</code>、<code>2</code> 的合集，即把 <strong>标准输出文件 </strong>、<strong> 标准错误文件 </strong>都重定向到 <code>/dev/null</code> 中，效果等价于使用 <code>1&gt; /dev/null 2&gt;&amp;1</code>，包括 IO 效率也是一致的【涉及到文件的管道，下文会有验证过程】。</p><p><code>/dev/null</code> 是一个极为特殊的设备文件，输出到这里的数据是不可见的，也就是数据会被丢弃，如果尝试从这个文件中读取数据，什么也读不到。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190616215014.png" alt="查看空设备文件" title="查看空设备文件"></p><p>如果读者希望在运行程序时，程序产生的日志、计算结果都不要在屏幕上输出，那么就可以选择将 <strong>标准输出文件 </strong>、<strong> 标准错误文件 </strong>都重定向到 <code>/dev/null</code>，此时无论程序产生了什么异常，你都看不到了。总的来说，这个空设备文件虽然看上去很奇怪，似乎没有什么价值，但是如果将所有的输出重定向这里，就可以达到禁止输出的效果。</p><p>好，至此概念讲解完毕，接下来会使用更加详细的命令来演示重定向的神奇功能，并且还会对比一些看起来差不多的命令。</p><p>本文中涉及的 <code>Shell</code> 脚本已经被我上传至 <code>GitHub</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/bin/20170504" target="_blank" rel="noopener">test_redirect 相关脚本 </a> ，脚本命名与下文中描述一致。</p><h1 id="举例演示"><a href="# 举例演示" class="headerlink" title="举例演示"></a> 举例演示 </h1><p> 仍旧拿标准的命令格式 <code>run_your_program &gt; /dev/null 2&gt;&amp;1</code> 来举例，为了适配 <code>Linux</code> 机器以及简化程序【读者可以直接使用我的 Shell 脚本在任何一台 <code>Linux</code> 机器上面运行】，我直接使用 <code>Shell</code> 脚本来演示。</p><p>我写了一个简单的脚本：<code>test_redirect.sh</code>，只有 6 行内容【有 3 行内容是打印日志的，方便查看输出】，如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &apos;========list all file in current path&apos;</span><br><span class="line">ls -a</span><br><span class="line">echo &apos;========list all file in ./not-exist-dir&apos;</span><br><span class="line">ls ./not-exist-dir</span><br><span class="line">echo &apos;========print date&apos;</span><br><span class="line">date</span><br></pre></td></tr></table></figure><p>这个脚本只做了三件事，其中，第 2 行列出当前目录的所有文件、文件夹，第 4 行列出当前目录下的 <code>not-exist-dir</code> 子目录中的所有文件、文件夹【当然，这是一个不存在的目录，目的是为了让脚本有标准错误信息】，第 6 行输出当前的日期。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190616215056.png" alt="脚本内容预览" title="脚本内容预览"></p><h2 id="直接运行打印在终端屏幕"><a href="# 直接运行打印在终端屏幕" class="headerlink" title="直接运行打印在终端屏幕"></a>直接运行打印在终端屏幕 </h2><p> 使用 <code>sh test_redirect.sh</code> 直接运行脚本，由于没有重定向的操作，默认就是把标准输出、标准错误全部打印在屏幕上面，如图可以看到输出内容【其中第 4 行的报错信息 <code>No such file or directory</code> 属于标准错误信息】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190616215130.png" alt="直接运行" title="直接运行"></p><p>我来仔细分析一下屏幕上输出的内容，3 行以 <code>========</code> 开头的内容就不多说了。</p><ul><li>第 2 行的内容是 <code>ls -a</code> 产生的，列出了当前目录的所有文件、文件夹 </li><li> 第 4 行的内容是 <code>ls ./not-exist-dir</code> 产生的，注意它是一个系统报错，也就是标准错误，用来提示用户命令执行失败【访问文件夹失败】，原因是文件夹不存在 </li><li> 第 6 行的内容是 <code>date</code> 产生的，输出当前系统的时间 </li></ul><h2 id="重定向到空设备文件"><a href="# 重定向到空设备文件" class="headerlink" title="重定向到空设备文件"></a> 重定向到空设备文件 </h2><p> 接下来做一个操作，把标准输出重定向到 <code>/dev/null</code>，标准错误仍旧打印在屏幕上面，运行命令改为 <code>sh test_redirect.sh &gt; /dev/null</code> 即可。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190616215214.png" alt="标准错误仍旧打印在屏幕上" title="标准错误仍旧打印在屏幕上"></p><p>运行后可以看到，屏幕上面只有标准错误信息，没有标准输出信息，这是因为标准输出信息被重定向到空设备文件【参数 <code>&gt; /dev/null</code>】，在屏幕上是看不到了。</p><p>接着把标准输出、标准错误都重定向到 <code>/dev/null</code>，运行命令改为 <code>sh test_redirect.sh &gt; /dev/null 2&gt;&amp;1</code> 即可。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190616215250.png" alt="屏幕上面没有打印任何信息" title="屏幕上面没有打印任何信息"></p><p>运行后可以看到，屏幕上面没有打印任何信息，而且由于被重定向到空设备文件，信息无法找回。</p><h2 id="重定向到文本文件"><a href="# 重定向到文本文件" class="headerlink" title="重定向到文本文件"></a>重定向到文本文件 </h2><p> 为了保存程序的输出信息【持久化】，方便以后排查问题，在实际场景中不会把标准输出、标准错误直接输出到屏幕，更不会重定向到空设备文件【这种操作会导致无法查看输出的信息，相当于永远丢失】，一般我会指定一个日志文件，用来存放程序所有的输出信息，只要文件还在，随时可以查看。</p><p>运行命令 <code>sh test_redirect.sh &gt; ./test_redirect.log</code>，可以把标准输出重定向到 <code>test_redirect.log</code> 文件，标准错误仍旧打印在屏幕上面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190616215342.png" alt="标准输出重定向到文件" title="标准输出重定向到文件"></p><p>使用命令 <code>sh test_redirect.sh &gt; ./test_redirect.log 2&gt;&amp;1</code>，可以把标准输出、标准错误都重定向到 <code>test_redirect.log</code> 文件，没有任何信息打印在屏幕上面。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616215457.png" alt="标准输出标准错误都重定向到文件" title="标准输出标准错误都重定向到文件"></p><h2 id="各种各样的重定向"><a href="# 各种各样的重定向" class="headerlink" title="各种各样的重定向"></a>各种各样的重定向 </h2><p> 以上都是常规的重定向输出，比较常用，读者看一遍也就懂了，下面再列举一些奇怪的、令人疑惑的重定向输出，需要细细分析才能理解其中的含义。</p><h3 id="奇葩操作方式"><a href="# 奇葩操作方式" class="headerlink" title="奇葩操作方式"></a>奇葩操作方式 </h3><p> 如果使用显示指定的重定向命令来运行程序 <code>sh test_redirect.sh 1&gt; ./test_redirect.log 2&gt; ./test_redirect.log</code>【简称为：<strong> 奇葩操作方式 </strong>】，也就是在命令中显示地指定标准输出、标准错误全部重定向到 <code>test_redirect.log</code> 文件中，那么它和 <code>sh test_redirect.sh &gt; ./test_redirect.log 2&gt;&amp;1</code>【简称为：<strong> 正常操作方式 </strong>】的效果一样吗？<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616215542.png" alt="奇葩操作方式" title="奇葩操作方式"></p><p>从上图的运行结果来看，两者效果 <strong>大概一样 </strong>，都是把标准输出、标准错误全部保存在 <code>test_redirect.log</code> 日志文件中，读者肯定也是这样想象的。</p><p>如果仔细观察一下，发现完全不一样，虽然日志文件中的内容有部分和 <strong>正常操作方式 </strong>产生的一致，但是明显少了几行，而且顺序还错乱了，最明显的就是 <code>No such file or directory</code> 这个标准错误信息为什么在第 1 行就出现了。由于运行机器环境的原因，读者如果在自己的机器上面测试一下，可能会发现结果和我的不一样，甚至自己前后运行几次的结果也不一样，遇到这种现象是正常的，不要怀疑人生。此外，如果有读者碰巧遇到了和 <strong>正常操作方式 </strong>一样的结果，也不要用来反驳我的结果，更不能草率地得出结论：这两种操作方式的效果一致。因为这只是读者你运气好，碰到了这个结果，其实不是你想象的那样。</p><p>总的来说，<strong> 奇葩操作方式 </strong>产生的结果一切皆有可能，内容缺失、位置错乱、内容正常这些结果都有可能产生，那它背后的原因是什么呢，让我来探究一番。</p><p>首先，根据目前的现象，我只能猜测是输出时有 2 个文件流对 <code>test_redirect.log</code> 日志文件有竞争【类似于多线程竞争一个锁、多个进程竞争一个 CPU 资源】，导致输出的内容相互覆盖、部分内容丢失，位置也就错乱了。那怎么验证这个猜测呢，以及使用 <strong>正常操作方式 </strong>时为什么没有这个问题呢？</p><p>为了验证这个猜测，必须知道程序在运行时对文件做了什么操作，我可以使用 <code>strace</code> 这个命令来追踪程序对文件的操作。</p><p>由于我没有找到使用 <code>strace</code> 直接追踪重定向命令的方法，例如如果使用命令 <code>strace sh test_redirect.sh &gt; ./test_redirect.log 2&gt;&amp;1</code>，其实这里面的重定向是对于 <code>strace</code> 生效的，即把 <code>strace</code> 的输出信息重定向到文件中了，从而追踪不到重定向时对文件的操作，这不是我想要的结果【添加 <code>-o</code> 参数也不行】。于是，我只好采取了一种迂回的思路：先把完整的重定向命令整理到 <code>Shell</code> 脚本中，然后使用 <code>strace</code> 追踪运行脚本的过程。</p><p>我整理出 2 个 <code>Shell</code> 脚本，如下：</p><p>1、<strong> 正常操作方式 </strong>对应的 <code>Shell</code> 脚本，<code>strace_normal.sh</code>，脚本内容如下 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh test_redirect.sh &gt; ./test_redirect.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p>2、<strong> 奇葩操作方式 </strong> 对应的 <code>Shell</code> 脚本，<code>strace_strange.sh</code>，脚本内容如下 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh test_redirect.sh 1&gt; ./test_redirect.log 2&gt;./test_redirect.log</span><br></pre></td></tr></table></figure><p> 接着开始使用 <code>strace</code> 命令进行验证，由于输出内容过多，先使用 <code>-o</code> 参数保存在文件中，再查看，<code>-f</code> 参数是为了追踪子进程的：</p><p>1、使用 <code>strace -o strace_normal.log -f sh strace_normal.sh</code>，追踪 <strong>正常操作方式 </strong>的系统调用，输出到 <code>strace_normal.log</code> 文件中，主要为了追踪对文件的操作，运行完成后使用 <code>cat strace_normal.log</code> 查看系统调用的内容。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616215621.png" alt="追踪系统调用" title="追踪系统调用"></p><p>由于输出信息内容太多，都是一些看不懂的系统调用，所以只需要看和重定向时操作的日志文件、文件描述符有关的内容即可，使用 <code>cat strace_normal.log |grep &#39;test_redirect.log\|dup&#39;</code> 过滤掉无关内容。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616230624.png" alt="过滤无关内容" title="过滤无关内容"></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">32828 dup2 (3, 255)                      = 255</span><br><span class="line">32830 open (&quot;./test_redirect.log&quot;, O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3</span><br><span class="line">32830 dup2 (3, 1)                        = 1</span><br><span class="line">32830 dup2 (1, 2)                        = 2</span><br><span class="line">32830 dup2 (3, 255)                      = 255</span><br></pre></td></tr></table></figure><p>我关心的重点内容也就是这几行了，可以明显看到打开了 <code>test_redirect.log</code> 日志文件【<code>open</code> 调用】，然后有 2 次文件描述符的复制【<code>dup2</code> 调用】，分别把 <code>3</code> 复制给 <code>1</code>、<code>1</code> 复制给 <code>2</code>，这样操作后 <code>stdout</code>、<code>stderr</code> 都会写入到 <code>test_redirect.log</code> 日志文件，但是文件只被打开了 1 次。</p><p>关于 <code>dup</code> 的概念：</p><blockquote><p>dup、dup2：复制一个文件描述符，有 2 种调用方式 <br>int dup (int oldfd)<br>int dup2 (int oldfd, int newfd)</p></blockquote><p>2、使用 <code>strace -o strace_strange.log -f sh strace_strange.sh</code>，追踪 <strong> 奇葩操作方式 </strong>的系统调用，详细过程省略，只查看重要的系统调用，使用 <code>cat strace_strange.log |grep &#39;test_redirect.log\|dup&#39;</code> 过滤输出信息。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616215751.png" alt="追踪奇葩操作方式对文件的调用" title="追踪奇葩操作方式对文件的调用"></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">59916 dup2 (3, 255)                      = 255</span><br><span class="line">59917 open (&quot;./test_redirect.log&quot;, O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3</span><br><span class="line">59917 dup2 (3, 1)                        = 1</span><br><span class="line">59917 open (&quot;./test_redirect.log&quot;, O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3</span><br><span class="line">59917 dup2 (3, 2)                        = 2</span><br><span class="line">59917 dup2 (3, 255)                      = 255</span><br></pre></td></tr></table></figure><p>明显可以看到一个不同，调用了 2 次 <code>open</code>，也就是打开了 2 次日志文件。</p><p>通过上面的对比分析验证，结论不言而喻，我来简单总结一下：</p><p><code>1&gt; ./test_redirect.log 2&gt; ./test_redirect.log</code>：把标准输出、标准错误都直接重定向到 <code>test_redirect.log</code> 日志文件，但是 <code>test_redirect.log</code> 日志文件会被打开 2 次，即产生了 2 个文件输出流，导致标准输出、标准错误互相覆盖，也就出现了上面比较奇怪的现象。</p><p><code>&gt; ./test_redirect.log 2&gt;&amp;1</code>：把标准输出、标准错误都直接重定向到 <code>test_redirect.log</code> 日志文件，但是标准错误输出时没有打开日志文件的操作，而是直接继承了标准输出的文件流，这样的话 <code>test_redirect.log</code> 日志文件只被打开了 1 次，也就不会出现上面比较奇怪的现象。</p><p>另外，如果从 <code>IO</code> 效率方面来看，显然 <strong>正常操作方式 </strong>的效率更高。</p><h3 id="一个特殊的符号"><a href="# 一个特殊的符号" class="headerlink" title="一个特殊的符号"></a>一个特殊的符号 </h3><p> 这里要说的特殊符号是 <code>&amp;</code> 符号，如果把它作为文件描述符使用，它表示标准输出、标准错误的集合，示例命令为 <code>&amp;&gt; ./test_redirect.log</code>，它表示把标准输出、标准错误全部重定向到 <code>test_redirect.log</code> 日志文件中，即和 <strong>正常操作方式 </strong>的效果一致。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616215941.png" alt="特殊符号的重定向" title="特殊符号的重定向"></p><p>我也可以使用上面的 <code>strace</code> 命令验证它的 <code>IO</code> 效率也是和 <strong>正常操作方式 </strong>一致的，我需要像前面那样，新建一个 <code>Shell</code> 脚本，<code>strace_special.sh</code>，内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh test_redirect.sh &amp;&gt; ./test_redirect.log</span><br></pre></td></tr></table></figure><p>使用 <code>strace -o strace_special.log -f sh strace_special.sh</code>，追踪这种重定向方式的系统调用，详细过程省略，只查看重要的系统调用，使用 <code>cat strace_special.log |grep &#39;test_redirect.log\|dup&#39;</code> 过滤输出信息。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616220153.png" alt="追踪对文件的操作" title="追踪对文件的操作"></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">70626 dup2 (3, 255)                      = 255</span><br><span class="line">70627 open (&quot;./test_redirect.log&quot;, O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3</span><br><span class="line">70627 dup2 (3, 1)                        = 1</span><br><span class="line">70627 dup2 (1, 2)                        = 2</span><br><span class="line">70627 dup2 (3, 255)                      = 255</span><br></pre></td></tr></table></figure><p>结果不言而喻，系统调用时对文件的操作和 <strong>正常操作方式 </strong>是一致的。</p><h3 id="重定向顺序产生的影响"><a href="# 重定向顺序产生的影响" class="headerlink" title="重定向顺序产生的影响"></a>重定向顺序产生的影响 </h3><p> 有的读者可能会遇到一种更加奇葩的操作方式，示例命令为 <code>sh test_redirect.sh 2&gt;&amp;1 1&gt; ./test_redirect.log</code>，即把文件描述符 <code>1</code>、<code>2</code> 的重定向操作调换一下位置，先指定 <code>2</code> 和 <code>1</code> 一样，再指定 <code>1</code> 重定向到文件。</p><p>通过上面的学习总结，读者应该已经可以猜出这种重定向操作的结果：标准错误重定向到终端屏幕，标准输出重定向到 <code>test_redirect.log</code> 日志文件，而不是两者都重定向到日志文件。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2017/20190616220112.png" alt="文件描述符顺序产生的影响" title="文件描述符顺序产生的影响"></p><p>这是为什么呢？其实是因为在指定 <code>2</code> 和 <code>1</code> 一样的时候，<code>1</code> 仍然是重定向到终端屏幕的，那 <code>2</code> 也就是跟着重定向到终端屏幕，接着指定 <code>1</code> 的时候，<code>1</code> 才改变重定向的操作，但是 <code>2</code> 仍然保持不变，这个思路和编程语言中的中间变量类似。</p><p>读者也可以使用前面的 <code>strace</code> 命令追踪这种重定向方式对文件的操作、对文件描述的复制过程，然后就明白为什么是这样的结果了，我的验证结果如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">14004 dup2 (3, 255)                      = 255</span><br><span class="line">14005 dup2 (1, 2)                        = 2</span><br><span class="line">14005 open (&quot;./test_redirect.log&quot;, O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3</span><br><span class="line">14005 dup2 (3, 1)                        = 1</span><br><span class="line">14005 dup2 (3, 255)                      = 255</span><br></pre></td></tr></table></figure><h2 id="常用重定向总结区分"><a href="# 常用重定向总结区分" class="headerlink" title="常用重定向总结区分"></a>常用重定向总结区分 </h2><p> 下面整理一些常用的重定向【文件描述符使用术语表达】，读者必须要区分开来，不要乱用：</p><ul><li><code>run_your_program</code>：没有使用重定向，<code>stdout</code>、<code>stderr</code> 全部输出到终端屏幕 </li><li><code>run_your_program &gt; /dev/null</code>：<code>stdout</code> 输出到空设备文件、<code>stderr</code> 输出到终端屏幕</li><li><code>run_your_program &gt; /dev/null 2&gt;&amp;1</code>：<code>stdout</code>、<code>stderr</code> 全部输出到空设备文件</li><li><code>run_your_program &gt; log_file</code>：<code>stdout</code> 输出到日志文件、<code>stderr</code> 输出到终端屏幕</li><li><code>run_your_program &gt; log_file 2&gt;&amp;1</code>：<code>stdout</code>、<code>stderr</code> 全部输出到日志文件</li><li><code>run_your_program &gt; log_file 2&gt; log_file</code>：<code>stdout</code>、<code>stderr</code> 全部输出到日志文件，但是输出内容会混乱，这种方式不建议使用</li><li><code>run_your_program 2&gt;&amp;1 1&gt; log_file.log</code>：<code>stdout</code> 输出到日志文件、<code>stderr</code> 输出到终端屏幕，有点迷惑人，不建议使用，要确认的确懂这个重定向的真实含义才能使用</li><li><code>run_your_program 2&gt;&amp;1</code>：<code>stdout</code>、<code>stderr</code> 全部输出到终端屏幕，相当于没有重定向，没必要使用【如果系统默认没有把 <code>stdout</code> 输出到终端屏幕，需要使用这种方式】</li><li><code>run_your_program &amp;&gt; log_file</code>：<code>stdout</code>、<code>stderr</code> 全部输出到日志文件，<code>&amp;</code> 表示 <code>stdout</code>、<code>stderr</code> 2 个的集合</li></ul><h1 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h1><p>1、<code>&amp;</code> 和后台作业</p><p> 在这里如果只使用 <code>nohup</code> 不使用 <code>&amp;</code> 把程序后台运行【仍旧是前台运行】，表面上看把输出日志重定向文件中了，屏幕不再滚动打印出来大量的文本内容。其实，程序此时仍旧在占用着键盘的输入流，你的终端命令行在等待着输入，你无法使用键盘进行其它的命令操作，而且你不能使用 <code>ctrl + c</code> 的方式中断，否则程序会退出。</p><p>此时如果想把进程调到后台运行，可以使用 <code>ctrl + z</code> 暂停进程【同时调到后台，变为暂停状态的作业】，然后使用 <code>bg</code> 让作业在后台继续运行，这样就可以手动把运行在前台的进程调整到后台，而没有影响到进程的运行。如果后台的作业比较多，先使用 <code>jobs</code> 查看作业的编号，使用 <code>bg 作业编号 </code> 指定某个作业在后台运行。</p><p>2、<code>Python</code> 脚本的输出缓存机制</p><p> 在执行 <code>Python</code> 脚本时，把打印的日志都重定向到一个日志文件中，发现日志内容并没有及时更新【在 <code>Python</code> 脚本中 <code>print</code> 的日志内容】，实时查看日志文件的内容【使用 <code>tail -f log_file.log</code> 命令】，发现不会像 <code>Java</code> 程序那样实时刷出来新的内容，而是会卡住一段时间，然后突然一大段日志出来。造成这种现象的原因是 <code>Python</code> 有输出流缓存机制，不会把输出内容实时写入输出流，而是等待缓冲区积累一定的内容再操作，这样一来，重定向到文件中的内容总是一批一批的。</p><p>当然，可以选择关闭这个选项，在执行 <code>Python</code> 脚本时，使用 <code>-u</code> 参数就可以强制把输出内容实时写入到输出流，也就可以实时重定向到日志文件了，命令示例 <code>nohup python -u your_python_file &gt; log_file.log 2&gt;&amp;1 &amp;</code>。</p><p>3、读者可以继续探索一下 <code>tee</code> 命令的使用，它可以帮助我们把 <code>stdout</code>、<code>stderr</code> 即输出到终端屏幕、又输出到文件，关键是不用写多行命令。同时，它还有一个优点，即使用 <code>tee</code> 命令是不影响原来的 IO 效率的。</p><p>4、本文中涉及的 <code>Shell</code> 脚本已经被我上传至 <code>GitHub</code>，读者可以下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/bin/20170504" target="_blank" rel="noopener">test_redirect 相关脚本</a> ，脚本命名与上文中描述一致。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Linux 命令系列</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redirect</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven 插件异常之 socket write error</title>
    <url>/2019011101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天在整理代码的时候，在本机（自己的电脑）通过 Maven 的 deploy 插件（org.apache.maven.plugins:maven-deploy-plugin:2.7）进行发布，把代码打包成构件发布到远程的 Maven 仓库（公司的私服），这样方便大家调用。可是，其中有一个项目发布不了（其它类似的 2 个项目都可以，排除了环境的原因），总是报错：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Failed to deploy artifacts: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:<span class="number">0.0</span><span class="number">.6</span>-<span class="number">20190112.081518</span>-<span class="number">1</span> from/<span class="function">to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error</span></span><br></pre></td></tr></table></figure><p></p><p>以上错误日志中的项目名称、包名称均被替换。本文就记录从发现问题到解决问题的过程。环境所使用的 Maven 版本为：3.5.0。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 对一个公共项目进行打包发布，部署到公司私服（已经排除环境因素），出现异常；</p><p>使用命令 Maven：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mvn deploy</span><br></pre></td></tr></table></figure><p></p><p>出现异常：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD FAILURE</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: <span class="number">02</span>:<span class="number">49</span> min</span><br><span class="line">[INFO] Finished at: <span class="number">2019</span>-<span class="number">01</span>-<span class="number">12</span>T16:<span class="number">17</span>:<span class="number">21</span>+<span class="number">08</span>:<span class="number">00</span></span><br><span class="line">[INFO] Final Memory: <span class="number">68</span>M/<span class="number">1253</span>M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:<span class="number">2.7</span>:deploy (<span class="keyword">default</span>-deploy) on project dt-x-y-z: Failed to deploy artifacts: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:<span class="number">0.0</span><span class="number">.6</span>-<span class="number">20190112.081518</span>-<span class="number">1</span> from/<span class="function">to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error -&gt; [Help 1]</span></span><br><span class="line"><span class="function">[ERROR]</span></span><br><span class="line"><span class="function">[ERROR] To see the full stack trace of the errors, re-run Maven with the -e <span class="keyword">switch</span>.</span></span><br><span class="line"><span class="function">[ERROR] Re-run Maven using the -X <span class="keyword">switch</span> to enable full debug logging.</span></span><br><span class="line"><span class="function">[ERROR]</span></span><br><span class="line"><span class="function">[ERROR] For more information about the errors and possible solutions, please read the following articles:</span></span><br><span class="line"><span class="function">[ERROR] [Help 1] http:<span class="comment">//cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException</span></span></span><br></pre></td></tr></table></figure><p>如果使用 -X 参数（完整命令：mvn deploy -X），可以稍微看到更详细的 Maven 部署日志信息：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD FAILURE</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: <span class="number">02</span>:<span class="number">49</span> min</span><br><span class="line">[INFO] Finished at: <span class="number">2019</span>-<span class="number">01</span>-<span class="number">12</span>T16:<span class="number">17</span>:<span class="number">21</span>+<span class="number">08</span>:<span class="number">00</span></span><br><span class="line">[INFO] Final Memory: <span class="number">68</span>M/<span class="number">1253</span>M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:<span class="number">2.7</span>:deploy (<span class="keyword">default</span>-deploy) on project dt-x-y-z: Failed to deploy artifacts: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:<span class="number">0.0</span><span class="number">.6</span>-<span class="number">20190112.081518</span>-<span class="number">1</span> from/<span class="function">to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error -&gt; [Help 1]</span></span><br><span class="line"><span class="function">org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:<span class="title">deploy</span> <span class="params">(<span class="keyword">default</span>-deploy)</span> on project dt-x-y-z: Failed to deploy artifacts: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:0.0.6-20190112.081518-1 from/to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error</span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.MojoExecutor.<span class="title">execute</span><span class="params">(MojoExecutor.java:<span class="number">213</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.MojoExecutor.<span class="title">execute</span><span class="params">(MojoExecutor.java:<span class="number">154</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.MojoExecutor.<span class="title">execute</span><span class="params">(MojoExecutor.java:<span class="number">146</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.<span class="title">buildProject</span><span class="params">(LifecycleModuleBuilder.java:<span class="number">117</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.<span class="title">buildProject</span><span class="params">(LifecycleModuleBuilder.java:<span class="number">81</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.<span class="title">build</span><span class="params">(SingleThreadedBuilder.java:<span class="number">51</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.LifecycleStarter.<span class="title">execute</span><span class="params">(LifecycleStarter.java:<span class="number">128</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.DefaultMaven.<span class="title">doExecute</span><span class="params">(DefaultMaven.java:<span class="number">309</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.DefaultMaven.<span class="title">doExecute</span><span class="params">(DefaultMaven.java:<span class="number">194</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.DefaultMaven.<span class="title">execute</span><span class="params">(DefaultMaven.java:<span class="number">107</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.cli.MavenCli.<span class="title">execute</span><span class="params">(MavenCli.java:<span class="number">993</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.cli.MavenCli.<span class="title">doMain</span><span class="params">(MavenCli.java:<span class="number">345</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.cli.MavenCli.<span class="title">main</span><span class="params">(MavenCli.java:<span class="number">191</span>)</span></span></span><br><span class="line"><span class="function">        at sun.reflect.NativeMethodAccessorImpl.<span class="title">invoke0</span><span class="params">(Native Method)</span></span></span><br><span class="line"><span class="function">        at sun.reflect.NativeMethodAccessorImpl.<span class="title">invoke</span><span class="params">(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span></span></span><br><span class="line"><span class="function">        at sun.reflect.DelegatingMethodAccessorImpl.<span class="title">invoke</span><span class="params">(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span></span></span><br><span class="line"><span class="function">        at java.lang.reflect.Method.<span class="title">invoke</span><span class="params">(Method.java:<span class="number">498</span>)</span></span></span><br><span class="line"><span class="function">        at org.codehaus.plexus.classworlds.launcher.Launcher.<span class="title">launchEnhanced</span><span class="params">(Launcher.java:<span class="number">289</span>)</span></span></span><br><span class="line"><span class="function">        at org.codehaus.plexus.classworlds.launcher.Launcher.<span class="title">launch</span><span class="params">(Launcher.java:<span class="number">229</span>)</span></span></span><br><span class="line"><span class="function">        at org.codehaus.plexus.classworlds.launcher.Launcher.<span class="title">mainWithExitCode</span><span class="params">(Launcher.java:<span class="number">415</span>)</span></span></span><br><span class="line"><span class="function">        at org.codehaus.plexus.classworlds.launcher.Launcher.<span class="title">main</span><span class="params">(Launcher.java:<span class="number">356</span>)</span></span></span><br><span class="line"><span class="function">Caused by: org.apache.maven.plugin.MojoExecutionException: Failed to deploy artifacts: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:0.0.6-20190112.081518-1 from/to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error</span></span><br><span class="line"><span class="function">        at org.apache.maven.plugin.deploy.DeployMojo.<span class="title">execute</span><span class="params">(DeployMojo.java:<span class="number">193</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.plugin.DefaultBuildPluginManager.<span class="title">executeMojo</span><span class="params">(DefaultBuildPluginManager.java:<span class="number">134</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.lifecycle.internal.MojoExecutor.<span class="title">execute</span><span class="params">(MojoExecutor.java:<span class="number">208</span>)</span></span></span><br><span class="line"><span class="function">        ... 20 more</span></span><br><span class="line"><span class="function">Caused by: org.apache.maven.artifact.deployer.ArtifactDeploymentException: Failed to deploy artifacts: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:0.0.6-20190112.081518-1 from/to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error</span></span><br><span class="line"><span class="function">        at org.apache.maven.artifact.deployer.DefaultArtifactDeployer.<span class="title">deploy</span><span class="params">(DefaultArtifactDeployer.java:<span class="number">143</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.plugin.deploy.AbstractDeployMojo.<span class="title">deploy</span><span class="params">(AbstractDeployMojo.java:<span class="number">167</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.plugin.deploy.DeployMojo.<span class="title">execute</span><span class="params">(DeployMojo.java:<span class="number">157</span>)</span></span></span><br><span class="line"><span class="function">        ... 22 more</span></span><br><span class="line"><span class="function">Caused by: org.eclipse.aether.deployment.DeploymentException: Failed to deploy artifacts: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:0.0.6-20190112.081518-1 from/to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error</span></span><br><span class="line"><span class="function">        at org.eclipse.aether.internal.impl.DefaultDeployer.<span class="title">deploy</span><span class="params">(DefaultDeployer.java:<span class="number">326</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.internal.impl.DefaultDeployer.<span class="title">deploy</span><span class="params">(DefaultDeployer.java:<span class="number">254</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.internal.impl.DefaultRepositorySystem.<span class="title">deploy</span><span class="params">(DefaultRepositorySystem.java:<span class="number">422</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.artifact.deployer.DefaultArtifactDeployer.<span class="title">deploy</span><span class="params">(DefaultArtifactDeployer.java:<span class="number">139</span>)</span></span></span><br><span class="line"><span class="function">        ... 24 more</span></span><br><span class="line"><span class="function">Caused by: org.eclipse.aether.transfer.ArtifactTransferException: Could not transfer artifact xxx.yyy.zzz:dt-x-y-z:jar:0.0.6-20190112.081518-1 from/to <span class="title">snapshots</span> <span class="params">(http://maven.myself.com/nexus/content/repositories/snapshots)</span>: Connection reset by peer: socket write error</span></span><br><span class="line"><span class="function">        at org.eclipse.aether.connector.basic.ArtifactTransportListener.<span class="title">transferFailed</span><span class="params">(ArtifactTransportListener.java:<span class="number">52</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.<span class="title">run</span><span class="params">(BasicRepositoryConnector.java:<span class="number">364</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.connector.basic.BasicRepositoryConnector.<span class="title">put</span><span class="params">(BasicRepositoryConnector.java:<span class="number">283</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.internal.impl.DefaultDeployer.<span class="title">deploy</span><span class="params">(DefaultDeployer.java:<span class="number">320</span>)</span></span></span><br><span class="line"><span class="function">        ... 27 more</span></span><br><span class="line"><span class="function">Caused by: org.apache.maven.wagon.TransferFailedException: Connection reset by peer: socket write error</span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.<span class="title">put</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">650</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.<span class="title">put</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">553</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.<span class="title">put</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">535</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.<span class="title">put</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">529</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.<span class="title">put</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">509</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.transport.wagon.WagonTransporter$PutTaskRunner.<span class="title">run</span><span class="params">(WagonTransporter.java:<span class="number">653</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.transport.wagon.WagonTransporter.<span class="title">execute</span><span class="params">(WagonTransporter.java:<span class="number">436</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.transport.wagon.WagonTransporter.<span class="title">put</span><span class="params">(WagonTransporter.java:<span class="number">419</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.connector.basic.BasicRepositoryConnector$PutTaskRunner.<span class="title">runTask</span><span class="params">(BasicRepositoryConnector.java:<span class="number">519</span>)</span></span></span><br><span class="line"><span class="function">        at org.eclipse.aether.connector.basic.BasicRepositoryConnector$TaskRunner.<span class="title">run</span><span class="params">(BasicRepositoryConnector.java:<span class="number">359</span>)</span></span></span><br><span class="line"><span class="function">        ... 29 more</span></span><br><span class="line"><span class="function">Caused by: java.net.SocketException: Connection reset by peer: socket write error</span></span><br><span class="line"><span class="function">        at java.net.SocketOutputStream.<span class="title">socketWrite0</span><span class="params">(Native Method)</span></span></span><br><span class="line"><span class="function">        at java.net.SocketOutputStream.<span class="title">socketWrite</span><span class="params">(SocketOutputStream.java:<span class="number">111</span>)</span></span></span><br><span class="line"><span class="function">        at java.net.SocketOutputStream.<span class="title">write</span><span class="params">(SocketOutputStream.java:<span class="number">155</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.io.SessionOutputBufferImpl.<span class="title">streamWrite</span><span class="params">(SessionOutputBufferImpl.java:<span class="number">126</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.io.SessionOutputBufferImpl.<span class="title">flushBuffer</span><span class="params">(SessionOutputBufferImpl.java:<span class="number">138</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.io.SessionOutputBufferImpl.<span class="title">write</span><span class="params">(SessionOutputBufferImpl.java:<span class="number">169</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.io.ContentLengthOutputStream.<span class="title">write</span><span class="params">(ContentLengthOutputStream.java:<span class="number">115</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon$RequestEntityImplementation.<span class="title">writeTo</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">209</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.DefaultBHttpClientConnection.<span class="title">sendRequestEntity</span><span class="params">(DefaultBHttpClientConnection.java:<span class="number">158</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.conn.CPoolProxy.<span class="title">sendRequestEntity</span><span class="params">(CPoolProxy.java:<span class="number">162</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.protocol.HttpRequestExecutor.<span class="title">doSendRequest</span><span class="params">(HttpRequestExecutor.java:<span class="number">237</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.protocol.HttpRequestExecutor.<span class="title">execute</span><span class="params">(HttpRequestExecutor.java:<span class="number">122</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.MainClientExec.<span class="title">execute</span><span class="params">(MainClientExec.java:<span class="number">271</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.ProtocolExec.<span class="title">execute</span><span class="params">(ProtocolExec.java:<span class="number">184</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RetryExec.<span class="title">execute</span><span class="params">(RetryExec.java:<span class="number">88</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.execchain.RedirectExec.<span class="title">execute</span><span class="params">(RedirectExec.java:<span class="number">110</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.client.InternalHttpClient.<span class="title">doExecute</span><span class="params">(InternalHttpClient.java:<span class="number">184</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.httpclient.impl.client.CloseableHttpClient.<span class="title">execute</span><span class="params">(CloseableHttpClient.java:<span class="number">82</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.<span class="title">execute</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">834</span>)</span></span></span><br><span class="line"><span class="function">        at org.apache.maven.wagon.providers.http.AbstractHttpClientWagon.<span class="title">put</span><span class="params">(AbstractHttpClientWagon.java:<span class="number">596</span>)</span></span></span><br><span class="line"><span class="function">        ... 38 more</span></span><br><span class="line"><span class="function">[ERROR]</span></span><br><span class="line"><span class="function">[ERROR]</span></span><br><span class="line"><span class="function">[ERROR] For more information about the errors and possible solutions, please read the following articles:</span></span><br><span class="line"><span class="function">[ERROR] [Help 1] http:<span class="comment">//cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException</span></span></span><br></pre></td></tr></table></figure><p>由于对 Maven 构件的原理不清楚，通过日志报错也看不出根本原因是什么，根据最后一行日志的链接：<a href="http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException" target="_blank" rel="noopener">http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException</a> ，我看到描述：<br></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Unlike many other errors, this exception is not generated by the Maven core itself but by a plugin. As a rule of thumb, plugins use this error to signal a problem <span class="keyword">in</span> their configuration or the information they retrieved from the POM.</span><br><span class="line"></span><br><span class="line">The concrete meaning of the exception depends on the plugin so please have a look at its documentation. The documentation <span class="keyword">for</span> many common Maven plugins can be reached via our plugin index.</span><br></pre></td></tr></table></figure><p></p><p>大致意思也就是说这种类型的错误一般不是 Maven 的问题，而是所使用的 Maven 构件的问题，在这里我使用了 deploy 构件，我也知道和 deploy 构件有关，但是具体原因是什么也没说明；</p><p>于是接下来使用 -e 参数（完整命令：mvn deploy -e），除了上述的报错日志外，还可以打印更为详细的错误日志追踪信息，然后发现一直会有下面的错误输入，而且一直重复，没有要停的迹象，我只能手动停掉 mvn 进程：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.IllegalArgumentException: progressed file size cannot be greater than size: <span class="number">59156480</span> &gt; <span class="number">58029604</span></span><br></pre></td></tr></table></figure><p>异常信息截图 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzkj4vhui7j20vi06xdi6.jpg" alt="构件大小相关异常" title="构件大小相关异常"></p><p> 换算一下单位：<br>59156480KB=56.42M（正是需要发布的构件的大小）；<br>58029604KB=55.34M；</p><p>1、通过搜索引擎对异常信息的搜索，大部分结果显示和 Maven 后台的 Web 服务有关，如果使用的是 Nginx，会有一个参数用来限制上传文件的大小，上传文件的大小超过最大限制，就会上传失败，并且抛出异常。我部署其它的小构件没有问题，怀疑是这个原因，于是我询问运维人员公司的 Maven 私服对上传的公共构件有没有大小限制（即可能是 Nginx 服务有没有限制上传文件的大小），运维说不会。但是我还是怀疑，于是想通过 Web 端的界面来手动上传我的构件，发现 Web 端的界面没有开放，无法完成上传操作，接下来我就想看看 Maven 后台服务的对应参数配置的值是多大（也可能使用的是默认值），但是不知道后台采用的是什么服务（Nginx 还是 Netty 不确定），先放弃这条路；</p><p>2、也有结果显示是 Maven 的版本问题，有些版本有 bug，所以造成了这个问题。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 既然没有分析出来具体的原因，只能尝试每一种解决方案了。</p><p>1、既然怀疑是 Maven 私服限制了构件的大小，那就想办法减小构件。先在本地 install，然后去本地仓库看一下生成的构件的大小，结果我惊讶地发现构件居然有 330M 之大，吓死人了，这个打包发布构件的配置肯定有问题，肯定把第三方依赖全部打进去了。我查看了以前生成的正常的构件，也就 60M 左右。</p><p>以下放出对比图 2 个 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzkisemw0oj20oy0d6glu.jpg" alt="旧版本正常构件大小" title="旧版本正常构件大小"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzkit8ztcpj20oy0d6t91.jpg" alt="本地新构件过大" title="本地新构件过大"></p><p> 这一看就是把第三方各种依赖包都一起发布了，才会造成构件有这么大，于是更改 pom.xml 文件，把第三方依赖去除，deploy 的时候是不需要的，同时也删除了一些 resources 资源文件夹里面的文本文件，删除时发现文本文件竟然有几十 M，怪不得以前发布的构件大小有 60M 左右，原来都是文本文件在占用空间；</p><p>更新了之后，直接重新 deploy，不报错了，直接 deploy 成功，去私服仓库搜索查看，大概 30M 左右，很正常 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fzkjfjiisoj20im0igdgr.jpg" alt="最终正常的构件" title="最终正常的构件"></p><p>2、问题使用方法一已经解决了，也就是和 Maven 版本没有关系了，而且，在我的当前 Maven 环境下，我去 deploy 其它构件也是成功的，不会有任务报错，所以也从侧面反映了这个问题和 Mave 版本无关，和 Maven 环境也无关；</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a> 问题总结 </h1><p> 参考：<a href="http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException" target="_blank" rel="noopener">http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException</a> ；</p><p>apache 的官方 jira：<br><a href="http://mail-archives.apache.org/mod_mbox/maven-issues/201808.mbox/%3CJIRA.13182024.1535592594000.205524.1535738700211@Atlassian.JIRA%3E" target="_blank" rel="noopener">http://mail-archives.apache.org/mod_mbox/maven-issues/201808.mbox/%3CJIRA.13182024.1535592594000.205524.1535738700211@Atlassian.JIRA%3E</a> ；</p><p><a href="https://issues.apache.org/jira/browse/MNG-6469?page=com.atlassian.jira.plugin.system.issuetabpanels%3Aall-tabpanel" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/MNG-6469?page=com.atlassian.jira.plugin.system.issuetabpanels%3Aall-tabpanel</a> ；</p><p>这个问题去网上搜索不到资料，很痛苦，问人也没有能帮到我的，只能自己去慢慢摸索试验，整个过程比较艰难；</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>deploy</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 项目依赖冲突问题总结</title>
    <url>/2019112901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>今天遇到一个常见的依赖冲突问题，在一个 <code>Spark</code> 项目中，引用了多个其它项目的公共包【例如公共 <code>elt</code> 模块、算法模块】，在提交运行 <code>Spark</code> 任务时，由于依赖冲突而失败，高低版本无法兼容。</p><p>本文记录问题解决过程以及经验总结，重要开发环境说明：<code>Spark v1.6</code>、<code>es-hadoop v5.6.8</code>、<code>kafka v0.9.x</code> 。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在一个 <code>SparkStreaming</code> 项目中，由于业务需要而新增加了算法模块的依赖【公司开放的公共 <code>jar</code> 包】，结果无法正常运行，根本原因在于依赖包冲突，版本无法完全匹配。</p><p>下面简单描述一下各种现象，这当然是为了给读者参考才这么做的，在实际开发过程中如果也这么尝试是很浪费时间的【当然对于初学者还是很有必要的，实际踩坑才知道痛苦】。</p><p>在一开始，添加算法模块的依赖后，使用本地 <code>local</code> 模式试运行程序正常，相关算法接口可用，但是当提交任务到 <code>Spark</code> 集群后【<code>standalone</code> 模式】，提交任务失败，出现 <code>kryo</code> 序列化异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-11-26_18:00:32 [task-result-getter-0] WARN scheduler.TaskSetManager:70: Lost task 0.0 in stage 0.0 (TID 0, dev4): java.io.EOFException</span><br><span class="line">	at org.apache.spark.serializer.KryoDeserializationStream.readObject (KryoSerializer.scala:232)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject (TorrentBroadcast.scala:217)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply (TorrentBroadcast.scala:178)</span><br><span class="line">	at org.apache.spark.util.Utils$.tryOrIOException (Utils.scala:1205)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock (TorrentBroadcast.scala:165)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute (TorrentBroadcast.scala:64)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast._value (TorrentBroadcast.scala:64)</span><br><span class="line">	at org.apache.spark.broadcast.TorrentBroadcast.getValue (TorrentBroadcast.scala:88)</span><br><span class="line">	at org.apache.spark.broadcast.Broadcast.value (Broadcast.scala:70)</span><br><span class="line">	at org.apache.spark.scheduler.ResultTask.runTask (ResultTask.scala:62)</span><br><span class="line">	at org.apache.spark.scheduler.Task.run (Task.scala:89)</span><br><span class="line">	at org.apache.spark.executor.Executor$TaskRunner.run (Executor.scala:227)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191201000221.png" alt="启动 Spark 任务失败" title="启动 Spark 任务失败"></p><p>经过简单排查，上述错误的原因在于 <code>Spark</code> 需要依赖 <code>kryo v2.21</code>，而算法模块里面依赖了 <code>kryo v4.0.1</code>，在多版本同时存在的情况下，<code>Java</code> 类加载器加载到了高版本的 <code>kryo</code>【当然先加载到哪个类不确定，但是由前面的现象可以判定先加载了高版本的 <code>jar</code> 包】，导致 <code>Spark</code> 不兼容。</p><p>进一步想到可以将算法模块中的高版本 <code>kryo</code> 排除【当然此时没有考虑这样做对算法接口的影响】，我还就这么做了，又试了一次，结果出现以下异常【敏感包名使用 <code>xxx.yyy</code> 替换】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.reflect.InvocationTargetException</span><br><span class="line">	at org.apache.dubbo.common.bytecode.Wrapper0.invokeMethod (Wrapper0.java)</span><br><span class="line">	at com.xxx.yyy.consumer.proxy.JavassistProxyFactory$1.doInvoke (JavassistProxyFactory.java:28)</span><br><span class="line">	at com.xxx.yyy.consumer.proxy.AbstractProxyInvoker.doInvoke (AbstractProxyInvoker.java:57)</span><br><span class="line">	at com.xxx.yyy.consumer.metric.ThanosConsumerMetric.makeMetric (ThanosConsumerMetric.java:90)</span><br><span class="line">	at com.xxx.yyy.consumer.proxy.AbstractProxyInvoker.invoke (AbstractProxyInvoker.java:53)</span><br><span class="line">	at com.xxx.yyy.consumer.proxy.InvokerInvocationHandler.invoke (InvokerInvocationHandler.java:36)</span><br><span class="line">	at org.apache.dubbo.common.bytecode.proxy1.classify (proxy1.java)</span><br><span class="line">	at com.xxx.zzz.analyz.rpc.ThanosRpcAlgorithmAnalyzer.classify (ThanosRpcAlgorithmAnalyzer.java:50)</span><br><span class="line">	at com.xxx.zzz.analyz.rpc.ThanosRpcAlgorithmAnalyzer.classify (ThanosRpcAlgorithmAnalyzer.java:55)</span><br><span class="line">	at com.xxx.zzz.analyz.rpc.ThanosRpcAlgorithmAnalyzer.main (ThanosRpcAlgorithmAnalyzer.java:70)</span><br><span class="line">Caused by: org.apache.dubbo.rpc.RpcException: Failed to invoke the method classify in the service com.xxx.yyy.service.Classifier. Tried 3 times of the providers [172.18.5.66:31142, 172.18.5.145:31142] (2/2) from the registry dev3:2181 on the consumer 172.18.7.203 using the dubbo version 2.7.3. Last error is: Failed to invoke remote method: classify, provider: dubbo://172.18.5.145:31142/com.xxx.yyy.service.Classifier?application=xxx-rpc-consumer&amp;check=false&amp;cluster=backpressure&amp;deprecated=false&amp;dubbo=2.0.2&amp;interface=com.xxx.yyy.service.Classifier&amp;lazy=false&amp;loadbalance=leastactive&amp;pid=10388&amp;qos.enable=false&amp;reference.filter=requestid,activelimit&amp;register.ip=172.18.7.203&amp;release=2.7.3&amp;remote.application=xxx-rpc-provider&amp;retries=2&amp;revision=0.1-20191122.093730-4&amp;serialization=kryo&amp;side=consumer&amp;sticky=false&amp;timeout=2147483647&amp;timestamp=1574327320883&amp;weight=16, cause: org.apache.dubbo.remoting.RemotingException: io.netty.handler.codec.EncoderException: java.lang.NoClassDefFoundError: com/esotericsoftware/kryo/pool/KryoFactory</span><br><span class="line">io.netty.handler.codec.EncoderException: java.lang.NoClassDefFoundError: com/esotericsoftware/kryo/pool/KryoFactory</span><br><span class="line">	at io.netty.handler.codec.MessageToByteEncoder.write (MessageToByteEncoder.java:125)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:658)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:716)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:651)</span><br><span class="line">	at io.netty.handler.timeout.IdleStateHandler.write (IdleStateHandler.java:266)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:658)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:716)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:651)</span><br><span class="line">	at io.netty.channel.ChannelDuplexHandler.write (ChannelDuplexHandler.java:106)</span><br><span class="line">	at org.apache.dubbo.remoting.transport.netty4.NettyClientHandler.write (NettyClientHandler.java:87)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:658)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.access$2000 (AbstractChannelHandlerContext.java:32)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write (AbstractChannelHandlerContext.java:939)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write (AbstractChannelHandlerContext.java:991)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run (AbstractChannelHandlerContext.java:924)</span><br><span class="line">	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks (SingleThreadEventExecutor.java:380)</span><br><span class="line">	at io.netty.channel.nio.NioEventLoop.run (NioEventLoop.java:357)</span><br><span class="line">	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run (SingleThreadEventExecutor.java:116)</span><br><span class="line">	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run (DefaultThreadFactory.java:137)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">Caused by: java.lang.NoClassDefFoundError: com/esotericsoftware/kryo/pool/KryoFactory</span><br><span class="line">	at java.lang.ClassLoader.defineClass1 (Native Method)</span><br><span class="line">	at java.lang.ClassLoader.defineClass (ClassLoader.java:763)</span><br><span class="line">	at java.security.SecureClassLoader.defineClass (SecureClassLoader.java:142)</span><br><span class="line">	at java.net.URLClassLoader.defineClass (URLClassLoader.java:467)</span><br><span class="line">	at java.net.URLClassLoader.access$100 (URLClassLoader.java:73)</span><br><span class="line">	at java.net.URLClassLoader$1.run (URLClassLoader.java:368)</span><br><span class="line">	at java.net.URLClassLoader$1.run (URLClassLoader.java:362)</span><br><span class="line">	at java.security.AccessController.doPrivileged (Native Method)</span><br><span class="line">	at java.net.URLClassLoader.findClass (URLClassLoader.java:361)</span><br><span class="line">	at java.lang.ClassLoader.loadClass (ClassLoader.java:424)</span><br><span class="line">	at sun.misc.Launcher$AppClassLoader.loadClass (Launcher.java:349)</span><br><span class="line">	at java.lang.ClassLoader.loadClass (ClassLoader.java:357)</span><br><span class="line">	at org.apache.dubbo.common.serialize.kryo.KryoObjectOutput.&lt;init&gt;(KryoObjectOutput.java:39)</span><br><span class="line">	at org.apache.dubbo.common.serialize.kryo.KryoSerialization.serialize (KryoSerialization.java:51)</span><br><span class="line">	at org.apache.dubbo.remoting.exchange.codec.ExchangeCodec.encodeRequest (ExchangeCodec.java:234)</span><br><span class="line">	at org.apache.dubbo.remoting.exchange.codec.ExchangeCodec.encode (ExchangeCodec.java:69)</span><br><span class="line">	at org.apache.dubbo.rpc.protocol.dubbo.DubboCountCodec.encode (DubboCountCodec.java:40)</span><br><span class="line">	at org.apache.dubbo.remoting.transport.netty4.NettyCodecAdapter$InternalEncoder.encode (NettyCodecAdapter.java:70)</span><br><span class="line">	at io.netty.handler.codec.MessageToByteEncoder.write (MessageToByteEncoder.java:107)</span><br><span class="line">	... 19 more</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191201001332.png" alt="算法接口抛异常" title="算法接口抛异常"></p><p>这里可以明确得出的是，由于擅自排除了算法模块需要的高版本 <code>kryo</code>，现在算法接口无法提供服务了，缺失 <code>KryoFactory</code> 类。</p><p>没办法，只好对算法模块中的 <code>kryo</code> 做了影子复制，把包名 <code>com.esotericsoftware.kryo</code> 变更了一下，这样既不会影响到算法接口的使用，也不会影响到 <code>Spark</code> 任务提交。</p><p>好，<code>kryo</code> 的冲突问题解决了，但是紧接着又出现了 <code>netty</code> 冲突问题，现象类似，异常信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-11-29_18:23:32 [appclient-register-master-threadpool-0] INFO client.AppClient$ClientEndpoint:58: Connecting to master spark://dev4:7077...</span><br><span class="line">2019-11-29_18:23:32 [shuffle-client-0] ERROR client.TransportClient:235: Failed to send RPC 8750922883607188033 to dev4/172.18.5.204:7077: java.lang.AbstractMethodError: org.apache.spark.network.protocol.MessageWithHeader.touch (Ljava/l</span><br><span class="line">ang/Object;) Lio/netty/util/ReferenceCounted;</span><br><span class="line">java.lang.AbstractMethodError: org.apache.spark.network.protocol.MessageWithHeader.touch (Ljava/lang/Object;) Lio/netty/util/ReferenceCounted;</span><br><span class="line">	at io.netty.util.ReferenceCountUtil.touch (ReferenceCountUtil.java:77)</span><br><span class="line">	at io.netty.channel.DefaultChannelPipeline.touch (DefaultChannelPipeline.java:116)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:785)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:701)</span><br><span class="line">	at io.netty.handler.codec.MessageToMessageEncoder.write (MessageToMessageEncoder.java:112)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0 (AbstractChannelHandlerContext.java:716)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:708)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:791)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:701)</span><br><span class="line">	at io.netty.handler.timeout.IdleStateHandler.write (IdleStateHandler.java:303)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0 (AbstractChannelHandlerContext.java:716)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:708)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.access$1700 (AbstractChannelHandlerContext.java:56)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write (AbstractChannelHandlerContext.java:1102)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write (AbstractChannelHandlerContext.java:1149)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run (AbstractChannelHandlerContext.java:1073)</span><br><span class="line">	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute (AbstractEventExecutor.java:163)</span><br><span class="line">	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks (SingleThreadEventExecutor.java:510)</span><br><span class="line">	at io.netty.channel.nio.NioEventLoop.run (NioEventLoop.java:518)</span><br><span class="line">	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run (SingleThreadEventExecutor.java:1044)</span><br><span class="line">	at io.netty.util.internal.ThreadExecutorMap$2.run (ThreadExecutorMap.java:74)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">2019-11-29_18:23:32 [appclient-register-master-threadpool-0] WARN client.AppClient$ClientEndpoint:91: Failed to connect to master dev4:7077</span><br><span class="line">java.io.IOException: Failed to send RPC 8750922883607188033 to dev4/172.18.5.204:7077: java.lang.AbstractMethodError: org.apache.spark.network.protocol.MessageWithHeader.touch (Ljava/lang/Object;) Lio/netty/util/ReferenceCounted;</span><br><span class="line">	at org.apache.spark.network.client.TransportClient$3.operationComplete (TransportClient.java:239)</span><br><span class="line">	at org.apache.spark.network.client.TransportClient$3.operationComplete (TransportClient.java:226)</span><br><span class="line">	at io.netty.util.concurrent.DefaultPromise.notifyListener0 (DefaultPromise.java:577)</span><br><span class="line">	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow (DefaultPromise.java:551)</span><br><span class="line">	at io.netty.util.concurrent.DefaultPromise.notifyListeners (DefaultPromise.java:490)</span><br><span class="line">	at io.netty.util.concurrent.DefaultPromise.setValue0 (DefaultPromise.java:615)</span><br><span class="line">	at io.netty.util.concurrent.DefaultPromise.setFailure0 (DefaultPromise.java:608)</span><br><span class="line">	at io.netty.util.concurrent.DefaultPromise.tryFailure (DefaultPromise.java:117)</span><br><span class="line">	at io.netty.util.internal.PromiseNotificationUtil.tryFailure (PromiseNotificationUtil.java:64)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.notifyOutboundHandlerException (AbstractChannelHandlerContext.java:818)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0 (AbstractChannelHandlerContext.java:718)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:708)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:791)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.write (AbstractChannelHandlerContext.java:701)</span><br><span class="line">	at io.netty.handler.timeout.IdleStateHandler.write (IdleStateHandler.java:303)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0 (AbstractChannelHandlerContext.java:716)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite (AbstractChannelHandlerContext.java:708)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext.access$1700 (AbstractChannelHandlerContext.java:56)</span><br><span class="line">	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write (AbstractChannelHandlerContext.java:1102)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191201001713.png" alt="netty 异常" title="netty 异常"></p><p>这个问题我见过很多次，通过简单排查发现 <code>Spark</code> 需要的是 <code>netty-all v4.0.29</code>，而算法模块需要的是 <code>v4.1.25</code>，我在本地看到实际加载的是 <code>v4.0.29</code>，这里 <code>Spark</code> 任务为什么提交失败我有疑惑【我只能怀疑服务器加载类的顺序和我本机的不一致，导致服务器上面实际加载的并不是 <code>Spark</code> 需要的版本】。</p><p>接着按照我的怀疑把高版本 <code>netty-all</code> 排除了，恢复正常【这里不需要复制影子，因为版本差别不大，算法模块可以兼容低版本 <code>netty-all</code> 依赖】。</p><p>但是，接着又出现 <code>org.apache.curator:curator-recipes</code> 依赖的问题，这是 <code>Spark</code> 任务读取 <code>kafka</code> 需要的依赖，而在算法模块中也需要。</p><p>异常信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: org.apache.curator.framework.api.CreateBuilder.creatingParentsIfNeeded () Lorg/apache/curator/framework/api/ProtectACLCreateModePathAndBytesable;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2018/20191201001855.png" alt="curator 异常" title="curator 异常"></p><p>其中，在 <code>Spark</code> 中需要的版本是 <code>v2.4.0</code>，而在算法模块中需要的是 <code>v4.0.1</code>，我看到实际加载的是 <code>v4.0.1</code>，所以 <code>Spark</code> 任务又失败了。</p><p>再按照这个节奏进行下去，读者是不是要疯掉了！好，我们到此为止，准备使用万能优雅的 <code>maven-shade-plugin</code> 插件解决这类让人抓狂的问题【只需要找到冲突的 <code>jar</code> 包替换包名，不需要排除】。</p><h1 id="问题分析解决"><a href="# 问题分析解决" class="headerlink" title="问题分析解决"></a>问题分析解决 </h1><h2 id="简单分析解决"><a href="# 简单分析解决" class="headerlink" title="简单分析解决"></a> 简单分析解决 </h2><p> 在上面的流程中，我会想到变更 <code>jar</code> 包依赖版本，或者移除多余的依赖，尝试让合适的版本出现，从而兼容代码中所有的调用。但是，遇到稍微复杂的情况这种做法显然是徒劳的。</p><p>诚然，这种方式针对单线程或者本地 <code>local</code> 模式运行的程序是可以生效的，但是对于集群模式的【<code>standalone</code>、<code>yarn</code> 等】<code>Spark</code> 任务，就无能为力了，很难恰好找到匹配的版本，毕竟公共包本身使用的依赖不是你能控制的，也不会为了你而做兼容【公共包面向大众发布，一般都会使用最新版本的依赖】。</p><p>接着详细来解释一下我这个典型场景，<code>Spark</code> 使用了一个低版本的 <code>kryo</code>，而算法模块使用了另外高版本的 <code>kyro</code>，但是诡异的是它们的依赖坐标不一致【算法模块是 <code>com.esotericsoftware:kryo</code>、<code>Spark</code> 是 <code>com.esotericsoftware.kryo:kryo</code>】，而实际类的包名却是一致的【都是 <code>com.esotericsoftware.kryo</code>】，这就导致类冲突无法兼容【在人们的经验中，<code>jar</code> 包坐标不同，类的包名也应该不同才对】。当然，<code>kryo</code> 高低版本之间的类不同也是无法兼容的原因之一。</p><p>如果选择移除算法模块的 <code>kryo</code>，调用算法接口时会报找不到类异常，如果移除 <code>Spark</code> 的 <code>kryo</code>，提交 <code>Spark</code> 任务时会报无法反序列化异常。</p><p>而且，比较让人崩溃的是，真的无法找到兼容两者的版本，那就只能利用 <code>maven-shade-plugin</code> 插件了。</p><p>我这里的项目本身使用的 <code>maven-shade-plugin</code> 插件是为了把所有的依赖都打包在一起，形成 <code>uber jar</code>，需要启动 <code>Spark</code> 任务时一起提交到集群。这样做主要是因为 <code>Spark</code> 集群的 <code>libs</code> 中没有存放任何公共依赖包，比较纯净，所以需要提交任务的客户端自己打包携带，这样也可以避免很多业务方共同使用同一个 <code>Spark</code> 集群产生依赖冲突问题。</p><p>无奈，最终只好决定使用 <code>maven-shade-plugin</code> 插件的高级功能：影子别名，直接变更类名，就不怕再冲突了。</p><p>使用 <code>maven-shade-plugin</code> 插件制作影子的相关类配置【把类的包名替换掉，避免冲突，根据项目的实际冲突情况而配置，这里仅供参考】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;relocations&gt;</span><br><span class="line">        &lt;relocation&gt;</span><br><span class="line">            &lt;pattern&gt;com.google&lt;/pattern&gt;</span><br><span class="line">            &lt;shadedPattern&gt;iplaypi.com.google&lt;/shadedPattern&gt;</span><br><span class="line">        &lt;/relocation&gt;</span><br><span class="line">        &lt;relocation&gt;</span><br><span class="line">            &lt;pattern&gt;io.netty&lt;/pattern&gt;</span><br><span class="line">            &lt;shadedPattern&gt;iplaypi.io.netty&lt;/shadedPattern&gt;</span><br><span class="line">        &lt;/relocation&gt;</span><br><span class="line">        &lt;relocation&gt;</span><br><span class="line">            &lt;pattern&gt;org.apache.curator&lt;/pattern&gt;</span><br><span class="line">            &lt;shadedPattern&gt;iplaypi.org.apache.curator&lt;/shadedPattern&gt;</span><br><span class="line">        &lt;/relocation&gt;</span><br><span class="line">        &lt;relocation&gt;</span><br><span class="line">            &lt;pattern&gt;com.esotericsoftware&lt;/pattern&gt;</span><br><span class="line">            &lt;shadedPattern&gt;iplaypi.com.esotericsoftware&lt;/shadedPattern&gt;</span><br><span class="line">        &lt;/relocation&gt;</span><br><span class="line">        &lt;relocation&gt;</span><br><span class="line">            &lt;pattern&gt;de.javakaffee&lt;/pattern&gt;</span><br><span class="line">            &lt;shadedPattern&gt;iplaypi.de.javakaffee&lt;/shadedPattern&gt;</span><br><span class="line">        &lt;/relocation&gt;</span><br><span class="line">    &lt;/relocations&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>我这里把 <code>guava</code>、<code>netty</code>、<code>curator</code>、<code>kryo</code> 全部制作影子了，仅供参考。</p><h2 id="抽象简化问题"><a href="# 抽象简化问题" class="headerlink" title="抽象简化问题"></a>抽象简化问题 </h2><p> 下面就用模型简化一下我遇到的这类场景，使用 <code>guava</code> 包冲突做示例。</p><p><code>Maven</code> 项目中有 <code>a</code>、<code>b</code>、<code>c</code> 三个模块【分散为三个模块读者更容易理解，解决问题思路也更清晰】，<code>a</code> 同时依赖了 <code>b</code>、<code>c</code>。其中，<code>b</code> 依赖了低版本 <code>guava</code> 并调用了一个低版本独有的方法，<code>c</code> 依赖了高版本 <code>guava</code> 并调用了高版本独有的方法【当然引用特有的类也行】。</p><p>它们之间的关系如下图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209000340.png" alt="项目依赖关系" title="项目依赖关系"></p><p>在这个 <code>Maven</code> 项目中，发生 <code>jar</code> 包冲突很明显是因为，项目中依赖了同一个 <code>jar</code> 包的多个版本，而且分别调用了高低版本特有的方法，或者引用了高低版本特有的类。面对此类问题，一般的解决思路是只保留一个版本，排除掉不需要的版本，但是上面这种情况太特殊了，排除 <code>jar</code> 包不能解决问题。</p><p>可以试想一下，排除掉低版本 <code>guava</code> 的话 <code>b</code> 会报错，排掉高版本 <code>guava</code> 的话 <code>c</code> 会报错，所以希望在项目中同时使用低版本 <code>guava</code> 和高版本 <code>guava</code>。</p><p>那就只能使用 <code>maven-shade-plugin</code> 插件来构建影子 <code>jar</code> 包，替换类路径，制作影子的效果如下图【思路就是构建 <code>c</code> 时替换掉 <code>guava</code> 的包名】：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209000438.png" alt="shade 插件替换类路径" title="shade 插件替换类路径"></p><p>这样就可以非常优雅地解决问题，但是会导致打包的 <code>jar</code> 比以前大一点。如果 <code>Maven</code> 项目本身没有那么多模块，只有一个大模块，建议拆分，至少把有冲突的部分单独拆出来构建影子模块。</p><p>这个方案的详细说明以及代码演示读者可以参考我的另外一篇博文：<a href="https://www.playpi.org/2019120101.html">解决 jar 包冲突的神器：maven-shade-plugin</a> 。</p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p> 在制作影子时，<code>Maven</code> 的子模块是必不可少的帮手，否则还需要下载源码自己重新打包，麻烦而且做法不合适。</p><p><code>Java</code> 项目拆分为子模块的好处之一，遇到依赖冲突时，可以很方便地使用 <code>maven-shade-plugin</code> 插件，分分钟就可以制作影子。例如上面的抽象简化例子，如果 <code>a</code>、<code>b</code>、<code>c</code> 没有拆分，一直是一个模块，遇到这种依赖冲突就没办法解决，怎么排除都是不行的，只能单独构建一个子模块用来制作影子。</p><p>当然，如果上面的 <code>c</code> 本身就依赖了很多 <code>jar</code> 包，它们之间在 <code>c</code> 模块中就有冲突，也不好制作影子，还是单独新建一个纯净的子模块比较好【例如把类似 <code>guava</code> 冲突的 <code>jar</code> 包以及代码抽出来，单独创建 <code>c-sub-shade</code> 模块，在里面制作影子，这个模块给 <code>c</code> 引用】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209000650.png" alt="shade 子模块" title="shade 子模块"></p><p>注意，上图和我本文中遇到的例子有一点不同，我的 <code>jar</code> 包在 <code>c</code> 模块中并没有冲突，所以可以直接利用 <code>c</code> 制作影子模块 <code>c-shade</code>，当然不怕麻烦也可以制作 <code>c-sub-shade</code>。</p><p>此外，我在一年前也遇到过一种简单的场景：<a href="https://www.playpi.org/2018100801.html">Spark Kryo 异常</a>，当时直接通过排除依赖就解决问题了，但是这次的场景太复杂，只能启用 <code>maven-shade-plugin</code> 插件了。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Maven</tag>
        <tag>shade</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Aria2 加速百度网盘下载</title>
    <url>/2018110901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在日常工作和生活当中，应该有不少人自愿或者被迫使用百度网盘，一是因为其它厂商基本都关停了网盘服务；二是在获取互联网资料的时候，基本都是先获取到百度网盘链接，然后自己再去下载；三是有时候想备份一些文件，也只能想起来有百度网盘可以使用。这样的话，慢慢地总是会碰到需要百度网盘的时候，我们暂且不考虑这家企业的口碑怎么样，百度网盘这个产品本身还是不错的：有免费的大量空间，使用人群多，分享获取资料方便。</p><p>但是，产品让人诟病的地方也有几个，而且由此造成的用户体验非常差，大家骂声一片。本文就详细讲述百度网盘这个产品让人诟病的地方以及可以使用技术方式绕过它，从而提升自己的体验。当然，如果你的钱到位的话，直接充值会员吧，可以消除一切不好的使用体验，同时也免去了阅读本文的时间。</p><a id="more"></a><h1 id="使用中遇到的问题"><a href="# 使用中遇到的问题" class="headerlink" title="使用中遇到的问题"></a>使用中遇到的问题 </h1><p> 本文是针对不充会员的免费用户群体的，在 <code>Windows</code> 平台安装，在 <code>Chrome</code> 浏览器中使用。</p><h2 id="下载速度太慢，慢到反人类"><a href="# 下载速度太慢，慢到反人类" class="headerlink" title="下载速度太慢，慢到反人类"></a>下载速度太慢，慢到反人类 </h2><p> 让人诟病的问题之一是下载速度太慢了，对于免费用户基本维持在几 <code>KB/s</code> 到十几 <code>KB/s</code> 之间，也就是说如果你想下载一部 <code>1GB</code> 大小的电影，按照 <code>1000MB</code> 计算，下载速度按照 <code>10KB/s</code> 算【取这样的数值方便后续计算】，下载完需要 1000 个 100 秒，也就是约等于 27.78 个小时【10 万秒】，所以在下载列表中经常看到下载任务还需要大于一天才能完成，这怎么让人受得了，不骂才怪呢！</p><p>但是只要充值会员，下载速度基本就暴增，可以完全利用宽带的带宽，例如 <code>100M</code> 的宽带，下载速度可达 <code>12.8MB/s</code>，哪怕只是 <code>10M</code> 的宽带，下载速度也能到 <code>1.28MB/s</code>。因此，百度网盘客户端对于免费用户限制速度限制得太严重了，不充值会员根本没法使用。而且，有时候勉强能使用的时候，经常会弹出会员试用 300 秒的提示，只要选择了，下载速度立马飞速提升，300 秒后又急速下降，经常下降到只有 <code>3.14KB/s</code>，让人抓狂。</p><h2 id="网页版限制下载大文件，强迫安装百度网盘客户端"><a href="# 网页版限制下载大文件，强迫安装百度网盘客户端" class="headerlink" title="网页版限制下载大文件，强迫安装百度网盘客户端"></a>网页版限制下载大文件，强迫安装百度网盘客户端 </h2><p> 既然百度网盘客户端做了下载速度限制，那么大多数人会想到选择使用浏览器直接下载，同时又可以免去安装百度网盘客户端的麻烦，浏览器的下载速度通常在几百 <code>KB/s</code>，不会像百度网盘客户端那样特别地慢。但是，直接使用网页版的百度网盘下载文件，对文件大小有限制，太大的文件会被网页拦截，下载不了，而是弹出安装百度网盘客户端的提示，这样又回到了原点，因为如果用百度网盘客户端下载速度被限制了。</p><h1 id="解决问题"><a href="# 解决问题" class="headerlink" title="解决问题"></a>解决问题 </h1><h2 id="使用 -aria2- 突破线程数限制、下载速度限制"><a href="# 使用 -aria2- 突破线程数限制、下载速度限制" class="headerlink" title="使用 aria2 突破线程数限制、下载速度限制"></a> 使用 aria2 突破线程数限制、下载速度限制 </h2><p> 注意，下文中安装配置过程涉及到的配置文件、脚本文件，已经被我上传至 <code>GitHub</code>，读者可以下载直接使用：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20181109" target="_blank" rel="noopener">aria.conf、Start.bat</a> 。</p><h3 id="简介"><a href="# 简介" class="headerlink" title="简介"></a>简介 </h3><p><code>Aria2</code> 是一个多平台轻量级的下载工具，支持 <code>Http</code>、<code>Ftp</code>、<code>BitTorrent</code>、<code>Web</code> 资源等多种格式，使用命令行启动任务，更多具体信息查看官网说明：<a href="https://aria2.github.io" target="_blank" rel="noopener">Aria2 介绍</a> 。这种工具可以最大程度利用你的网络带宽，实际上你可以自由配置，包括线程数、网络传输速度、<code>RPC</code> 端口、断点续传是否开启等。</p><h3 id="安装"><a href="# 安装" class="headerlink" title="安装"></a> 安装 </h3><p> 去官网下载安装包：<a href="https://github.com/aria2/aria2/releases" target="_blank" rel="noopener">Aria2 安装包 </a> ，我的 <code>Windows</code> 系统 64 位，选择对应的安装包下载。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjctk362fj20ih0gdt90.jpg" alt="安装包下载" title="安装包下载"></p><p> 下载完成后，得到一个 <code>zip</code> 格式的文件，其实直接解压即可，不需要安装，解压后会得到一系列文件，为了方便管理，都放在 <code>aria2</code> 文件夹下面，再复制到程序对应的目录。其中，有一个 <code>.exe</code> 文件，就是运行任务时需要的文件。</p><p>此外，为了方便起见，把 <code>.exe</code> 文件的路径配置到系统的环境变量中去，这样在任何目录都可以执行 <code>aria2</code> 命令了；如果不配置则只能在 <code>aria2</code> 目录中执行相关命令，否则会找不到程序。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjcyfaaw9j20in08kmxd.jpg" alt="解压" title="解压"></p><h3 id="配置"><a href="# 配置" class="headerlink" title="配置"></a>配置 </h3><p>1、如果单纯使用命令行启动下载任务，可以把参数信息直接跟在命令后面，临时生效，也就是参数只对当前下载任务有效。显然，这样做很麻烦，每次都是一长串的命令，而且当任务非常多的时候也无法管理，所以不建议使用这种方式。当然，如果只是测试折腾一下，或者也不经常使用，只是偶尔下载一个东西，还是用这种方式比较简介，不用管其它复杂的配置，不用管插件的安装。</p><p> 单命令行启动任务示例，从电影天堂下载《一出好戏》这部电影。如果下载百度网盘的文件，需要使用 <a href="https://chrome.google.com/webstore/detail/baiduexporter/jgebcefbdjhkhapijgbhkidaegoocbjj?hl=zh-CN" target="_blank" rel="noopener">baiduexporter</a> 插件生成 <code>url</code>，生成方式见后续步骤。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">aria2c.exe -c -s32 -k32M -x16 -t1 -m0 --<span class="built_in">enable</span>-rpc=<span class="literal">true</span> 下载 url 取值 </span><br><span class="line">-t1 表示的是每隔 1 秒重试一次 </span><br><span class="line">-m0 表示的是重试设置 </span><br><span class="line"> 此外，下载 url 中会包含 --header 的信息：User-Agent、Referer、Cookie、url</span><br><span class="line"> 理论上 User-Agent、Referer 应该时固定的，Cookie、url 每次会生成不一样的 </span><br><span class="line">User-Agent: netdisk;5.3.4.5;PC;PC-Windows;5.1.2600;WindowsBaiduYunGuanJia</span><br><span class="line">Referer: http://pan.baidu.com/disk/home</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjec4bt6kj20gj0ahgm8.jpg" alt="aria2 命令行参数" title="aria2 命令行参数"></p><p>这里再给一个完整的下载命令示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">aria2c -c -s256 -k2M -x256 -t1 -m0 --enable-rpc=true -o &quot;pyspark-part1.zip&quot; --header &quot;User-Agent: netdisk;5.3.4.5;PC;PC-Windows;5.1.2600;WindowsBaiduYunGuanJia&quot; --header &quot;Referer: http://pan.baidu.com/disk/home&quot; --header &quot;Cookie: BDUSS=FFzb2s3Z2NRcnlTRE00WkxLYn5jTzhLdXktflVYbWprdXRpZm5EQ1FnYXlyTzFaSVFBQUFBJCQAAAAAAAAAAAEAAADYoS0veWVhckxQRjEzMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALIfxlmyH8ZZb; pcsett=1506245668-3f7c157ceb2130e195638efdf62944aa&quot; &quot;https://pcs.baidu.com/rest/2.0/pcs/file?method=download&amp;app_id=250528&amp;path=%2FQQ% E7% BE% A4% E5%90%88% E4% B9% B0% E5% A4% A7% E6%95% B0% E6%8D% AE% E8% A7%86% E9% A2%91%2Fxtwy% E4% B9%8Bpyspark% E8% A7%86% E9% A2%91%2F% E5% AD% A6% E5% BE%92% E6%97% A0% E5% BF% A7pyspark% E8% AF% BE% E7% A8%8Bpart1.zip&quot;</span><br></pre></td></tr></table></figure><p>2、如果是后台启动，通过其它管理插件来创建下载任务，则直接使用配置文件，文件名称为 <code>aria2.conf</code>，并在启动 <code>aria2</code> 时指定配置文件的位置。这样做的好处是使用一个配置文件就可以指定常用的参数配置，不用更改，每次下载文件前启动 <code>aria2</code> 即可。</p><p>配置文件可选项如下，例如下载文件存放位置、是否开启 RPC、是否开启断点续传，具体更为详细的内容请参考文档：<a href="https://aria2.github.io/manual/en/html/index.html" target="_blank" rel="noopener">Aria2 配置信息文档 </a> 。</p><p> 以下为配置文件 <code>aria.conf</code> 示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## '#' 开头为注释内容，选项都有相应的注释说明，根据需要修改 ##</span></span><br><span class="line"><span class="comment">## 被注释的选项填写的是默认值，建议在需要修改时再取消注释  ##</span></span><br><span class="line"><span class="comment">## 文件保存相关 ##</span></span><br><span class="line"><span class="comment"># 文件的保存路径 (可使用绝对路径或相对路径), 默认：当前启动位置 </span></span><br><span class="line">dir=E:\\aria2download\\</span><br><span class="line"><span class="comment"># 启用磁盘缓存，0 为禁用缓存，需 1.16 以上版本，默认：16M</span></span><br><span class="line">disk-cache=32M</span><br><span class="line"><span class="comment"># 文件预分配方式，能有效降低磁盘碎片，默认:prealloc</span></span><br><span class="line"><span class="comment"># 预分配所需时间: none &lt; falloc &lt; trunc &lt; prealloc</span></span><br><span class="line"><span class="comment"># NTFS 建议使用 falloc</span></span><br><span class="line">file-allocation=none</span><br><span class="line"><span class="comment"># 断点续传 </span></span><br><span class="line"><span class="built_in">continue</span>=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 下载连接相关 ##</span></span><br><span class="line"><span class="comment"># 最大同时下载任务数，运行时可修改，默认：5</span></span><br><span class="line">max-concurrent-downloads=32</span><br><span class="line"><span class="comment"># 同一服务器连接数，添加时可指定，默认：1</span></span><br><span class="line">max-connection-per-server=5</span><br><span class="line"><span class="comment"># 最小文件分片大小，添加时可指定，取值范围 1M -1024M, 默认：20M</span></span><br><span class="line"><span class="comment"># 假定 size=10M, 文件为 20MiB 则使用两个来源下载；文件为 15MiB 则使用一个来源下载 </span></span><br><span class="line">min-split-size=16M</span><br><span class="line"><span class="comment"># 单个任务最大线程数，添加时可指定，默认：5</span></span><br><span class="line">split=32</span><br><span class="line"><span class="comment"># 整体下载速度限制，运行时可修改，默认：0</span></span><br><span class="line"><span class="comment">#max-overall-download-limit=0</span></span><br><span class="line"><span class="comment"># 单个任务下载速度限制，默认：0</span></span><br><span class="line"><span class="comment">#max-download-limit=0</span></span><br><span class="line"><span class="comment"># 整体上传速度限制，运行时可修改，默认：0</span></span><br><span class="line">max-overall-upload-limit=1M</span><br><span class="line"><span class="comment"># 单个任务上传速度限制，默认：0</span></span><br><span class="line"><span class="comment">#max-upload-limit=1000</span></span><br><span class="line"><span class="comment"># 禁用 IPv6, 默认:false</span></span><br><span class="line"><span class="built_in">disable</span>-ipv6=<span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 进度保存相关 ##</span></span><br><span class="line"><span class="comment"># 从会话文件中读取下载任务 </span></span><br><span class="line">input-file=aria2.session</span><br><span class="line"><span class="comment"># 在 Aria2 退出时保存 ` 错误 / 未完成 ` 的下载任务到会话文件 </span></span><br><span class="line">save-session=aria2.session</span><br><span class="line"><span class="comment"># 定时保存会话，0 为退出时才保存，需 1.16.1 以上版本，默认：0</span></span><br><span class="line"><span class="comment">#save-session-interval=60</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## RPC 相关设置 ##</span></span><br><span class="line"><span class="comment"># 启用 RPC, 默认:false</span></span><br><span class="line"><span class="built_in">enable</span>-rpc=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 允许所有来源，默认:false</span></span><br><span class="line">rpc-allow-origin-all=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 允许非外部访问，默认:false</span></span><br><span class="line">rpc-listen-all=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 事件轮询方式，取值:[epoll, kqueue, port, poll, select], 不同系统默认值不同 </span></span><br><span class="line"><span class="comment">#event-poll=select</span></span><br><span class="line"><span class="comment"># RPC 监听端口，端口被占用时可以修改，默认：6800</span></span><br><span class="line"><span class="comment">#rpc-listen-port=6800</span></span><br><span class="line"><span class="comment"># 设置的 RPC 授权令牌，v1.18.4 新增功能，取代 --rpc-user 和 --rpc-passwd 选项 </span></span><br><span class="line"><span class="comment">#rpc-secret=mivm.cn</span></span><br><span class="line"><span class="comment"># 设置的 RPC 访问用户名，此选项新版已废弃，建议改用 --rpc-secret 选项 </span></span><br><span class="line"><span class="comment">#rpc-user=&lt;USER&gt;</span></span><br><span class="line"><span class="comment"># 设置的 RPC 访问密码，此选项新版已废弃，建议改用 --rpc-secret 选项 </span></span><br><span class="line"><span class="comment">#rpc-passwd=&lt;PASSWD&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## BT/PT 下载相关 ##</span></span><br><span class="line"><span class="comment"># 当下载的是一个种子 (以.torrent 结尾) 时，自动开始 BT 任务，默认:true</span></span><br><span class="line">follow-torrent=<span class="literal">true</span></span><br><span class="line"><span class="comment"># BT 监听端口，当端口被屏蔽时使用，默认：6881-6999</span></span><br><span class="line">listen-port=51413</span><br><span class="line"><span class="comment"># 单个种子最大连接数，默认：55</span></span><br><span class="line"><span class="comment">#bt-max-peers=55</span></span><br><span class="line"><span class="comment"># 打开 DHT 功能，PT 需要禁用，默认:true</span></span><br><span class="line"><span class="built_in">enable</span>-dht=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 打开 IPv6 DHT 功能，PT 需要禁用 </span></span><br><span class="line"><span class="comment">#enable-dht6=false</span></span><br><span class="line"><span class="comment"># DHT 网络监听端口，默认：6881-6999</span></span><br><span class="line"><span class="comment">#dht-listen-port=6881-6999</span></span><br><span class="line"><span class="comment"># 本地节点查找，PT 需要禁用，默认:false</span></span><br><span class="line"><span class="comment">#bt-enable-lpd=true</span></span><br><span class="line"><span class="comment"># 种子交换，PT 需要禁用，默认:true</span></span><br><span class="line"><span class="built_in">enable</span>-peer-exchange=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 每个种子限速，对少种的 PT 很有用，默认：50K</span></span><br><span class="line"><span class="comment">#bt-request-peer-speed-limit=50K</span></span><br><span class="line"><span class="comment"># 客户端伪装，PT 需要 </span></span><br><span class="line">peer-id-prefix=-TR2770-</span><br><span class="line">user-agent=Transmission/2.77</span><br><span class="line"><span class="comment"># 当种子的分享率达到这个数时，自动停止做种，0 为一直做种，默认：1.0</span></span><br><span class="line">seed-ratio=0.1</span><br><span class="line"><span class="comment"># 强制保存会话，即使任务已经完成，默认:false</span></span><br><span class="line"><span class="comment"># 较新的版本开启后会在任务完成后依然保留.aria2 文件 </span></span><br><span class="line"><span class="comment">#force-save=false</span></span><br><span class="line"><span class="comment"># BT 校验相关，默认:true</span></span><br><span class="line"><span class="comment">#bt-hash-check-seed=true</span></span><br><span class="line"><span class="comment"># 继续之前的 BT 任务时，无需再次校验，默认:false</span></span><br><span class="line">bt-seed-unverified=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 保存磁力链接元数据为种子文件 (.torrent 文件), 默认:false</span></span><br><span class="line"><span class="comment">#bt-save-metadata=true</span></span><br></pre></td></tr></table></figure><p>配置完成后在启动 <code>aria2</code> 时指定配置文件的位置即可，例如我把 <code>aria.conf</code> 与 <code>aria2c.exe</code> 放在同一个文件夹下，则启动时直接指定 </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">aria2c.exe --conf-path=aria2.conf</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjeqk8oznj20l8096aai.jpg" alt="aria2 配置文件" title="aria2 配置文件"></p><p> 当然，这样做只是启动了 <code>aria2</code>，并没有开始创建下载任务，不像单个命令行那样简单，直接设置参数就起任务了。接下来还需要浏览器插件的配合，才能保证下载任务的创建与监控，虽然配置步骤麻烦一点，但是使用起来更为方便。</p><p>为了避免启动时还要输入命令行，在 <code>Windows</code> 平台下可以写一个 <code>bat</code> 脚本，每次双击脚本即可，以下脚本内容供参考 <code>Start.bat</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off &amp; title Aria2</span><br><span class="line">aria2c.exe --conf-path=aria2.conf</span><br></pre></td></tr></table></figure><h3 id="使用"><a href="# 使用" class="headerlink" title="使用"></a>使用 </h3><p> 注意，<strong> 使用之前先登录百度云，否则生成的链接无效 </strong>。</p><p>1、使用命令行启动单个任务无需多做介绍，直接敲下命令行，等待文件下载就行了。如果需要连续下载多个文件，则唯一的做法就是多敲下几个命令，多等待而已。因此，这种方式不适合任务数量多的情况，那这种情况下显然是需要批量下载的，并且可以对下载任务进行管理，那就要看下面的一项了：后台起 <code>aria2</code> 服务。</p><p>生成下载 <code>url</code> 的过程需要借助 <a href="https://chrome.google.com/webstore/detail/baiduexporter/jgebcefbdjhkhapijgbhkidaegoocbjj?hl=zh-CN" target="_blank" rel="noopener">baiduexporter</a>、<a href="https://chrome.google.com/webstore/detail/yaaw-for-chrome/dennnbdlpgjgbcjfgaohdahloollfgoc?hl=zh-CN" target="_blank" rel="noopener">YAAW for Chrome</a> 插件，直接从 <code>Chrome</code> 浏览器的插件商店搜索安装即可。</p><p>如果无法翻墙，也可以从离线镜像库下载离线文件进行安装，离线库可以参考本站点的 <a href="https://www.playpi.org/about">关于页面 </a> 给出的工具链接。</p><p> 接下来描述使用方式，登录百度网盘账号，把需要下载的文件保存在自己的网盘中，选择需要下载的文件，然后可以看到本来的下载按钮旁边又多了导出下载按钮，包含几个选项：<code>ARIA2 RPC</code>、文本导出、设置。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjftqq3ugj210w0ejjs0.jpg" alt="Aria2 导出下载" title="Aria2 导出下载"></p><p>选择文本导出就会弹出当前下载文件的下载 <code>url</code>，复制粘贴到命令后即可直接下载该资源。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjfx3u157j21200ifmy2.jpg" alt="Aria2 文本导出" title="Aria2 文本导出"></p><p>导出的内容格式如下，当然实际使用的时候里面的参数也是可以更改的，但是下载 <code>url</code> 一定不不能变的。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">https://pcs.baidu.com/rest/2.0/pcs/file?method=download&amp;app_id=250528&amp;path=%2F% E9%80%86% E5%90%91% E8% B5%84% E6%96%99%2FIDA%20Pro% E6%9D%83% E5% A8%81% E6%8C%87% E5%8D%97.pdf</span><br></pre></td></tr></table></figure><p>2、根据前面的描述，后台起了 <code>aria2</code> 服务，但是还没真正用起来，想要用起来，必须配合两个插件：<br><a href="https://chrome.google.com/webstore/detail/baiduexporter/jgebcefbdjhkhapijgbhkidaegoocbjj?hl=zh-CN" target="_blank" rel="noopener">baiduexporter</a>、<a href="https://chrome.google.com/webstore/detail/yaaw-for-chrome/dennnbdlpgjgbcjfgaohdahloollfgoc?hl=zh-CN" target="_blank" rel="noopener">YAAW for Chrome</a> 。</p><p>这 2 个插件中前者的作用是获取百度网盘的文件 <code>url</code>，这个 <code>url</code> 当然不是分享文件产生的 <code>url</code>，而是下载文件产生的 <code>url</code>；后者插件的作用是配合前者自动创建下载任务，实际下载利用的是已经启动的 <code>aria2</code> 后台，并时时监控任务状态，提供任务管理界面。</p><p>插件的安装不再赘述，接下来直接描述使用流程，要确保以上两个安装的插件都已经启用。根据上一步骤已经知道导出下载这个按钮，里面包含着一个 <code>ARIA2 RPC</code> 选项，这个选项就是直接使用 后台 <code>aria2</code> 服务创建下载任务，然后 <code>YAAW for Chrome</code> 插件监控着所有下载任务。</p><p>还有一个前提，就是启动 <code>aria2</code> 服务时要开启 <code>RPC</code> 模式。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启用 RPC, 默认:false</span></span><br><span class="line"><span class="built_in">enable</span>-rpc=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p>这样做了之后，<code>aria2</code> 后台服务会开启一个端口，一般默认 6800【如果 <code>aria2</code> 更改了端口，<code>YAAW for Chrome</code> 也要做相应的配置】，这个端口用来给 <code>YAAW for Chrome</code> 汇报下载任务的情况，并提供管理下载任务的接口，这样的话，直接通过 <code>YAAW for Chrome</code> 就可以通过可视化的方式创建、暂停、查看任务。</p><p>后台启动 <code>aria2</code>，开启 <code>RPC</code> 模式。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjg7ftepxj20gj0ahmxk.jpg" alt="后台启动 aria2" title="后台启动 aria2"></p><p>打开 <code>YAAW for Chrome</code> 插件查看端口配置信息。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjga6q57mj20y30kyaav.jpg" alt="YAAW 配置" title="YAAW 配置"></p><p>通过 <code>baiduexporter</code> 插件，直接选择 <code>PRC</code> 下载，再去 <code>YAAW</code> 界面刷新查看下载任务。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjgepy1l1j21400dcaao.jpg" alt="RPC 下载" title="RPC 下载"></p><p>可以看到，<code>aria2</code> 参数还没优化【线程数、分块大小设置】，下载速度已经有将近 <code>400Kb/s</code> 了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjgfb0g00j21000cnq3b.jpg" alt="YAAW 查看任务" title="YAAW 查看任务"></p><h2 id="使用油猴插件绕过浏览器下载大文件的限制"><a href="# 使用油猴插件绕过浏览器下载大文件的限制" class="headerlink" title="使用油猴插件绕过浏览器下载大文件的限制"></a>使用油猴插件绕过浏览器下载大文件的限制 </h2><h3 id="现象"><a href="# 现象" class="headerlink" title="现象"></a> 现象 </h3><p> 还是刚才那个文件，文件大小只有 <code>149M</code>，不想通过百度网盘客户端下载，只想通过网页版下载，那就直接点击下载按钮，发现被限制了，必须让你安装百度网盘客户端。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjglvadsdj212c0hzwff.jpg" alt="网页限制大文件" title="网页限制大文件"></p><p>本来还在想通过网页版直接下载，速度也不会很慢，但是被限制了，这个时候我们的万能插件要出场了：<br><a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=zh-CN" target="_blank" rel="noopener">Tampermonkey</a> ，又称油猴、暴力猴。</p><h3 id="解决方式"><a href="# 解决方式" class="headerlink" title="解决方式"></a>解决方式 </h3><p> 使用万能的插件，屏蔽百度网盘网页版原来的网页内容，从而导致百度网盘的限制失效，这个插件就是 <code>Tampermonkey</code>：<a href="https://tampermonkey.net" target="_blank" rel="noopener">官网 </a> 、<a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=zh-CN" target="_blank" rel="noopener">Chrome 浏览器插件商店</a> 。</p><p> 这个插件的作用其实就是帮你管理各种自定义脚本，并运用在网页解析渲染中，从而实现对网页内容的改变，例如：去除网页的广告、去除百度搜索内容的广告条目、更改新浪微博展示界面。其中，也包括让百度网盘的下载文件大小限制失效，从而可以自由下载。</p><p>1、好，现在需要在插件的基础上安装一个脚本：百度网盘直接下载助手。要安装这个脚本，则首先需要找到它，选择获取新脚本，会引导我们进入脚本仓库。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjhpp1dbsj20ep0adt94.jpg" alt="获取新脚本" title="获取新脚本"></p><p>2、各种脚本仓库，我们选择 <a href="https://greasyfork.org/zh-CN" target="_blank" rel="noopener">GreasyFork</a> 。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjhs41z1sj20zd0q2dhg.jpg" alt="脚本仓库列表" title="脚本仓库列表"></p><p>3、在搜索框中搜索：百度网盘直接下载助手，选择其中一个。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjhuwpvohj20s70q2n18.jpg" alt="选择脚本" title="选择脚本"></p><p>4、安装选择的脚本。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjhwddpjgj20ro0q240i.jpg" alt="安装脚本" title="安装脚本"></p><p>5、可以看到脚本内容，点击安装。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjhyame9cj20xg0q2dht.jpg" alt="脚本内容" title="脚本内容"></p><p>6、安装完成后，选择管理面板可以查看已经安装的脚本以及是否启用，也可以删除或者二次编辑。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxji95kjl0j21hc0693yu.jpg" alt="管理面板" title="管理面板"></p><p>7、回到百度网盘，选择文件，可以看到多了一个下载助手选项，选择 <code>API</code> 下载，下载，即可使用浏览器直接下载，不会因为文件太大有网页的限制。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjidt1sdoj214a0q2ab1.jpg" alt="下载助手" title="下载助手"></p><p>8、当然，如果自己会写脚本，或者从别处直接复制的源脚本代码，在插件中选择添加新脚本，自己编辑即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjhte0bjfj20i009yt96.jpg" alt="添加新脚本" title="添加新脚本"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxjigww3m8j20k00fv74q.jpg" alt="编辑脚本内容" title="编辑脚本内容"></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Aria2</tag>
        <tag>百度网盘</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Java 获取 HBase 中多版本数据的方法</title>
    <url>/2019071101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近工作比较繁忙，在处理需求、写代码的过程中踩到了一些坑，不过问题都被我一个一个解决了，所以最近三周都没有更新博客内容。不过，我是整理了提纲、打了草稿，近期会陆续整理出来。今天就先整理出来一个简单的知识点：使用 <code>Java API</code> 从 <code>HBase</code> 中获取多版本【Version 的概念】数据的方法，开发环境基于 <code>JDK v1.8</code>、<code>HBase v1.1.2</code>、<code>Zookeeper v3.4.6</code>，在演示过程中还会使用原生的 <code>HBase Shell</code> 进行配合，加深理解。</p><a id="more"></a><h1 id="入门概念"><a href="# 入门概念" class="headerlink" title="入门概念"></a>入门概念 </h1><p> 先列举一些关于 <code>HBase</code> 的基础概念，有助于继续阅读下文，如果不太了解需要先回顾一下：</p><ul><li>列式分布式数据库，基于 <code>Google BigTable</code> 论文开发，适合海量的数据存储 </li><li>Rowkey、Column Family、Qualifier、Timestamp、Cell、Version 的概念</li><li>HBase Shell、Java API、Phoenix</li></ul><h1 id="示例代码"><a href="# 示例代码" class="headerlink" title="示例代码"></a> 示例代码 </h1><p> 下面的演示会以 <code>HBase Shell</code>、<code>Java API</code> 这两种方式分别进行，便于读者理解。</p><h2 id="建表造数据"><a href="# 建表造数据" class="headerlink" title="建表造数据"></a>建表造数据 </h2><p> 为了使用 <code>Java API</code> 获取多版本数据，我要先做一些基础工作：创建表、造数据、造多版本数据。为了尽量简化数据的复杂度，以及能让读者理解，我准备了 2 条数据，下面使用一个表格来整理这 2 条数据，读者可以看得更清晰：</p><table><thead><tr><th style="text-align:center">Rowkey</th><th style="text-align:center">Column Family</th><th style="text-align:center">Qualifier</th><th style="text-align:center">Version</th><th style="text-align:center">Value</th></tr></thead><tbody><tr><td style="text-align:center">row01</td><td style="text-align:center">cf</td><td style="text-align:center">name</td><td style="text-align:center">1</td><td style="text-align:center">JIM</td></tr><tr><td style="text-align:center">row01</td><td style="text-align:center">cf</td><td style="text-align:center">name</td><td style="text-align:center">2</td><td style="text-align:center">Jack</td></tr><tr><td style="text-align:center">row02</td><td style="text-align:center">cf</td><td style="text-align:center">name</td><td style="text-align:center">1</td><td style="text-align:center">Lucy</td></tr><tr><td style="text-align:center">row02</td><td style="text-align:center">cf</td><td style="text-align:center">age</td><td style="text-align:center">1</td><td style="text-align:center">20</td></tr></tbody></table><p>从上表可以看出，一共 2 条数据，<code>row01</code> 有 1 列，2 个版本，<code>row02</code> 有 2 列，1 个版本。下面使用原生的 <code>HBase Shell</code> 开始逐步建表、造数据。</p><p>1、进入交互式客户端 </p><p> 使用 <code>hbase shell</code> 进入交互式客户端，在输出的日志中可以看到当前环境 <code>HBase</code> 的版本号。</p><p>登录成功后终端显示：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192301.png" alt="登录成功" title="登录成功"></p><p>2、创建表：学生表 </p><p> 使用 <code>create &#39;TB_HBASE_STUDENT&#39;,&#39;cf&#39;</code> 创建一张表，为了便于后面的操作，表名最好使用大写形式，否则涉及到表名的操作需要加单引号。由于 <code>HBase</code> 是列式存储结构，所以创建表时不需要指定具体的列名称，只要指定 <code>Column Family</code> 名称即可。</p><p>执行后终端显示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 row (s) in 2.5260 seconds</span><br><span class="line"> =&gt; Hbase::Table - TB_HBASE_STUDENT</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192317.png" alt="创建表" title="创建表"></p><p>3、查看表结构 </p><p> 使用 <code>describe &#39;TB_HBASE_STUDENT&#39;</code> 查看表结构，执行后终端显示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Table TB_HBASE_STUDENT is ENABLED</span><br><span class="line">TB_HBASE_STUDENT</span><br><span class="line">COLUMN FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME =&gt; &apos;cf&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;, VERSIONS =&gt; &apos;1&apos;, IN_MEMORY =&gt; &apos;false&apos;, KEEP_DELETED_CELLS =&gt; &apos;FALSE&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, TTL =&gt; &apos;FOREVER&apos;, COMPRESSION =&gt; &apos;NONE&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, BLOCKCACHE =&gt; &apos;true&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;&#125;</span><br><span class="line">1 row (s) in 0.0390 seconds</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192331.png" alt="查看表结构" title="查看表结构"></p><p>可以看到表的基本信息，其中 <code>Column Family</code> 名称为 <code>cf</code>，最大版本 <code>VERSIONS</code> 为 1，这会导致只会存储一个版本的列数据，当再次插入数据的时候，后面的值会覆盖掉前面的值。</p><p>4、修改最大版本 </p><p> 为了满足我的需求，需要更改表，把 <code>cf</code> 的最大版本数 <code>VERSIONS</code> 增加，设置为 3 。使用 <code>alter &#39;TB_HBASE_STUDENT&#39;,{NAME=&gt;&#39;cf&#39;,VERSIONS=&gt;3}</code> 命令即可。执行后终端显示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Updating all regions with the new schema...</span><br><span class="line">0/1 regions updated.</span><br><span class="line">1/1 regions updated.</span><br><span class="line">Done.</span><br><span class="line">0 row (s) in 3.7710 seconds</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192344.png" alt="修改最大版本数" title="修改最大版本数"></p><p>修改成功后，我使用 <code>describe &#39;TB_HBASE_STUDENT&#39;</code> 再次查看表结构，终端显示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Table TB_HBASE_STUDENT is ENABLED</span><br><span class="line">TB_HBASE_STUDENT</span><br><span class="line">COLUMN FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME =&gt; &apos;cf&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;, VERSIONS =&gt; &apos;3&apos;, IN_MEMORY =&gt; &apos;false&apos;, KEEP_DELETED_CELLS =&gt; &apos;FALSE&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, TTL =&gt; &apos;FOREVER&apos;, COMPRESSION =&gt; &apos;NONE&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, BLOCKCACHE =&gt; &apos;true&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;&#125;</span><br><span class="line">1 row (s) in 0.0380 seconds</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192357.png" alt="再次查看表结构" title="再次查看表结构"></p><p>这次可以看到，<code>VERSIONS =&gt; &#39;3&#39;</code> 表示 <code>cf</code> 已经支持存储 3 个版本的数据了。</p><p>5、插入 2 条数据 </p><p><code>HBase</code> 的插入数据功能是使用 <code>put</code> 命令，每次插入 1 列，根据上述表格数据格式，需要执行 4 次 <code>put</code> 操作。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">put &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&apos;cf:name&apos;,&apos;JIM&apos;</span><br><span class="line">put &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&apos;cf:name&apos;,&apos;Jack&apos;</span><br><span class="line">put &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:name&apos;,&apos;Lucy&apos;</span><br><span class="line">put &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:age&apos;,&apos;20&apos;</span><br></pre></td></tr></table></figure><p> 执行后终端显示如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.8.7-p357 :012 &gt;   put &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&apos;cf:name&apos;,&apos;JIM&apos;</span><br><span class="line">0 row (s) in 0.1600 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :013 &gt; put &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&apos;cf:name&apos;,&apos;Jack&apos;</span><br><span class="line">0 row (s) in 0.0180 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :014 &gt; put &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:name&apos;,&apos;Lucy&apos;</span><br><span class="line">0 row (s) in 0.0160 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :015 &gt; put &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:age&apos;,&apos;20&apos;</span><br><span class="line">0 row (s) in 0.0180 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :016 &gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192412.png" alt="插入 2 条数据" title="插入 2 条数据"></p><h2 id="命令行查看"><a href="# 命令行查看" class="headerlink" title="命令行查看"></a>命令行查看 </h2><p>1、先尝试使用 <code>get</code> 命令来获取这 2 条数据，分别执行 3 次 <code>get</code> 操作。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:name&apos;</span><br><span class="line">get &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:age&apos;</span><br><span class="line">get &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&apos;cf:name&apos;</span><br></pre></td></tr></table></figure><p> 执行后终端显示如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.8.7-p357 :026 &gt;   get &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:name&apos;</span><br><span class="line">COLUMN                CELL</span><br><span class="line">cf:name               timestamp=1566118670447, value=Lucy</span><br><span class="line"></span><br><span class="line">1 row (s) in 0.0160 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :027 &gt; get &apos;TB_HBASE_STUDENT&apos;,&apos;row02&apos;,&apos;cf:age&apos;</span><br><span class="line">COLUMN                CELL</span><br><span class="line">cf:age                timestamp=1566118677185, value=20</span><br><span class="line"></span><br><span class="line">1 row (s) in 0.0060 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :028 &gt; get &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&apos;cf:name&apos;</span><br><span class="line">COLUMN                CELL</span><br><span class="line">cf:name               timestamp=1566118661397, value=Jack</span><br><span class="line"></span><br><span class="line">1 row (s) in 0.0080 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :029 &gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192431.png" alt="读取数据" title="读取数据"></p><p>可以看到，此时并没有获取到 <code>row01</code> 的 2 个版本的数据，只获取了最新版本的结果。</p><p>2、使用 <code>get</code> 获取多版本数据，执行 <code>get</code> 时需要加上 <code>VERSIONS</code> 相关的参数。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&#123;COLUMN=&gt;&apos;cf:name&apos;,VERSIONS=&gt;3&#125;</span><br></pre></td></tr></table></figure><p>执行后终端显示如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.8.7-p357 :029 &gt; get &apos;TB_HBASE_STUDENT&apos;,&apos;row01&apos;,&#123;COLUMN=&gt;&apos;cf:name&apos;,VERSIONS=&gt;3&#125;</span><br><span class="line">COLUMN                CELL</span><br><span class="line">cf:name               timestamp=1566118661397, value=Jack</span><br><span class="line">cf:name               timestamp=1566118652009, value=JIM</span><br><span class="line"></span><br><span class="line">2 row (s) in 0.0140 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :030 &gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192445.png" alt="读取多版本数据" title="读取多版本数据"></p><p>可以看到，2 个版本的数据都读取出来了。</p><p>3、使用 <code>scan</code> 扫描数据 </p><p> 此外还有一个 <code>scan</code> 命令可以扫描表中的数据，使用 <code>scan &#39;TB_HBASE_STUDENT&#39;,{LIMIT=&gt;5}</code> 尝试扫描 5 条数据出来。</p><p>执行后终端显示如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.8.7-p357 :031 &gt;   scan &apos;TB_HBASE_STUDENT&apos;,&#123;LIMIT=&gt;5&#125;</span><br><span class="line">ROW                   COLUMN+CELL</span><br><span class="line">row01                 column=cf:name, timestamp=1566118661397, value=Jack</span><br><span class="line">row02                 column=cf:age, timestamp=1566118677185, value=20</span><br><span class="line">row02                 column=cf:name, timestamp=1566118670447, value=Lucy</span><br><span class="line"></span><br><span class="line">2 row (s) in 0.0420 seconds</span><br><span class="line"></span><br><span class="line">1.8.7-p357 :032 &gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192456.png" alt="扫描数据" title="扫描数据"></p><p>由于表中只有 2 条数据，所以只显示出 2 条，而且 <code>scan</code> 默认也是获取最新版本的数据结果。</p><p>4、如果想退出 <code>HBase Shell</code> 交互式客户端，使用 <code>!quit</code> 命令即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192505.png" alt="退出客户端" title="退出客户端"></p><h2 id="代码示例"><a href="# 代码示例" class="headerlink" title="代码示例"></a>代码示例 </h2><p> 上面使用原生的 <code>HBase Shell</code> 操作演示了创建表、插入数据、读取数据的过程，下面将使用 <code>Java API</code> 演示读取数据的过程，而创建表、插入数据的过程就不再演示。</p><p>这里需要特别注意，为了正常使用 <code>Java API</code> 的相关接口，<code>Java</code> 项目需要依赖 <code>hbase-client</code>、<code>commons-configuration</code>、<code>hadoop-auth</code>、<code>hadoop-hdfs</code> 等组件。我的代码已经上传至 <code>GitHub</code>，详见：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-hbase/src/main/java/org/playpi/study/test" target="_blank" rel="noopener">TestHBase.java</a> ，搜索类名 <code>TestHBase</code> 即可。</p><p>1、代码示例 </p><p> 代码结构比较简单，分为：构造查询请求、发送请求、解析结果输出几部分，注释中也注明了各个部分的作用，总计也就 50 行代码左右。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * HBase Java API Get 测试 </span><br><span class="line">     */</span><br><span class="line">public void testGet () &#123;</span><br><span class="line">	String hTableName = &quot;TB_HBASE_STUDENT&quot;;</span><br><span class="line">	IplaypiStudyConfig configuration = IplaypiStudyConfig.getInstance ();</span><br><span class="line">	byte [] cfbyte = &quot;cf&quot;.getBytes ();</span><br><span class="line">	byte [] col01byte = &quot;name&quot;.getBytes ();</span><br><span class="line">	byte [] col02byte = &quot;age&quot;.getBytes ();</span><br><span class="line">	try &#123;</span><br><span class="line">		// 构造查询请求，2 条数据，多个版本 </span><br><span class="line">		List&lt;Get&gt; getList = Lists.newArrayList ();</span><br><span class="line">		Get get = new Get (Bytes.toBytes (&quot;row01&quot;));</span><br><span class="line">		get.addColumn (cfbyte, col01byte);</span><br><span class="line">		// 设置最大版本数，默认为 1</span><br><span class="line">		get.setMaxVersions (3);</span><br><span class="line">		getList.add (get);</span><br><span class="line">		Get get2 = new Get (Bytes.toBytes (&quot;row02&quot;));</span><br><span class="line">		get2.addColumn (cfbyte, col01byte);</span><br><span class="line">		get2.addColumn (cfbyte, col02byte);</span><br><span class="line">		getList.add (get2);</span><br><span class="line">		// 发送请求，获取结果 </span><br><span class="line">		HTable hTable = new HTable (configuration, hTableName);</span><br><span class="line">		Result [] resultArr = hTable.get (getList);</span><br><span class="line">		/**</span><br><span class="line">             * 以下有两种解析结果的方法 </span><br><span class="line">             * 1 - 通过 Result 类的 getRow () 和 getValue () 两个方法，只能获取最新版本 </span><br><span class="line">             * 2 - 通过 Result 类的 rawCells () 方法返回一个 Cell 数组，可以获取多个版本，如果使用 getColumnCells 可以指定列 </span><br><span class="line">             * 注意，高版本不再建议使用 KeyValue 的方式，注释中有说明 </span><br><span class="line">             */</span><br><span class="line">		// 1-</span><br><span class="line">		log.info (&quot;====get result by first method&quot;);</span><br><span class="line">		for (Result result : resultArr) &#123;</span><br><span class="line">			log.info (&quot;&quot;);</span><br><span class="line">			log.info (&quot;--------&quot;);</span><br><span class="line">			String rowStr = Bytes.toString (result.getRow ());</span><br><span class="line">			log.info (&quot;====row:[&#123;&#125;]&quot;, rowStr);</span><br><span class="line">			// 如果包含 name 列，则获取输出 </span><br><span class="line">			if (result.containsColumn (cfbyte, col01byte)) &#123;</span><br><span class="line">				String valStr = Bytes.toString (result.getValue (cfbyte, col01byte));</span><br><span class="line">				log.info (&quot;====name:[&#123;&#125;],getValue&quot;, valStr);</span><br><span class="line">				// 以下方式不建议使用，但是可以获取多版本 </span><br><span class="line">				List&lt;KeyValue&gt; keyValueList = result.getColumn (cfbyte, col01byte);</span><br><span class="line">				for (KeyValue keyValue : keyValueList) &#123;</span><br><span class="line">					log.info (&quot;====name:[&#123;&#125;],getColumn -&gt; getValue&quot;, Bytes.toString (keyValue.getValue ()));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			// 如果包含 age 列，则获取输出 </span><br><span class="line">			if (result.containsColumn (cfbyte, col02byte)) &#123;</span><br><span class="line">				String valStr = Bytes.toString (result.getValue (cfbyte, col02byte));</span><br><span class="line">				log.info (&quot;====age:[&#123;&#125;],getValue&quot;, valStr);</span><br><span class="line">				// 以下方式不建议使用，但是可以获取多版本 </span><br><span class="line">				List&lt;KeyValue&gt; keyValueList = result.getColumn (cfbyte, col02byte);</span><br><span class="line">				for (KeyValue keyValue : keyValueList) &#123;</span><br><span class="line">					log.info (&quot;====age:[&#123;&#125;],getColumn -&gt; getValue&quot;, Bytes.toString (keyValue.getValue ()));</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		// 2-</span><br><span class="line">		log.info (&quot;&quot;);</span><br><span class="line">		log.info (&quot;====get result by second method&quot;);</span><br><span class="line">		for (Result result : resultArr) &#123;</span><br><span class="line">			log.info (&quot;&quot;);</span><br><span class="line">			log.info (&quot;--------&quot;);</span><br><span class="line">			String rowStr = Bytes.toString (result.getRow ());</span><br><span class="line">			log.info (&quot;====row:[&#123;&#125;]&quot;, rowStr);</span><br><span class="line">			//name 列 </span><br><span class="line">			List&lt;Cell&gt; cellList = result.getColumnCells (cfbyte, col01byte);</span><br><span class="line">			// 1 个 cell 就是 1 个版本 </span><br><span class="line">			for (Cell cell : cellList) &#123;</span><br><span class="line">				// 高版本不建议使用 </span><br><span class="line">				log.info (&quot;====name:[&#123;&#125;],getValue&quot;, Bytes.toString (cell.getValue ()));</span><br><span class="line">				//getValueArray: 数据的 byte 数组 </span><br><span class="line">				//getValueOffset:rowkey 在数组中的索引下标 </span><br><span class="line">				//getValueLength:rowkey 的长度 </span><br><span class="line">				String valStr = Bytes.toString (cell.getValueArray (), cell.getValueOffset (), cell.getValueLength ());</span><br><span class="line">				log.info (&quot;====name:[&#123;&#125;],[getValueArray,getValueOffset,getValueLength]&quot;, valStr);</span><br><span class="line">				log.info (&quot;====timestamp:[&#123;&#125;],cell&quot;, cell.getTimestamp ());</span><br><span class="line">			&#125;</span><br><span class="line">			//age 列不演示了，省略...</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	catch (IOException e) &#123;</span><br><span class="line">		log.error (&quot;!!!!error: &quot; + e.getMessage (), e);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、运行结果 </p><p> 执行运行，可以看到结果输出，与数据表中一致，多版本数据结果也可以全部获取：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:58: ====get result by first method</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:60: </span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:61: --------</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:63: ====row:[row01]</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:67: ====name:[Jack],getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:71: ====name:[Jack],getColumn -&gt; getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:71: ====name:[JIM],getColumn -&gt; getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:60: </span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:61: --------</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:63: ====row:[row02]</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:67: ====name:[Lucy],getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:71: ====name:[Lucy],getColumn -&gt; getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:77: ====age:[20],getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:81: ====age:[20],getColumn -&gt; getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:86: </span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:87: ====get result by second method</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:89: </span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:90: --------</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:92: ====row:[row01]</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:98: ====name:[Jack],getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:103: ====name:[Jack],[getValueArray,getValueOffset,getValueLength]</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:104: ====timestamp:[1566118661397],cell</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:98: ====name:[JIM],getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:103: ====name:[JIM],[getValueArray,getValueOffset,getValueLength]</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:104: ====timestamp:[1566118652009],cell</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:89: </span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:90: --------</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:92: ====row:[row02]</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:98: ====name:[Lucy],getValue</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:103: ====name:[Lucy],[getValueArray,getValueOffset,getValueLength]</span><br><span class="line">2019-08-18_17:54:18 [main] INFO test.TestHBase:104: ====timestamp:[1566118670447],cell</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192521.png" alt="Java 程序运行结果" title="Java 程序运行结果"></p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p>1、在使用 <code>Java API</code> 时注意低版本、高版本之间的差异，必要时及时升级，就像上文代码中的 <code>Result.getColumn</code>、<code>KeyValue.getValue ()</code>、<code>Cell.getValue ()</code> 这几个方法。</p><p>2、<code>Phoenix</code> 是一款基于 <code>HBase</code> 的工具，在 <code>HBase</code> 之上提供了 <code>OLTP</code> 相关的功能，例如完全的 <code>ACID</code> 支持、<code>SQL</code>、二级索引等，此外 <code>Phoenix</code> 还提供了标准的 <code>JDBC</code> 的 <code>API</code>。在使用 <code>Phoenix</code> 时，可以很方便地像操作 <code>SQL</code> 那样操作 <code>HBase</code>。</p><p> 使用 <code>Phoenix</code> 创建表、查询数据示例如图。</p><p>创建表，使用：<br><code>CREATE TABLE IF NOT EXISTS TB_HBASE_STUDENT (&quot;pk&quot;varchar primary key,&quot;cf&quot;.&quot;name&quot;varchar,&quot;cf&quot;.&quot;age&quot;varchar);</code></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192546.png" alt="使用 Phoenix 创建表" title="使用 Phoenix 创建表"></p><p>查询示例，使用：<br><code>select * from&quot;TB_HBASE_STUDENT&quot;limit 5;</code></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190818192540.png" alt="使用 Phoenix 查询" title="使用 Phoenix 查询"></p><p>3、本示例的代码放在 <code>GirHub</code>，详见：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-hbase/src/main/java/org/playpi/study/test" target="_blank" rel="noopener">TestHBase.java</a> ，搜索类名 <code>TestHBase</code> 即可。参考 <code>GitHub</code> 的代码时，注意在 <code>iplaypistudy-common-config</code> 模块中增加自己的配置文件，如果开发环境的版本不匹配，也要升级版本，在 <code>pom.xml</code> 更改即可。</p><p>4、想要使用 <code>HBase Shell</code> 删除表时，必须先使用 <code>disable YOUR_TABLE_NAME</code> 来禁用表，然后再使用 <code>drop YOUR_TABLE_NAME</code> 删除表，直接删除表是不被允许的。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HBase</tag>
        <tag>version</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Vultr 创建云主机详细步骤</title>
    <url>/2019072801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>我在以前的一篇博客中，详细记录了自己搭建翻墙梯子的过程，参考：<br><a href="https://www.playpi.org/2018111601.html">使用 Vultr 搭建 Shadowsocks（VPS 搭建 SS）</a> ，其中，我还顺便留下了我的 <code>Vultr</code> 推广链接：<br><a href="https://www.vultr.com/?ref=7443790" target="_blank" rel="noopener">我的 10 美元推广链接 </a> 。可能是因为这篇博客的流量还不错，基本每个月都会有几个人通过我的推广链接注册，当然，注册后真正使用的人只有 1-2 个。</p><p> 我看了一下我的账户，平均每个月都会收到一份有效注册所带来的优惠券，大概可以给我带来 <code>$10</code> 的收入，足够抵消我的月租消费了，这也是注册 <code>Vultr</code> 后并真正使用 <code>Vultr</code> 的人带给我的收入，我觉得这是意外的惊喜。</p><p>所以，本着分享的理念以及「吃饭」的需要，我推荐大家使用 <code>Vultr</code>，但是担心可能有些读者第一次使用 <code>Vultr</code>，系统又是英文的，不太熟悉。在此，我把节点的创建过程再整理出来，图文并茂，并说明注意事项，给读者参考。读者参考本文一步一步操作，就可以从零开始创建 <code>Vultr</code> 主机，只需要再花费 <code>$10</code> 就可以使用半年的 <code>Vultr</code> 云主机。至于搭建梯子的过程还是请继续参考上面给出的以前的博客内容：<a href="https://www.playpi.org/2018111601.html">使用 Vultr 搭建 Shadowsocks（VPS 搭建 SS）</a> 。</p><p><strong>声明 </strong>：2019 年 08 月 09 日发现 <code>Vultr</code> 官方不会再赠送 <code>$10</code> 的代金券给新注册用户，只会给我发放代金券，但是 <code>$25</code> 的代金券仍然有效，请读者选择 <code>$25</code> 对应的链接打开注册，以免错失了代金券。</p><a id="more"></a><p>首先声明，本文中的文字与截图整理于 2019 年 07 月 26 日到 2019 年 08 月 03 日，以后 <code>Vultr</code> 这个产品的界面或者功能可能会变化，所以请读者以实际使用时的产品为准，本文仅供参考。但是我觉得无论 <code>Vultr</code> 这个产品再怎么变，本文描述的这几大核心功能也不会变，最多就是界面操作的变化，读者可以放心参考使用。</p><h1 id="开篇推荐"><a href="# 开篇推荐" class="headerlink" title="开篇推荐"></a>开篇推荐 </h1><p> 使用 <code>Vultr</code> 的云主机，最好选择洛杉矶地区的或者日本的服务器，我亲自测试这两个地区的服务器最稳定，已经推荐给很多人，而且网速相对来说较好，我的推广链接【可以获取 10 美元的代金券，只要充值 10 美元就能使用】：<a href="https://www.vultr.com/?ref=7443790" target="_blank" rel="noopener">我的 10 美元推广链接 </a> ，官网链接也在这里：<a href="https://my.vultr.com" target="_blank" rel="noopener">Vultr</a> 。</p><p> 这里再多说点，如果使用上面的推广链接注册 <code>Vultr</code> 帐号，可以获取 10 美元的代金券，需要在 30 天之内使用，使用的条件就是充值 10 美元以上的钱。例如充值 10 美元就会获取 20 美元的帐号余额，这些钱如果购买 3.5 美元的主机可以使用半年了，挺划算的。</p><p>此外还有一个限时的大优惠，如果准备长期使用 <code>Vultr</code>，肯定要充值多一点，我这里有一个限时的推广链接：<a href="https://www.vultr.com/?ref=8421997-6G" target="_blank" rel="noopener">我的 25 美元推广链接 </a> ，可以获取 100 美元的代金券，使用条件就是 <strong> 充值 25 美元以上的金额 </strong>。假如充值了 25 美元，总共获取 100 美元入账【账号需要活跃 30 天】，购买 3.5 美元的主机可以使用 29 个月，适合长期使用 <code>Vultr</code> 的。</p><p>以下列举 <code>Vultr</code> 的五大好处：</p><ul><li><strong>扣费灵活 </strong>，<code>Vultr</code> 有一个好处就是主机的费用并不是按照月份扣除的，而是按照天扣除的，每天扣除的费用是 <strong>月租 / 30</strong>。例如你的主机只用了 10 天，然后销毁不用了，实际只会扣除月租 1/3 的钱，这种方式很是灵活，哪怕主机的 <code>IP</code> 地址被屏蔽了也可以销毁重新生成一个，并不会浪费钱。它不像国内的云服务商，一般是按照月份扣费的。</li><li><strong>主机管理灵活 </strong>，它不像国内的云服务商，购买一台云主机后，直接先扣费，然后分配一台主机，<code>IP</code> 地址是固定的，如果有问题只能重启。而在 <code>Vultr</code> 中是可以随意创建、销毁虚拟主机的，根据你自己的需求，选择配置、主机机房位置、操作系统，几分钟就可以生成一台主机，如果用了几天觉得不好，或者 <code>IP</code> 地址被封，再销毁重新创建即可，<code>Vultr</code> 只会扣除你几天的费用，非常人性化。</li><li><strong>价格优惠 </strong>，根据配置的不同，价格有多个档次，有 <code>$2.5 / 月 </code>（只有 <code>IP6</code> 地址）、<code>$3.5 / 月</code>、<code>$5 / 月</code> 等等，更贵的也有，一般个人使用选择这三个中的一个就够用了，但是要注意便宜的经常售罄，而且最便宜的只支持 <code>IP6</code>，慎用。大家如果看到没有便宜的主机了不用着急，可以先买了贵的用着，反正费用是按照天数扣除的，等后续发现便宜的套餐赶紧购买，同时把贵的主机给销毁，不会亏钱的。</li><li><strong> 付费方式灵活 </strong>，付费方式除了支持常见的 <strong>Paypal</strong>、<strong> 信用卡 </strong>等方式，它还支持 <strong>比特比 </strong>、<strong> 支付宝 </strong>、<strong> 微信 </strong>等方式。就问你是不是很人性化，作为一家国外的公司，还特意支持 <strong>支付宝 </strong>、<strong> 微信 </strong>的方式支付，也从侧面反映了随着中国的日益强大，中国的电子支付方式正在走向全球，越来越流行。</li><li><strong>机房分布全球 </strong>，它的机房位置遍布全球，例如 <strong>日本 </strong>、<strong> 新加坡 </strong>、<strong> 澳大利亚 </strong>、<strong> 美国 </strong>、<strong> 德国 </strong>、<strong> 英国 </strong>、<strong> 加拿大 </strong>，读者根据网络的需求可以灵活选择。</li></ul><p>至于使用 <code>Vultr</code> 云主机做什么，我想最大的用处就是自行搭建梯子，可以参考我以前的博客内容：<a href="https://www.playpi.org/2018111601.html">使用 Vultr 搭建 Shadowsocks（VPS 搭建 SS）</a> 。</p><h1 id="产品介绍"><a href="# 产品介绍" class="headerlink" title="产品介绍"></a>产品介绍 </h1><p> 首先来看一下官网主页，官网主页地址为：<a href="https://my.vultr.com" target="_blank" rel="noopener">Vultr</a> ，目前看官网的 UI 和几个月前相比有变化，颜色在视觉上加深了，图标显得更加拟物化。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803184837.png" alt="官网首页截图" title="官网首页截图"></p><p>登录的时候需要特别注意，它的验证码非常丧心病狂，一般是六位，而且很难看清楚，更加让人抓狂的是，有时候看不清还不能换一个，只能在输入认证错误后再重新输入，这种用户体验比不上国内的厂商。当然，在常用的网络环境中，<code>Vultr</code> 会检测出当前为常用网络，从而跳过验证码验证这一步骤，所以有时候不需要输入验证码。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803184912.png" alt="登录验证码" title="登录验证码"></p><p>登录成功后，进入到主页，默认是在 <code>Products</code> 模块下面的 <code>Instances</code> 标签页。读者可以看到我这里已经有主机显示出来，如果读者是第一次注册后登录进去或者还没有创建主机的话，是看不到类似于我这里图中的 <code>Server</code> 列表的。不过不用着急，后面我会带领读者一步一步进行主机的创建。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803185111.png" alt="Vultr 系统主页" title="Vultr 系统主页"></p><p>先来熟悉一下系统的所有模块与常用功能，毕竟界面是全英文的，读者熟悉后方便在后续的操作中熟练找到需要的模块与功能。</p><p>注意查看上面的首页图，读者也可以在登录进入系统之后，随便点击浏览一下。先看左侧列表，分为五个大模块：<code>Products</code>、<code>Billing</code>、<code>Support</code>、<code>Affiliate</code>、<code>Account</code>，下面简单描述一下这五个大模块，读者看完后在心里可以有一个基本的概念：</p><ul><li><code>Products</code>：<strong> 产品管理 </strong>模块，在里面可以管理主机、登录密钥、DNS、系统快照等信息，最常用的就是主机的创建、查看、销毁 </li><li><code>Billing</code>：<strong> 账单管理 </strong> 模块，在里面可以查看历史消费记录、支付方式，最常用的就是欠费充值、查看历史消费记录 </li><li><code>Support</code>：<strong> 系统支持 </strong> 模块，可以在里面浏览一些常见问题，或者联系客服，一般情况下用不到，目前无需关心 </li><li><code>Affiliate</code>：<strong> 营销推广 </strong> 模块，可以利用 <code>Vultr</code> 为你生成的唯一链接，拉取新用户注册使用，然后就会给你返代金券，可抵扣消费，一般情况下用不到，不过可以分享给身边的人试试 </li><li><code>Account</code>：<strong> 帐号信息 </strong> 模块，包括姓名、地址、邮箱等信息，每月的扣费记录会以账单的形式发送到你的邮箱，这个模块除了第一次设置，以后基本用不到，一般情况下每个月看一次邮箱即可 </li></ul><h1 id="产品管理"><a href="# 产品管理" class="headerlink" title="产品管理"></a> 产品管理 </h1><p><strong> 产品管理 </strong>里面的功能很多，但是对于我这样需求简单的人来说，不需要那么多功能，我只需要创建主机、系统快照这两个功能足够，所以我也只会介绍这两个功能。</p><h2 id="主机创建"><a href="# 主机创建" class="headerlink" title="主机创建"></a>主机创建 </h2><p> 在 <code>Products</code> 模块的 <code>Instances</code> 标签页中，可以看到 <code>Server</code> 列表，也就是用户创建的主机列表，如果还没有创建，则显示为空。看看我的主机列表，已经有一台主机，如下图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024429.png" alt="我的主机列表" title="我的主机列表"></p><p>读者可以注意到右侧有一个蓝色背景的圆形按钮，如果把鼠标的光标放上去，会显示 <code>Deploy New Server</code>，它就是用来创建主机的，下面我将一步一步演示创建的过程。</p><p>点击上述蓝色按钮，会进入 <code>Deploy New Instance</code> 配置界面，读者在 <code>Choose Server</code> 中首先选择 <code>Cloud Compute</code>，它表示 <strong>云主机 </strong>，也就是虚拟主机，它旁边还有三个产品类型可以忽略。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024414.png" alt="选择云主机" title="选择云主机"></p><p>接着在 <code>Server Location</code> 中选择机房位置，这个要根据网络的需要请读者自行选择，如果你在中国大陆，需要搭建梯子，建议选择日本或者美国洛杉矶的机房位置，我这里以日本为例。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024359.png" alt="选择机房位置" title="选择机房位置"></p><p>继续往下看，在 <code>Server Type</code> 中选择操作系统类型，我选择 <code>CentOS 7x64</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024345.png" alt="选择操作系统" title="选择操作系统"></p><p>在 <code>Server Size</code> 中选择主机配置，同时也代表价格，我选择 <code>$5/mon</code>，表示每个月费用五美元，再详细看一下机器的配置：<code>25GB SSD</code> 表示固态硬盘大小、<code>$0.007/h</code> 表示每小时费用 0.007 美元、<code>1 CPU</code> 表示机器的 CPU 为一核、<code>1024MB Memory</code> 表示机器的内存大小、<code>1000GB Bandwidth</code> 表示机器的流量大小。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024328.png" alt="选择配置" title="选择配置"></p><p>最后的 <code>Additional Features</code>、<code>Startup Script</code>、<code>SSH Keys</code>、<code>Server Hostname &amp; Label</code> 可以不用设置，如果读者对 <code>Linux</code> 服务器有一定的了解并且会简单操作，可以在 <code>Startup Script</code> 设置启动脚本用来安装需要的软件环境，也可以在 <code>SSH Keys</code> 中设置密钥用来后续的免密登录，在此不在赘述。</p><p>一切设置完成后，点击右下角的 <code>Deploy Now</code> 蓝色按钮，接着等待几分钟即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024308.png" alt="点击创建主机" title="点击创建主机"></p><p>在等待的过程中，可以回到前面的 <code>Instances</code> 标签页中查看 <code>Server</code> 列表，可以看到刚刚创建的机器正在初始化。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024248.png" alt="主机正在初始化" title="主机正在初始化"></p><p>大概需要几分钟的时间，主机就创建完成。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024229.png" alt="主机创建完成" title="主机创建完成"></p><p>主机创建完成，最重要的事情就是要得知它的 <code>IP</code> 地址、登录密码，才能进行下一步的操作。<code>IP</code> 地址其实在 <code>Server</code> 列表中已经可以看到，是 <code>198.13.59.132</code>，也可以直接点击主机，进入到主机的详情页。或者点击最右侧的三个点，选择 <code>Server Details</code> 进入主机的详情页。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024209.png" alt="进入主机详情页" title="进入主机详情页"></p><p>在 <code>Overview</code> 标签页，此时可以看到更多关于主机的信息，包括 <code>IP</code> 地址、登录用户名、登录密码、流量使用情况、CPU 消耗监控、当前扣费情况。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024153.png" alt="查看主机详情页" title="查看主机详情页"></p><h2 id="系统快照"><a href="# 系统快照" class="headerlink" title="系统快照"></a>系统快照 </h2><p> 前面主机创建的过程读者看了可能会觉得很麻烦，需要设置那么多东西，如果以后机器有问题需要重新创建还要来一遍，体验多不好。况且，如果机器上面安装了一些软件，设置了一些参数，从头再来很麻烦的，有没有简单的方式可以复制一台已经存在的主机呢，除了 <code>IP</code> 地址不一样，其它配置完全一致，并且还要保留机器上面的软件、参数等信息。</p><p>可以，当然可以，接下来，<strong> 系统快照 </strong>功能就要出场了。<strong> 系统快照 </strong>其实就是把操作系统在某一时刻的状态保存下来，包括系统的配置、安装的软件、参数的配置，生成的系统快照就可以随时重复使用，就像克隆一样。</p><p>为了使用系统快照，必须先创建系统快照，在主机的详情页中，有一个 <code>Snapshots</code> 标签页，就是用来创建系统快照的。先在文本框中填入一个名字，用来标记这一个系统快照，然后点击右侧的 <code>Take Snapshot</code> 开始创建。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024054.png" alt="创建系统快照" title="创建系统快照"></p><p>在创建的过程中，可以在 <code>Products</code> 模块中的 <code>Snapshots</code> 标签页中查看系统快照的生成状态，这个过程一般需要很长时间，根据系统的复杂度而定。当然，如果系统中没有安装任何软件，创建起来还是很快的，几分钟就行。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804033858.png" alt="查看系统快照的生成状态" title="查看系统快照的生成状态"></p><p>等系统快照创建完成，使用系统快照就简单得多了，在创建云主机的过程中，不需要选择那么多的参数，选择机房位置后，在 <code>Server Type</code> 中点击 <code>Snapshot</code> 标签页，可以看到系统快照列表，从中选择一个自己需要的系统快照，直接生成即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804024026.png" alt="利用快照创建主机" title="利用快照创建主机"></p><p>使用系统快照创建的主机，除了机房位置、<code>IP</code> 地址与系统快照中的不一样，其它配置信息都是一样，也包括原来的软件、系统配置。</p><h1 id="账单管理"><a href="# 账单管理" class="headerlink" title="账单管理"></a>账单管理 </h1><p><strong> 账单管理 </strong>模块包含设置支付方式、充值、消费记录查看等功能，一般都会用到充值功能，用户使用这种虚拟服务一般不会充值太多的钱，可能半年或者一年才会充值一次。</p><h2 id="支付方式选择"><a href="# 支付方式选择" class="headerlink" title="支付方式选择"></a>支付方式选择 </h2><p> 支付方式就是用户选择使用什么方式来支付，设置好就行，以后除非更换支付方式，否则再也用不到这个功能。除了常规的 <strong>信用卡 </strong>、<strong>Paypal</strong> 支付方式，<code>Vultr</code> 还支持 <strong>支付宝 </strong>、<strong> 微信 </strong>、<strong> 比特比 </strong>支付方式，这支付体验对于中国用户来说简直太友好了，直接下单扫码分分钟就能完成。</p><p>在 <code>Billing</code> 模块选择 <code>Make Payment</code> 标签页，可以看到左侧列表中有多种支付方式可以选择，我这里已经绑定了信用卡。其中，<code>Credit Card</code> 表示信用卡、<code>Bitcoin</code> 表示比特币、<code>Alipay</code> 表示支付宝，<code>Wechat Pay</code> 表示微信支付，读者可以自行选择。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804012211.png" alt="设置支付方式" title="设置支付方式"></p><p>绑定具体的支付方式时，需要填写帐号信息，读者根据要求填写即可。</p><h2 id="查看历史消费记录"><a href="# 查看历史消费记录" class="headerlink" title="查看历史消费记录"></a>查看历史消费记录 </h2><p> 查看历史消费记录，就是为了对对账，看看有没有额外的乱扣费现象，一般情况下通过邮箱查看就行，不用特意登录 <code>Vultr</code> 里面看。</p><p>不过，账单默认是不会被发送到邮箱的，也不会通知用户，需要提前设置好通知方式，在 <code>Billing</code> 模块中的 <code>History</code> 标签页最底部有一个通知方式设置，选择通过邮箱发送即可，这个邮箱帐号是在 <code>Account</code> 模块中设置的，可以参考下文的相关内容。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804012240.png" alt="设置账单通知方式" title="设置账单通知方式"></p><p>选择 <code>Billing</code> 模块中的 <code>Histroy</code> 标签页，可以看到我的消费记录，八月一日扣除了我七月份的费用，总计 <code>$3.5</code>，这算是很便宜的主机配置，以前我用的是 <code>$5</code> 的主机，后来发现流量用不完就换了便宜的主机。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804012307.png" alt="消费记录查看" title="消费记录查看"></p><p>接着再看看我的邮箱，收到了费用扣除账单通知，一共扣除 <code>$3.5</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804012337.png" alt="邮箱收到账单通知" title="邮箱收到账单通知"></p><p>仔细看 <code>History</code> 标签页中的历史清单，可以发现其中还有一些是进账，这种情况可能是自己充值，或者是邀请新用户使用 <code>Vultr</code> 带来的代金券。可以看到在七月份有两笔钱进账，总计二十美元，这明确记得我在七月份没有充值，应该是 <code>Vultr</code> 发放给我的代金券，如果按照 <code>$5 / 月 </code> 计算，这笔钱可以抵扣我四个月的主机费用了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190804012349.png" alt="二十美元代金券收入" title="二十美元代金券收入"></p><h1 id="系统支持"><a href="# 系统支持" class="headerlink" title="系统支持"></a> 系统支持 </h1><p> 我自始至终只使用了两次这个模块，都是为了调整我的消费额度，前提是必须把需求说明清楚，并整理成英文，然后类似于提交 <strong>工单 </strong>一样把需求从后台发给客服。我的需求就是把我的月消费额度下调至 <code>$15 / 月 </code>，主机节点个数下调至 3 个，这样可以防止由于自己误操作导致的费用消耗过多，或者密码泄漏被人滥用。当然，这些情况理论上都不会发生，我只是图一个安心而已。</p><p> 有了自己的需求，我整理了一段简单的说明，内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">New Instance Limit:</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">New Monthly Instances Cost Limit:</span><br><span class="line">15</span><br><span class="line"></span><br><span class="line">Intended Usage:</span><br><span class="line">I want to increase my limit of instance cost,15 is my choose.</span><br></pre></td></tr></table></figure><p>然后在 <code>Support</code> 模块中，选择 <code>Tickets</code> 功能。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803184502.png" alt="Tickets 功能" title="Tickets 功能"></p><p>可以看到在右上角有一个 <code>Open New Ticket</code> 按钮，是用来新建工单的，点击它。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803184551.png" alt="新建 Ticket 按钮" title="新建 Ticket 按钮"></p><p>在跳转到的内容填写页面中填写你的需求即可，需要选择问题类型、主机、标题、内容，填写完成后点击下方的 <code>Open Ticket</code> 按钮即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803184624.png" alt="填写详细信息并提交 Ticket" title="填写详细信息并提交 Ticket"></p><p>接下来就是等待了，客服不会及时回复的，一般需要等待 1 个工作日【24 个小时】。而且由于时差的原因，客服一般是在半夜回复，我们只能等到第二天再看。</p><p>提交后也可以在工单列表中查看历史工单，并可以随时打开进行补充，它就像一个聊天对话系统，但不是实时的，读者要做的就是等待。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803184701.png" alt="查看历史 Tickets" title="查看历史 Tickets"></p><p>给你们看一下客服给我的回复，提交工单、客服回复前后相差 32 个小时，这效率也是挺低的，还好这个功能基本不会用到，要不然等这么久会疯掉的。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Hello, </span><br><span class="line"></span><br><span class="line">The limits have been set as requested.</span><br><span class="line"></span><br><span class="line">Please let us know if you need further assistance. Our team is here and always happy to help.</span><br><span class="line"></span><br><span class="line">Thank you for choosing Vultr!</span><br><span class="line"></span><br><span class="line">Best Regards,</span><br><span class="line">Nachelle</span><br><span class="line">Vultr.com</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803184728.png" alt="客服给我的回复" title="客服给我的回复"></p><p>我这个申请的调整结果可以在 <code>Billing</code> 模块中的 <code>Limits</code> 标签页中查看，主机个数、消费上线都已经调整成我希望的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803194606.png" alt="查看调整的结果" title="查看调整的结果"></p><h1 id="营销推广"><a href="# 营销推广" class="headerlink" title="营销推广"></a>营销推广 </h1><p><strong> 营销推广 </strong>模块里面的功能基本不会用到，除非你能邀请到别人注册并充值使用 <code>Vultr</code> 这个产品，这样的话 <code>Vultr</code> 就会返给你代金券，可以抵扣消费，但是不能提现。</p><p>所以我在此只简单介绍其中的两个小功能：分享链接、用户统计。</p><h2 id="分享链接"><a href="# 分享链接" class="headerlink" title="分享链接"></a>分享链接 </h2><p> 分享链接，就是把 <code>Vultr</code> 为你生成的唯一链接分享出去，别人点击你的链接注册后，就算作是你带来的用户，如果注册用户又充值并且在 <code>Vultr</code> 里面消费，你就会收到代金券。然而，用户只是注册是不行的，不算作有效用户，毕竟随便找几个邮箱就可以注册了，必须充值使用才算。</p><p>在 <code>Affilicate</code> 模块中，选择 <code>Linking Code</code> 标签页，就可以看到 <code>Vultr</code> 为你生成的唯一链接了。例如我的唯一链接是：<a href="https://www.vultr.com/?ref=7443790" target="_blank" rel="noopener">我的 Vultr $10 代金券链接 </a> ，文本形式则是：<code>https://www.vultr.com/?ref=7443790</code>，如下图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803193050.png" alt="我的唯一链接" title="我的唯一链接"></p><h2 id="用户统计"><a href="# 用户统计" class="headerlink" title="用户统计"></a> 用户统计 </h2><p> 用户统计就是查看自己邀请到的用户点击、用户注册、用户消费情况，选择 <code>Stats</code> 标签页，可以看到每个月的点击用户、注册用户、消费用户数据，并且 <code>Vultr</code> 已经使用条形统计图的方式展示出来。以此可以查看自己为 <code>Vultr</code> 带来的用户，以及自己能不能有代金券的收入。</p><p>看看我的用户统计，七月份比较惨淡，共有二十多个用户点击了我的链接，但是只有一个用户注册了，至于这个用户有没有充值继续使用还不确定，要等两个月之后才能判断。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803193109.png" alt="七月份用户统计" title="七月份用户统计"></p><h1 id="帐号信息"><a href="# 帐号信息" class="headerlink" title="帐号信息"></a>帐号信息 </h1><p> 帐号信息在 <code>Account</code> 模块中设置，能用到的也就是个人简介，在 <code>Profile</code> 标签页中。而且这个模块一般用不到，读者无需关心。</p><p>我也就是填写姓名、邮箱、地址等信息。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190803204627.png" alt="个人简介设置" title="个人简介设置"></p><p>其中，邮箱帐号是很有必要的，在 <strong>账单管理 </strong>中设置账单的通知方式时，使用的就是这里填写的邮箱帐号，这样我每个月才会收到 <code>Vultr</code> 发来的扣费通知。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>知识改变生活</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
        <tag>Vultr</tag>
        <tag>VPS</tag>
        <tag>vps</tag>
        <tag>Affiliate</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>写了 20 万字的博客，我收获了什么</title>
    <url>/2019080801.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>当我思考到这个标题的时候，使用搜索引擎搜索了一下，发现谷歌、百度都能搜索到很多相关的结果，这就说明有很多人曾经思考过同样的问题。诚然，这些人分布在各个行业，有的人只是为了单纯记录生活和工作，有的人是为了总结归纳，有的人是为了分享知识，甚至有的人可能本身就在自媒体行业，以写为生。不管身处哪个行业，这群人曾经在某个时间点共同思考过一个相同的问题：我收获了什么。而我，现在也在思考着这个问题。</p><a id="more"></a><h1 id="关于付出与收获"><a href="# 关于付出与收获" class="headerlink" title="关于付出与收获"></a>关于付出与收获 </h1><p> 我从小到大一直听说的道理：<strong> 付出就有收获 </strong>。等真正长大了，才发现这句话是错的，应该改为：<strong> 付出可能有收获，也可能一无所获 </strong>。为什么呢，因为有很多人在没有收获时总是习惯于自我安慰，努力找出一点不可量化的收获，例如尝到了教训、积累了经验、拓展了思维，并把 <strong>失败乃成功之母 </strong>挂在嘴边。其实有很多时候努力就是白费了，白白浪费了时间与精力，最终并没有任何收获。</p><p>以下内容记录我的付出与收获，当然都是广义上的概念。</p><h1 id="时间观念"><a href="# 时间观念" class="headerlink" title="时间观念"></a>时间观念 </h1><p> 坚持写博客这件事，让我重拾自己的时间观念，如果给自己定了目标，必须想办法完成，这可以鞭策自己高效地利用时间，从而大大提升做事的效率。而对于自我约束不够的人来说，只能任由时间从指缝间流逝而毫无察觉，同时，迷茫、拖延症、恐惧未来而不行动、抱怨、丧失信心这些问题会永远笼罩在这个群体之上，而我，曾经也是其中的一员。通过坚持写博客，我的时间观念渐渐形成，每天不再迷茫，不再抱怨，重新树立起信心，为自己坚持的目标而行动起来。如今我发现，博客的内容产出只是副产品，我获得的无形的东西远比博客内容多的多，也重要的多。我又想起了那句话：明日复明日，明日何其多，我生待明日，万事成蹉跎，目标是可以以 <strong>年 </strong>为单位来规划的，但是记得，具体实现一定要以 <strong>天 </strong>为刻度来积累，否则必将难成一事。</p><p>玩手机、看剧真的是一件非常消耗时间的事情，一旦进入状态，基本一到两个小时就废掉了，而且可以说毫无收获，消磨时间寻求开心当然不算收获。所以在娱乐方面，一定要严格控制时间，并且尽量避免无效的内容，应该工作的时候工作，应该学习的时候学习，应该玩的时候才玩，这些本来用于教育孩子的准绳到了自由的成年人身上，却很难办到。</p><h1 id="专注力"><a href="# 专注力" class="headerlink" title="专注力"></a>专注力 </h1><p> 不要以为某件事情很简单，等你做了就知道，绝对不是你想象的那样，写博客亦是如此。一篇 1000-2000 字的博客，算是正常的篇幅，但是从无到有再到检验无误，一般也要 3-4 个小时，而且这必须是在专注的情况下。如果中途有什么事情，例如微信消息、电话、刷新闻，导致写作中断的话，会影响思路的连贯性，从而导致完成进度被拖延。并不要以为只耽搁了几分钟，这些片刻的打断其实都会大大影响写作的效率，从计划的 3-4 个小时延长到 4-5 个小时很正常。只有经过多次的专注训练，才能保证写作效率。</p><p>而且，把专注力延伸到其它事情上面，以后无论做什么事情，都可以保持专注而且高效。</p><h1 id="取舍权衡"><a href="# 取舍权衡" class="headerlink" title="取舍权衡"></a>取舍权衡 </h1><p> 取舍从何说起呢？一开始我准备写博客的时候，最原始的期望就是把我几年的纸质笔记电子化，既能避免丢失又方便回顾查看，然后纸质版就可以丢弃。诚然，笔记的内容包罗万象，从技术总结、常识技巧、历史知识，到诗歌、散文，可谓内容繁杂，如果按照我一开始的设想进行下去，恐怕没有那么多时间与精力。在思考了一段时间以后，我的态度从不舍得，到可以果断地放弃大部分内容，可谓转变巨大，现在来看，这个决定是正确的。</p><p>而我对内容评判的标准，就是这些知识对于现在的我来说有没有实际用处。比如历史知识，我曾经为了扩展知识面，研究了一些朝代的历史，也包括中国近代史，现在这些知识已经刻在了我的脑海里，而且在潜移默化地影响着我，所以以前的笔记完全可以舍弃。还有，在整理技术内容的时候，有时候一天遇到好几个技术难题，或者有意思的问题，都想整理出来，但是时间不允许，经过权衡只能挑选一个整理「有时候确实觉得难以割舍，就只好先列好提纲，延迟几天再整理，当然这种情况尽量避免，否则内容积压过多」。</p><p>再往大了说，为了整理博客内容，必然要放弃休息时间、娱乐时间，比如晚上、周末，只能坐在电脑前整理笔记、查阅资料，为了博客的内容结构而苦思冥想。有时候回想一下，不免错过了一些美好的事和人，后来渐渐学会在取舍之间权衡，并能独自接受后果，这种心态是最重要的。</p><h1 id="自驱动力"><a href="# 自驱动力" class="headerlink" title="自驱动力"></a>自驱动力 </h1><p> 成长为一个自驱动类型的人，而不是他驱动，做任何事情都必须有较强的目的性，这样事情做成了会有成就感，失败了也会总结成长。每天如果忙而无目的性，就是浪费时间，很多人看似在忙，生活很充实，其实只是在逃避自己：每天上班、看剧、玩手机、运动健身，这对于我来说大部分时间是没有意义的，或者勉强点说有那么一点点意义。不要被旁人的说教冲昏了头脑，别人每天看剧、健身、早睡早起、生活规律，看起来无忧无虑，你要知道，别人不是家里有矿就是家里有房，而你一无所有。如果你还把仅仅拥有的大好时间、充沛精力浪费掉，等到三十五岁的时候，就哭了。</p><p>再说一下作息规律、按时休息的问题，对于正常的人来说，谁不想按时休息，保证充足的睡眠，每天有旺盛的精力。但是按时休息与不按时休息之间有好几个维度可以选择，例如每天睡八个小时算是充足，那我每天睡六个小时行不行呢，或者六个半小时、七个小时、七个半小时呢，只要自己的生物钟能适应，选择合适的休息时间即可。但是我经常听到身边的人说：要早睡，每天睡够八个小时，小心猝死，我一开始也觉得害怕，后来渐渐发现话说得太严重而且略显矫情。</p><p>不趁年轻的时候多熬夜，以后就没有机会了，毕竟每个人的时间都是一样的，除了通过提高做事效率来延长生命，再有只能通过少睡这种方法了，当然少睡并不是指熬夜、睡眠不足，只是不要赖床。</p><p>我听很多身边的人说，他们习惯早早洗澡躺床上睡觉，其实呢，都在玩手机，基本每天都要浪费将近一个小时，然后昏昏睡去，这算什么呢？</p><h1 id="积累"><a href="# 积累" class="headerlink" title="积累"></a>积累 </h1><p> 终于渐渐真正理解了什么叫水滴石穿，俗话说：「集腋成裘，聚沙成塔」，只有亲身经历并且经过长时间的日积月累，才能真正明白这是什么含义。</p><p>坚持真的是一件很难的事情，更难的是长期坚持，还应了那句古话：「不积跬步，无以至千里；不积小流，无以成江海」。</p><p>灵感稍纵即逝，当有什么感悟出现的时候一定要记下来，因为可能一会儿就忘记了，记下以后反复查阅，最终才能真正变为自己的思想。</p><p>另外，以前流传的一句网红励志名言：<strong> 积跬步以致千里，积怠惰以致深渊 </strong>，并且配以数字公式：<strong>1.01 的 365 次方 = 37.78；0.99 的 365 次方 = 0.03</strong>，每次看能都醍醐灌顶。</p><p>切记：厚积薄发，未来的舞台很精彩！</p><h1 id="眼界"><a href="# 眼界" class="headerlink" title="眼界"></a>眼界 </h1><p> 在初中的时候，我们的英语老师经常说的一句话：<strong> 眼高手低、矮墙难过 </strong>，就是说很多人整天想这想那，思维很开放，但是每天啥也不干，这样肯定是很难成事的。</p><p>日常中，基本每个人都会有自己的思考，想象着自己的未来，但是几乎没有人能行动起来，总是沉浸在自己的幻想中，并且每天重复着索然无味的工作，还会经常安慰自己：平平淡淡才是真。</p><p>其实，想法是很重要的，每个人可以把思维打开，提高眼界，放开了想。但是注意千万不要多想，要脚踏实地，先找到合理的目标，再慢慢实现，比如我写博客，一开始定的目标是 10 万字，后来达到了，又定了一个目标 20 万字，现在又达到了。</p><p>这里面就会涉及到一个广义的眼界问题，除了自己的本职工作，或者说务正业，人在成长的过程中必须还要关注到其它的方方面面，并主动去汲取知识，这样才能不断成长。</p><p>例如我，从写博客说起，知道的越多，才发现自己知道的越少，知识真的是浩如烟海。我经常查询资料、文档，总会发现很多新奇的、未知的知识，有时候感兴趣就会多了解一点，有时候并没有那么多时间，只好放弃。但是无论怎样，眼界确实拓宽了，我相信这种积累对于我来说是大有裨益的。</p><p>另外，在触及一个崭新的领域时，总会遇到一些小麻烦、大麻烦，而如果立马打退堂鼓，是怎么也不会有收获的。反之，遇到难题先不要退宿，而是冷静下来，换一个不同的角度思考一下，想办法解决它。如果独立分析、解决了问题，此时信心会大增，如果遇到挫折没解决，人可能会颓废一阵。但是这都不重要，要始终记住：人的进步可以是螺旋上升的，一时的挫折没有什么，站在整个人生的角度看，遇到的问题越多越好，以后会越来越有经验的。</p><h1 id="精力消耗"><a href="# 精力消耗" class="headerlink" title="精力消耗"></a>精力消耗 </h1><p> 每天都得有思考，很累但是很值得，放弃了很多东西，诸如娱乐时间、休憩时间等等，但总体来说是有很大的收获的。</p><p>由于现在的碎片化信息太多，扑面而来的短视频、假新闻、推荐广告、营销文，可以说是无孔不入，进入了所有人的生活里，所有人都会被干扰，每天不得不应对大量的垃圾信息。况且，每天我们的聊天应用的群里、微信朋友圈里，会有各种各样的分享链接，有时候忍不住打开，也会浪费时间。有的人可能会说，可以利用碎片化时间学习，然后再看一些垃圾信息放松娱乐，但是我们自己回想一下，身边有这样的例子吗，有几个人是能坚持学习的。</p><p>回头看看那些不时立下英语学习、时间管理、跑步健身的 <code>flag</code>，哪一个不是偶尔分享一次，后面就没下文了，概括来说只是打个卡而已。这是人性的弱点，面对大环境的冲击，没有几个人能逃得过，只能沉湎于当前的海量无效信息中。</p><p>在 2018 年年中我玩抖音的时候【之前我确实不知道有这个应用】，突然有一天思考：这个东西太浪费我的生命了，玩一会两个小时过去了，如果一个月玩一次还可以，每天都玩肯定不行。接下来，我把抖音卸载了，并且以后再也没有安装过，后来再看到类似的短视频时，只会瞄两眼，我基本告别了短视频。但是一年半之后，当我再次对短视频感兴趣时，是自己也准备做短视频了，想看一下别人是怎么做的，参考一些优秀的短视频创作者，希望能带来一些灵感。此时，我再也不会沉浸其中，只是看到优秀的短视频，总是忍不住重复看几遍，并尝试分析他们的优秀元素。</p><p>接下来就是全身心投入到记录、创作之中了，我把每天自己的思考使用便签记录下来，基本每天都会整理一下，列出大纲。等到有完整的大块时间，例如 3-5 小时，就可以写出一篇博客，如果是有些内容短小的选题，我就会简单整理一下，发到微博上面。</p><p>这样安排，我每天也会觉得过得很忙，看似有各种事情，但是保持每天整理、总结，可以看到你前面的路是清晰的，是光明的。</p><p>另外，如果我们的职业是一个普通的打工者，在工作当中会慢慢消磨掉一个人的耐心、精力，时间久了之后会把人身上的锐利锋芒磨掉，可能我们会经常抱怨，不再想什么前途，不再想什么总结。记住，这样是不对的，在工作当中不要过于激情，除非非常喜欢，而是保持冷静，安心把自己的事情做好即可。</p><p>而额外的时间一定要留给自己，哪怕只是休闲，也要学会善待自己。</p><p>但是，对于一个总在前进的人，精力始终是不够用的，还要学会提高效率。</p><h1 id="时间消耗"><a href="# 时间消耗" class="headerlink" title="时间消耗"></a>时间消耗 </h1><p> 本小节主要描述时间消耗在了什么地方，以及耗时多久，拿一篇常规的博客来说，2000-3000 字的，配图在 10 张以内的。</p><p>选题阶段，基本是不消耗什么时间的，也就是平时看到有什么好玩、优秀的内容，留意一下而已，但是重要的是每天都会留意。</p><p><strong>思考提炼阶段 </strong>，平时会有积累，遇到技术问题，或者是遇到自己感兴趣的选题，就会重点关注，实时留意。这个东西可能每天都会有关注一下，看一点点资料，提炼一些要点，至少需要半个月的坚持，才能保证把一个选题梳理清楚。假如以每天耗时 10 分钟计算，15 天需要 150 分钟，接着就可以准备动手写博客了。</p><p><strong>构思阶段 </strong>，构思就是先在脑海中根据选题列出关键词，可能涉及到哪些概念，需要什么资源，快速地想一下，一般 10 分钟即可。</p><p><strong>列提纲阶段 </strong>，就是根据上一步骤的构思结果，把所有的内容稍微扩充一点，搭一个博客的骨架，也可以理解为把博客的一级、二级目录完成，有时候还需要查询资料，这个过程大概需要 30-60 分钟。</p><p><strong>配图阶段 </strong>，配图就是根据提纲，预估可能会用到哪一些图片，大部分是原创的，例如代码截图、官网信息截图、操作流程截图等等。如果需要特别复杂的截图，比如安装步骤，可能一套操作下来就有十几张图片；如果是代码示例验证类的，还需要写代码。总体来说，这个过程可长可短，要根据实际情况而定，如果图很容易获得，也就 10 分钟搞定，如果图片很多又是原创，需要数小时。</p><p><strong>文字整理阶段 </strong>，文字整理阶段是最耗时的，需要按照提纲把内容扩充并整理成文字。当然，大部分都是原创，以 2000-3000 字为基准，至少需要 3 小时。</p><p><strong>发布检查阶段 </strong>，如果有问题，还要及时修复，再重新发布。正常的话，这个过程需要 5 分钟发布，10 分钟检查。但是如果遇到问题，例如错别字、配错图等等，还需要额外的时间安排，一般至少需要 30 分钟。</p><p><strong>回顾补充阶段 </strong>，本来执行完上面的步骤一篇博客就算彻底完成了，但是在以后的日子里，可能还会想起来补充一点内容，此时就需要再回头更改，更新博客，这个过程一般 30 分钟足够。</p><p>整体来看，想写一篇博客并没有那么简单，目前自我感觉达到了熟练的程度，效率会有一点点提升，我相信以后的效率会更高的。</p><h1 id="带给自己的反馈"><a href="# 带给自己的反馈" class="headerlink" title="带给自己的反馈"></a>带给自己的反馈 </h1><p><strong> 成就感 </strong>，首先，看到自己的文字成果，我有了大大的满足感，这就够了。</p><p><strong>证明自己 </strong>，自己的博客代表了自己的软实力，可以展现自己的综合能力，把博客链接发出去，不需要多说什么，别人看到内容就会认可你。</p><p><strong>金钱收入 </strong>，我留下了微信赞赏码，有缘人可以给我转钱，目前已经收到 4 个人的赞赏，虽然钱不多，但是我很开心。</p><p><strong>推广收入 </strong>，我在写如何使用 <code>VPS</code> 的那篇博客里面，留下了我使用 <code>Vultr</code> 的推广链接，这样别人注册后我就可以领取代金券，目前已经收到将近 200 美元，我是很吃惊的，这已经可以维持我每个月的 <code>VPS</code> 费用了【假如每个月持续有代金券收入的话】。</p><p><strong>耐心锻炼 </strong>，说实话，写博客消耗耐心，谁会愿意坐在那好几个小时，去写一篇技术博客，很难的。但是反过来，只要坚持住，等到熟练了、习惯了，这就不叫事了，可以说增加了耐心。</p><p><strong>排查问题的能力 </strong>，通过解决各种各样的问题，已经可以熟练排查技术问题了，从哪里入手、猜测原因、如何证明，有了一套自己的方案。</p><p><strong>搜索资料能力 </strong>，有时候需要参考资料，就需要先找到，例如官网、论坛、官方文档、电子书、优秀博客等，前前后后搜索、收集了很多资料。</p><p><strong>英文阅读能力 </strong>，在技术的世界里，总会有很多英文的文档，此时只能边查边读了，次数多了，英文阅读能力也就同步提升上来。</p><p><strong>文字组织能力 </strong>，写了 20 万字，虽然不是 20 万字的中文【还会有一些代码、引用注释等】，但是打个八折也还有十几万字呢，文字组织能力已经提升了很多，可以把概念、方法、知识清晰地传递给别人。</p><p><strong>协助别人解决问题 </strong>，我创建了一个技术交流群，并且在每篇博客的末尾都留下了二维码，用来近距离协助需要的人，或者我们也可以一起讨论技术，共同成长。</p><h1 id="鼓励自己"><a href="# 鼓励自己" class="headerlink" title="鼓励自己"></a>鼓励自己 </h1><p> 继续坚持，再接再厉，也可以确定下一个目标了，例如写到 30 万字。</p><p>在维护博客站点的过程中，除了接触到很多有趣的知识，还训练了自己的逻辑归纳能力。总之，看待世界的方式变了，看待人的方式也变了，这正符合我对人生螺旋式上升的设定。</p><p>另外，保持分享，保持进步，想加强某一方面的知识，最好的办法就是去分享，说得就是这个意思，而且不只是加强知识，还有可能优化思想。</p><h1 id="关于规划"><a href="# 关于规划" class="headerlink" title="关于规划"></a>关于规划 </h1><p> 千万不要在想到一件事情后，就只是计划以后什么时间去做，或者等待有空了去做，并安慰自己有时间就会去做的。那么，这种事情明显都要被搁置的，因为你不会有时间，人永远都是繁忙的，或者你永远想不起来了，事情被搁置在角落。</p><p>所以，经常有人说，遇到好看的内容、好玩的东西、想去的地方，第一步总是收藏了、先 <code>mark</code> 后看、加入计划清单等等。其实这就是做一个动作而已，这件事情会被永远忘记，能想起来的概率极低，不信你看看自己的收藏夹、关注信息、计划清单，是不是内容积累越来越多。</p><p>所以，有什么事情就要立马去做，千万不要犹豫，不能延迟，如果实在做不了就立马放弃，千万不要对它有期望，生活本身就是不完美的。</p><p>当然，这里面还有一个重要的注意点，你不可能把很多事情都放弃，总有一些舍不得的，或者是真的值得做的，但是当前又没有时间做，或者近期都无法规划出时间，怎么办？</p><p>这个其实也好办，就是要为自己留一个资源池，专门存放未来值得做的计划。什么意思呢？就是你要把你觉得重要的，但是近期又没时间做的，或者比较难的，或者耗时比较久的，你就把它记下来，并用一些关键词描述，不用太详细。然后放在你的计划清单中，以后可以定期整理，整理的时候可以把一些不重要的，或者自己已经忘记的清理掉，保证资源池的大小合理。</p><p>对于资源池中的计划清单，可以在未来几个月或者几年慢慢完成，这样可以保证以后再看的时候，回头看着能想起来，同时也能保持自己的激情、学习能力，不至于太过清闲。</p><p>就像我前面说的，有些人就是喜欢收藏、转发、<code>mark</code>，这些内容里面可能会有网页、视频、图片、好玩的东西、想去的地方、想买的东西等等，其实在以后的日子里可能永远不会再碰他们。对于这种情况我建议是把这些内容当做备份池，有时候需要就去里面搜索一下，看看是否有可用的内容，还会顺便删除一些没用的，或者已经失效的。</p><p>做到了这些，在一个人有限的精力与时间内，才能去做更多有意义的事，否则，每天都在看似重复的忙碌中度过，其实什么也没有做成。</p><p>好，那就不妨定个小目标：<strong> 本站点技术博客写到 30 万字 </strong>。</p><h1 id="最后的鸡汤"><a href="# 最后的鸡汤" class="headerlink" title="最后的鸡汤"></a>最后的鸡汤 </h1><p> 对于年轻人，大家都有感受，每天聊聊天、玩玩手机、打打游戏、谈谈恋爱，很舒服，每个月把挣的钱花光，买自己想要的东西，吃自己想吃的东西，去想去的地方玩，过的很爽。我以前也是过这种日子，每天快乐无边，但是突然有一天，我想通了：自己只是普通人，毕业于普通学校，能力也是一般，只是来到了一线城市工作，才勉强能找一份糊口的工作，而且我并没有什么其它技能，如果真的一直这样下去，最终只能是一颗螺丝钉，等到三十五岁失业。</p><p>我也一直在心底问自己：什么才叫努力，自己算努力吗？其实，我更想用一个比喻来说明，大家应该听过有一种无脚鸟「电影《阿飞正传》里面有谈及」，一生只能不停地飞，无法停下，飞累了就在风里面睡觉，直到精疲力尽而死，这种鸟一辈子只能落地一次，停下落地的时候就是生命终结之时。当然，这是人们构想的，实际上并不存在这种鸟，但我想说，我现在就是这种鸟。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>essay</tag>
        <tag>gain</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title>在技术之路上的一些小技巧</title>
    <url>/2020021301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>本文记录一些工作当中常用的小工具、小技巧，有时候自己可以查看备忘，同时也给读者参考。当然，内容是在不断补充的，涉及的维度也会扩展。</p><a id="more"></a><h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><p><code>Python</code> 是一种脚本语言，想要运行 <code>Python</code> 脚本就需要先安装 <code>Python</code> 环境【就像运行 <code>Java</code> 程序需要 <code>JRE</code> 一样】，安装后别忘记配置环境变量。</p><p>官方网站：<a href="https://www.python.org/downloads" target="_blank" rel="noopener">python</a> 。</p><p>唯一需要注意的是安装时先核对脚本的语法，是安装 <code>v2.7.X</code> 版本还是 <code>v3.X</code> 版本，它们的语法有时候不兼容，导致脚本无法跑通。</p><h2 id="虚拟环境"><a href="# 虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境 </h2><p> 在某个项目中，使用 <code>Python</code> 构造 <code>Elasticsearch</code> 请求获取结果数据，但是脚本的内容是针对 <code>Python v3.X</code> 环境的，而服务器上是 <code>Python v2.7</code> 版本的环境，而且个人没有权限更改【如果自己通过编译安装指定的版本，后续使用时如果缺失第三方模块还是需要手动安装，如果又引发模块之间的依赖，手动安装过程会崩溃的】，所以可以在服务器上面虚拟一个指定版本的 <code>Python</code> 环境出来。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 在任意目录，虚拟出 Python 2.7 环境 </span><br><span class="line">virtualenv py2.7</span><br><span class="line">-- 进入环境 </span><br><span class="line">cd py2.7/</span><br><span class="line">-- 激活环境 </span><br><span class="line">source bin/activate</span><br><span class="line">-- 如果缺失第三方模块，直接安装即可 </span><br><span class="line">pip install requests</span><br><span class="line">-- 取消环境 </span><br><span class="line">source bin/deactive</span><br></pre></td></tr></table></figure><h2 id="缓存问题"><a href="# 缓存问题" class="headerlink" title="缓存问题"></a>缓存问题 </h2><p> 假如跑一个脚本，把输出重定向到一个文件中：<code>nohup python test.py &gt; nohup.out 2&gt;&amp;1 &amp;</code>，结果发现 <code>nohup.out</code> 中显示不出来 <code>python</code> 程序中 <code>print</code> 的内容【或者是不及时显示，隔一段时间才会有一点内容】。</p><p>这是因为 <code>python</code> 的输出有缓冲机制，导致我们从 <code>nohup.out</code> 中并不能够马上看到输出。其实运行 <code>python</code> 脚本的时候有个 <code>-u</code> 参数，使得 <code>python</code> 不启用缓冲，把程序中的输出内容实时输出到文件：<code>nohup python -u test.py &gt; nohup.out 2&gt;&amp;1 &amp;</code> 。</p><h2 id="编码问题"><a href="# 编码问题" class="headerlink" title="编码问题"></a>编码问题 </h2><p><code>python</code> 的 <code>chardet</code> 模块，可以查看字符串的编码：<code>chardet.detect (data)</code> 。</p><h2 id="处理文本文件"><a href="# 处理文本文件" class="headerlink" title="处理文本文件"></a> 处理文本文件 </h2><p> 在处理 <code>csv</code> 文件时，遇到异常：<code>Error: field larger than field limit &lt;131072&gt;</code>，这其实是因为 <code>Python</code> 读取 <code>csv</code> 文件时有一个默认设置，某列的内容最大长度为 131072【基于 <code>Python v2.5</code>】。</p><p>重点在于 <code>Error: field larger than field limit &lt;131072&gt;</code>，是因为 <code>csv</code> 文件中的某个字段的长度大于 <code>csv</code> 框架能处理的最大长度，需要在文件头加上参数配置代码：<code>csv.field_size_limit (sys.maxint)</code> ，这样就可以支持 <code>int</code> 的最大值所对应的长度了。</p><p>此外，由于 <code>csv</code> 文件的特殊性，<code>csv</code> 是特定分隔符分隔的文本文件，可能会导致内容混乱的状况，比如某一列包含了大量的换行符【又没有使用双引号封装起来】，会导致 <code>csv</code> 文件认为就是多行数据，这样这些行都是错误的数据【因为列数不够】，如果有连续的换行符，会导致空白行出现，<code>Python</code> 也会报错：<code>line contains NULL byte</code> 。</p><h1 id="Excel- 的知识"><a href="#Excel- 的知识" class="headerlink" title="Excel 的知识"></a>Excel 的知识 </h1><p> 对于分析人员，经常会用到 <code>Excel</code> 工具，用来看数据，或者操作数据。</p><p>但是，有时候文本内容过多，不再适合使用 <code>Excel</code> 操作了，不仅很卡，而且有崩溃的风险。</p><p>根据我的经验，以最多 5 万行内容，最大 <code>20MB</code> 为好，如果是 <code>Mac OS</code> 系统，需要更少。</p><p>下面列举一下 <code>Excel</code> 支持的内容上限：</p><p><code>Excel</code> 2003 支持的最大行数是 65536，<code>Excel</code> 2007 支持的最大行数是 1048576 。</p><p><code>Excel</code> 2003 支持的最大列数是 256，<code>Excel</code> 2007 以及以上支持的最大列数是 16384 。</p><p>更多其它规范参考官方介绍：<a href="https://support.office.com/zh-cn/article/Excel-% E8% A7%84% E8%8C%83% E4% B8%8E% E9%99%90% E5%88% B6-1672b34d-7043-467e-8e27-269d656771c3#ID0EBABAAA=Office_2010" target="_blank" rel="noopener">Excel 规范与限制 </a> 。</p><h1 id="文件编码转换工具"><a href="# 文件编码转换工具" class="headerlink" title="文件编码转换工具"></a> 文件编码转换工具 </h1><p><code>iconv</code> 需要单独安装：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 转换文件内容编码，从 gb18030 转到 utf-8</span><br><span class="line">iconv --list 查看支持的编码 </span><br><span class="line">iconv -f gb18030 -t utf-8 oldfile -o newfile</span><br><span class="line"></span><br><span class="line">-- 查看文件编码内容简要信息 </span><br><span class="line">file filename</span><br></pre></td></tr></table></figure><h1 id="文件名编码转换工具"><a href="# 文件名编码转换工具" class="headerlink" title="文件名编码转换工具"></a> 文件名编码转换工具 </h1><p> 在 <code>Linux</code> 系统中，如果把一个以中文命名的文件上传上去【特别是从 <code>Windows</code> 系统上传上去】，文件名可能会乱码，导致无法使用 <code>Shell</code> 操作文件，此时可以使用 <code>xx</code> 工具转换文件名的编码。</p><p><code>convmv</code> 需要单独安装：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 转换文件名编码，从 utf-8 转到 gbk</span><br><span class="line">convmv --list 查看支持的编码 </span><br><span class="line">convmv -f utf-8 -t gbk filename 显示效果 </span><br><span class="line">convmv -f utf-8 -t gbk --notest filename 真的转换 </span><br><span class="line"></span><br><span class="line">-- 查看文件编码内容简要信息 </span><br><span class="line">file filename</span><br></pre></td></tr></table></figure><h1 id="常用命令"><a href="# 常用命令" class="headerlink" title="常用命令"></a>常用命令 </h1><h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2><h3 id="进程目录"><a href="# 进程目录" class="headerlink" title="进程目录"></a> 进程目录 </h3><p> 根据进程编号找到启动进程的目录，从而判断进程的启动路径。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pwdx pid</span><br></pre></td></tr></table></figure><h3 id="负载查看"><a href="# 负载查看" class="headerlink" title="负载查看"></a>负载查看 </h3><p> 对于操作系统上面的进程导致的机器负载升高，可以查看到底是哪个进程或者线程导致的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xxx</span><br><span class="line">yyy</span><br></pre></td></tr></table></figure><h3 id="进程查看"><a href="# 进程查看" class="headerlink" title="进程查看"></a>进程查看 </h3><p> 查看某个进程的启动目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 筛选进程名称，获取 pid</span><br><span class="line">jps | grep &apos;process name&apos;</span><br><span class="line">-- 根据 pid 查看目录 </span><br><span class="line">pwdx &apos;pid&apos;</span><br><span class="line">-- 进入目录 </span><br><span class="line">cd &apos;dir&apos;</span><br></pre></td></tr></table></figure><h3 id="使用 -sed- 操作文本文件"><a href="# 使用 -sed- 操作文本文件" class="headerlink" title="使用 sed 操作文本文件"></a>使用 sed 操作文本文件 </h3><p> 搜索替换之类的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 把文件中的 xxx 全部替换为 yyy，不带 -i 参数直接输出内容，不会更改文件 </span><br><span class="line">sed -i &quot;s/xxx/yyy/g&quot; your_file</span><br><span class="line"></span><br><span class="line"> 在文件第 n 行前插入内容 xxx，不带 -i 参数直接输出内容，不会更改文件 </span><br><span class="line"> 注意 Linux 中以换行符 LF 作为一行的判断条件，所以指定不存在的行号时无法插入数据 </span><br><span class="line">sed -i &quot;ni\xxx&quot; your_file</span><br><span class="line"></span><br><span class="line"> 输出文件的第 n 到 m 行内容 </span><br><span class="line">sed -n &quot;n,mp&quot; your_file</span><br></pre></td></tr></table></figure><h3 id="查看 -Linux- 系统的发行版本"><a href="# 查看 -Linux- 系统的发行版本" class="headerlink" title="查看 Linux 系统的发行版本"></a>查看 Linux 系统的发行版本 </h3><p><code>lsb_release -a</code>，该命令适用于所有 <code>Linux</code> 系统，会显示出完整的版本信息，包括 <code>Linux</code> 系统的名称，如：<code>Debian</code>、<code>Ubuntu</code>、<code>CentOS</code> 等，和对应的版本号，以及该版本的代号，例如在 <code>Debian 8</code> 中将会显示代号 <code>jessie</code>。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 输出示例：</span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:	Ubuntu</span><br><span class="line">Description:	Ubuntu 14.04.6 LTS</span><br><span class="line">Release:	14.04</span><br><span class="line">Codename:	trusty</span><br></pre></td></tr></table></figure><p><code>cat /etc/issue</code>，该命令适用于所有的 <code>Linux</code> 系统，显示的版本信息较为简略，只有系统名称和对应的版本号。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 输出示例：</span><br><span class="line">Ubuntu 14.04.6 LTS \n \l</span><br></pre></td></tr></table></figure><p><code>cat /etc/redhat-release</code>，该命令仅适用于 <code>Redhat</code> 系列的 <code>Linux</code> 系统，显示的版本信息也较为简略。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 输出示例：</span><br><span class="line">CentOS release 6.10 (Final)</span><br></pre></td></tr></table></figure><p><code>uname -a</code>、<code>cat /proc/version</code>，可以查看 <code>Linux</code> 的内核版本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 输出示例 1：</span><br><span class="line">Linux wufazhuce 3.13.0-32-generic #57-Ubuntu SMP Tue Jul 15 03:51:08 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux</span><br><span class="line"></span><br><span class="line"> 输出示例 2：</span><br><span class="line">Linux version 3.13.0-32-generic (buildd@kissel) (gcc version 4.8.2 (Ubuntu 4.8.2-19ubuntu1) ) #57-Ubuntu SMP Tue Jul 15 03:51:08 UTC 2014</span><br></pre></td></tr></table></figure><h3 id="查看 -Linux- 系统的核数"><a href="# 查看 -Linux- 系统的核数" class="headerlink" title="查看 Linux 系统的核数"></a> 查看 Linux 系统的核数 </h3><p> 继续阅读之前先搞清楚几个概念：物理 <code>CPU</code> 个数、单颗 <code>CPU</code> 核数、单核 <code>CPU</code> 线程数。</p><ul><li>一台物理机的 <code>CPU</code> 个数 </li><li> 一个 <code>CPU</code> 的核数 </li><li> 一个 <code>CPU</code> 核上面支持的线程数 </li></ul><p> 当一台机器有多个物理 <code>CPU</code>，那么各个 <code>CPU</code> 之间就要通过总线进行通信，效率比较低。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200412175009.jpg" alt="多个 CPU 通过总线通信" title="多个 CPU 通过总线通信"></p><p>此时可以利用多核的特性，在多核 <code>CPU</code> 上，不同的核之间通过 <code>L2 cache</code> 进行通信，存储和外设通过总线与 <code>CPU</code> 通信，效率提高。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200412175024.jpg" alt="多核之间通信" title="多核之间通信"></p><p>当然，如果利用多核超线程，即每个 <code>CPU</code> 核有两个逻辑的处理单元，两个线程共同分享一个 <code>CPU</code> 核的资源，计算起来更快。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200412175032.jpg" alt="多核超线程" title="多核超线程"></p><p>因此，一台机器的总核数为：物理机的 <code>CPU</code> 个数 X 一个 <code>CPU</code> 的核数，总逻辑 <code>CPU</code> 个数为：物理机的 <code>CPU</code> 个数 X 一个 <code>CPU</code> 的核数 X 一个 <code>CPU</code> 核上面支持的线程数。</p><p>查看一台机器的 <code>CPU</code> 信息，主要就是 <code>/proc/cpuinfo</code> 文件，里面包含了关于 <code>CPU</code> 的信息，以 <code>CentOS</code> 系统为例，输出内容如下【只是截取了一小部分】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">processor	: 23</span><br><span class="line">vendor_id	: GenuineIntel</span><br><span class="line">cpu family	: 6</span><br><span class="line">model		: 62</span><br><span class="line">model name	: Intel (R) Xeon (R) CPU E5-2620 v2 @ 2.10GHz</span><br><span class="line">stepping	: 4</span><br><span class="line">microcode	: 1060</span><br><span class="line">cpu MHz		: 1200.000</span><br><span class="line">cache size	: 15360 KB</span><br><span class="line">physical id	: 1</span><br><span class="line">siblings	: 12</span><br><span class="line">core id		: 5</span><br><span class="line">cpu cores	: 6</span><br><span class="line">apicid		: 43</span><br><span class="line">initial apicid	: 43</span><br><span class="line">fpu		: yes</span><br><span class="line">fpu_exception	: yes</span><br><span class="line">cpuid level	: 13</span><br><span class="line">wp		: yes</span><br><span class="line">flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm ida arat epb xsaveopt pln pts dtherm tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms</span><br><span class="line">bogomips	: 4189.67</span><br><span class="line">clflush size	: 64</span><br><span class="line">cache_alignment	: 64</span><br><span class="line">address sizes	: 46 bits physical, 48 bits virtual</span><br><span class="line">power management:</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>其中，<code>model name</code> 表示 <code>CPU</code> 的型号；<code>physical id</code> 表示物理 <code>CPU</code> 个数，编号从 0 开始；<code>cpu cores</code> 表示单颗 <code>CPU</code> 核数；<code>processor</code> 表示所有 <code>CPU</code> 线程数，编号从 0 开始。</p><p>因此，查看 <code>CPU</code> 信息时可以使用管道、过滤、查找来输出需要的内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 查看 CPU 型号信息 </span><br><span class="line">cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c</span><br><span class="line"></span><br><span class="line"> 查看物理 CPU 个数 </span><br><span class="line">cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l</span><br><span class="line"></span><br><span class="line"> 查看单颗 CPU 核数 </span><br><span class="line">cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq</span><br><span class="line"></span><br><span class="line"> 查看所有 CPU 线程数 </span><br><span class="line">cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l</span><br></pre></td></tr></table></figure><p>顺带提一下查看内存的信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /proc/meminfo</span><br></pre></td></tr></table></figure><h3 id="split- 拆分文件"><a href="#split- 拆分文件" class="headerlink" title="split 拆分文件"></a>split 拆分文件 </h3><p> 把文件按照 60 行一个文件进行拆分，拆分后的文件以 <code>data_</code> 作为前缀，以 2 位数字作为后缀：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">split -l 60 your_file -d -a 2 data_</span><br><span class="line"></span><br><span class="line"> 拆分后的文件为 data_00、data_01、data_02 等等 </span><br></pre></td></tr></table></figure><h3 id="curl- 请求网络"><a href="#curl- 请求网络" class="headerlink" title="curl 请求网络"></a>curl 请求网络 </h3><p> 可以模拟请求，传输参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST 请求，参数放在 seeds 中 </span><br><span class="line">curl --location --request POST &apos;url&apos; \</span><br><span class="line">--header &apos;content-type: application/x-www-form-urlencoded; charset=UTF-8&apos; \</span><br><span class="line">--header &apos;Content-Type: application/x-www-form-urlencoded&apos; \</span><br><span class="line">--data-urlencode &apos;seeds=[&#123;&quot;keyword&quot;:&quot; 王者荣耀 & quot;, &quot;TOP_PAGE&quot;: &quot;100&quot;&#125;,&#123;&quot;keyword&quot;:&quot;LOL&quot;, &quot;TOP_N&quot;: &quot;100&quot;&#125;]&apos;</span><br><span class="line"></span><br><span class="line">GET 请求，获取信息 </span><br><span class="line">curl --location --request GET url&apos;</span><br><span class="line"></span><br><span class="line">POST 请求，参数放在文件中 </span><br><span class="line">curl -X POST --data-binary @your_file url</span><br></pre></td></tr></table></figure><p>查询 <code>Elasticsearch</code> 的数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 查询指定索引、指定类型的数据，返回 1 条数据，格式化结果 </span><br><span class="line">curl -X POST &apos;dev:9202/your_index/your_type/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,&quot;size&quot;:1</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h3 id="文本文件行数"><a href="# 文本文件行数" class="headerlink" title="文本文件行数"></a>文本文件行数 </h3><p> 获取文本文件的内容行数，返回数值：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wc -l 输入文件名称 </span><br></pre></td></tr></table></figure><h3 id="文件去重"><a href="# 文件去重" class="headerlink" title="文件去重"></a>文件去重 </h3><p> 对单个文本文件的内容进行去重，返回去重后的文本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sort 输入文件 | uniq &gt; 输出文件 </span><br></pre></td></tr></table></figure><p>说明：<code>|</code> 竖线表示管道，把前一个命令的输出作为后一个命令的输入，<code>&gt;</code> 右尖括号表示重定向，把前一个命令的输出内容导出到文件中，<code>sort</code> 表示排序，但是并不会去除重复内容，所以会有重复的行，<code>uniq</code> 表示去除重复的内容，则输出结果就是去重后的内容。</p><h3 id="随机获取文本内容"><a href="# 随机获取文本内容" class="headerlink" title="随机获取文本内容"></a>随机获取文本内容 </h3><p> 随机抽取单个文件中的内容行数，例如随机输出 100 行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shuf -n 行数 输入文件 &gt; 输出文件 </span><br></pre></td></tr></table></figure><p>说明：<code>-n</code> 后面紧跟着数字，表示行数，不需要空格。</p><h3 id="计算交集差集并集"><a href="# 计算交集差集并集" class="headerlink" title="计算交集差集并集"></a>计算交集差集并集 </h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat 输入文件 1 输入文件 2 | sort | uniq -d &gt; 输出文件 </span><br></pre></td></tr></table></figure><p> 说明：<code>cat</code> 表示查看文件内容，<code>uniq</code> 的 <code>-d</code> 参数表示抽取重复的内容，即出现 2 次及以上的内容，在这里得到的结果也就是交集了。</p><p>此外，还有 <code>-u</code> 参数表示抽取唯一的内容，则可以计算差集。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat 输入文件 1 输入文件 2 输入文件 2 | sort | uniq -u &gt; 输出文件（注意输入文件 2 故意重复 2 次）</span><br></pre></td></tr></table></figure><p>说明：<code>uniq</code> 的 <code>-u</code> 参数表示抽取唯一的内容，即只出现一次的内容，这样得到的输出结果必然是只在输入文件 1 中，而不在输入文件 2 中。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat 输入文件 1 输入文件 2 | sort | uniq &gt; 输出文件 </span><br></pre></td></tr></table></figure><p>说明：这个很容易理解了，合并文件后简单去重，也就是并集了。</p><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>查看 <code>topic</code> 信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --list --zookeeper dev:2181</span><br></pre></td></tr></table></figure><p>生产数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --topic your_topic --broker-list dev:9092</span><br></pre></td></tr></table></figure><p>消费数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --zookeeper dev:2181 --topic your_topic</span><br></pre></td></tr></table></figure><p>查看 <code>topic</code> 状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper dev:2181 --describe --topic your_topic</span><br></pre></td></tr></table></figure><p>查看消费情况【消费组消费量、积压量、生产量】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-offset-checker.sh --zookeeper dev:2181 --group your_group --topic your_topic</span><br><span class="line"></span><br><span class="line"> 如果上述脚本不可用，可以直接引用类 </span><br><span class="line">kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group your_group --topic your_topic --zkconnect dev:2181</span><br></pre></td></tr></table></figure><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p>操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 登录 </span><br><span class="line">zkCli.sh -server ip:port</span><br><span class="line"></span><br><span class="line"> 退出 </span><br><span class="line">quit</span><br></pre></td></tr></table></figure><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><p>操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 登录，n 表示桶，默认 0</span><br><span class="line">redis-cli -h host -p port -n 0 --raw</span><br><span class="line"></span><br><span class="line"> 查看配置信息，例如数据量、占用内存 </span><br><span class="line">info</span><br><span class="line"></span><br><span class="line"> 查看单个配置项，例如最大内存 </span><br><span class="line">config get maxmemory</span><br><span class="line"></span><br><span class="line"> 退出 </span><br><span class="line">quit</span><br></pre></td></tr></table></figure><h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><p><code>HBase</code> 操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 登录 </span><br><span class="line">hbase shell</span><br><span class="line"></span><br><span class="line"> 帮助文档 </span><br><span class="line">!help</span><br><span class="line"></span><br><span class="line"> 退格 </span><br><span class="line">ctrl + Backspace</span><br><span class="line"></span><br><span class="line"> 退出 </span><br><span class="line">!quit</span><br><span class="line"></span><br><span class="line"> 查看表信息 </span><br><span class="line">!list</span><br><span class="line"></span><br><span class="line"> 获取数据 </span><br><span class="line">get &apos; 表名称 & apos;,&apos;pk 值 & apos;</span><br><span class="line"></span><br><span class="line"> 扫描数据 </span><br><span class="line">scan &apos; 表名称 & apos;,&#123;LIMIT =&gt; 5&#125;</span><br><span class="line"></span><br><span class="line"> 检查 Region 状态 </span><br><span class="line">hbase hbck</span><br><span class="line"></span><br><span class="line"> 此命令用于修复未分配，错误分配或者多次分配 Region 的问题，注意用户权限问题 </span><br><span class="line">hbase hbck -fixAssignments</span><br><span class="line">sudo -u hbase hbase hbck -fixAssignments</span><br><span class="line"></span><br><span class="line"> 检查 Region 的元数据 </span><br><span class="line">get &apos;hbase:meta&apos;,&apos;your_region_name&apos;</span><br><span class="line"></span><br><span class="line"> 检测数据表的状态 </span><br><span class="line">hbase hbck&quot;YOUR_TABLE&quot;</span><br><span class="line"></span><br><span class="line"> 修复 Region 空洞问题【Region hole】，注意用户权限问题 </span><br><span class="line">sudo -u hbase hbase hbck -fix&quot;YOUR_TABLE&quot;</span><br><span class="line"></span><br><span class="line"> 手动做 major_compact</span><br><span class="line">major_compact &quot;your_table_name&quot;</span><br></pre></td></tr></table></figure><p><code>phoenix</code> 操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 登录 </span><br><span class="line">phoenix-client/bin/sqlline.py dev:2181:/hbase-unsecure</span><br><span class="line"></span><br><span class="line"> 帮助文档 </span><br><span class="line">!help</span><br><span class="line"></span><br><span class="line"> 退出 </span><br><span class="line">!quit</span><br><span class="line"></span><br><span class="line"> 查看表信息 </span><br><span class="line">!tables</span><br><span class="line"></span><br><span class="line"> 查询数据 </span><br><span class="line">select * from &quot; 表名称 & quot; where &quot;pk&quot;=&apos;pk 值 & apos;;</span><br><span class="line">select * from &quot; 表名称 & quot; limit 5;</span><br><span class="line"></span><br><span class="line"> 导出数据 </span><br><span class="line">-- 格式化输出 </span><br><span class="line">!outputformat csv</span><br><span class="line">-- 设置导出文件到 data.csv</span><br><span class="line">!record data.csv</span><br><span class="line">-- 查询需要导出的数据 </span><br><span class="line">select * from &quot; 表名称 & quot; limit 1000;</span><br><span class="line">-- 完成导数操作 </span><br><span class="line">!record</span><br><span class="line"></span><br><span class="line"> 格式化显示 </span><br><span class="line">!outputformat vertical</span><br><span class="line">!outputformat csv</span><br><span class="line">!outputformat table</span><br></pre></td></tr></table></figure><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>启动 <code>Spark</code> 命令行，使用 <code>spark-shell --master yarn-client</code>，然后就可以在交互式命令行中写 <code>scala</code>、<code>python</code> 代码了。</p><p>举例：读取 2 个文件，做并集：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var list1=sc.textFile (&quot;/tmp/pengfei/file1.txt&quot;).flatMap (x =&gt; x.split (&quot;\\t&quot;))</span><br><span class="line"> 文件在 HDFS 中，一行数据有被 Tab 分隔的多条内容 </span><br><span class="line"></span><br><span class="line">var list2=sc.textFile (&quot;/tmp/pengfei/file2.txt&quot;).flatMap (x =&gt; x.split (&quot;\\t&quot;))</span><br><span class="line"></span><br><span class="line">list1.union (list2).saveAsTextFile (&quot;/tmp/pengfei/union.txt&quot;)</span><br></pre></td></tr></table></figure><p>触发任务后在 <code>yarn</code> 中就可以看到任务的运行情况，注意，启动 <code>Spark-shell</code> 的时候也可以直接在本地运行，但是处理数据量大的时候内存会不够用，不建议。启动 <code>Spark-Shell</code> 的时候，可以指定使用 <code>yarn</code> 模式：<code>spark-shell --master yarn-client</code>，如果不指定，默认在本地启动，内存与处理速度会慢。</p><p><code>spark-shell --help</code>，查看启动参数详情，例如以下参数，<code>--executor-memory 4G</code>、<code>--total-executor-cores 4</code>、<code>--executor-cores 2</code> 可以加大内存，增加 <code>core</code> 数。</p><p>常用方法举例：<code>dinstinct</code>【去重】、<code>intersection</code>【交集】、<code>subtract</code>【差集】、<code>union</code>【并集】、<code>saveAsTextFile</code>【导出】、<code>textFile</code>【读取】。</p><p>分割去重过滤：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.flatMap (x=&gt;x.split (&quot;\\t&quot;)).distinct ().filter (x=&gt;11&gt;x.length ())</span><br></pre></td></tr></table></figure><p>单词计数写回文件，按照 <code>value</code> 降序排列：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val wordcount = sc.textFile (&quot;&quot;).flatMap (line =&gt; line.split (&quot;\\t&quot;)).map (word =&gt; (word, 1)).reduceByKey ((a, b) =&gt; a + b)</span><br><span class="line"></span><br><span class="line">val finalresult=wordcount.filter (count =&gt; count._2 &gt; 100)</span><br><span class="line"></span><br><span class="line">finalresult.persist ()</span><br><span class="line"></span><br><span class="line">finalresult.foreach (println)</span><br><span class="line"></span><br><span class="line">finalresult.count ()</span><br><span class="line"></span><br><span class="line">finalresult=finalresult.sortBy (_._2,false)</span><br><span class="line"></span><br><span class="line">val textresult=finalresult.map (count =&gt; count._1 + &quot;,&quot; + count._2)</span><br><span class="line"></span><br><span class="line">textresult.foreach (println)</span><br><span class="line"></span><br><span class="line">textresult.saveAsTextFile (&quot;&quot;)</span><br></pre></td></tr></table></figure><h1 id="大数据任务调度系统"><a href="# 大数据任务调度系统" class="headerlink" title="大数据任务调度系统"></a>大数据任务调度系统 </h1><h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><h3 id="移动队列"><a href="# 移动队列" class="headerlink" title="移动队列"></a> 移动队列 </h3><p> 在资源紧张的情况下，可以手动移动 <code>Spark</code> 任务的队列，合理利用空闲的资源。</p><p>如果 <code>yarn</code> 队列没有资源了，而自己又有 <code>Spark</code> 任务需要跑，在提交 <code>Spark</code> 任务后，可以看到任务在等待分配资源，此时可以把 <code>Spark</code> 任务移动到别的空闲队列去【也可以在提交 <code>Spark</code> 任务的时候指定队列】。</p><p>或者某些运行耗时比较长的任务，也可以先移动到别的空闲队列跑，释放自己业务的队列资源给其它任务使用。前提是确保不影响别的队列的正常使用，不能长久占用别人的队列。</p><p>使用 <code>yarn</code> 自带的命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 指定 Spark 任务的 applicationId，以及目标队列名称 </span><br><span class="line">-- 注意用户权限 </span><br><span class="line">yarn application -movetoqueue applicationId -queue queueName</span><br></pre></td></tr></table></figure><p>如果不熟悉这些命令，可以使用 <code>yarn -help</code>、<code>yarn application -help</code> 等命令查看帮助说明文档。</p><h3 id="取消任务"><a href="# 取消任务" class="headerlink" title="取消任务"></a>取消任务 </h3><p> 如果想 <code>kill</code> 掉一个正在 <code>yarn</code> 环境上运行的 <code>Spark</code> 任务，可以直接使用 <code>kill</code> 命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 指定 Spark 任务的 applicationId</span><br><span class="line">yarn application -kill applicationId</span><br></pre></td></tr></table></figure><p>当然，如果使用的 <code>yarn-client</code> 模式提交任务，并且有权限看到 <code>Driver</code> 端的进程，也可以直接使用 <code>Linux</code> 的命令 <code>kill</code> 掉进程【不够优雅】。</p><h3 id="下载日志"><a href="# 下载日志" class="headerlink" title="下载日志"></a>下载日志 </h3><p> 下载已经完成的 <code>Spark</code> 任务的文本日志，在 <code>Saprk</code> 任务的 <code>UI</code> 界面，可以看到 <code>Excutor</code> 的日志，但是当日志多的时候，看起来不方便，搜索就更不用说了。</p><p>当任务完成之后，可以使用 <code>yarn</code> 命令下载文本日志进行查看、分析：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 指定 Spark 任务的 applicationId，所属用户 </span><br><span class="line">yarn logs -applicationId applicationId -appOwner userName</span><br></pre></td></tr></table></figure><p>注意，由于用户权限的问题，在下载日志之前需要切换用户，否则获取不到日志或者抛出权限相关错误：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 切换用户，根据实际情况而定 </span><br><span class="line">-- 决定着去哪个目录获取日志文件 </span><br><span class="line">export HADOOP_USER_NAME=xxx</span><br></pre></td></tr></table></figure><h1 id="操作系统"><a href="# 操作系统" class="headerlink" title="操作系统"></a>操作系统 </h1><h2 id="回车换行"><a href="# 回车换行" class="headerlink" title="回车换行"></a> 回车换行 </h2><p> 在文本数据处理中，<code>CR</code>、<code>LF</code>、<code>CR/LF</code> 是不同操作系统上使用的换行符，表现为文本另起一行输出。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CR：Carriage Return</span><br><span class="line">LF：Line Feed</span><br></pre></td></tr></table></figure><p>下面列出常见的操作系统标准：</p><ul><li><code>Dos</code> 和 <code>Windows</code> 采用回车符 + 换行符，<code>CR/LF</code> 表示下一行 </li><li><code>UNIX/Linux</code> 采用换行符，<code>LF</code> 表示下一行</li><li> 苹果 <code>MAC OS</code> 系统则采用回车符，<code>CR</code> 表示下一行 </li></ul><p> 还需要注意，<code>CR</code> 用符号 <code>\\r</code> 表示，十进制 <code>ASCII</code> 编码是 13，十六进制编码为 <code>0x0d</code>，<code>LF</code> 使用 <code>\\n</code> 符号表示，十进制 <code>ASCII</code> 编码是 10，十六制编码为 <code>0x0a</code> 。</p><p>所以在 <code>Windows</code> 平台上的换行效果，在文本文件中是使用 <code>0d</code>、<code>0a</code> 这两个字节来实现的，而 <code>UNIX</code> 和苹果平台上的换行效果则是使用 <code>0a</code> 或 <code>0d</code> 一个字符来实现的，节约了存储空间。</p><p>在一个操作系统平台上使用另一种换行标准的文本文件，可能会带来意想不到的问题，特别是在程序代码中，有时候代码在编辑器中显示正常，但是在编译打包时却会因为换行符问题而出错【备注：使用 <code>Git</code> 版本控制系统时，<code>Git</code> 客户端已经根据当前的操作系统环境，自动帮助我们实时替换了换行符号】。</p><p>例如常见的一个现象，<code>Unix/Mac</code> 系统下的文件在 <code>Windows</code> 里打开的时候，会发现所有的文字变成了一行，而同理，<code>Windows</code> 里的文件在 <code>Unix/Mac</code> 下打开的话，在每行的结尾可能会多出一个 <code>^M</code> 符号。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
        <tag>Yarn</tag>
        <tag>Python</tag>
        <tag>Java</tag>
        <tag>HBase</tag>
        <tag>Shell</tag>
        <tag>Phoenix</tag>
        <tag>Zookeeper</tag>
        <tag>Excel</tag>
        <tag>Linux</tag>
        <tag>Kakfa</tag>
      </tags>
  </entry>
  <entry>
    <title>解决微博图床防盗链的问题</title>
    <url>/2019042701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>对于不少自己搭建博客的人来说，图床的选择可真是一个大难点，以前还有各种免费好用的图床工具，例如七牛云、又拍云、SM.MS、Imgur、GitHub、微博图床等，当然还有腾讯云、阿里云的云存储服务，但是免费的意味着不稳定，说不定哪天图片就没有了，有一些国外的访问速度又不行，国内的云存储服务商收费又比较高，还有的必须绑定认证的域名才能使用。本来搭建一个小小的博客，只为了记录知识，传播技术，遇到耗财或者耗精力的这种问题，都比较头疼。</p><p>后来纠结了好几天，最终决定使用免费的 <strong>微博图床 </strong>，一是因为新浪微博这家厂商体量大，微博图床短期内应该不会出问题，二是看到好多网友说他们已经稳定使用微博图床 3-5 年了，没有出过问题。我大概使用的时间还没有一年，以前都是本地化的，没有整理成完整的文章，后来开始慢慢整理并部署上线。没想到最近【2019 年 4 月 24 日左右发现】微博图床出问题了，访问图片链接全部是返回 403 状态码，表示拒绝访问，其实是微博图床开启了防盗链，本文就记录这个现象以及可行的解决方案。</p><a id="more"></a><h1 id="微博图床防盗链开启"><a href="# 微博图床防盗链开启" class="headerlink" title="微博图床防盗链开启"></a>微博图床防盗链开启 </h1><h2 id="初始现象"><a href="# 初始现象" class="headerlink" title="初始现象"></a> 初始现象 </h2><p> 在 2019 年 4 月 24 日的时候，我发现一个严重的问题，我的博客里面的图片显示不出来了，并不是被封了，如果被封也会显示图片的，只不过是马赛克图片。发现这个问题的缘由是新写了一篇博客，本地生成测试的时候，发现图片全部不显示了，一开始还以为是网络问题。</p><p>博客里面的图片全部无法正常显示 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hfpnoi01j20lc0i00tr.jpg" alt="图片全部无法正常显示" title="图片全部无法正常显示"></p><p> 接着我随机抽了一些图片链接在浏览器中直接打开看，发现是可以看到图片的，然后在博客中还是看不到图片，如果在博客中选择图片链接，使用右键 <strong>在新标签页中打开 </strong>，也是不能看到。这就说明微博图床开始检测请求的合法性了，对于不正常的请求统统拒绝。</p><p>当然，如果直接使用图片的链接在浏览器中单独打开，是可以看到图片的，紧接着在博客中就可以看到对应的图片了，但是这并不是说明图片可以使用了，其实是浏览器的缓存作用，如果及时清除浏览器的缓存，发现又不能使用了。</p><p>复制图片地址在浏览器中打开，图片可以正常显示 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hfpvew8yj212p0k2q3i.jpg" alt="在浏览器中打开图片可以正常显示" title="在浏览器中打开图片可以正常显示"></p><h2 id="分析现象"><a href="# 分析现象" class="headerlink" title="分析现象"></a> 分析现象 </h2><p> 接着使用浏览器的调试工具查看详细的请求信息，按 <strong>F12</strong> 按键，调出调试工具，刷新网页，使用 <strong>jpg</strong> 过滤无效内容，可以看到所有的图片访问请求结果都是 403，也就是拒绝访问。</p><p>随便点开一个链接的请求信息，查看 Status Code 为 403，也就是拒绝访问，注意查看请求头的 <strong>Referer</strong> 参数，值是一个链接，表示当前请求所属的页面，即 <strong>引用来源 </strong>，而新浪微博恰好会检测这个参数，拒绝所有的外链请求，即不是从新浪的站点发送的图片请求。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hfqpbdc6j20rd0g1abk.jpg" alt="403 拒绝访问" title="403 拒绝访问"></p><p>原来，近期微博图床对图片 CDN 添加了引用来源【Referer】检测，非微博站内引用将会返回 403 错误码，即拒绝访问。那能不能伪造或者清除这个参数呢，其实是可以的，只不过伪造、清除都需要增加一些 Javascript 动态脚本来处理，需要一些技术支持。</p><p>如果选择清除 Referer 参数，可以先验证一下，把图片的链接直接复制到浏览器中访问，就不会有这个参数，发现可以正常访问，没有 403 错误。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hfroxnhfj20oa0ijq3w.jpg" alt="单独在浏览器中访问" title="单独在浏览器中访问"></p><p>注意，一开始我发现使用浏览器能直接访问，紧着着博客里面的图片也能访问了，我还以为是需要单独访问一次图片，然后就可以任意访问了，后来发现其实是浏览器缓存的作用，空欢喜一场。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hfsl0troj20ph0dujsl.jpg" alt="缓存欺骗了我" title="缓存欺骗了我"></p><p>也看到有说法是，微博图床仅仅针对开启 SSL 的链接【即 HTTPS】实行站外禁止访问，而普通的 HTTP 链接仍旧安然无恙，这种说法是错误的【但是确实有这种现象出现】。我测试了一下，的确是有这样的现象，前提是来源页面开启了 SSL，而图床链接使用基本的 HTTP，这样的话由于 <strong>Referer</strong> 的特性，请求图片链接时不会传输 <strong>Referer</strong> 这个参数的值【即来源页面的信息不会传递给请求页面】，微博图床自然也就无法检测了。所以最简单的方案就是把所有微博图床的链接全部由 HTTPS 替换为 HTTP，但是由于我的博客全面开启了 SSL，为了加绿锁，因此不引用普通的 HTTP 链接，这种简单的方案我就无法采用了，只能遗憾舍弃。</p><h1 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案 </h1><p> 考虑切换图床，免费的已经基本没有了，收费的比较贵，或者找到方案先临时使用，不然会给查看博客的人带来很大困扰，毕竟没有图片的博客怎么能看，这也影响博客的质量与声誉。</p><h2 id="尝试清除来源引用"><a href="# 尝试清除来源引用" class="headerlink" title="尝试清除来源引用"></a>尝试清除来源引用 </h2><p> 在静态网页的 <strong>头部 </strong>代码中【即 head 标记】添加如下配置项：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;</span><br></pre></td></tr></table></figure><p>它的作用就是阻止浏览器发送 <strong>Referer</strong> 信息，对整个页面的所有链接生效【当然也有针对单个链接设置的方法：&lt;a rel=”noreferrer” href=”your-website-url” /&gt;，这里不采用】，这样一来微博图床就不知道请求的引用来源了，可以达到和直接在浏览器中访问一样的效果。<strong> 但是要注意，不是每种浏览器都支持这种语法的，此设置对有的浏览器来说无效。</strong></p><p>那么在 Hexo 框架中怎么增加呢，显然不会有相关配置项，只能更改源代码，而且使用了 Next 主题，应该要更改主题的源代码，以保证 Hexo 在渲染静态页面为每个页面都增加这个配置。查阅文档，了解了渲染模板所在位置，打开 <strong>themes/next/layout/_partials/head.swig</strong> 文件，在里面添加 meta 标记就行。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hit3tj2sj20nn07eq3f.jpg" alt="修改 head.swig 文件" title="修改 head.swig 文件"></p><p>修改完成后查看页面的源代码，已经有这个属性了，并且所有的图片都可以正常访问了，完美。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hiusk7jqj20tu091gmn.jpg" alt="查看页面的源代码" title="查看页面的源代码"></p><p>但是我觉得这肯定不是长久之计，以后说不定还会有幺蛾子出现，所以要随时准备着。</p><h2 id="尝试其他方案"><a href="# 尝试其他方案" class="headerlink" title="尝试其他方案"></a>尝试其他方案 </h2><p> 先观察一段时间，这段时间要考虑其他方案的可行性和成本。</p><h2 id="建议"><a href="# 建议" class="headerlink" title="建议"></a>建议 </h2><p> 微博图床开启防盗链，个人博客对于新浪图床的依赖时代基本要告别了，虽然有其他免费图床可以使用，但稳定性和可持续性上显然无法与大企业维护的图床相比。为了博客内容稳定考虑，还是考虑后续逐渐把图片迁移到其他云存储空间，费用方面能承受就行。</p><h1 id="其他知识点"><a href="# 其他知识点" class="headerlink" title="其他知识点"></a>其他知识点 </h1><h2 id="微博图床简单介绍"><a href="# 微博图床简单介绍" class="headerlink" title="微博图床简单介绍"></a> 微博图床简单介绍 </h2><p> 对于大多数个人博客维护者而言，免费的图床既节省成本，也能够提升页面访问的速度，而新浪微博图床则成了首选。</p><p>新浪微博由于本身体量大，其图床免费无限容量，只需要有一个微博账号就可使用。同时具备全网 CDN 加速，支持 HTTPS，无论是国内还是国外网络访问，速度都很不错。而且新浪如此企业，不会像其他个人或者团队经营的免费图床一样随时可能会关掉。</p><p>基于这些优势，不少人会优先选择新浪微博图床作为网站提供图片服务。毕竟直接挂 CDN 或者自建图床的话，也是一个持久的付费维护，如果一旦被攻击，更是造成费用暴增。</p><h2 id="Referer"><a href="#Referer" class="headerlink" title="Referer"></a>Referer</h2><p><strong>Referer</strong> 首部包含了当前请求页面的来源页面的地址，即表示当前页面是通过此来源页面里的链接进入的。服务端一般使用 <strong>Referer</strong> 首部识别访问来源，可能会以此进行统计分析、日志记录以及缓存优化等。同时也让服务器能够发现过时的和错误的链接并及时维护。</p><p>需要注意的是 <strong>referer</strong> 实际上是 <strong>referrer</strong> 的误拼写，它可能是 HTTP 协议中第一个被拼写错误的标准头，为保持向下兼容就将错就错了。可以参见 RFC 文档的 Referer 的介绍：<br><a href="https://tools.ietf.org/html/rfc2616#section-14.36" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc2616#section-14.36</a> ，原文有这样的描述：</p><blockquote><p>the “referrer”, although the header field is misspelled.</p></blockquote><p>此外还可以参考维基百科的相关介绍：<br><a href="https://zh.wikipedia.org/wiki/HTTP% E5%8F%83% E7%85% A7% E4% BD%8D% E5%9D%80" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/HTTP% E5%8F%83% E7%85% A7% E4% BD%8D% E5%9D%80</a> 。</p><p>在以下几种情况下，<strong>Referer</strong> 不会被发送 </p><ul><li> 来源页面采用的协议为表示本地文件的 file 或者 data URI</li><li>当前请求页面采用的是非安全协议，而来源页面采用的是安全协议【HTTPS】</li><li>为整个页面设置 &lt;meta name=”referrer” content=”no-referrer” /&gt;</li><li>为单个链接设置 &lt;a rel=”noreferrer” href=”your-website-url” /&gt;</li></ul><p>注意第二种情况，如果你的博客开启了 SSL，可以使用 HTTP 的图片链接，就可以正常访问了。但是要牺牲你的博客的安全性，因为浏览器会检测到你的博客内容里面有普通的 HTTP 链接，就会导致不可信【尽管存在有效的证书，也没有用】，小绿锁会消失，并给出警告。</p><p>例如我的博客，为了测试，使用了一个 HTTP 图片链接，其它的图片都是 HTTPS 链接，可以发现 HTTP 的图片可以正常访问，其它的图片仍旧被拒绝访问了。此时，发现博客的小绿锁已经没有了，并且给出了警告提示。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g2hlkwnfm9j214a0hr75v.jpg" alt="不安全的方案" title="不安全的方案"></p><h1 id="后记"><a href="# 后记" class="headerlink" title="后记"></a>后记 </h1><p> 使用上述的解决方案后，我又发现了一个严重的问题，由于清除了引用来源 referer，博客文章的地址就不会发送出去，导致我的 <strong>不蒜子 </strong>统计失效，也就是每篇文章的阅读数、整个站点的访问量【pv】、整个站点的访客数【uv】都会停止统计。这会导致整个博客的动态流量不可见，对于写博客的我来说内心会有一点点失落，所以我要想办法解决这个问题。</p><p>已经知道问题的根源了，解决起来也是很容易的，直接开启引用来源 referer 即可，但是由于和微博图床的图片防盗链冲突，不能同时开启。也就是说除了微博图床的防盗链要关闭 referer，其它的链接仍旧正常开启，看看能不能想办法只把微博图床的链接关闭 referer。</p><p>标记 a 可以增加 ref=”noreferrer” 属性，但是在 Hexo 中我无法找到合适的方式来完成这个操作。本来准备在 <strong>_macro/post.swig</strong> 中对渲染后的标记属性进行替换，示例 swig 语句：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; post.content|replace (&apos;group&apos;, &apos;noreferrer&apos;, &apos;g&apos;) &#125;&#125;</span><br></pre></td></tr></table></figure><p>把 <strong>ref=”group”</strong> 替换为 <strong>ref=”noreferrer”</strong>，但是测试后发现行不通，传递过来的 <strong>content</strong> 只包含 p 标记，并没有 a 标记，也就是说明 a 标记是在其它地方渲染的。</p><p>而如果直接在渲染标记 a 的地方进行选择性替换，发现微博图床的图片链接，就把 ref 属性替换掉，需要去更改 Hexo 的源代码，其中有一个 <strong>markdown (str)</strong> 方法，显然这种临时方案不合理，也很麻烦。</p><p>为了稳定地解决这个问题，我还是决定更换图床，然后使用第三方工具进行图片迁移。</p><h2 id="更换图床"><a href="# 更换图床" class="headerlink" title="更换图床"></a>更换图床 </h2><p> 和以前一样，挑选了一圈，也是很纠结，最终还是下定决心直接使用 GitHub 了，稳定又方便。其实就是新建一个仓库，专门用来存放图片，只不过需要考虑一下图片过多、图片过大会不会被 GitHub 限制。</p><p>去 GitHub 搜索帮助文档，<a href="https://help.github.com/en/articles/what-is-my-disk-quota" target="_blank" rel="noopener">帮助文档信息 </a> ，可以得知仓库最大为 100GB，但是官方建议保持在 1GB 以下，单个文件低于 100MB，因此用来存放文件绰绰有余。另外需要注意，仓库文件超过 1GB 时会收到 GitHub 的提醒邮件，超过 75GB 时，每次在提交时都会收到警告。</p><p> 原文描述如下：</p><blockquote><p>We recommend repositories be kept under 1GB each. Repositories have a hard limit of 100GB. If you reach 75GB you’ll receive a warning from Git in your terminal when you push. This limit is easy to stay within if large files are kept out of the repository. If your repository exceeds 1GB, you might receive a polite email from GitHub Support requesting that you reduce the size of the repository to bring it back down.</p></blockquote><blockquote><p>In addition, we place a strict limit of files exceeding 100 MB in size.</p></blockquote><p>既然有这种限制，最好还是把图片压缩一下，推荐使用图片压缩工具：<a href="https://github.com/meowtec/Imagine" target="_blank" rel="noopener">Imagine</a> ，这个工具可以实时看到压缩效果，而且压缩率还不错，能到 50%。但是，如果想要保持图片的色彩度、还原度，压缩效果肯定是不行的，甚至有时候压缩后的图片比压缩前的还大。</p><p>压缩图片示例 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/20190502183444.png" alt="压缩图片示例" title="压缩图片示例"></p><h2 id="迁移图片"><a href="# 迁移图片" class="headerlink" title="迁移图片"></a> 迁移图片 </h2><p> 迁移图片本来是个很麻烦的事情，要把图片迁移、博客文章里面的链接替换掉，但是还好有现成的工具可以使用，在这里推荐：<a href="https://github.com/Molunerfinn/PicGo" target="_blank" rel="noopener">PicGo</a> ，这个工具本来不是做图片迁移的，仅仅是图片上传生成链接而已，但是有人开发了插件，专门用来迁移 markdown 文件里面的图片，会自动迁移图片并且更新 markdown 里面的图片链接。这个插件是：<a href="https://github.com/PicGo/picgo-plugin-pic-migrater" target="_blank" rel="noopener">picgo-plugin-pic-migrater</a> ，而且，还可以支持批量迁移，指定一个文件夹，直接迁移文件夹里面的所有 markdown 文件。</p><h2 id="迁移过程"><a href="# 迁移过程" class="headerlink" title="迁移过程"></a>迁移过程 </h2><p> 详细的迁移步骤就不再记录，几个重要的步骤：在 GitHub 建立仓库、使用 PicGo 工具迁移图片，重新整理 markdown 文件。操作前切记备份好自己的 markdown 文件，以免迁移出现问题导致文件丢失。</p><p>在使用 PicGo 的过程中，发现总是迁移失败，重试了多次之后确定是因为在 markdown 语法中增加了注释，相当于给图片链接增加了 alt 属性【生成时图片会有一个 img 标记】，导致 PicGo 的插件识别不了，迁移失败。我已经在 GitHub 的项目中提了 issue：<a href="https://github.com/PicGo/picgo-plugin-pic-migrater/issues/1" target="_blank" rel="noopener">https://github.com/PicGo/picgo-plugin-pic-migrater/issues/1</a> ，作者也回复了，后续会修复。而我比较着急，等不了，又不可能把这些注释全部清除，也不好，所以我决定自己迁移，通过 Java 写代码解决。</p><p>写代码也比较简单，主要有四个步骤：读取 markdown 文件内容并利用正则抽取微博图床的图片链接、下载所有图片并上传至 GitHub、替换内容中抽取出的所有图片链接为 GitHub 的图片链接、内容写回新文件。</p><p>使用 Java 处理不需要多少代码，主要要依赖几个 jar 包：处理文件的 io 包、处理网络请求的 httpclient 包、处理 git 的 jgit 包。详细内容可以参考我的另外一篇博客：<a href="https://www.playpi.org/2019050201.html">使用 Java 代码迁移微博图床到 GitHub 图床 </a> 。</p><h2 id="小细节"><a href="# 小细节" class="headerlink" title="小细节"></a> 小细节 </h2><p> 针对 PicGo 的使用还有一些小细节可以注意一下：自定义域名、子文件夹路径、图片压缩【不压缩针对 GitHub 速度会很慢，能压缩到 200KB 最好】、文件重命名。</p><h2 id="未来考虑"><a href="# 未来考虑" class="headerlink" title="未来考虑"></a>未来考虑 </h2><p> 迁移完成之后，以后新的图片就直接使用 PicGo 上传到 GitHub 图床了，同时需要注意区分子文件夹。在 GitHub 仓库中，暂时每年新建一个文件夹，以年份数字为名称。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>weibo</tag>
        <tag>https</tag>
        <tag>referer</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 的 Reindex API 详解</title>
    <url>/2020011601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在业务中只要有使用到 <code>Elasticsearch</code> 的场景，那么有时候会遇到需要重构索引的情况，例如 <code>mapping</code> 被污染了、某个字段需要变更类型等。如果对 <code>reindex API</code> 不熟悉，那么在遇到重构的时候，必然事倍功半，效率低下。但是如果熟悉了，就可以方便地进行索引重构，省时省力。</p><p>本文演示内容基于 <code>Elasticsearch v5.6.8</code>，在以后会不断补充完善。</p><a id="more"></a><h1 id="常用方式"><a href="# 常用方式" class="headerlink" title="常用方式"></a>常用方式 </h1><p> 提前声明，在开始演示具体的 <code>API</code> 的时候，有一点读者必须知道，<code>reindex</code> 不会尝试自动设置目标索引，它也不会复制源索引的设置。读者应该在运行 <code>reindex</code> 操作之前设置好目标索引的参数，包括映射、分片数、副本数等等。目标索引如果不设置 <code>mapping</code>，则会使用默认的配置，默认配置不会自动处理一些有特殊要求的字段【例如分词字段、数值类型字段】，则会引发字段类型错误的结果。</p><p>当然，关于设置索引，最常见的做法不是手动设置索引信息，而是使用索引模版【使用动态模版：<code>dynamic_templates</code>】，只要索引模版的匹配形式可以匹配上源索引和目标索引，我们不需要去考虑索引配置的问题，模版会为我们解决对应的问题。当然，关于的索引的分片数、副本数，还是需要考虑的。</p><p>最后，关于版本的说明，以下内容只针对 <code>v5.x</code> 以及之后的版本，更多版本的使用方式读者可以参考文末的备注信息。</p><h2 id="迁移数据简单示例"><a href="# 迁移数据简单示例" class="headerlink" title="迁移数据简单示例"></a>迁移数据简单示例 </h2><p> 涉及到 <code>_reindex</code> 关键字，简单示例如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行返回结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 9991,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;total&quot;: 12505,</span><br><span class="line">  &quot;updated&quot;: 12505,</span><br><span class="line">  &quot;created&quot;: 0,</span><br><span class="line">  &quot;deleted&quot;: 0,</span><br><span class="line">  &quot;batches&quot;: 13,</span><br><span class="line">  &quot;version_conflicts&quot;: 0,</span><br><span class="line">  &quot;noops&quot;: 0,</span><br><span class="line">  &quot;retries&quot;: &#123;</span><br><span class="line">    &quot;bulk&quot;: 0,</span><br><span class="line">    &quot;search&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;throttled_millis&quot;: 0,</span><br><span class="line">  &quot;requests_per_second&quot;: -1,</span><br><span class="line">  &quot;throttled_until_millis&quot;: 0,</span><br><span class="line">  &quot;failures&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200203234351.png" alt="演示结果" title="演示结果"></p><p>演示结果迁移了 12505 条数据，耗时 9991 毫秒。</p><p>以上只是一个非常基础的示例，还有一些可以优化的参数没有指定，全部使用的是默认值，例如看到 <code>batches</code>、<code>total</code> 对应的数值，就可以算出一批的数据大小默认为 1000，12505 条数据需要 13 批次才能迁移完成。再看到 <code>updated</code> 的数值，就可以猜测是更新了目标索引的数据，而不是创建数据，说明目标索引本来就有数据，被重新覆盖了。而这些内容在后续的小节中都会逐一解释，并再次演示。</p><p>注意一点，如果 <code>Elasticsearch</code> 是 <code>v6.x</code> 以及以下的版本，会涉及到索引的 <code>type</code>，如果源索引只有一个 <code>type</code>，则可以省略 <code>type</code> 这个参数，即不需要指定【数据会迁移到目标索引的同名 <code>type</code> 里面】。但是，如果涉及到多个 <code>type</code> 的数据迁移，肯定是要指定的【例如把多个 <code>type</code> 的数据迁移到同一个 <code>type</code> 中，或者仅仅把某个 <code>type</code> 的数据迁移到另外一个 <code>type</code> 中】。因此，为了准确无误，最好还是指定 <code>type</code>【当然再高的版本就没有 <code>type</code> 的概念了，无需指定】。</p><p>如果根据上面的示例，再添加 <code>type</code> 参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;type&quot;: &quot;user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">    &quot;type&quot;: &quot;user&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="version-type- 参数"><a href="#version-type- 参数" class="headerlink" title="version_type 参数"></a>version_type 参数 </h2><p> 就像 <code>_update_by_query</code> 里面的逻辑一样，<code>_reindex</code> 会生成源索引的快照【<code>snapshot</code>】，但是它的目标索引必须是一个不同的索引【另外创建一个】，以便避免版本冲突问题。同时，针对 <code>dest index</code> 可以像 <code>index API</code>【索引数据】 一样进行配置，以乐观锁控制并发写入【并发写入相同的数据，通过 <code>version</code> 来控制，有冲突时会写入失败，可以重试】。</p><p>像上面那样最简单的方式，不设置 <code>version_type</code> 参数【默认为 <code>internal</code>】或显式设置它为 <code>internal</code>，效果都一样。此时，<code>Elasticsearch</code> 将会直接将文档转储到 <code>dest index</code> 中，直接覆盖任何具有相同类型和 <code>id</code> 的 <code>document</code>，不会产生冲突问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">    &quot;version_type&quot;: &quot;internal&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果把 <code>version_type</code> 设置为 <code>external</code>，则 <code>Elasticsearch</code> 会从 <code>source</code> 读取 <code>version</code> 字段，当遇到具有相同类型和 <code>id</code> 的 <code>document</code> 时，只会保留 <code>newer verion</code>，即最新的 <code>version</code> 对应的数据。此时可能会有冲突产生【例如把 <code>op_type</code> 设置为 <code>create</code>】，对于产生的冲突现象，返回体中的 <code>failures</code> 会携带冲突的数据信息【类似详细的日志可以查看】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">    &quot;version_type&quot;: &quot;external&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的说法看起来似乎有点不好理解，再简单直观点来说，就是在 <code>redinex</code> 的时候，我们的 <code>dest index</code> 可以不是一个新创建的不包含数据的 <code>index</code>，而是已经包含有数据的。如果我们的 <code>source index</code> 和 <code>dest index</code> 里面有相同类型和 <code>id</code> 的 <code>document</code>【一模一样的数据】，对于使用 <code>internal</code> 来说，就是直接覆盖，而使用 <code>external</code> 的话，只有当 <code>source index</code> 的数据的 <code>version</code> 比 <code>dest index</code> 数据的 <code>version</code> 更加新的时候，才会去更新【即保留最新的 <code>version</code> 对应的数据】。</p><p>再说明一下，<code>internal</code> 可以理解为使用内部版本号，即 <code>Elasticsearch</code> 不会单独比较版本号，对于 <code>dest index</code> 来说，无论是索引数据还是更新数据，写入时都按部就班把版本号累加，所以也就不会有冲突问题【从 <code>source index</code> 出来的数据是不携带版本信息的】，但是有可能会出现版本号不合法的问题，参考后面的 <strong>使用脚本配置 </strong>小节【使用脚本时人为变更版本号】。</p><p>另一方面，<code>external</code> 表示外部版本号，即 <code>Elasticsearch</code> 会单独比较版本号再决定写入的流程，对于 <code>dest index</code> 来说，无论是索引数据还是更新数据，写入时会先比较版本号，只保留版本号最大的数据【如果是来自不同索引的数据，版本号会不一致；如果是来自不同集群的数据，版本号规则可能也不一致】。</p><h2 id="op-type- 参数"><a href="#op-type- 参数" class="headerlink" title="op_type 参数"></a>op_type 参数 </h2><p><code>op_type</code> 参数控制着写入数据的冲突处理方式，如果把 <code>op_type</code> 设置为 <code>create</code>【默认值】，在 <code>_reindex API</code> 中，表示写入时只在 <code>dest index</code> 中添加不存在的 <code>doucment</code>，如果相同的 <code>document</code> 已经存在，则会报 <code>version confilct</code> 的错误，那么索引操作就会失败。【这种方式与使用 <code>_create API</code> 时效果一致】</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">    &quot;op_type&quot;: &quot;create&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 如果这样设置了，也就不存在更新数据的场景了【冲突数据无法写入】，则 <code>version_type</code> 参数的设置也就无所谓了【但是返回体的 <code>failures</code> 中还是会携带冲突信息】。</p><p>另外也可以把 <code>op_type</code> 设置为 <code>index</code>，表示所有的数据全部重新索引创建。</p><p>再总结一下，如果把 <code>version_type</code> 设置为 <code>external</code>，无论 <code>op_type</code> 怎么设置，都有可能产生冲突【会比较版本】；如果把 <code>version_type</code> 设置为 <code>internal</code>，则在 <code>op_type</code> 为 <code>index</code> 的时候不会产生冲突，在 <code>op_type</code> 为 <code>create</code> 的时候可能有冲突。</p><h2 id="conflicts- 配置"><a href="#conflicts- 配置" class="headerlink" title="conflicts 配置"></a>conflicts 配置 </h2><p> 默认情况下，当发生 <code>version conflict</code> 的时候，<code>_reindex</code> 会被 <code>abort</code>，任务终止【此时数据还没有 <code>reindex</code> 完成】，在返回体中的 <code>failures</code> 指标中会包含冲突的数据【有时候数据会非常多】，除非把 <code>conflicts</code> 设置为 <code>proceed</code>。</p><p>关于 <code>abort</code> 的说明，如果产生了 <code>abort</code>，已经执行的数据【例如更新写入的】仍然存在于目标索引，此时任务终止，还会有数据没有被执行，也就是漏数了。换句话说，该执行过程不会回滚，只会终止。如果设置了 <code>proceed</code>，任务在检测到数据冲突的情况下，不会终止，会跳过冲突数据继续执行，直到所有数据执行完成，此时不会漏掉正常的数据，只会漏掉有冲突的数据。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">    &quot;op_type&quot;: &quot;create&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;conflicts&quot;: &quot;proceed&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>故意把 <code>op_type</code> 设置为 <code>create</code>，人为制造数据冲突的场景，测试时更容易观察到冲突现象。</p><p>如果把 <code>conflicts</code> 设置为 <code>proceed</code>，在返回体结果中不会再出现 <code>failures</code> 的信息，但是通过 <code>version_conflicts</code> 指标可以看到具体的数量。</p><h2 id="query- 配置"><a href="#query- 配置" class="headerlink" title="query 配置"></a>query 配置 </h2><p> 迁移数据的时候，肯定有只是复制源索引中部分数据的场景，此时就需要配置查询条件【使用 <code>query</code> 参数】，只复制命中条件的部分数据，而不是全部，这和查询 <code>Elasticsearch</code> 数据的逻辑一致。</p><p>如下示例，通过 <code>query</code> 参数，把需要 <code>_reindex</code> 的 <code>document</code> 限定在一定的范围，我这里是限定更新时间 <code>update_timestamp</code> 在 1546272000000【20190101000000】之后。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">      &quot;bool&quot;: &#123;</span><br><span class="line">        &quot;must&quot;: [</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;range&quot;: &#123;</span><br><span class="line">              &quot;update_timestamp&quot;: &#123;</span><br><span class="line">                &quot;gte&quot;: 1546272000000</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="批次大小配置"><a href="# 批次大小配置" class="headerlink" title="批次大小配置"></a>批次大小配置 </h2><p> 如果在 <code>query</code> 参数的同一层次【即 <code>source</code> 参数中】再添加 <code>size</code> 参数，并不是表示随机获取部分数据，而是表示 <code>scroll size</code> 的大小【会影响批次的次数，进而影响整体的速度】，这个有点迷惑人。另外，直接在 <code>query</code> 中添加 <code>size</code> 参数是不被允许的。</p><p>如果不显式设置，默认是一批 1000 条数据，在一开始的简单示例中也看到了。</p><p>如下，设置 <code>scroll size</code> 为 100：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">      &quot;bool&quot;: &#123;</span><br><span class="line">        &quot;must&quot;: [</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;range&quot;: &#123;</span><br><span class="line">              &quot;update_timestamp&quot;: &#123;</span><br><span class="line">                &quot;gte&quot;: 1546272000000</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;size&quot;: 100</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200205001736.png" alt="返回结果" title="返回结果"></p><p>根据返回结果可以看到，实际迁移 12505 条数据，<code>batches</code> 为 126【可以算出每次 <code>batch</code> 为 100 条数据】，耗时为 31868 毫秒，是前面简单示例耗时的 3 倍【前面简单示例的耗时是 10 秒左右】。</p><p>注意，千万不要用错 <code>size</code> 参数的位置，可以继续参考下面的 <strong>随机 size 配置 </strong>小节。</p><h2 id="多对一迁移"><a href="# 多对一迁移" class="headerlink" title="多对一迁移"></a>多对一迁移 </h2><p> 如果需要把多个索引的数据或者多个 <code>type</code> 的数据共同迁移到同一个目标索引中，则需要在 <code>source</code> 参数中指定多个索引。</p><p>把同一个索引中的不同 <code>type</code> 的数据共同迁移到同一个索引中，例如把 <code>my-index-user</code> 下的 <code>user</code>、<code>user2</code> 数据共同迁移到 <code>my-index-user-v2</code> 中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: [</span><br><span class="line">      &quot;my-index-user&quot;,</span><br><span class="line">      &quot;my-index-user&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot;: [</span><br><span class="line">      &quot;user&quot;,</span><br><span class="line">      &quot;user2&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把不同索引中的数据共同迁移到同一个索引中，例如把 <code>my-index-user</code> 下的 <code>user</code>、<code>my-index-user-v2</code> 下的 <code>user2</code> 数据共同迁移到 <code>my-index-user-v3</code> 中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: [</span><br><span class="line">      &quot;my-index-user&quot;,</span><br><span class="line">      &quot;my-index-user-v2&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot;: [</span><br><span class="line">      &quot;user&quot;,</span><br><span class="line">      &quot;user2&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v3&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里要注意的是，对于上面的第二个示例，如果 <code>my-index-user</code> 和 <code>my-index-user-v2</code> 中有 <code>document</code> 的 <code>id</code> 是一样的，则无法保证最终出现在 <code>my-index-user-v3</code> 里面的 <code>document</code> 是哪个，因为迭代是随机的。按照默认的配置【即前面的 <code>version_type</code>、<code>opt_type</code> 等参数】，最后一条数据会覆盖前一条数据。</p><p>当然，对于第一个示例也会有这个问题。</p><p>另外，不要想着一对多迁移、多对多迁移等操作，不支持，因为写入时必须指定唯一确定的索引，否则 <code>Elasticsearch</code> 不知道数据要往哪个索引里面写入。</p><h2 id="随机 -size- 配置"><a href="# 随机 -size- 配置" class="headerlink" title="随机 size 配置"></a>随机 size 配置 </h2><p> 有时候想提前测试一下迁移结果是否准确，或者使用少量数据做一下性能测试，则需要随机取数的配置，可以使用 <code>size</code> 参数。注意，<code>size</code> 参数的位置是与 <code>source</code>、<code>dest</code> 在同一层级的，即在最外层。</p><p>例如随机取数 100 条，示例如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;size&quot;: 100</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200205004107.png" alt="随机 100 条数据结果" title="随机 100 条数据结果"></p><p>可以看到，随机迁移了 100 条数据，耗时 223 毫秒。</p><p>注意这里，千万不要用错 <code>size</code> 参数的位置，一个是表示 <code>scroll size</code> 的大小【如上面的 <strong>query 配置 </strong>中，配置在与 <code>query</code> 同一个层级，在 <code>source</code> 里面】，一个是表示随机抽取多少条【本小节示例，配置在最外层】。</p><p>我曾经就把 <code>size</code> 设置错误，放在与 <code>query</code> 同一层级，也就是误把 <code>scroll size</code> 设置为 10 了【本来是想先迁移 10 条数据看看结果】，导致 <code>reindex</code> 速度非常慢，30 分钟才 20 万数据量【我还在疑惑为什么设置的随机 10 条不生效，把全部数据都迁移了】。</p><p>后来发现了，把任务取消，重新提交 <code>reindex</code> 任务，准确地把随机 <code>size</code> 设置为 10 万，把 <code>scroll size</code> 设置为 2000。测试后才正式开始迁移数据，速度达到了 30 分钟 500 万，和前面的误操作比较明显提升了很多。</p><h2 id="排序配置"><a href="# 排序配置" class="headerlink" title="排序配置"></a>排序配置 </h2><p> 好，上面有了随机数据条数的设置，但是如果我们想根据某个字段进行排序，获取 <code>top 100</code>，有没有办法呢？有，当然有，可以使用排序的功能，关键字为 <code>sort</code>，使用方式和查询 <code>Elasticsearch</code> 时一致。</p><p>例如按照更新时间 <code>update_timestamp</code> 的降序排列，获取前 100 条数据：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;sort&quot;: &#123;</span><br><span class="line">      &quot;update_timestamp&quot;: &quot;desc&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;size&quot;: 100</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200205005139.png" alt="返回结果" title="返回结果"></p><h2 id="指定字段配置"><a href="# 指定字段配置" class="headerlink" title="指定字段配置"></a>指定字段配置 </h2><p> 如果迁移数据时只需要特定的字段，可以使用 <code>_source</code> 参数指定字段，字段少了迁移速度也可以提升。下面的示例指定了 3 个字段：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;_source&quot;: [</span><br><span class="line">      &quot;id&quot;,</span><br><span class="line">      &quot;city_level&quot;,</span><br><span class="line">      &quot;task_ids&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200205235937.png" alt="返回结果" title="返回结果"></p><p>可以看到，迁移 12505 条数据，耗时 3611 毫秒，比前面的简单示例快了不少。</p><p>查看目标数据，可以看到只有 3 个字段【注意，<code>_id</code> 字段是 <code>document</code> 的主键，会自动携带】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200206001202.png" alt="有 3 个字段的数据示例" title="有 3 个字段的数据示例"></p><p>但是有一点需要注意，如果 <code>Elasticsearch</code> 的索引设置中，使用 <code>_source、excludes</code> 排除了部分字段的存储【为了节省磁盘空间】，实际上没有存储字段，只是做了索引，则不可以直接迁移，会丢失这些字段。</p><h2 id="使用脚本配置"><a href="# 使用脚本配置" class="headerlink" title="使用脚本配置"></a>使用脚本配置 </h2><p> 如果集群开启了允许使用 <code>script</code> 的功能【在配置文件 <code>elasticsearch.yml</code> 中使用 <code>script.inline: true</code> 开启】，就可以使用 <code>script</code> 做一些简单的数据转换。</p><p>例如把满足条件的数据做一个 <code>_version</code> 增加，并且移除指定的字段，在写入目标索引时，利用 <code>version_type</code> 参数保留最新版本的数据。</p><p>以下示例为了方便查看结果，只获取 3 个字段，脚本逻辑：对于 <code>city_level</code> 等于 1 的数据【<code>city</code> 为北京、上海、广州、深圳】，做一个版本自增，并且把 <code>city_level</code> 字段移除。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;_source&quot;: [</span><br><span class="line">      &quot;id&quot;,</span><br><span class="line">      &quot;city&quot;,</span><br><span class="line">      &quot;city_level&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">    &quot;version_type&quot;: &quot;external&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;script&quot;: &#123;</span><br><span class="line">    &quot;source&quot;: &quot;if (ctx._source.city_level == &apos;1&apos;) &#123;ctx._version++; ctx._source.remove (&apos;city_level&apos;)&#125;&quot;,</span><br><span class="line">    &quot;lang&quot;: &quot;painless&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;size&quot;: 100</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>数据结果查看：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200206012210.png" alt="数据结果查看" title="数据结果查看"></p><p>数据结果中可以看到数据的 <code>city_level</code> 字段已经消失了，只剩下 2 个字段。</p><p>再执行一次，如果数据相同，会有冲突问题，因为设置了 <code>version_type</code> 为 <code>external</code>，会比较版本【数据的版本不够新从而无法写入】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">         &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">         &quot;type&quot;: &quot;user&quot;,</span><br><span class="line">         &quot;id&quot;: &quot;AW3zlTvZa9C6UomAXwqT&quot;,</span><br><span class="line">         &quot;cause&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,</span><br><span class="line">            &quot;reason&quot;: &quot;[user][AW3zlTvZa9C6UomAXwqT]: version conflict, current version [3] is higher or equal to the one provided [1]&quot;,</span><br><span class="line">            &quot;index_uuid&quot;: &quot;tJienWj1T_udvoJQTcDzyg&quot;,</span><br><span class="line">            &quot;shard&quot;: &quot;1&quot;,</span><br><span class="line">            &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;status&quot;: 409</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200206012415.png" alt="冲突现象" title="冲突现象"></p><p>如果把 <code>version_type</code> 设置为 <code>internal</code>，同时指定 <code>op_type</code> 为 <code>index</code>【默认是 <code>create</code>】，则会出现版本号不合法的异常。因为在脚本中手动自增了版本号，不符合按照 <code>index</code> 方式索引数据的要求。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">action_request_validation_exception</span><br><span class="line">Validation Failed: 1: illegal version value [0] for version type [INTERNAL];</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200206012755.png" alt="版本号不合法" title="版本号不合法"></p><p>在此引申一下脚本的内容，<code>Elasticsearch</code> 提供了脚本的支持，可以通过 <code>Groovy</code> 外置脚本【已经过时，<code>v6.x</code> 以及之后的版本，不建议使用】、内置 <code>painless</code> 脚本实现各种复杂的操作【类似于写逻辑代码，对数据进行 <code>ETL</code> 操作】，如上面的示例。</p><p><code>painless</code> 有轻便之意，使用时直接在语法中调用即可，无需外置，也就是不支持通过外部文件存储 <code>painless</code> 脚本来调用。</p><blockquote><p>默认的脚本语言是 Groovy，一种快速表达的脚本语言，在语法上与 JavaScript 类似。它在 Elasticsearch v1.3.0 版本首次引入并运行在沙盒中，然而 Groovy 脚本引擎存在漏洞，允许攻击者通过构建 Groovy 脚本，在 Elasticsearch Java VM 运行时脱离沙盒并执行 shell 命令。<br>因此，在版本 v1.3.8、v1.4.3 和 v1.5.0 及更高的版本中，它已经被默认禁用。此外，您可以通过设置集群中的所有节点的 config/elasticsearch.yml 文件来禁用动态 Groovy 脚本：script.groovy.sandbox.enabled: false，这将关闭 Groovy 沙盒，从而防止动态 Groovy 脚本作为请求的一部分被接受。</p></blockquote><p>当然，对于常用的脚本，可以通过 <code>_scripts/calculate-score</code> 接口创建后缓存起来【也需要集群的配置：<code>script.store: true</code>】，会生成一个唯一 <code>id</code>，下次可以直接使用【就像声明了一个方法】，还支持参数传递。</p><h2 id="使用 -Ingest-Node- 配置"><a href="# 使用 -Ingest-Node- 配置" class="headerlink" title="使用 Ingest Node 配置"></a>使用 Ingest Node 配置 </h2><p><code>Ingest</code> 其实就是定义了一些预处理的规则，可以预处理数据，提升性能，主要依靠 <code>Pipeline</code>、<code>Processors</code>。当然前提还是需要集群支持，定义一些 <code>Ingest</code> 节点、预处理流程，可以通过配置 <code>elasticsearch.xml</code> 文件中的 <code>node.ingest: true</code> 来开启 <code>Ingest</code> 节点。</p><p> 这个功能应该说是最好用的了，当你的 <code>source</code> 因为不合理的结构，需要重新结构化所有的数据时，通过 <code>Ingest Node</code>，可以很方便地在新的 <code>index</code> 中获得不一样的 <code>mapping</code> 和 <code>value</code>【例如把数值类型转为字符串类型，或者把值替换掉】。</p><p>使用方式也很简单【需要提前创建 <code>pipeline</code>】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;,</span><br><span class="line">    &quot;pipeline&quot;: &quot;some_ingest_pipeline&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;size&quot;: 100</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果没有创建 <code>pipeline</code>，会报错，在返回体的 <code>failures</code> 中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;type&quot;: &quot;illegal_argument_exception&quot;,</span><br><span class="line">&quot;reason&quot;: &quot;pipeline with id [some_ingest_pipeline] does not exist&quot;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200206014248.png" alt="报错信息" title="报错信息"></p><h2 id="迁移远程集群数据到当前环境"><a href="# 迁移远程集群数据到当前环境" class="headerlink" title="迁移远程集群数据到当前环境"></a>迁移远程集群数据到当前环境 </h2><p> 有时候需要跨集群迁移数据，例如把 <code>A</code> 集群的数据复制到 <code>B</code> 集群中，只要 <code>A</code> 集群的节点开放了 <code>ip</code>、端口，就可以使用 <code>remote</code> 参数。</p><p>在 <code>B</code> 集群中也需要设置白名单，在 <code>elasticsearch.xml</code> 文件中配置 <code>reindex.remote.whitelist: otherhost:9200</code> 参数即可，多个使用英文逗号隔开。</p><p>使用示例【如果有认证机制则还需要带上用户名、密码信息】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;remote&quot;: &#123;</span><br><span class="line">      &quot;host&quot;: &quot;http://otherhost:9200&quot;,</span><br><span class="line">      &quot;username&quot;: &quot;username&quot;,</span><br><span class="line">      &quot;password&quot;: &quot;password&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里需要注意，对于复制在其他集群上的 <code>index</code> 数据来说，就不存在直接从本地镜像复制的便利【速度快】，需要从网络上下载数据再写到本地。默认的设置，<code>buffer</code> 的 <code>size</code> 是 <code>100Mb</code>，在 <code>scroll size</code> 是 1000 的情况下【默认值】，如果单个 <code>document</code> 的平均大小超过 <code>100Kb</code>，则会报错，数据过大。</p><p>因此在遇到非常大的 <code>document</code> 时，需要减小 <code>batch</code> 的 <code>size</code>【尽管会导致 <code>batch</code> 变多，迁移速度变慢，但是安全】，使用 <code>size</code> 参数【参考前面的 <strong>批次大小配置 </strong>小节】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user&quot;,</span><br><span class="line">    &quot;remote&quot;: &#123;</span><br><span class="line">      &quot;host&quot;: &quot;http://otherhost:9200&quot;,</span><br><span class="line">      &quot;username&quot;: &quot;username&quot;,</span><br><span class="line">      &quot;password&quot;: &quot;password&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;size&quot;: 100</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;my-index-user-v2&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="返回体"><a href="# 返回体" class="headerlink" title="返回体"></a>返回体 </h2><p> 在提交迁移数据任务后，如果耐心等待，会有执行的结果返回，正常情况下，返回的结果格式如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 9675,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;total&quot;: 12505,</span><br><span class="line">  &quot;updated&quot;: 12505,</span><br><span class="line">  &quot;created&quot;: 0,</span><br><span class="line">  &quot;deleted&quot;: 0,</span><br><span class="line">  &quot;batches&quot;: 13,</span><br><span class="line">  &quot;version_conflicts&quot;: 0,</span><br><span class="line">  &quot;noops&quot;: 0,</span><br><span class="line">  &quot;retries&quot;: &#123;</span><br><span class="line">    &quot;bulk&quot;: 0,</span><br><span class="line">    &quot;search&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;throttled_millis&quot;: 0,</span><br><span class="line">  &quot;requests_per_second&quot;: -1,</span><br><span class="line">  &quot;throttled_until_millis&quot;: 0,</span><br><span class="line">  &quot;failures&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200206015432.png" alt="返回信息" title="返回信息"></p><p>下面挑选几个指标解释说明一下：</p><ul><li><code>took</code>，整个操作从开始到结束的毫秒数 </li><li><code>total</code>，已成功处理的文档数</li><li><code>updated</code>，已成功更新的文档数</li><li><code>deleted</code>，已成功删除的文档数</li><li><code>batches</code>，由查询更新拉回的滚动响应数【结合 <code>total</code> 可以算出 <code>scroll size</code>】，与 <code>scroll size</code> 有关</li><li><code>version_conflicts</code>，按查询更新的版本冲突数【涉及到版本的比较判断】</li><li><code>retries</code>，逐个更新尝试的重试次数，<code>bulk</code> 是批量操作的重试次数，<code>search</code> 是搜索操作的重试次数</li><li><code>failures</code>，如果在此过程中存在任何不可恢复的错误，发生 <code>abort</code>，则会返回故障信息数组【内容可能会比较多】</li></ul><p> 这里需要注意的是 <code>failures</code> 信息，如果里面的信息不为空，则表示本次 <code>_reindex</code> 是失败的，是被中途 <code>abort</code>，一般都是因为发生了 <code>conflicts</code>。前面已经描述过如何合理设置【业务场景可接受的方式，例如把 <code>conflicts</code> 设置为 <code>proceed</code>】，可以确保在发生 <code>conflict</code> 的时候还能继续运行。但是，这样设置后任务不会被 <code>abort</code>，可以正常执行完成，则最终也就不会返回 <code>failures</code> 信息了，但是通过 <code>version_conflicts</code> 指标可以看到具体的数量。</p><h2 id="查看任务进度以及取消任务"><a href="# 查看任务进度以及取消任务" class="headerlink" title="查看任务进度以及取消任务"></a>查看任务进度以及取消任务 </h2><p> 一般来说，如果我们的 <code>source index</code> 很大【比如几百万数据量】，则可能需要比较长的时间来完成 <code>_reindex</code> 的工作，可能需要几十分钟。而在此期间不可能一直等待结果返回，可以去做其它事情，如果中途需要查看进度，可以通过 <code>_tasks API</code> 进行查看。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET _tasks?detailed=true&amp;actions=*reindex</span><br></pre></td></tr></table></figure><p>返回结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;nodes&quot;: &#123;</span><br><span class="line">    &quot;ietwyYpJRo-gz_C1tCbpgQ&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: &quot;dev4_xx&quot;,</span><br><span class="line">      &quot;transport_address&quot;: &quot;xx.xx.xx.204:9308&quot;,</span><br><span class="line">      &quot;host&quot;: &quot;xx.xx.xx.204&quot;,</span><br><span class="line">      &quot;ip&quot;: &quot;xx.xx.xx.204:9308&quot;,</span><br><span class="line">      &quot;roles&quot;: [</span><br><span class="line">        &quot;master&quot;,</span><br><span class="line">        &quot;data&quot;,</span><br><span class="line">        &quot;ingest&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;tasks&quot;: &#123;</span><br><span class="line">        &quot;ietwyYpJRo-gz_C1tCbpgQ:420711&quot;: &#123;</span><br><span class="line">          &quot;node&quot;: &quot;ietwyYpJRo-gz_C1tCbpgQ&quot;,</span><br><span class="line">          &quot;id&quot;: 420711,</span><br><span class="line">          &quot;type&quot;: &quot;transport&quot;,</span><br><span class="line">          &quot;action&quot;: &quot;indices:data/write/reindex&quot;,</span><br><span class="line">          &quot;status&quot;: &#123;</span><br><span class="line">            &quot;total&quot;: 12505,</span><br><span class="line">            &quot;updated&quot;: 0,</span><br><span class="line">            &quot;created&quot;: 0,</span><br><span class="line">            &quot;deleted&quot;: 0,</span><br><span class="line">            &quot;batches&quot;: 5,</span><br><span class="line">            &quot;version_conflicts&quot;: 4000,</span><br><span class="line">            &quot;noops&quot;: 0,</span><br><span class="line">            &quot;retries&quot;: &#123;</span><br><span class="line">              &quot;bulk&quot;: 0,</span><br><span class="line">              &quot;search&quot;: 0</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;throttled_millis&quot;: 0,</span><br><span class="line">            &quot;requests_per_second&quot;: -1,</span><br><span class="line">            &quot;throttled_until_millis&quot;: 0</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;description&quot;: &quot;reindex from [my-index-user] to [my-index-user-v2]&quot;,</span><br><span class="line">          &quot;start_time_in_millis&quot;: 1580958992770,</span><br><span class="line">          &quot;running_time_in_nanos&quot;: 1441736539,</span><br><span class="line">          &quot;cancellable&quot;: true</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200206113250.png" alt="查看任务状态" title="查看任务状态"></p><p>根据任务的各项指标，就可以预估完成进度，从而预估完成时间，做到心中有数。</p><p>注意观察里面的几个重要指标，例如从 <code>description</code> 中可以看到任务描述，从 <code>tasks</code> 中可以找到任务的 <code>id</code>【例如 <code>ietwyYpJRo-gz_C1tCbpgQ:420711</code>】，从 <code>cancellable</code> 可以判断任务是否支持取消操作。</p><p>这个 <code>API</code> 其实就是模糊匹配，同理也可以查询其它类型的任务信息，例如使用 <code>GET _tasks?detailed=true&amp;actions=*byquery</code> 查看查询请求的状态。</p><p>如果知道了 <code>task_id</code>，也可以使用 <code>GET /_tasks/task_id</code> 更加准确地查询指定的任务状态，避免集群的任务过多，不方便查看。</p><p>如果遇到操作失误的场景，想取消任务，有没有办法呢？有，泼出去的水还是可以收回的，通过 <code>_tasks API</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _tasks/task_id/_cancel</span><br></pre></td></tr></table></figure><p>这里的 <code>task_id</code> 就是通过上面的查询任务接口获取的，另外还需要任务支持取消操作【<code>cancellable</code> 为 <code>true</code>】。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 参考官网：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-reindex.html" target="_blank" rel="noopener">docs-reindex</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase 错误之 ConnectionLoss for hbase-unsecure</title>
    <url>/2019092901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在当前的业务中，需要连接 <code>HBase</code> 获取数据，但是最近在某一台节点上面的进程总是出现连接异常，类似下面：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-09-20_18:54:44 [http-nio-28956-exec-5] WARN zookeeper.ZKUtil:629: hconnection-0x8a9f6680x0, quorum=host1:2181,host10:2181,host11:2181,host61:2181,host62:2181, baseZNode=/hbase-unsecure Unable to get data of znode /hbase-unsecure/meta-region-server</span><br><span class="line">org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase-unsecure/meta-region-server</span><br><span class="line">	at org.apache.zookeeper.KeeperException.create (KeeperException.java:99)</span><br></pre></td></tr></table></figure><p>看起来是连接超时，然后重试，日志中持续了多次。本文开发环境基于 <code>HBase v1.1.2</code>、<code>Zookeeper v3.4.6</code>、<code>Hadoop v2.7.1</code>。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 一个正常的连接 <code>HBase</code> 取数的服务，在某个节点上出现大量的异常日志，无法连接到 <code>HBase</code>，一直在重试，同时观察到在其它节点上相同的服务却是正常的。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-09-20_18:54:44 [http-nio-28956-exec-5] ERROR zookeeper.RecoverableZooKeeper:277: ZooKeeper getData failed after 4 attempts</span><br><span class="line">2019-09-20_18:54:44 [http-nio-28956-exec-5] WARN zookeeper.ZKUtil:629: hconnection-0x8a9f6680x0, quorum=host1:2181,host10:2181,host11:2181,host61:2181,host62:2181, baseZNode=/hbase-unsecure Unable to get data of znode /hbase-unsecure/meta-region-server</span><br><span class="line">org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase-unsecure/meta-region-server</span><br><span class="line">	at org.apache.zookeeper.KeeperException.create (KeeperException.java:99)</span><br><span class="line">	at org.apache.zookeeper.KeeperException.create (KeeperException.java:51)</span><br><span class="line">	at org.apache.zookeeper.ZooKeeper.getData (ZooKeeper.java:1155)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData (RecoverableZooKeeper.java:359)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData (ZKUtil.java:621)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState (MetaTableLocator.java:481)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation (MetaTableLocator.java:167)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:598)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:579)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:558)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation (ZooKeeperRegistry.java:61)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta (ConnectionManager.java:1192)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1159)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations (RpcRetryingCallerWithReadReplicas.java:300)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call (ScannerCallableWithReplicas.java:152)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call (ScannerCallableWithReplicas.java:60)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries (RpcRetryingCaller.java:200)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientSmallReversedScanner.loadCache (ClientSmallReversedScanner.java:211)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientSmallReversedScanner.next (ClientSmallReversedScanner.java:185)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta (ConnectionManager.java:1256)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1162)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1146)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1103)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getRegionLocation (ConnectionManager.java:938)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HRegionLocator.getRegionLocation (HRegionLocator.java:83)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare (RegionServerCallable.java:79)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries (RpcRetryingCaller.java:124)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:889)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:855)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:908)</span><br><span class="line">	at com.xxx.yyy.commons.search.reader.hbase.BaseHBaseReader.batchGet (BaseHBaseReader.java:94)</span><br><span class="line">	at com.xxx.yyy.commons.search.searcher.AbstractBaseSearcher.getContent (AbstractBaseSearcher.java:269)</span><br><span class="line">	at com.xxx.yyy.commons.search.searcher.AbstractBaseSearcher.getInfo (AbstractBaseSearcher.java:194)</span><br><span class="line">	at com.xxx.yyy.runner.search.BaseSearchRunner.combinaSearch (BaseSearchRunner.java:139)</span><br><span class="line">	at com.xxx.yyy.api.newsforum.NewsForumPostServiceImpl.combinaSearch (NewsForumPostServiceImpl.java:53)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.Wrapper9.invokeMethod (Wrapper9.java)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke (JavassistProxyFactory.java:46)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke (AbstractProxyInvoker.java:72)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke (InvokerWrapper.java:53)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke (ExceptionFilter.java:64)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke (MonitorFilter.java:75)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke (TimeoutFilter.java:42)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke (TraceFilter.java:78)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke (ContextFilter.java:70)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke (GenericFilter.java:132)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke (ClassLoaderFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke (EchoFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke (InvokerInvocationHandler.java:52)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.proxy4.combinaSearch (proxy4.java)</span><br><span class="line">	at sun.reflect.GeneratedMethodAccessor87.invoke (Unknown Source)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">	at org.jboss.resteasy.core.MethodInjectorImpl.invoke (MethodInjectorImpl.java:137)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget (ResourceMethodInvoker.java:288)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:242)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:229)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:356)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:179)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service (ServletContainerDispatcher.java:220)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:56)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:51)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.rest.DubboHttpServer$RestHandler.handle (DubboHttpServer.java:86)</span><br><span class="line">	at com.alibaba.dubbo.remoting.http.servlet.DispatcherServlet.service (DispatcherServlet.java:64)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter (ApplicationFilterChain.java:291)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.doFilter (ApplicationFilterChain.java:206)</span><br><span class="line">	at org.apache.catalina.core.StandardWrapperValve.invoke (StandardWrapperValve.java:219)</span><br><span class="line">	at org.apache.catalina.core.StandardContextValve.invoke (StandardContextValve.java:106)</span><br><span class="line">	at org.apache.catalina.authenticator.AuthenticatorBase.invoke (AuthenticatorBase.java:504)</span><br><span class="line">	at org.apache.catalina.core.StandardHostValve.invoke (StandardHostValve.java:142)</span><br><span class="line">	at org.apache.catalina.valves.ErrorReportValve.invoke (ErrorReportValve.java:79)</span><br><span class="line">	at org.apache.catalina.core.StandardEngineValve.invoke (StandardEngineValve.java:88)</span><br><span class="line">	at org.apache.catalina.connector.CoyoteAdapter.service (CoyoteAdapter.java:534)</span><br><span class="line">	at org.apache.coyote.http11.AbstractHttp11Processor.process (AbstractHttp11Processor.java:1081)</span><br><span class="line">	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process (AbstractProtocol.java:658)</span><br><span class="line">	at org.apache.coyote.http11.Http11NioProtocol$Http11ConnectionHandler.process (Http11NioProtocol.java:222)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun (NioEndpoint.java:1566)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run (NioEndpoint.java:1523)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run (TaskThread.java:61)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">2019-09-20_18:54:45 [http-nio-28956-exec-5] ERROR zookeeper.ZooKeeperWatcher:655: hconnection-0x8a9f6680x0, quorum=host1:2181,host10:2181,host11:2181,host61:2181,host62:2181, baseZNode=/hbase-unsecure Received unexpected KeeperException, re-throwing exception</span><br><span class="line">org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase-unsecure/meta-region-server</span><br><span class="line">	at org.apache.zookeeper.KeeperException.create (KeeperException.java:99)</span><br><span class="line">	at org.apache.zookeeper.KeeperException.create (KeeperException.java:51)</span><br><span class="line">	at org.apache.zookeeper.ZooKeeper.getData (ZooKeeper.java:1155)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData (RecoverableZooKeeper.java:359)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData (ZKUtil.java:621)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState (MetaTableLocator.java:481)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation (MetaTableLocator.java:167)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:598)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:579)</span><br><span class="line">	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable (MetaTableLocator.java:558)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation (ZooKeeperRegistry.java:61)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta (ConnectionManager.java:1192)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1159)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations (RpcRetryingCallerWithReadReplicas.java:300)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call (ScannerCallableWithReplicas.java:152)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call (ScannerCallableWithReplicas.java:60)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries (RpcRetryingCaller.java:200)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientSmallReversedScanner.loadCache (ClientSmallReversedScanner.java:211)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ClientSmallReversedScanner.next (ClientSmallReversedScanner.java:185)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta (ConnectionManager.java:1256)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1162)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1146)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion (ConnectionManager.java:1103)</span><br><span class="line">	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getRegionLocation (ConnectionManager.java:938)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HRegionLocator.getRegionLocation (HRegionLocator.java:83)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare (RegionServerCallable.java:79)</span><br><span class="line">	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries (RpcRetryingCaller.java:124)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:889)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:855)</span><br><span class="line">	at org.apache.hadoop.hbase.client.HTable.get (HTable.java:908)</span><br><span class="line">	at com.xxx.yyy.commons.search.reader.hbase.BaseHBaseReader.batchGet (BaseHBaseReader.java:94)</span><br><span class="line">	at com.xxx.yyy.commons.search.searcher.AbstractBaseSearcher.getContent (AbstractBaseSearcher.java:269)</span><br><span class="line">	at com.xxx.yyy.commons.search.searcher.AbstractBaseSearcher.getInfo (AbstractBaseSearcher.java:194)</span><br><span class="line">	at com.xxx.yyy.runner.search.BaseSearchRunner.combinaSearch (BaseSearchRunner.java:139)</span><br><span class="line">	at com.xxx.yyy.api.newsforum.NewsForumPostServiceImpl.combinaSearch (NewsForumPostServiceImpl.java:53)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.Wrapper9.invokeMethod (Wrapper9.java)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke (JavassistProxyFactory.java:46)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke (AbstractProxyInvoker.java:72)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke (InvokerWrapper.java:53)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke (ExceptionFilter.java:64)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke (MonitorFilter.java:75)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke (TimeoutFilter.java:42)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke (TraceFilter.java:78)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke (ContextFilter.java:70)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke (GenericFilter.java:132)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke (ClassLoaderFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke (EchoFilter.java:38)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke (ProtocolFilterWrapper.java:91)</span><br><span class="line">	at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke (InvokerInvocationHandler.java:52)</span><br><span class="line">	at com.alibaba.dubbo.common.bytecode.proxy4.combinaSearch (proxy4.java)</span><br><span class="line">	at sun.reflect.GeneratedMethodAccessor87.invoke (Unknown Source)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">	at org.jboss.resteasy.core.MethodInjectorImpl.invoke (MethodInjectorImpl.java:137)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget (ResourceMethodInvoker.java:288)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:242)</span><br><span class="line">	at org.jboss.resteasy.core.ResourceMethodInvoker.invoke (ResourceMethodInvoker.java:229)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:356)</span><br><span class="line">	at org.jboss.resteasy.core.SynchronousDispatcher.invoke (SynchronousDispatcher.java:179)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service (ServletContainerDispatcher.java:220)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:56)</span><br><span class="line">	at org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service (HttpServletDispatcher.java:51)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at com.alibaba.dubbo.rpc.protocol.rest.DubboHttpServer$RestHandler.handle (DubboHttpServer.java:86)</span><br><span class="line">	at com.alibaba.dubbo.remoting.http.servlet.DispatcherServlet.service (DispatcherServlet.java:64)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:790)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter (ApplicationFilterChain.java:291)</span><br><span class="line">	at org.apache.catalina.core.ApplicationFilterChain.doFilter (ApplicationFilterChain.java:206)</span><br><span class="line">	at org.apache.catalina.core.StandardWrapperValve.invoke (StandardWrapperValve.java:219)</span><br><span class="line">	at org.apache.catalina.core.StandardContextValve.invoke (StandardContextValve.java:106)</span><br><span class="line">	at org.apache.catalina.authenticator.AuthenticatorBase.invoke (AuthenticatorBase.java:504)</span><br><span class="line">	at org.apache.catalina.core.StandardHostValve.invoke (StandardHostValve.java:142)</span><br><span class="line">	at org.apache.catalina.valves.ErrorReportValve.invoke (ErrorReportValve.java:79)</span><br><span class="line">	at org.apache.catalina.core.StandardEngineValve.invoke (StandardEngineValve.java:88)</span><br><span class="line">	at org.apache.catalina.connector.CoyoteAdapter.service (CoyoteAdapter.java:534)</span><br><span class="line">	at org.apache.coyote.http11.AbstractHttp11Processor.process (AbstractHttp11Processor.java:1081)</span><br><span class="line">	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process (AbstractProtocol.java:658)</span><br><span class="line">	at org.apache.coyote.http11.Http11NioProtocol$Http11ConnectionHandler.process (Http11NioProtocol.java:222)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun (NioEndpoint.java:1566)</span><br><span class="line">	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run (NioEndpoint.java:1523)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)</span><br><span class="line">	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run (TaskThread.java:61)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">2019-09-20_18:54:45 [http-nio-28956-exec-10-SendThread (host1:2181)] INFO zookeeper.ClientCnxn:975: Opening socket connection to server host1/192.168.20.101:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">2019-09-20_18:54:45 [http-nio-28956-exec-10-SendThread (host1:2181)] INFO zookeeper.ClientCnxn:852: Socket connection established to host1/192.168.20.101:2181, initiating session</span><br><span class="line">2019-09-20_18:54:45 [http-nio-28956-exec-10-SendThread (host1:2181)] WARN zookeeper.ClientCnxn:1102: Session 0x0 for server host1/192.168.20.101:2181, unexpected error, closing socket connection and attempting reconnect</span><br><span class="line">java.io.IOException: Connection reset by peer</span><br><span class="line">	at sun.nio.ch.FileDispatcherImpl.read0 (Native Method)</span><br><span class="line">	at sun.nio.ch.SocketDispatcher.read (SocketDispatcher.java:39)</span><br><span class="line">	at sun.nio.ch.IOUtil.readIntoNativeBuffer (IOUtil.java:223)</span><br><span class="line">	at sun.nio.ch.IOUtil.read (IOUtil.java:192)</span><br><span class="line">	at sun.nio.ch.SocketChannelImpl.read (SocketChannelImpl.java:380)</span><br><span class="line">	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO (ClientCnxnSocketNIO.java:68)</span><br><span class="line">	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport (ClientCnxnSocketNIO.java:366)</span><br><span class="line">	at org.apache.zookeeper.ClientCnxn$SendThread.run (ClientCnxn.java:1081)</span><br></pre></td></tr></table></figure><p>注意查看重点内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-09-20_18:54:44 [http-nio-28956-exec-5] ERROR zookeeper.RecoverableZooKeeper:277: ZooKeeper getData failed after 4 attempts</span><br><span class="line">2019-09-20_18:54:44 [http-nio-28956-exec-5] WARN zookeeper.ZKUtil:629: hconnection-0x8a9f6680x0, quorum=host1:2181,host10:2181,host11:2181,host61:2181,host62:2181, baseZNode=/hbase-unsecure Unable to get data of znode /hbase-unsecure/meta-region-server</span><br><span class="line">org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase-unsecure/meta-region-server</span><br><span class="line">...</span><br><span class="line">2019-09-20_18:54:45 [http-nio-28956-exec-10-SendThread (host1:2181)] WARN zookeeper.ClientCnxn:1102: Session 0x0 for server host1/192.168.20.101:2181, unexpected error, closing socket connection and attempting reconnect</span><br></pre></td></tr></table></figure><p>看起来是当前节点网络有问题，或者 <code>Zookeeper</code> 连接资源紧张。</p><p>与此同时，还有大量类似下面这种连接重试出现：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-09-30_00:24:56 [http-nio-28956-exec-8-SendThread (alps61:2181)] INFO zookeeper.ClientCnxn:1098: Unable to read additional data from server sessionid 0x16af866e055f894, likely server has closed socket, closing socket connection and </span><br><span class="line">attempting reconnect</span><br><span class="line">2019-09-30_00:24:56 [http-nio-28956-exec-2-SendThread (alps61:2181)] INFO zookeeper.ClientCnxn:1098: Unable to read additional data from server sessionid 0x16af866e040a3c2, likely server has closed socket, closing socket connection and </span><br><span class="line">attempting reconnect</span><br><span class="line">2019-09-30_00:24:56 [http-nio-28956-exec-8-SendThread (alps61:2181)] INFO zookeeper.ClientCnxn:1098: Unable to read additional data from server sessionid 0x16af866e040a720, likely server has closed socket, closing socket connection and </span><br><span class="line">attempting reconnect</span><br><span class="line">2019-09-30_00:24:56 [http-nio-28956-exec-6-SendThread (alps61:2181)] INFO zookeeper.ClientCnxn:1098: Unable to read additional data from server sessionid 0x46d5ce1483b88cf, likely server has closed socket, closing socket connection and </span><br><span class="line">attempting reconnect</span><br><span class="line">2019-09-30_00:24:56 [http-nio-28956-exec-2-SendThread (alps61:2181)] INFO zookeeper.ClientCnxn:1098: Unable to read additional data from server sessionid 0x16af866e040a349, likely server has closed socket, closing socket connection and </span><br><span class="line">attempting reconnect</span><br><span class="line">2019-09-30_00:24:56 [http-nio-28956-exec-6-SendThread (alps61:2181)] INFO zookeeper.ClientCnxn:1098: Unable to read additional data from server sessionid 0x16af866e03f75aa, likely server has closed socket, closing socket connection and </span><br><span class="line">attempting reconnect</span><br><span class="line">2019-09-30_00:24:56 [http-nio-28956-exec-4-SendThread (alps61:2181)] INFO zookeeper.ClientCnxn:1098: Unable to read additional data from server sessionid 0x16af866e040a8f0, likely server has closed socket, closing socket connection and </span><br><span class="line">attempting reconnect</span><br></pre></td></tr></table></figure><p>其实就是有进程在占用过多的 <code>Zookeeper</code> 连接，导致 <code>Zookeeper</code> 的 <code>Server</code> 端拒绝响应。</p><h1 id="问题排查"><a href="# 问题排查" class="headerlink" title="问题排查"></a>问题排查 </h1><p> 由于没有 <code>root</code> 权限，只能请运维帮忙排查，通过排查，发现当前主机创建的 <code>Zookeeper</code> 连接数过多，超过了设置的最大值。</p><p>使用 <code>netstat -antp | grep 2181 | wc -l</code> 命令，注意需要 <code>root</code> 用户的权限。这个命令统计的是所有 <code>Zookeeper</code> 连接【通过使用 2181 端口过滤】，包含等待的和正在通信的，如果查看正在通信的，加上一个 <code>grep ESTABLISHED</code> 过滤即可。</p><p>当然，如果机器开放了部分可以使用高级用户执行的命令【例如使用 <code>root</code> 用户执行 <code>pwdx</code>】，则更方便查看，操作时指定用户即可，例如：<code>sudo -u root netstat -antp | grep 2181 | wc -l</code>，可以查看端口 2181 占用的情况。</p><p>局部截图如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190930214400.png" alt="zk 连接进程查看" title="zk 连接进程查看"></p><p>由于直接发现了问题，所以也不用进一步查看 <code>Zookeeper</code> 的日志了。</p><p>至于为什么 <code>Zookeeper</code> 的连接数会这么多，罪魁祸首请读者参考我的另外一篇博客：<br><a href="https://www.playpi.org/2019093001.html">HBase 错误之 NoClassDefFoundError：ProtobufUtil</a> 。</p><p>由于当前节点创建的 <code>Zookeeper</code> 连接数过多，所以再创建新连接时无法顺利连接通信，一直等待重试。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 问题排查出来，解决就简单了，直接找到问题程序，修复资源泄漏问题，然后重启，保证合理的 <code>Zookeeper</code> 连接数量，不要因为某一个程序的失误而影响到其它业务。</p><p>另外如果有必要查看 <code>Zookeeper</code> 日志，需要特别留意 <code>Zookeeper</code> 查看日志的方法，日志文件是不能被直接打开的，需要工具转换为文本日志，然后才能查看分析。</p><p>关于 <code>Zookeeper</code> 日志的转换查看方法，可以参考我的另外一篇博客内容：<a href="https://www.playpi.org/2019092001.html">Zookeeper - 日志查看</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HBase</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 博客集成 travis-ci 自动化测试发布</title>
    <url>/2018100201.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>我的博客一开始是搭建在阿里云上面的，购买了一台 <code>VPS</code>，然后在上面部署了 <code>Git</code> 仓库服务、<code>Nginx</code> 服务，同时也购买了一个域名。每次在本地写完博客，<strong>generate</strong> 后，直接使用 <code>Hexo</code> 自带的 <strong>deploy</strong> 命令把内容发布，同时在服务端的 <code>Git</code> 里面再设置一个 <code>WebHook</code>，触发自动拉取更新到 <code>Nginx</code> 项目目录的操作。这样，只要安心在本地写博客就行，写完就 <strong>generate、deploy</strong> 两下，看似很完美。</p><p>然而，使用了几个月就发现了各种麻烦事，例如：<code>VPS</code> 流量不够【恶意攻击或者爬虫】、<code>VPS</code> 服务不稳定【怀疑是被恶意攻击】、每次都要在本地生成【<strong>generate</strong> 命令】、两台电脑的环境配置不一致导致的兼容性问题、博客的整个管理还是略显繁琐。于是，我思考了好几天，并查看了别的成熟案例，最终决定使用 <code>GitHub</code>、<code>travis-ci</code> 搭配，完全的自动化测试部署，本地只负责写 <code>Markdown</code> 文档。这种方案才是真的简约、安全、方便。</p><a id="more"></a><h1 id="前提"><a href="# 前提" class="headerlink" title="前提"></a>前提 </h1><h2 id="开源项目"><a href="# 开源项目" class="headerlink" title="开源项目"></a> 开源项目 </h2><p> 首先说一下大前提，由于使用的所有工具、服务都是免费的，会暴露项目的信息、配置文件、日志信息，也就是说在 <code>GitHub</code> 中的项目类型要设置为 <code>public</code> 类型，使用 <code>travis-ci</code> 也要使用免费版本的【域名是 <code>org</code> 后缀的，不是 <code>com</code> 后缀的】。</p><p>把本地的项目提交到 <code>GitHub</code> 上面去，所以需要在 <code>GitHub</code> 上面新建一个空白项目，用来对接本地的项目。这里需要注意，为了使用 <code>GitHub Pages</code> 提供的独立子域名【<a href="https://username.github.io" target="_blank" rel="noopener">https://username.github.io</a> 】，需要把项目名称设置为 <strong>username.github.io</strong> 格式的。当然，任意项目名称命名的项目都可以作为 <code>GitHub Pages</code>，可以在 <code>GitHub</code> 的域名后面指定项目名称访问，但是不能使用独立子域名访问。</p><p>关于这个项目的分支管理，就比较独特了，因为源代码可以说只有配置文件、<code>Markdown</code> 文本文件，而经过 <code>Hexo</code> 编译生成文件基本全部是 <code>HTML</code> 文件。为了方便管理，这两种文件不要放在一起。所以可以用 <strong>matser</strong> 分支存放 <code>Hexo</code> 编译生成 <code>HTML</code> 文件，给 <code>GitHub Pages</code> 使用；而重新建立一个 <strong>source</strong> 分支【可以设置为孤儿分支，<code>orphan</code>】用来存放配置文件、<code>Markdown</code> 文本文件，用来更改、提交博客内容。这两个分支是完全没有关联的，不需要合并，他们存放的是完全不同类型的文件。</p><p>总结一下，对于 <code>GitHub</code> 中的项目，命名最好遵循 <strong>username.github.io</strong> 这样的格式，方便 <code>GitHub Pages</code> 分配独立的子域名，设置两个分支：<code>master</code>、<code>source</code>。其中，<code>master</code> 分支用来给 <code>travis-ci</code> 提交编译生成的 <code>HTML</code> 文件，可以通过 <code>GitHub Pages</code> 访问；<code>source</code> 分支用来本地提交写博客内容的 <code>Markdown</code> 文件，同时也给 <code>travis-ci</code> 监控，用来获取最新的博客并生成 <code>HTML</code> 文件提交到 <code>master</code> 分支。</p><p>为了直观起见，下面画一个流程图，清晰地表现出 <code>GitHub</code> 项目的设置：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001757.png" alt="画一个流程图" title="画一个流程图"></p><h2 id="子模块管理"><a href="# 子模块管理" class="headerlink" title="子模块管理"></a>子模块管理 </h2><p> 此外，还需要特别注意主题对应的项目，因为在 <code>Hexo</code> 项目中，主题是独立的项目，存放在 <code>themes</code> 文件夹内，例如默认的 <strong>landscape</strong> 主题。由于是独立的项目，而且是嵌套在 <code>Hexo</code> 中的，对于 <code>Git</code> 来说它属于子模块【<code>submodule</code>】，所以在对接 <code>GitHub</code> 时会遇到一些子模块的问题。具体如何解决我在这里不赘述，可以自行搜索解决方案，但是我要提出必要的思路：</p><p>一、由于主题子模块默认是在 <code>GitHub</code> 上 <code>clone</code> 下来的，而为了优化显示，我们一定会更改配置文件以及源代码，所以此时一定要解除主题与原来官方 <code>GitHub</code> 仓库的关系，转而把它连接到自己的 <code>GitHub</code> 仓库中。这样自己维护主题配置，避免更新时被官方的空白配置覆盖掉，当然，这样做就失去了与原来官方 <code>GitHub</code> 仓库的联系，导致不能及时获取更新【优化升级、<code>bug</code> 修复等】。</p><p>二、针对一中的情况，最好的做法是先在自己的仓库中 <code>Fork</code> 一份官方的主题源代码，然后在 <code>Hexo</code> 中的主题文件夹中使用自己 <code>Fork</code> 的主题源代码，这样既可以自己维护主题的配置，也能及时从官方拉取更新。此处会用到 <strong>git submodule init</strong>、<strong>git submodule update</strong> 等命令。</p><p>三、还有一种最简单但是不合理的做法，直接取消主题的 <code>Git</code> 项目属性，即把 <code>Git</code> 相关的配置删除，这样主题项目就不是 <code>Hexo</code> 的子模块了，只是一个普通的文件夹，可以随意更改，并且仅仅作为 <code>Hexo</code> 的一个子文件夹而已，永远不会更新。</p><h1 id="持续集成"><a href="# 持续集成" class="headerlink" title="持续集成"></a>持续集成 </h1><p><code>travis-ci</code> 是一种持续集成的工具，持续集成【<code>Continuous Integration</code>】简称为 <code>CI</code>，当然类似的工具有好几种，例如：<code>Jenkins</code>、<code>GitLab CI</code>、<code>Go CD</code> 等，这里就不再赘述。这种工具可以提供一个持续集成功能的平台，在平台上面为你的项目配置好需要执行的操作，例如测试、编译、打包、部署等，这些配置都会有特定的方言规则，不同工具之间大同小异。此外，<code>travis-ci</code> 有两种版本，一种是收费的版本，网址为：<a href="https://travis-ci.com" target="_blank" rel="noopener">https://travis-ci.com</a> ，还有一种是免费的版本，网址为：<a href="https://travis-ci.org" target="_blank" rel="noopener">https://travis-ci.org</a> ，我使用的是免费的版本。</p><p> 那么，使用这种持续集成的工具有什么好处呢？下面就会一一列举，当然，只是看解释说明可能无法感受，所以可以亲手测试一下各种场景，或者等完全部署完成之后再回头看它的好处。</p><h2 id="优点一修改可以立即生效"><a href="# 优点一修改可以立即生效" class="headerlink" title="优点一修改可以立即生效"></a>优点一修改可以立即生效 </h2><p> 例如你几天前发表了一篇博客，过了几天你发现里面竟然有错别字或者概念性的歧义，为了保证博客的质量，这个最好及时修复。如果自己的电脑在身边还可以操作，直接 <strong>修改文件、generate、deploy</strong> 即可，但是如果只有一台普通的电脑，里面没有 <code>Git</code>、<code>Hexo</code>、<code>Node.js</code> 等环境，这个就很麻烦，恐怕装开发环境就要很久。</p><p>但是使用了 <code>travis-ci</code> 之后，这些和环境有关的操作都是它自动化完成的，你只要负责修改文件、提交更新到 <code>GitHub</code> 即可。你可以在本地只安装 <code>Git</code> 环境，<code>clone</code> 代码之后修改完再提交，当然更简单的是直接使用浏览器登录 <code>GitHub</code> 网站，在线直接修改文件提交。提交之后，会自动触发 <code>travis-ci</code> 的工作流程，编译、生成、部署等步骤全部由 <code>travis-ci</code> 自动完成，真的是解放了双手。</p><h2 id="优点二自动部署到多个远程仓库"><a href="# 优点二自动部署到多个远程仓库" class="headerlink" title="优点二自动部署到多个远程仓库"></a>优点二自动部署到多个远程仓库 </h2><p> 这个优点在 <code>Hexo</code> 自带的 <code>deploy</code> 功能中也有，可以把最新的代码同步到 <code>GitHub</code> 以外的远程仓库。有的人觉得在中国大陆 <code>GitHub</code> 的访问速度比较慢，就想着多部署几个站点，例如 <code>Gitcafe</code>、码云等，很简单，在 <code>travis-ci</code> 的脚本中多配置几行命令脚本即可，完全是自定义。</p><h2 id="优点三部署快捷方便"><a href="# 优点三部署快捷方便" class="headerlink" title="优点三部署快捷方便"></a>优点三部署快捷方便 </h2><p> 当后期博客项目过大的时候，会需要一些自定义的优化点，例如搜索、字数统计、文件压缩等，这些特性都需要插件的支持，所以会安装很多插件，同时生成的静态文件也会越来越多。如果按照传统的手动管理方式，每次都需要提交大量的文件更新到远程仓库，耗时长而且没有必要，但是使用 <code>travis-ci</code> 之后，只需要提交 <code>Markdown</code> 文件的变更，其它的大量文件都交给 <code>travis-ci</code> 去生成，这样一来速度就很快了，时间消耗都转移到 <code>travis-ci</code> 上面去了。</p><h2 id="优点四显示构建图标"><a href="# 优点四显示构建图标" class="headerlink" title="优点四显示构建图标"></a>优点四显示构建图标 </h2><p> 对接 <code>travis-ci</code> 后，可以在 <code>README</code> 文件里显示持续集成工具构建结果的图标，是失败还是成功就很形象了。</p><h2 id="其它优点"><a href="# 其它优点" class="headerlink" title="其它优点"></a>其它优点 </h2><p>1、通过设置失败邮件提醒，在构建失败时会发送邮件通知。</p><p>2、如果设置了优点四中的构建图标，可以在 <code>GitHub</code> 的项目中，直接点击图标，然后会自动跳转到 <code>travis-ci</code> 的构建页面，可以查看构建日志、历史记录、项目配置等信息。</p><p>3、此外还可以配置自动化测试、构建成功才继续部署等选择项。</p><h1 id="配置详解"><a href="# 配置详解" class="headerlink" title="配置详解"></a> 配置详解 </h1><h2 id="登录持续集成帐号"><a href="# 登录持续集成帐号" class="headerlink" title="登录持续集成帐号"></a> 登录持续集成帐号 </h2><p> 打开官方网站：<a href="https://travis-ci.org" target="_blank" rel="noopener">https://travis-ci.org</a> ，登录帐号，注意不需要注册，一定要使用 <code>GitHub</code> 帐号授权的方式登录，只有这样 <code>travis-ci</code> 才能获取到 <code>GitHub</code> 上面的项目信息，进而进行管理。</p><h2 id="开启项目管理权限"><a href="# 开启项目管理权限" class="headerlink" title="开启项目管理权限"></a>开启项目管理权限 </h2><p> 在 <code>Settings</code>、<code>Repositories</code> 中可以看到自己在 <code>GitHub</code> 上面的项目列表，但是 <code>travis-ci</code> 默认是不会管理任何一个项目的，需要手动开启。由于只需要监控我的博客项目，所以只是开启这一个，然后在开启按钮的右边点击设置按钮，进行下一步的设置。</p><p>开启管理权限。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001740.png" alt="开启管理权限" title="开启管理权限"></p><p>进入到具体项目的设置页面，在这里，需要勾选 <strong>General</strong> 下面的 <strong>Build pushed branches</strong>、<strong>Build pushed pull requests</strong>，这两个选项的意思是当 <code>GitHub</code> 的项目有 <strong>push</strong> 操作时，则 <code>travis-ci</code> 会执行配置的流程。</p><p>设置 <code>General</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001733.png" alt="设置 General" title="设置 General"></p><p>再看下面的 <strong>Auto Cancellation</strong>，需要勾选 <strong>Auto cacel branch builds</strong>、<strong>Auto cancel pull request builds</strong>，这两个选项的意思是自动取消构建过程，主要用于当有连续多个 <code>push</code>、<code>push pull request</code> 发生时，可能先后间隔很短时间内触发了多次构建操作，这样显然浪费资源，没必要构建中间的 <code>push</code>，所以构建排队队列中的任务会自动取消，只保留最新的 <code>push</code> 触发的构建作业。当然，前提是必须等待正在运行的构建作业完成。</p><p>设置 <code>Auto Cancellation</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001725.png" alt="设置 Auto Cancellation" title="设置 Auto Cancellation"></p><h2 id="按需设置环境变量"><a href="# 按需设置环境变量" class="headerlink" title="按需设置环境变量"></a>按需设置环境变量 </h2><p> 在设置中的 <strong>Environment Variables</strong> 里面，可以指定一些环境变量【其实就是全局变量】，这些变量可以在后面的构建脚本中直接使用。那么为什么要这么设置呢，有必要吗？</p><p>其实，一是为了安全，如果直接在构建脚本中使用字符串的形式暴露出来，势必会泄漏个人信息，例如在 <code>GitHub</code> 申请的 <code>TOKEN</code>、邮箱、用户名，这些信息肯定不能泄漏；二是为了方便，设置了全局变量，在构建脚本中直接引用，简化脚本内容，而且以后如果有更改，直接来到 <code>travis-ci</code> 更改环境变量即可，不需要更改构建脚本。因此，这些信息的设置是很有必要的。</p><p>当然，也不用在这里设置太多信息，有一些不重要的信息直接在构建脚本中使用字符串设置变量即可【构建方言规则里面有 <code>env</code>、<code>global</code> 可以设置只在脚本中有效的全局变量】。</p><p>我在这里设置了四个全局变量：<code>REPO_TOKEN</code>、<code>GITHUB_URL</code>、<code>USER_EMAIL</code>、<code>USER_NAME</code>，其中 <code>REPO_TOKEN</code> 是在 <code>GitHub</code> 中生成的访问验证信息，下面会讲怎么生成。</p><p>设置 <code>Environment Variables</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001706.png" alt="设置 Environment Variables" title="设置 Environment Variables"></p><p>切记，不要勾选 <strong>Display value in build log</strong>，否则这些信息还是会在 <code>travis-ci</code> 的构建日志中显示出来，也就是暴露了。</p><h2 id="其它设置选项"><a href="# 其它设置选项" class="headerlink" title="其它设置选项"></a>其它设置选项 </h2><p> 还有一个名称为 <strong>Cron Jobs</strong> 的设置选项，这个设置就是开启定时任务，可以选择分支、周期、任务操作，如果你需要周期性地对 <code>GitHub</code> 项目进行操作就可以在这里配置。举个例子，如果你不要求你的博客的实时性，即不需要实时更新，可以不用设置上面的 <strong>General</strong>，直接在这里添加一个周期性任务，每天自动构建一次，这样你更新的博客内容要等一天才能更新到博客网站上面。</p><p>显然，如果为了保证实时性，这个选项是没有意义的，一般不需要开启。</p><p>至此，在 <code>travis-ci</code> 中的设置内容已经完成，<code>travis-ci</code> 已经在监控 <code>GitHub</code> 中的项目了，但是还有两件重要的事没做：生成验证信息、写自动构建脚本。</p><h2 id="生成项目的访问验证信息"><a href="# 生成项目的访问验证信息" class="headerlink" title="生成项目的访问验证信息"></a>生成项目的访问验证信息 </h2><p> 在设置环境变量的步骤中，用到了一个变量：<code>REPO_TOKEN</code>，这个是访问 <code>GitHub</code> 项目的验证信息，作用等同于用户名、密码，下面我们需要生成它。</p><p>在 <code>GitHub</code> 的个人设置中【不是单个项目的设置】，依次找到 <strong>Settings</strong>、<strong>Developer settings</strong>、<strong>Personal access tokens</strong>，这里面的内容就是开发者设置信息，可以生成一些隐私信息给开发者使用，方便程序直接调用接口，我也需要给 <code>travis-ci</code> 生成一个。</p><p>设置 <code>Personal access tokens</code>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001642.png" alt="设置 Personal access tokens" title="设置 Personal access tokens"></p><p>选择 <strong>Generate new token</strong> 按钮，为了安全，<code>GitHub</code> 还会要求验证一次密码，接着就进入到配置页面。在配置页面填写名称、权限即可，我这里只选择了 <strong>repo</strong> 权限，其它的目前没有必要。</p><p>注意，生成的 <code>TOKEN</code> 信息是一串字符串，<code>GitHub</code> 只会显示一次，所以要及时复制，刷新页面或者后续再回来查看是看不到的，只能重新申请。把这里生成的 <code>TOKEN</code> 作为设置环境变量步骤中的 <strong>REPO_TOKEN</strong> 的值即可，这样，在 <code>travis-ci</code> 构建脚本中就能访问 <code>GitHub</code> 从而进行 <code>push</code> 代码更新了。</p><p>生成 <code>token</code> 填写信息。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001556.png" alt="生成 token 填写信息" title="生成 token 填写信息"></p><h2 id="写自动构建脚本"><a href="# 写自动构建脚本" class="headerlink" title="写自动构建脚本"></a>写自动构建脚本 </h2><p> 在 <code>GitHub</code> 项目的 <code>source</code> 分支的根目录下，添加一个 <strong>.travis.yml</strong> 文件，这是 <code>travis-ci</code> 官方要求的，里面填写构建流程。这个配置文件已经被我上传至 <code>GitHub</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypi.github.io/tree/source" target="_blank" rel="noopener">.travis.yml</a> ，配置文件命名固定为：<code>.travis.yml</code>。</p><p>构建脚本内容的格式需要符合 <code>travis-ci</code> 的方言规范，里面也会用到上面设置的环境变量【只有具有脚本属性的内容才可以使用环境变量，其它不可以，例如邮件通知里面就不能使用环境变量】，获取环境变量的值使用 <strong>${环境变量名称}</strong> 格式，与使用 <code>Linux</code> 平台的环境变量格式一致，完整内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用语言为 Node.js</span><br><span class="line">language: node_js</span><br><span class="line"># Node.js 版本，Node 11.0.0 版本 yarn install 会报错不支持 </span><br><span class="line"># node_js: stable</span><br><span class="line">node_js: 10.10.0</span><br><span class="line"># 设置只监听哪个分支 </span><br><span class="line">branches:</span><br><span class="line">  only:</span><br><span class="line">  - source</span><br><span class="line"># 缓存，可以节省集成的时间，这里用了 yarn, 如果不用可以删除 </span><br><span class="line">cache:</span><br><span class="line">  apt: true</span><br><span class="line">  yarn: true</span><br><span class="line">  directories:</span><br><span class="line">    - node_modules</span><br><span class="line">    - CNAME</span><br><span class="line"># env</span><br><span class="line"># 全局变量，为了安全，不要在这里设置，我这里设置只是示例，其实没有用到 </span><br><span class="line">env:</span><br><span class="line"> global:</span><br><span class="line">   - GITHUB_XXX_URL: github.com/iplaypi/iplaypi.github.io.git</span><br><span class="line"># tarvis 生命周期执行顺序详见官网文档 </span><br><span class="line">before_install:</span><br><span class="line"># 更改时区 </span><br><span class="line">- export TZ=&apos;Asia/Shanghai&apos;</span><br><span class="line">- git config --global user.name $&#123;USER_NAME&#125;</span><br><span class="line">- git config --global user.email $&#123;USER_EMAIL&#125;</span><br><span class="line"># 由于使用了 yarn, 所以需要下载，不用 yarn 这两行可以删除 </span><br><span class="line">- curl -o- -L https://yarnpkg.com/install.sh | bash</span><br><span class="line">- export PATH=$HOME/.yarn/bin:$PATH</span><br><span class="line"># hexo 基础工具 </span><br><span class="line">- npm install -g hexo-cli</span><br><span class="line"># 初始化所需模块，在 package.json 中配置的有，这样 node_modules 就不用提交到 GitHub 了 </span><br><span class="line"># 下次如果换电脑，安装完 Node.js, 全局 (-g 参数) 安装完 hexo-cli, 直接在项目根目录初始化即可 (在 package.json 配置的都会自动下载)</span><br><span class="line">- npm install</span><br><span class="line"># 本地搜索需要工具 </span><br><span class="line">- npm install hexo-generator-searchdb --save</span><br><span class="line"># 字数统计，时长统计需要工具，Node 版本 7.6.0 之前，请安装 2.x 版本，npm install hexo-wordcount@2 --save</span><br><span class="line">- npm install hexo-wordcount --save</span><br><span class="line"># 站点地图，seo 优化使用 </span><br><span class="line">- npm install hexo-generator-sitemap --save</span><br><span class="line">- npm install hexo-generator-baidu-sitemap --save</span><br><span class="line"># 中英文之间自动增加空格插件 </span><br><span class="line"># - npm install hexo-filter-auto-spacing --save (这个人用的少，不用了)</span><br><span class="line">- npm install hexo-pangu-spacing --save</span><br><span class="line"># rss 订阅插件 </span><br><span class="line">- npm install hexo-generator-feed --save</span><br><span class="line"># 三维卡通人物 </span><br><span class="line">- npm install --save hexo-helper-live2d</span><br><span class="line"># 三维卡通人物 - 小猫咪模型下载 (保险起见，把模型文件放到自己的文件夹里，不用每次下载)</span><br><span class="line"># - npm install --save live2d-widget-model-hijiki</span><br><span class="line"># 压缩文件 </span><br><span class="line">- npm install hexo-neat --save</span><br><span class="line">install:</span><br><span class="line"># 不用 yarn 的话这里改成 npm i 即可 </span><br><span class="line">- yarn</span><br><span class="line"># script</span><br><span class="line"># 以后把主题发布到 GitHub 中，先从官方 Fork 再更新自定义的，这里还需要更新子模块内容，示例:git submodule init,git submodule update</span><br><span class="line"># 新建.gitmodules 文件，内容 </span><br><span class="line"># [submodule &quot;themes/next&quot;]</span><br><span class="line">#    path = themes/next</span><br><span class="line">#    url = git://github.com/xin053/MyHexo_NexT_Theme</span><br><span class="line"># 此外，还有那个评论系统的升级，Valine, 思考怎么做 </span><br><span class="line">script:</span><br><span class="line">- hexo clean</span><br><span class="line">- hexo generate</span><br><span class="line"># 成功之后才会提交，如果失败就会跳过并发送失败邮件通知 </span><br><span class="line">after_success:</span><br><span class="line"># 获取 master 分支内容 </span><br><span class="line">- git clone https://$&#123;GITHUB_URL&#125; .deploy_git</span><br><span class="line">- cd .deploy_git</span><br><span class="line">- git checkout master</span><br><span class="line">- cp -rf ../public/* ./</span><br><span class="line"># 必要配置文件 </span><br><span class="line">- cp -rf ../README.md ../.gitignore ../CNAME ../index.php ./</span><br><span class="line"># 更改 .gitignore 内容，与 source 分支的不一样，直接置空，目前没有需要过滤的 </span><br><span class="line">- echo &quot;&quot; &gt; ./.gitignore</span><br><span class="line">- git add .</span><br><span class="line"># 提交记录包含时间，跟上面更改时区配合 </span><br><span class="line">- git commit -m &quot;Travis CI Auto Builder at `date +&quot;% Y-% m-% d % H:% M&quot;`&quot;</span><br><span class="line"># 推送到主分支 </span><br><span class="line">- git push --force --quiet &quot;https://$&#123;REPO_TOKEN&#125;@$&#123;GITHUB_URL&#125;&quot; master:master</span><br><span class="line"></span><br><span class="line"># 邮件通知机制，我在这里设置了成功 / 失败都会通知，这里不能使用环境变量 </span><br><span class="line"># configure notifications (email, IRC, campfire etc)</span><br><span class="line"># please update this section to your needs!</span><br><span class="line"># https://docs.travis-ci.com/user/notifications/</span><br><span class="line">notifications:</span><br><span class="line">  email:</span><br><span class="line">    - playpi@qq.com</span><br><span class="line">  on_success: always</span><br><span class="line">  on_failure: always</span><br></pre></td></tr></table></figure><p>我在构建脚本里面已经尽可能添加了注释说明，解释地很清晰了，那我在这里再说明一下构建脚本具体的思路：</p><ul><li>指定环境、工具版本、监控的分支【只监控 source 分支】，开启缓存，设置全局变量 </li><li> 在 before_install 流程中进行环境的初始化 </li><li> 在 install 流程中安装基础环境【在这里 yarn 会使用缓存的内容，节约时间】</li><li>在 script 流程中生成 HTML 文件 </li><li> 在 after_success 流程中将最新代码推送到 master 分支【构建成功才会进行】</li><li>在 notifications 流程中执行通知邮箱与通知方式 </li></ul><p> 这里要特别注意，我没有在构建脚本中使用 <strong>hexo deploy</strong>，所以在安装插件阶段也没有安装 <strong>hexo-deployer-git</strong>【对于我来说它不够灵活，只能发布 <code>public</code> 文件夹下面的内容】，因为我这里情况比较复杂，需要复制一些自定义的文件到 <code>master</code> 分支，而且我这里不再提交更新到 <code>VPS</code> 或者其它托管网站【这个我使用别的方式另外做了】。如果你的情况只是简单地自动部署，则在 <strong>after_success</strong> 流程中不需要那么多脚本，直接 <strong>hexo deploy</strong> 就行【当然别忘了在 <code>Hexo</code> 的配置文件 <code>_config.yml</code> 中加上 <code>deploy</code> 相关配置】。</p><p>此外，我这里直接把主题的 <code>Git</code> 属性取消了，主题的文件夹被当作普通的文件夹提交到了 <code>source</code> 分支，这只是暂时的做法【而且显然不妥】，后面会把主题独立发布为一个项目，作为 <code>Hexo</code> 的一个 <code>Git</code> 子模块使用，敬请期待。我现在这么做虽然不妥，但是没有办法，因为我自己更改了太多的主题配置文件，而且版本过于陈旧，把这个主题项目单独整理出来需要消耗一些时间，以后会作为独立的博客发表一篇的，到时候构建脚本也会有小改动，敬请期待。</p><h2 id="原理简述"><a href="# 原理简述" class="headerlink" title="原理简述"></a>原理简述 </h2><p><code>travis-ci</code> 为什么可以做到实时更新，只要有 <code>push pull request</code> 或者 <code>push</code> 就能被 <code>travis-ci</code> 监控到，然后去执行构建脚本。其实，背后使用的还是 <code>GitHub</code> 的 <code>Webhooks</code> 技术，由于给了 <code>travis-ci</code> 认证权限，<code>travis-ci</code> 就申请了 <code>Webhooks</code> 的发送请求，每当监控的项目有 <code>push</code> 或者 <code>push request</code> 请求时，<code>GitHub</code> 会发送项目的信息给 <code>travis-ci</code>，这样 <code>travis-ci</code> 就可以做出相应的动作，例如执行构建脚本。</p><p> 这种做法我在另外一篇博客中也有实战经验，为了体验一下 <code>VPS</code> 上面的博客自动更新，也折腾了好几天，使用 <code>PHP</code> 自己搭建的服务脚本，有 <code>GitHub</code> 通知时自动拉取更新到本地指定的目录，有兴趣的可以参考一下：<a href="https://www.playpi.org/2019030601.html">使用 Github 的 WebHooks 实现代码自动更新 </a> 。</p><p> 可以去项目的设置中【不是用户设置】，找到 <strong>Settings</strong>、<strong>Webhooks</strong>，可以看到有一条名称为 <strong><a href="https://notify.travis-ci.org" target="_blank" rel="noopener">https://notify.travis-ci.org</a> </strong>的 <code>Webhooks</code> 记录，它就是 <code>GitHub</code> 用来通知 <code>travis-ci</code> 的接口。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512003256.png" alt="Webhooks" title="Webhooks"></p><h1 id="效果预览"><a href="# 效果预览" class="headerlink" title="效果预览"></a>效果预览 </h1><h2 id="简化命令"><a href="# 简化命令" class="headerlink" title="简化命令"></a> 简化命令 </h2><p> 完成了整个浩大的自动化部署工程后，以前需要使用的 <code>Hexo</code> 三部曲：</p><ul><li>hexo clean</li><li>hexo generate</li><li>hexo deploy</li></ul><p>完全不需要了，取而代之的是 <code>Git</code> 三部曲：</p><ul><li>git add .</li><li>git commit -am ‘update message’</li><li>git push</li></ul><p>当然，在本地测试时还是要使用 <code>Hexo</code> 三部曲 </p><ul><li>hexo clean</li><li>hexo generate</li><li>hexo sever</li></ul><h2 id="查看项目构建信息"><a href="# 查看项目构建信息" class="headerlink" title="查看项目构建信息"></a> 查看项目构建信息 </h2><p> 在本地更新 <code>source</code> 分支的文本内容，提交到 <code>GitHub</code> 上面，然后去看 <code>travis-ci</code> 的构建结果。</p><p>构建基础信息，包含构建消耗时间、项目 <code>Commit</code> 的 <code>id</code> 值、分支名、构建流程消耗时间等等。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001610.png" alt="构建基础信息" title="构建基础信息"></p><p>接着往下看，有构建日志、构建脚本内容。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001421.png" alt="构建日志" title="构建日志"></p><p>查看一下构建历史列表，可以看到所有的构建信息，每一个都会有编号，从 1 开始增加。成功的构建是绿色的，失败的是红色的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001344.png" alt="构建历史列表" title="构建历史列表"></p><h2 id="给项目添加构建图标"><a href="# 给项目添加构建图标" class="headerlink" title="给项目添加构建图标"></a>给项目添加构建图标 </h2><p> 在 <code>travis-ci</code> 的项目名称右边，可以看到有一个图标，点击，在弹出的对话框中选择分支与格式，我选择 <code>source</code> 分支，<code>Markdown</code> 格式，然后在下面的文本框中就会生成一个链接，直接复制粘贴到 <code>GitHub</code> 项目中的 <code>README</code> 文件中即可。</p><p>构建图标链接生成。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001324.png" alt="构建图标链接生成" title="构建图标链接生成"></p><p><code>GitHub</code> 项目的 <code>README</code> 文件填写。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001333.png" alt="GitHub 项目的 README 文件填写" title="GitHub 项目的 README 文件填写"></p><p><code>GitHub</code> 项目的构建图标查看。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190512001033.png" alt="GitHub 项目的构建图标查看" title="GitHub 项目的构建图标查看"></p><p>点击这个图标，是可以直接跳转到 <code>travis-ci</code> 的构建页面，可以查看构建日志、历史记录、项目配置等信息。</p><p>至此，整个自动化部署方案完全实现，并验证通过，效果超级好，以后可以直接使用 <code>Git</code> 命令提交更新了。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>travis-ci</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven 使用中遇到的证书问题以及 JDK8 问题</title>
    <url>/2018082501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在 Java 开发过程中，使用 Maven 往私服 deploy 构件【Java 打成的 jar 包】的时候，原本正常的流程突然出问题了，报错信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[WARNING] Could not transfer metadata org.leapframework:leap:0.4.0b-SNAPSHOT/maven-metadata.xml from/to bingo-maven-repository-hosted ($bingo.maven$): sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target</span><br></pre></td></tr></table></figure><p>看到里面的 <strong>security</strong> 和 <strong>certification</strong> 关键词就猜测是安全与证书的问题。恰好最近私服的域名访问从 http 升级为了 https，也就是增加了 SSL 证书，我想可能和这个有关。本文就记录解决这个问题的流程，以及后续由此又引发了其它的问题，例如 JDK8 导致的注解问题、IDEA 的乱码问题。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><p> 在分析问题现象之前，首先需要了解一个基本事实，Maven 是依赖于 JDK 环境运行的，所以使用 Maven 之前必须安装 JDK，并且配置好 <strong>JAVA_HOME</strong> 。在使用 Maven 过程中遇到的一些问题可能会和 JDK 环境有关，例如 SSL 证书问题、JDK 版本问题。</p><p>以下内容现象基于 Windoes7 X64 操作系统，JDK 版本为 1.7u89，Maven 版本为 3.5。</p><p>好，言归正传，继续关注遇到的问题。在某一天，发现公司的 Maven 私服仓库更新了管理系统，并且增加了 SSL 证书【证书类型是 <strong>Let’s Encrypt</strong> ，有效期三个月，这为后续的各种问题埋下了伏笔】，这样访问的链接全部变为 https 开头的了。但是我又注意到一个现象，我发现仓库里的很多 SNAPSHOT 类型的 jar 包消失了，这应该是管理系统设置了自动清除机制，把没用的快照版本的 jar 包全部清除，节约空间。但是，其中有一些 jar 包对于我来说是有用的，更麻烦的是这些 jar 包根本没有 RELEASE 正式版，都是前人留下的坑，为了图方便临时打了一个快照版本 jar 包给别人使用，竟然把资源文件也打进去，导致一个 jar 包有将近 100M 大小。这种操作显然是违背 Maven 的理念的，面对这种情况，再想申请发布一个 RELEASE 版本的 jar 包也麻烦，而且这种业务类型的代码就不应该打成 jar 包给别人使用。</p><p>思考了半天，我决定采用一个折中的办法：取得代码阅读权限，移除没用的资源文件，仅仅发布代码，仍旧发布 SNAPSHOT 版本，以后有时间再把业务代码复制出来，不再使用 jar 的形式。思路确定了，就开始行动。</p><p>一开始我发现开发环境本地仓库有这些 jar 包，还想手动上传到 Maven 私服仓库的，把坐标定义准确就行了。但是后续发现 Maven 私服仓库的管理系统不支持手动上传 jar 包，只支持通过账号、密码认证的方式，从源代码发布 jar 包到仓库，而且个人账号只能发布 SNAPSHOT 版本的，管理员账号才能发布 RELEASE 版本的。</p><p>路走到了这里，那我只能先获取项目代码的权限，然后新开分支，删掉无用的配置文件，仅仅发布源代码到私服仓库，先发布 SNAPSHOT 版本使用。</p><p>准备工作做好后，接着开始 deploy，就遇到了一连串的问题，在确认账号密码没有问题的前提下，deploy 失败，错误信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[WARNING] Could not transfer metadata org.leapframework:leap:0.4.0b-SNAPSHOT/maven-metadata.xml from/to bingo-maven-repository-hosted ($bingo.maven$): sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target</span><br></pre></td></tr></table></figure><p>看到里面的 <strong>security</strong> 和 <strong>certification</strong> 关键词就猜测是安全与证书的问题，公司私服的其它环境并没有变化，只能从 SSL 证书入手解决问题，然而一开始没有头绪。 但是又问了同事，发现他们可以正常 deploy，又测试了一下线上的发布系统，也可以正常发布 jar 包到公司私服仓库。那只有 2 个怀疑方向了，一个是本地 Maven 的版本问题，一个是本地 JDK 的版本问题。后来通过对比发现，的确是 JDK 版本的问题，某些低版本的 JDK 不会自动导入 Let’s Encrypt 的证书，才会导致 Maven 进行 deploy 时认证失败【Maven 底层是依赖于 JDK 的】，自然而然 delpoy 也就失败了。</p><p>参考：<a href="https://stackoverflow.com/questions/34110426/does-java-support-lets-encrypt-certificates" target="_blank" rel="noopener">stackoverflow 讨论一例 </a> 。</p><blockquote><p>The Let’s Encrypt certificate is just a regular public key certificate. Java supports it (according to <a href="https://letsencrypt.org/docs/certificate-compatibility/" target="_blank" rel="noopener">Let’s Encrypt Certificate Compatibility</a> , for Java 7 &gt;= 7u111 and Java 8 &gt;= 8u101).</p></blockquote><p> 在找原因的过程中还一度怀疑是公司私服仓库的 SSL 证书问题，后面发现是本地环境的问题，但是背后的根本原因还是 SSL 证书的问题。恰好遇到了 Let’s Encrypt 类型的证书，又恰好 JDK 版本过低，引起一系列连锁反应。</p><h1 id="问题解决"><a href="# 问题解决" class="headerlink" title="问题解决"></a>问题解决 </h1><p> 既然找到了问题，那就容易解决了，直接升级 JDK 即可，JDK7 需要升级到 &gt;=7u111，JDK8 需要升级到 &gt;=8u101。</p><h2 id="手动导入证书"><a href="# 手动导入证书" class="headerlink" title="手动导入证书"></a>手动导入证书 </h2><p> 其实，如果不升级 JDK，还有一种繁琐的解决办法，那就是手动导入证书。解决思路就是从需要访问的 https 站点下载证书，然后导入本地的 Java 环境证书库，缺点就是每次证书更新都需要重新导入，显得麻烦。其实这种做法更有助于我们理解这个问题的核心所在，高版本的 JDK 会自动帮我们导入 Let’s Encrypt 证书，但是低版本的不会，我们不仅能知其然，也知其所以然。</p><h3 id="下载证书"><a href="# 下载证书" class="headerlink" title="下载证书"></a>下载证书 </h3><p> 证书可以在访问网站时，在 url 文本框的左侧，有一把小绿锁，选中点击，接着查看证书，下载即可。</p><p>点击小绿锁 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tan4wr2ij20cm0aqwel.jpg" alt="点击小绿锁" title="点击小绿锁"></p><p> 下载证书 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1taned34lj20d60i9wes.jpg" alt="下载证书" title="下载证书"></p><p> 此外也可以通过浏览器调试工具的 Security 标签查看下载证书，下图是使用 Chrome 浏览器的效果，其它浏览器可能会略有不同。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tanr9da2j20l40mjdgo.jpg" alt="浏览器调试工具的 Security 标签" title="浏览器调试工具的 Security 标签"></p><h3 id="把证书文件导入证书库"><a href="# 把证书文件导入证书库" class="headerlink" title="把证书文件导入证书库"></a>把证书文件导入证书库 </h3><p> 先要清楚本地 Java 的证书库的位置，一般在 <strong>{JAVA_HOME}/jre/lib/security/</strong> 目录下面，里面有一个 <strong>cacerts</strong> 文件，它就是所有证书的集合组成的文件。另外还要清楚 <strong>keytool</strong> 工具，它是 JDK 提供的可以操作证书的工具，可以直接使用。</p><p>Java 证书库的位置 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tasd88jdj20rt0ffab4.jpg" alt="Java 证书库的位置" title="Java 证书库的位置"></p><p> 以下命令供参考，特别需要注意 <strong>命令执行权限 </strong>、<strong> 文件写权限 </strong>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 把证书文件 maven.datastory.cer 导入 Java 证书库 cacerts 中，别名为 maven.datastory，密码是 changeit</span><br><span class="line">keytool -import -alias maven.datastory -keystore cacerts -file  maven.datastory.cer -trustcacerts -storepass changeit</span><br><span class="line"></span><br><span class="line">-- 在证书库中查看指定别名的证书信息，需要输入密码 </span><br><span class="line">keytool -list -keystore cacerts -alias maven.datastory</span><br><span class="line"></span><br><span class="line">-- 删除证书库中指定别名的证书 </span><br><span class="line">keytool -delete -keystore cacerts -alias maven.datastory</span><br></pre></td></tr></table></figure><h3 id="后续维护问题"><a href="# 后续维护问题" class="headerlink" title="后续维护问题"></a>后续维护问题 </h3><p> 这种手动导入证书的方式，只能确保一时可以使用，因为证书是会过期的，特别是 Let’s Encrypt 证书，有效期只有 3 个月。所以后期维护起来会很麻烦，如果某一天发现 deploy 又报一样的错，那估计是证书过期了，也有可能是站点的证书被更换了。因此，还是升级高版本的 JDK 比较好，把证书的维护更新工作都交给 JDK 来执行，自己安心写代码就行了。</p><p>我后期就经历了这一过程，用了没多久发现 deploy 还是失败，只好把证书下载下来重复了导入的过程。而且一开始没有往证书过期上面怀疑，浪费了一些找问题的时间。</p><h2 id="自定义证书库"><a href="# 自定义证书库" class="headerlink" title="自定义证书库"></a>自定义证书库 </h2><p> 其实还有一种更为繁琐的做法，那就是自定义证书库，思路就是把 Java 的证书库复制一份，并且把自己的证书添加进去，然后为 Maven 指定这个自己的证书库。指定证书库的参数【例如路径、密码、证书库类型】需要在 Maven 命令执行之前配置，就像设置一些环境变量一样。</p><p>更为详细的做法就不演示了，毕竟一般都没有必要这样做，可以参考：<a href="http://kael-aiur.com/% E5% B7% A5% E5%85% B7% E4% BD% BF% E7%94% A8/maven% E6% B7% BB% E5%8A% A0% E4% BF% A1% E4% BB% BB% E8% AF%81% E4% B9% A6.html" target="_blank" rel="noopener">自定义 Maven 证书库 </a> 。</p><h2 id="题外话"><a href="# 题外话" class="headerlink" title="题外话"></a> 题外话 </h2><p> 如果 IDEA 因为 Maven 的依赖问题，有红色的线条提醒，可能是没有及时更新 UI 界面导致的，其实依赖都完整了，此时重新启动 IDEA 即可，我一直怀疑这是 IDEA 的 bug，有时候明明缺少依赖，IDEA 也不提示错误。</p><p>而判断是否真的缺失 Maven 依赖，应该使用 Maven 命令编译、打包【mvn compile package】，看看日志是否正常，不能以 IDEA 的显示为依据【有时候 IDEA 会抽风】。如果真的缺少 Maven 依赖，使用 Maven 命令编译、打包是会失败的，并且有提示。而如果明明不缺少依赖，但是代码中报错一大堆，此时强制更新【reimport 重新导入】 Maven 依赖即可，必要时也需要重启 IDEA。</p><p>另外有一个很好用的小技巧，如果本地仓库存在一个可以使用的 jar 包，可以直接复制给别人使用，按照相同的目录放在指定的路径下面即可，这样 Maven 就会认为本地已经存在 jar 包了，不再去私服仓库下载。这种做法虽然很低级，但是却实用，可以快速解决私服仓库没有 jar 包，初始化环境时无法下载依赖的情况。</p><h2 id="其它问题记录"><a href="# 其它问题记录" class="headerlink" title="其它问题记录"></a>其它问题记录 </h2><p> 在同一时期，同事的环境已经升级到 <code>JDK8</code> 以上，并且 <code>&gt;=8u101</code>，<code>Maven</code> 版本是 <code>v3.2.1</code>，可以正常 <code>deploy</code> 构件。但是突然有一天就出错，从日志来看是认证问题，切换为别人的账号密码就正常，使用他自己的账号密码却报错，我猜测是账号的问题，找运维解决。</p><p>报错信息如下，留意关键部分：<code>Not authorized , ReasonPhrase:Unauthorized.</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[INFO] --- maven-install-plugin:2.4:install (default-install) @ project-name ---</span><br><span class="line">[INFO] Installing D:\datastory\workspace\study\project-name\target\project-name-1.1.11-SNAPSHOT.jar to D:\pro\env\maven\repository\com\datastory\radar\project-name\1.1.11-SNAPSHOT\project-name-1.1.11-SNAPSHOT.jar</span><br><span class="line">[INFO] Installing D:\datastory\workspace\study\project-name\pom.xml to D:\pro\env\maven\repository\com\datastory\radar\project-name\1.1.11-SNAPSHOT\project-name-1.1.11-SNAPSHOT.pom</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ project-name ---</span><br><span class="line">Downloading: http://maven.domain/nexus/content/repositories/snapshots/com/datastory/radar/project-name/1.1.11-SNAPSHOT/maven-metadata.xml</span><br><span class="line">[WARNING] Could not transfer metadata com.datastory.radar:project-name:1.1.11-SNAPSHOT/maven-metadata.xml from/to snapshots (http://maven.domain/nexus/content/repositories/snapshots): Not authorized , ReasonPhrase:Unauthorized.</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD FAILURE</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 5.860 s</span><br><span class="line">[INFO] Finished at: 2018-08-10T21:48:24+08:00</span><br><span class="line">[INFO] Final Memory: 24M/326M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project project-name: Failed to retrieve remote metadata com.datastory.radar:project-name:1.1.11-SNAPSHOT/maven-metadata.xml: Could not transfer metadata com.datastory.radar:project-name:1.1.11-SNAPSHOT/maven-metadata.xml from/to snapshots (http://maven.domain/nexus/content/repositories/snapshots): Not authorized , ReasonPhrase:Unauthorized. -&gt; [Help 1]</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.</span><br><span class="line">[ERROR] Re-run Maven using the -X switch to enable full debug logging.</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] For more information about the errors and possible solutions, please read the following articles:</span><br><span class="line">[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException</span><br></pre></td></tr></table></figure><p><code>Not authorized , ReasonPhrase:Unauthorized.</code> 这个错误表明认证失败，说明远程仓库【或者私服】没有开放访问权限，需要密钥、用户名密码之类的认证方式。</p><p>我检查了一下我的 <code>settings.xml</code> 配置文件，发现已经配置好了 <code>server</code> 属性，并且确保了 <code>id</code> 与 项目 <code>pom.xml</code> 中指定仓库的 <code>id</code> 一致。但是还是出现异常，感觉上 <code>Maven</code> 使用的配置文件就不是我的这份，查看 <code>MAVEN_HOME</code> 也没有指定。</p><p>询问了一下运维人员，果然是的，服务器执行 <code>mvn</code> 相关命令，默认使用公共的配置文件【没有认证信息】，如果需要使用自己的配置文件【有自己特有的配置信息】，使用 <code>-s</code> 参数指定即可。如果需要经常使用，可以在 <code>.bashrc</code> 脚本中加上 <code>alias</code>：<code>alias mcp=&#39;mvn -s&quot;/path/to/your/settings.xml&quot;clean package&#39;</code>，这样每次登录时都会自动设置别名命令。</p><h1 id="JDK8- 注解问题"><a href="#JDK8- 注解问题" class="headerlink" title="JDK8 注解问题"></a>JDK8 注解问题 </h1><p> 切换到 <code>JDK8</code> 并且升级之后，在 <code>deploy</code> 构件到私服仓库的时候，出现了另外一个问题，直接 <code>deploy</code> 失败，报错信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.7:jar (attach-javadocs) on project [projectname]: MavenReportException: Error while generating Javadoc:</span><br><span class="line">Exit code: 1 - [path-to-file]:[linenumber]: warning: no description for @param</span><br></pre></td></tr></table></figure><p><code>deploy</code> 失败日志截图 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tay67elbj20qo0fqtfc.jpg" alt="deploy 失败日志截图" title="deploy 失败日志截图"></p><p> 查看里面的关键信息，可以找出 <code>maven-javadoc-plugin</code> 这个插件，说明是这个插件在生成 <code>Javadoc</code> 的时候出问题了。而我回想了一下，最近的插件版本、代码结构并没有变化，唯一变化的就是开发环境，<code>JDK</code> 由 1.7 版本切换为了 1.8 版本，那就往这方面找问题了。</p><p>查了一下资料，由于 <code>JDK8</code> 的 <code>Javadoc</code> 生成机制比之前的版本要严谨许多，在 <code>Javadoc</code> 中添加了 <code>doclint</code>，而这个工具的主要目的是获得符合 <code>W3C HTML 4.01</code> 标准规范的 <code>HTML</code> 文档。所以使用 <code>maven-javadoc-plugin</code> 插件 <code>deploy</code> 的时候，<code>JDK8</code> 环境触发了 <code>Javadoc</code> 验证，验证自然不能通过，<code>Maven</code> 插件直接报错，<code>deploy</code> 不成功。</p><p>为了验证这个过程，我又把本地环境的 <code>JDK</code> 切回到了 1.7 版本，可以正常 <code>deploy</code>，成功发布 <code>SNAPSHOT</code> 版本的构件到私服仓库。而由于线上发布系统的 <code>JDK</code> 版本强制设置为了 1.8，无法更改，所以无法在线上做验证，只能发现在线上发布的 <code>RELEASE</code> 版本构件一定是失败的。</p><p>既然找到了原因所在，接下来就容易操作了，可以选择关闭 <code>Javadoc</code> 验证，或者直接不使用 <code>maven-javadoc-plugin</code> 这个插件。而我选择继续使用这个插件，但是可以选择是跳过生成 <code>Javadoc</code> 还是关闭 <code>Javadoc</code> 验证，根据自己的需要了，具体步骤与效果我会在下面演示。</p><p>先来看一下这个插件的 <code>pom.xml</code> 文件配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- javadoc 打包插件 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.9&lt;/version&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;id&gt;attach-javadocs&lt;/id&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;goal&gt;jar&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;!-- 直接跳过 Javadoc 生成 --&gt;</span><br><span class="line">                &lt;skip&gt;true&lt;/skip&gt;</span><br><span class="line">                &lt;encoding&gt;UTF-8&lt;/encoding&gt;</span><br><span class="line">                &lt;charset&gt;UTF-8&lt;/charset&gt;</span><br><span class="line">                &lt;!-- 此参数针对 jdk8 环境使用，如果本机是 jdk7 环境会报错，所以增加上述 skip 配置，保证线上和本地都可以部署 (install/deploy), 当然最好使用 profile 激活灵活的配置 --&gt;</span><br><span class="line">                &lt;!-- add this to disable checking, 禁用 Javadoc 检查 --&gt;</span><br><span class="line">                &lt;additionalparam&gt;-Xdoclint:none&lt;/additionalparam&gt;</span><br><span class="line">                &lt;!-- 使用 profile 激活灵活的配置 --&gt;</span><br><span class="line">                &lt;additionalparam&gt;$&#123;javadoc.opts&#125;&lt;/additionalparam&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><p>以上配置是非常完整的，把所有的重要配置项都列出来了，并给出了注释，实际使用中选择自己需要的即可，如果看不懂没有关系，接着往下看，详细解释了参数的使用以及最终的优化配置方案。</p><p>在这里需要注意一个问题，如果你的 <code>pom.xml</code> 文件中根本没有配置 <code>maven-javadoc-plugin</code> 插件，但是这些错误仍旧存在，那是为什么呢？其实是因为 <code>Maven</code> 已经默认给每个生命周期都绑定了对应的插件，如果没有在 <code>pom.xml</code> 中配置自定义的插件，则使用 <code>Maven</code> 默认的【这里的默认有 2 层意思，一个是插件类型默认，一个是版本号默认】。例如当前项目如果没有配置 <code>javadoc</code> 插件，则会默认使用仓库里版本最高的稳定版 <code>maven-javadoc-plugin</code> 插件，插件的配置也都是默认的，无法更改。</p><p>而使用 <code>Maven</code> 默认的插件，很可能会引发莫名的问题，根本原因就在于对于某个插件、某个版本的插件、插件的默认配置，我们都是未知的，出了问题也比较难定位，所以在一些重要的插件上面还是手动显式配置出来比较好，这样问题都能在自己的掌握之中。</p><h2 id="跳过 -Javadoc- 的生成"><a href="# 跳过 -Javadoc- 的生成" class="headerlink" title="跳过 Javadoc 的生成"></a>跳过 Javadoc 的生成 </h2><p> 如果直接配置了跳过 <code>Javadoc</code> 的生成【使用 <code>skip</code> 参数】，<code>configuration</code> 下面的内容都不需要配置了，配置了也不会用到。由于插件会直接跳过 <code>Javadoc</code> 的生成，所以也就不存在验证的过程了。然而，这种做法对于构件的使用方是不友好的，因为缺失了 <code>Javadoc</code>，当查看源码遇到问题时就无法寻求有效的帮助了。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;skip&gt;true&lt;/skip&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="开启 -Javadoc- 生成但是关闭 -Javadoc- 验证"><a href="# 开启 -Javadoc- 生成但是关闭 -Javadoc- 验证" class="headerlink" title="开启 Javadoc 生成但是关闭 Javadoc 验证"></a>开启 Javadoc 生成但是关闭 Javadoc 验证 </h2><p> 因此，还是要开启 <code>Javadoc</code> 的生成，但是关闭 <code>JDK8</code> 对于 <code>Javadoc</code> 的严格验证，此时需要在 <code>configuration</code> 里面增加参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;additionalparam&gt;-Xdoclint:none&lt;/additionalparam&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>一般为了方便他人查看项目的参数，最好把这种重要的参数值设置为全局变量，在 <code>pom.xml</code> 文件的 <code>properties</code> 节点下面声明即可，例如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 设置全局变量 </span><br><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;additionalparam.val&gt;-Xdoclint:none&lt;/additionalparam.val&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">-- 使用全局变量 </span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;additionalparam&gt;$&#123;additionalparam.val&#125;&lt;/additionalparam&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="潜在的问题"><a href="# 潜在的问题" class="headerlink" title="潜在的问题"></a>潜在的问题 </h2><p> 难道这样配置就完了吗，显然有潜在的问题，作为经历过的人，我告诉你，附加参数 <code>-Xdoclint:none</code> 是只有 <code>JDK8</code> 及以上版本才会支持的，如果有人在构建项目时使用了 <code>JDK7</code> 的环境，最终的结果还是失败，失败的原因是参数不合法，无法支持。</p><p>报错信息举例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.7:jar (attach-javadocs) on project [projectname]: MavenReportException: Error while generating Javadoc:</span><br><span class="line">Exit code: 1 - javadoc: 错误 - 无效的标记: -Xdoclint:none</span><br></pre></td></tr></table></figure><p>所以接下来还要想一个更好的办法，不仅能关闭 <code>Javadoc</code> 的验证，还要根据当前的实际 <code>JDK</code> 环境来自动切换参数的取值，这样就可以兼容所有的环境了。显然，没有什么比 <code>profile</code> 更适合这个情况了，配置一个 <code>profile</code> 激活信息，根据 <code>JDK</code> 的版本激活全局变量，参数值传入给 <code>additionalparam</code> 使用，比起上面的固定的全局变量，这种可变的全局变量更灵活。</p><p>详细配置如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 全局变量 javadoc.opts 在 JDK8 及以上版本才激活 </span><br><span class="line">&lt;profiles&gt;</span><br><span class="line">  &lt;profile&gt;</span><br><span class="line">    &lt;id&gt;doclint-java8-disable&lt;/id&gt;</span><br><span class="line">    &lt;activation&gt;</span><br><span class="line">      &lt;jdk&gt;[1.8,)&lt;/jdk&gt;</span><br><span class="line">    &lt;/activation&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">      &lt;javadoc.opts&gt;-Xdoclint:none&lt;/javadoc.opts&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line">  &lt;/profile&gt;</span><br><span class="line">&lt;/profiles&gt;</span><br><span class="line"></span><br><span class="line">-- 使用激活的全局变量，如果没有激活则为空 </span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;additionalparam&gt;$&#123;javadoc.opts&#125;&lt;/additionalparam&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="插件版本的踩坑"><a href="# 插件版本的踩坑" class="headerlink" title="插件版本的踩坑"></a>插件版本的踩坑 </h2><p> 在解决问题的过程中还遇到了一个典型的问题，由插件版本引起。</p><p>一开始在项目的 <code>pom.xml</code> 文件中没有配置插件 <code>maven-javadoc-plugin</code> 的版本号，即 <code>version</code> 参数，导致项目使用的是公司私服仓库最新的版本：<code>v3.0.0</code>，而在这个版本中使用 <code>-Xdoclint:none</code> 关闭验证是无效的，不知道是插件本身的问题还是参数 <code>-Xdoclint:none</code> 对 3.0.0 版本的插件无效。后来指定版本为 2.9，就没有这个问题了。</p><p>由于一开始没有指定插件 <code>maven-javadoc-plugin</code> 的版本号，出错了也不知道为啥，在 <code>deploy</code> 的输出日志中看到使用的 <code>v3.0.0</code> 版本的插件，猜测可能和插件版本有关系，于是更换了版本，就没有问题了。因此这种重要的插件还是要手动指定自己认为稳定的版本，这样有问题也能在自己的掌握之中。</p><h2 id="参考"><a href="# 参考" class="headerlink" title="参考"></a>参考 </h2><ul><li><a href="http://www.locked.de/how-to-ignore-maven-javadoc-errors-in-java-8/" target="_blank" rel="noopener"> 在 JDK8 中禁用 Javadoc 验证 </a></li><li><a href="https://stackoverflow.com/questions/27728733/javadoc-error-invalid-flag-xdoclintnone-when-i-use-java-7-but-it-works-i" target="_blank" rel="noopener">stackoverflow 中的问答一例</a></li></ul><h1 id="IDEA- 乱码问题"><a href="#IDEA- 乱码问题" class="headerlink" title="IDEA 乱码问题"></a>IDEA 乱码问题</h1><p> 在解决上面的 <code>JDK8</code> 注解的问题过程中，遇到了一个乱码问题，系统环境是 <code>Windows7 X64</code>。当在 <code>JDK7</code> 的环境中配置了以下内容时：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;additionalparam&gt;-Xdoclint:none&lt;/additionalparam&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>本意是想测试这个参数在 <code>JDK7</code> 环境中的效果【前面已经验证过在 <code>JDK8</code> 中是完美运行的】，发现报错了，但是错误信息是乱码的，导致看不出来错误信息是什么，也就没法解决问题。</p><p>在 <code>JDK7</code> 中 <code>deploy</code> 报错乱码 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tb5tee2qj20qo0a1td9.jpg" alt="Maven 报错信息乱码" title="Maven 报错信息乱码"></p><p> 其实，这只是 IDEA 的编码设置问题，更改一下编码就行了。在 <strong>setting –&gt; maven –&gt; rumnner –&gt; VMoptions</strong> ，添加参数：<strong>-Dfile.encoding=GB2312</strong> ，就可以正常输出了。当然，Windows 系统配置编码为 <strong>GBK</strong> 也行。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tb6bm56gj20qo0fi0vd.jpg" alt="设置 IDEA 的 Maven 编码" title="设置 IDEA 的 Maven 编码"></p><p>为什么要这么配置呢，因为 Maven 是依赖于当前系统的编码的，可以使用 <strong>mvn -version</strong> 命令查看编码的信息，查看 <strong>Default locale</strong> 那一项，可以看到是 <strong>GBK</strong>。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tb6jiivhj20gj0ahaab.jpg" alt="查看 Maven 的编码使用" title="查看 Maven 的编码使用"></p><p>配置完成后，报错信息正常显示 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1tb6u2gzgj20qo0awq7a.jpg" alt="报错信息正常显示" title="报错信息正常显示"></p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a> 问题总结</h1><p>1、通过手动导入证书的方式，一开始解决了问题，后来过了一段时间突然又不能使用，这时候我很是疑惑的。问了问同事却都能正常使用，我还以为是我的 Maven 的版本问题，换了 Maven 版本也不行，最后折腾了很久发现是私服域名的 SSL 证书失效了，再重新导入一份就行了。因为私服域名的 <strong>Let’s Encrypt</strong> 证书有效期只有三个月，所以每次证书续期或者更换的时候，都要手动重新导入，旧证书会自动失效。这样多麻烦，所以还是直接升级 JDK 比较好，一劳永逸。</p><p>2、在与同事的开发环境对比的过程中，仔细对比了 Maven 的版本和 JDK 的版本，发现都是 Maven 3.5 与 JDK1.7，但是别人能用我的就不能用，一度怀疑人生。最终才发现根本原因是没有对比小版本号，同样是 JDK1.7，没有 <strong>&gt;=7u111</strong> 也不行。</p><p>3、关于 Maven 的插件版本问题，切记要手动指定自己认为可靠的版本，不要让 Maven 使用仓库最新的稳定版本，哪怕的确是使用最新的版本，也要指明，确保出了问题自己可控，否则就像无头的苍蝇乱打乱撞。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>JDK</tag>
        <tag>证书</tag>
      </tags>
  </entry>
  <entry>
    <title>Search Guard 安装部署实践</title>
    <url>/2020042701.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近 <code>Elasticsearch</code> 集群出了一个小事故，根本原因在于对集群请求的监控不完善，以及对 <code>Elasticsearch</code> 访问权限无监控【目前是使用 <code>LDAP</code> 账号就可以登录访问，而且操作权限很大，这有很大的隐患】。因此，最近准备上线 <code>Search Guard</code>，先在测试环境部署安装了一遍，并测试了相关服务，整理了如下安装部署文档，以供读者参考。</p><p>开发环境基于 <code>Elasticsearch v5.6.8</code>、<code>Search Guard v5.6.8-19.1</code>、<code>Java v1.8</code> 。</p><a id="more"></a><h1 id="相关包、文档参考"><a href="# 相关包、文档参考" class="headerlink" title="相关包、文档参考"></a>相关包、文档参考 </h1><h2 id="Search-Guard- 下载"><a href="#Search-Guard- 下载" class="headerlink" title="Search Guard 下载"></a>Search Guard 下载</h2><p><code>Search Guard</code> 首页：<a href="https://docs.search-guard.com/v5/search-guard-versions" target="_blank" rel="noopener">Search Guard versions</a> 。</p><p> 仓库在线包：<a href="https://oss.sonatype.org/service/local/repositories/releases/content/com/floragunn/search-guard-5/5.6.8-19.1/search-guard-5-5.6.8-19.1.zip" target="_blank" rel="noopener">repositories</a> ，也可以使用坐标：<code>com.floragunn:search-guard-5:5.6.8-19.1</code>。</p><p>此外，这个官方的在线包没了：<a href="https://releases.floragunn.com/search-guard-5/5.6.16-19.4/search-guard-5-5.6.16-19.4.zip" target="_blank" rel="noopener">search-guard-5</a> ，版本选择：<code>v5.6.8-19.1</code>。</p><h2 id="证书工具下载"><a href="# 证书工具下载" class="headerlink" title="证书工具下载"></a>证书工具下载 </h2><p> 证书工具 <code>tlstool</code>：<a href="https://search.maven.org/search?q=a:search-guard-tlstool" target="_blank" rel="noopener">search-guard-tlstool</a> ，版本选择：<code>v1.7</code>。</p><h2 id="相关文档参考"><a href="# 相关文档参考" class="headerlink" title="相关文档参考"></a>相关文档参考 </h2><p><code>offline-tls-tool</code>：<a href="https://docs.search-guard.com/latest/offline-tls-tool" target="_blank" rel="noopener">offline-tls-tool</a> 。</p><p><code>Search Guard</code>：<a href="https://docs.search-guard.com/latest/installation-windows#install-search-guard-on-elasticsearch" target="_blank" rel="noopener">installation-windows</a> 。</p><p><code>Search Guard sgadmin.sh</code> 命令参数：<a href="https://docs.search-guard.com/latest/sgadmin" target="_blank" rel="noopener">sgadmin</a> 。</p><h1 id="回滚"><a href="# 回滚" class="headerlink" title="回滚"></a> 回滚 </h1><p> 安装部署过程中，避免不了小概率的异常，所以需要考虑回滚操作。</p><p><code>Elasticsearch</code> 如果需要回滚，不需要卸载插件，不需要删除配置，直接在 <code>Elasticsearch</code> 配置中添加参数，关闭 <code>Search Guard</code> 插件的使用：<code>searchguard.disabled: true</code>，再重启 <code>Elasticsearch</code> 集群即可。</p><p>如果有其它强关联的业务服务，提前准备好对应的分支或者 <code>tag</code>，重新部署即可，不需要变更代码。</p><h1 id="部署操作"><a href="# 部署操作" class="headerlink" title="部署操作"></a>部署操作 </h1><p> 前提：不支持单台停机滚动安装，需要重启所有 <code>Elasticsearch</code> 节点，当然，停机时间很短暂。</p><p>以下记录安装、配置、部署流程。</p><p>提示：所有的证书文件、配置文件【包括 <code>Elasticsearch</code> 节点的、<code>Search Guard</code> 插件的】都可以提前准备好，<code>Search Guard</code> 插件也可以提前安装好。重启 <code>Elasticsearch</code> 集群后，在黄色状态下，开始激活 <code>Search Guard</code> 插件，可能需要一点时间，几分钟到十几分钟。</p><h2 id="准备证书"><a href="# 准备证书" class="headerlink" title="准备证书"></a>准备证书 </h2><p> 证书需要提前生成好，需要为所有的 <code>Elasticsearch</code> 节点都生成证书，即每个节点都有自己独立的证书文件。</p><p>附件为配置示例以及生成的证书示例，已经被我上传至 <code>GitHub</code>，读者可以下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20200427" target="_blank" rel="noopener">证书配置以及证书文件 </a> ，测试主机为：<code>dev4、dev5、dev6</code>，域名为：<code>playpi.org</code>。</p><h3 id="下载解压"><a href="# 下载解压" class="headerlink" title="下载解压"></a> 下载解压 </h3><p> 解压到本地磁盘中，任何主机都可以，提前做好。</p><p>注意每个目录的作用：</p><ul><li><code>config</code>，配置文件，需要根据自己的情况更改一些配置 </li><li><code>tools</code>，脚本文件，生成使用</li><li><code>deps</code>，依赖文件，工具需要的依赖包</li></ul><h3 id="准备配置文件"><a href="# 准备配置文件" class="headerlink" title="准备配置文件"></a> 准备配置文件 </h3><p> 配置 <code>ca</code> 证书、<code>Elasticsearch</code> 节点、客户端信息，<code>Elasticsearch</code> 节点信息包含：<code>name</code>、<code>dn</code>、<code>dns</code>、<code>ip</code>，具体参考附件内容。</p><p>以下给出 <code>Elasticsearch</code> 节点、客户端信息的示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">###</span><br><span class="line">### Nodes</span><br><span class="line">###</span><br><span class="line">#</span><br><span class="line"># Specify the nodes of your ES cluster here</span><br><span class="line">#      </span><br><span class="line">nodes:</span><br><span class="line">  - name: dev4</span><br><span class="line">    dn: CN=dev4.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br><span class="line">    ip: 192.168.1.4</span><br><span class="line">    dns: dev4.playpi.com</span><br><span class="line">  - name: dev5</span><br><span class="line">    dn: CN=dev5.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br><span class="line">    ip: 192.168.1.5</span><br><span class="line">    dns: dev5.playpi.com</span><br><span class="line">  - name: dev6</span><br><span class="line">    dn: CN=dev6.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br><span class="line">    ip: 192.168.1.6</span><br><span class="line">    dns: dev6.playpi.com</span><br><span class="line"></span><br><span class="line">###</span><br><span class="line">### Clients</span><br><span class="line">###</span><br><span class="line">#</span><br><span class="line"># Specify the clients that shall access your ES cluster with certificate authentication here</span><br><span class="line">#</span><br><span class="line"># At least one client must be an admin user (i.e., a super-user). Admin users can</span><br><span class="line"># be specified with the attribute admin: true    </span><br><span class="line">#        </span><br><span class="line">clients:</span><br><span class="line">  - name: client-admin</span><br><span class="line">    dn: CN=client-admin.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br><span class="line">    admin: true</span><br><span class="line">  - name: client-custom</span><br><span class="line">    dn: CN=client-custom.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br></pre></td></tr></table></figure><h3 id="生成证书文件"><a href="# 生成证书文件" class="headerlink" title="生成证书文件"></a>生成证书文件 </h3><p> 执行解压目录内的工具：<code>./tools/sgtlstool.sh -c &lt;path&gt;/tlsconfig.yml -ca -crt</code>，生成证书文件，输出目录为 <code>out</code>。</p><p>参数含义：</p><ul><li>-c，指定配置文件位置 </li><li>-ca，创建并指定本地证书授权中心【如果已经存在本地证书授权中心则不需要】</li><li>-crt，使用本地证书授权中心创建证书</li></ul><p> 除了 <code>root</code> 证书总计有 3 个文件【包含 <code>readme</code>】，<code>client</code> 总计有 5 个文件【包含 <code>readme</code>】，此外每个 <code>Elasticsearch</code> 节点对应有 5 个文件【包含 <code>config</code>】。</p><p>创建成功后输出日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Root certificate has been sucessfully created.</span><br><span class="line">The passwords of the private key files have been auto generated. You can find the passwords in root-ca.readme.</span><br><span class="line"></span><br><span class="line">Created 6 node certificates.</span><br><span class="line">Passwords for the private keys of the node certificates have been auto-generated. The passwords are stored in the config snippet files.</span><br><span class="line">Created 2 client certificates.</span><br><span class="line">Passwords for the private keys of the client certificates have been auto-generated. The passwords are stored in the file &quot;client-certificates.readme&quot;</span><br></pre></td></tr></table></figure><p>输出证书文件 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2020/20200504162349.png" alt="生成证书文件一览" title="生成证书文件一览"></p><p> 备注 <code>Windows</code> 操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.\tools\sgtlstool.bat -c .\config\tlsconfig.yml -ca -crt</span><br></pre></td></tr></table></figure><h3 id="检查证书文件"><a href="# 检查证书文件" class="headerlink" title="检查证书文件"></a>检查证书文件 </h3><p> 上面的截图中已经给出 <code>out</code> 目录中生成的文件，下面简单描述一下。</p><p>根据 <code>tlsconfig.yml</code> 配置会生成以下文件：</p><ul><li>1 份根证书文件【3 个文件，用于 <code>Elasticsearch</code> 配置】：<code>root-ca.key</code>、<code>root-ca.pem</code>、<code>root-ca.readme</code></li><li>每个 <code>node</code> 生成 1 份证书文件【5 个文件，用于 <code>Elasticsearch</code> 配置】：<code>&lt;node&gt;.key</code>、<code>&lt;node&gt;.pem</code>、<code>&lt;node&gt;_http.key</code>、<code>&lt;node&gt;_http.pem</code>【若密码生成方式设为 <code>auto</code>，密码在各个 <code>node</code> 的 <code>&lt;node&gt;_elasticsearch_config_snippet.yml</code> 文件中找】</li><li>客户端 1 份证书文件【5 个文件，用于 <code>sgadmin.sh</code> 执行激活】：<code>client-admin</code>.key、<code>client-admin.pem</code>、<code>client-custom.key</code>、<code>client-custom.pem</code>【若密码生成方式设为 <code>auto</code>，密码在 <code>client_certificates.readme</code> 中找】</li><li>其中，每个 <code>&lt;node&gt;_elasticsearch_config_snippet.yml</code> 文件中的内容，可以直接复制粘贴到每个 <code>Elasticsearch</code> 节点的配置文件中【视情况变更部分配置，例如 <code>searchguard.ssl.http.enabled: false</code>】</li></ul><p>除了用肉眼检查文件个数是否正确，还要检查证书文件是否合法【校验】，可以使用自带的工具：<code>/tools/sgtlsdiag.sh</code> 。</p><p>例如：<code>./tools/sgtlsdiag.sh -ca out/root-ca.pem -crt out/dev4.pem</code>。</p><ul><li>-ca，创建并指定本地证书授权中心【如果已经存在本地证书授权中心则不需要】</li><li>-crt，指定 <code>Elasticsearch</code> 节点证书文件 </li></ul><p> 此外，还可以检查 <code>Elasticsearch</code> 节点的配置是否正确：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./tools/sgtlsdiag.sh -es /etc/elasticsearch/elasticsearch.yml</span><br></pre></td></tr></table></figure><ul><li>-es，指定 <code>Elasticsearch</code> 配置文件 </li></ul><h2 id="安装 -Search-Guard"><a href="# 安装 -Search-Guard" class="headerlink" title="安装 Search Guard"></a> 安装 Search Guard</h2><p>提示：以下列出的是常规的安装、配置流程，实际操作中，可以提前把一切工作做好【证书生成、配置、插件安装】，然后直接重启 <code>Elasticsearch</code> 集群、激活 <code>Search Guard</code>，实际停机时间很短【保守估计 30 分钟以内，等待集群状态恢复绿色需要几小时到十几小时，视集群的分片恢复能力而定】。</p><p><code>Search Guard</code> 用户权限配置文件参考附件，已被我上传至 <code>GitHub</code>：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20200427" target="_blank" rel="noopener">Search Guard config</a> 。</p><h3 id="禁止重分配"><a href="# 禁止重分配" class="headerlink" title="禁止重分配"></a>禁止重分配 </h3><p> 防止停掉 <code>Elasticsearch</code> 节点时自动重分配。</p><p>可以在安装 <code>Search Guard</code> 插件之后，并且准备好配置文件之后再执行。</p><p>配置更新：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /_cluster/settings/</span><br><span class="line">&#123;</span><br><span class="line">    &quot;transient&quot;: &#123;</span><br><span class="line">        &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="停止集群"><a href="# 停止集群" class="headerlink" title="停止集群"></a>停止集群 </h3><p> 可以在安装 <code>Search Guard</code> 插件之后，并且准备好配置文件之后再执行。</p><p>由运维人员操作。</p><h3 id="每个节点安装插件"><a href="# 每个节点安装插件" class="headerlink" title="每个节点安装插件"></a>每个节点安装插件 </h3><p> 在线安装：在每个 <code>Elasticsearch</code> 节点上，执行：<code>./bin/elasticsearch-plugin install -b com.floragunn:search-guard-5:5.6.8-19.1</code>【在此使用坐标，或者使用仓库地址链接也可以】。</p><p>离线安装：下载安装包到本地，用 <code>zip</code> 包离线安装【在 <code>Windows</code> 系统上面试过：报 <code>unknown plugin</code>，暂未找到原因】。</p><h3 id="拷贝证书文件"><a href="# 拷贝证书文件" class="headerlink" title="拷贝证书文件"></a>拷贝证书文件 </h3><p> 将前面生成的证书文件拷贝至 <code>Elasticsearch</code> 的 <code>config</code> 目录。</p><p>包含以下内容：</p><ul><li>1 份根证书文件【2 个文件】：<code>root-ca.key</code> 和 <code>root-ca.pem</code></li><li>对应 <code>Elasticsearch</code> 节点的 1 份证书文件【4 个文件】：<code>&lt;node&gt;.key</code>、<code>&lt;node&gt;.pem</code>、 <code>&lt;node&gt;_http.key</code>、<code>&lt;node&gt;_http.pem</code></li><li>注意：<code>client</code> 客户端 4 个证书文件不需要拷贝，只把 <code>admin</code> 权限的 2 个文件拷贝到某一个节点即可，用于激活管理 <code>Search Guard</code></li><li>4 个证书文件【普通权限 2 个、<code>admin</code> 权限 2 个】，实际会用到 <code>admin</code> 权限的 2 个：<code>client-admin.key</code>、<code>client-admin.pem</code>【这 4 个证书文件实际是给通过 <code>tcp</code> 访问的客户端使用的，此外在执行 <code>sgadmin.sh</code> 的时候也需要使用】</li></ul><h3 id="修改集群配置"><a href="# 修改集群配置" class="headerlink" title="修改集群配置"></a>修改集群配置 </h3><p> 修改 <code>elasticsearch.yml</code> 配置文件，见备注部分，建议从 <code>&lt;node&gt;_elasticsearch_config_snippet.yml</code> 中直接复制粘贴，再根据实际情况更改部分内容。</p><p>注意：如果要保留 <code>http</code> 方式访问，参数 <code>searchguard.ssl.http.enabled</code> 要设为 <code>false</code>，否则访问会被拒绝。</p><p>测试环境这里选择关闭 <code>https</code> 访问，继续使用 <code>http</code> 访问。</p><h3 id="重启集群"><a href="# 重启集群" class="headerlink" title="重启集群"></a>重启集群 </h3><p> 此过程重要，需要仔细观察，必要时回退。</p><p>1、重启，并观察。</p><p>如果重启顺利，会在 <code>Elasticsearch</code> 节点日志中看到提示激活 <code>Search Guard</code> 的信息，不顺利的话可能是 <code>Search Guard</code> 相关的参数配置有误，检查修改即可。</p><p>如果还有其它无法解决的异常情况，考虑回退。</p><p>2、配置 <code>Search Guard</code>，所有的 <code>Elasticsearch</code> 节点都需要，可以提前做好。</p><p>在 <code>Elasticsearch</code> 的 <code>plugins/search-guard-5/sgconfig</code> 目录下，配置好 3 个与权限相关的文件，密码密文由 <code>hash.sh</code> 工具转换：</p><ul><li><code>sg_internal_users.yml</code>，用户定义，指定用户名、密码 </li><li><code>sg_roles.yml</code>，角色定义，用来限制权限，指定 2 种角色</li><li><code>sg_roles_mapping.yml</code>，映射关系，指定用户所属的角色，即完成真正的用户权限管理</li></ul><p> 这里使用的是默认的内部认证，即 <code>basic_internal_auth_domain</code>，在 <code>sgconfig/sg_config.yml</code> 中默认配置，如果使用其它认证方式【例如：<code>ODAP</code>、<code>kerberos_auth_domain</code>】，自行更改。</p><p>3、激活 <code>Search Guard</code>，只需要选择某 1 个 <code>Elasticsearch</code> 节点，并且需要前面 <code>client-admin</code> 客户端 2 个证书，在 <code>Elasticsearch</code> 集群重启后，在 <code>Elasticsearch</code> 节点的 <code>plugins/search-guard-5/tools</code> 目录下，执行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./sgadmin.sh -icl -nhnv -h dev4 -p 9300 -cd ../sgconfig/-cacert ../../../config/root-ca.pem -cert ../../../config/client-admin.pem -key ../../../config/client-admin.key -keypass JzgDTQIzoTDE</span><br></pre></td></tr></table></figure><p>注意各个参数的含义、取值，提前准备好即可：</p><ul><li>-h，主机名，默认 <code>localhost</code>，指定 1 个 <code>Elasticsearch</code> 节点即可，用于 <code>tcp</code> 通信 </li><li>-p，端口号，不是 <code>http</code>，是 <code>tcp</code> 的，默认 9300</li><li>-icl，忽略集群名字，不会严格校验</li><li>-nhnv，忽略主机名验证</li><li>-keypass，客户端密码，从 <code>client-admin</code> 客户端的 <code>readme</code> 文件中找</li><li>-cd，配置文件目录</li><li>-arc，接受红色状态的集群</li><li>-dci，删除 <code>searchguard</code> 索引，用于激活失败重新激活时删除已经创建的索引</li><li>-cn，集群名字</li><li>-sniff，嗅探节点</li><li>-er，设置索引副本数，默认自动扩展</li><li>-era，开启索引的副本自动扩展，<code>auto_expand_replicas</code></li><li>-dra，关闭索引的副本自动扩展，<code>auto_expand_replicas</code></li></ul><p> 备注 <code>Windows</code> 系统的操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.\sgadmin.bat -icl -nhnv -cd ..\sgconfig\ -cacert ..\..\..\config\root-ca.pem -cert ..\..\..\config\client-admin.pem -key ..\..\..\config\client-admin.key -keypass xx</span><br></pre></td></tr></table></figure><p>重启 <code>Elasticsearch</code> 节点后，可以看到 <code>Elasticsearch</code> 节点日志中，一直在提示执行 <code>sgsdmin.sh</code> 激活 <code>Search Guard</code> 插件：<code>Not yet initialized (you may need to run sgadmin)</code>。</p><p>如果此时有客户端访问 <code>Elasticsearch</code> 节点，会被拒绝：<code>speaks transport plaintext instead of ssl, will close the channel</code>。</p><p>整体日志内容截取如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2020-04-24T22:03:56,500][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44120) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:03:56,956][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:03:58,548][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:03:58,803][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:04:00,674][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:04:01,573][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44160) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:02,502][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:04:06,586][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44190) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:06,811][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:04:10,062][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:04:11,592][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44206) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:12,210][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:04:16,600][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44250) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:21,609][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44284) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:26,617][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44308) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:31,624][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44340) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:36,632][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44370) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:41,639][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44388) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:46,647][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44422) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:51,656][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44462) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:04:56,666][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44488) speaks transport plaintext instead of ssl, will close the channel</span><br><span class="line">[2020-04-24T22:05:01,624][ERROR][c.f.s.a.BackendRegistry] Not yet initialized (you may need to run sgadmin)</span><br><span class="line">[2020-04-24T22:05:01,677][WARN][c.f.s.s.t.SearchGuardSSLNettyTransport] [dev6] Someone (/192.168.1.62:44524) speaks transport plaintext instead of ssl, will close the channel</span><br></pre></td></tr></table></figure><p>由于 <code>Search Guard</code> 需要创建自己的索引，如果关闭了自动分配，新创建的索引从分片可能无法分配，<code>Search Guard</code> 激活过程会卡住，可以选择 <code>-esa</code> 参数，如果集群分片很多，需要开启，否则 <code>SearchGuard</code> 的主分片等待初始化需要很久。如果 <code>Elasticsearch</code> 集群默认是开启了自动分配，无需关心此问题。</p><p>通过测试发现 <code>Search Guard</code> 开启了分片自动扩展，实际初始时只有 1 个主分片，可以分配成功。但是注意副本数太多，自动扩展【<code>index.auto_expand_replicas</code> 设置为 <code>0-all</code>】是根据可用 <code>Elasticsearch</code> 节点来设置副本数的，实际中没必要【设置为 <code>false</code>】，并且把副本数减小【参数 <code>index.number_of_replicas</code>】，例如设置为 2 或者 3。</p><p>集群黄色的时候创建索引无法成功，一直在等待【大概率是因为测试环境的分片太多，加上刚刚重启，分配太慢了，等了至少 20 分钟还在等待，看 <code>Elasticsearch</code> 节点的日志，<code>put mapping</code> 超时】，后来等集群绿色的时候很快创建成功。</p><p>顺利执行 <code>sgadmin.sh</code> 激活插件的日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Search Guard Admin v5</span><br><span class="line">Will connect to dev6:9300 ... done</span><br><span class="line"> </span><br><span class="line">### LICENSE NOTICE Search Guard ###</span><br><span class="line"> </span><br><span class="line">If you use one or more of the following features in production</span><br><span class="line">make sure you have a valid Search Guard license</span><br><span class="line">(See https://floragunn.com/searchguard-validate-license)</span><br><span class="line"> </span><br><span class="line">* Kibana Multitenancy</span><br><span class="line">* LDAP authentication/authorization</span><br><span class="line">* Active Directory authentication/authorization</span><br><span class="line">* REST Management API</span><br><span class="line">* JSON Web Token (JWT) authentication/authorization</span><br><span class="line">* Kerberos authentication/authorization</span><br><span class="line">* Document- and Fieldlevel Security (DLS/FLS)</span><br><span class="line">* Auditlogging</span><br><span class="line"> </span><br><span class="line">In case of any doubt mail to &lt;sales@floragunn.com&gt;</span><br><span class="line">###################################</span><br><span class="line">Elasticsearch Version: 5.6.8</span><br><span class="line">Search Guard Version: 5.6.8-19.1</span><br><span class="line">Contacting elasticsearch cluster &apos;elasticsearch&apos; and wait for YELLOW clusterstate ...</span><br><span class="line">Clustername: dev_es_cluster</span><br><span class="line">Clusterstate: GREEN</span><br><span class="line">Number of nodes: 3</span><br><span class="line">Number of data nodes: 3</span><br><span class="line">searchguard index does not exists, attempt to create it ... done (0-all replicas)</span><br><span class="line">Populate config from /opt/package/elasticsearch-dev_es_cluster/plugins/search-guard-5/sgconfig</span><br><span class="line">Will update &apos;config&apos; with ../sgconfig/sg_config.yml</span><br><span class="line">   SUCC: Configuration for &apos;config&apos; created or updated</span><br><span class="line">Will update &apos;roles&apos; with ../sgconfig/sg_roles.yml</span><br><span class="line">   SUCC: Configuration for &apos;roles&apos; created or updated</span><br><span class="line">Will update &apos;rolesmapping&apos; with ../sgconfig/sg_roles_mapping.yml</span><br><span class="line">   SUCC: Configuration for &apos;rolesmapping&apos; created or updated</span><br><span class="line">Will update &apos;internalusers&apos; with ../sgconfig/sg_internal_users.yml</span><br><span class="line">   SUCC: Configuration for &apos;internalusers&apos; created or updated</span><br><span class="line">Will update &apos;actiongroups&apos; with ../sgconfig/sg_action_groups.yml</span><br><span class="line">   SUCC: Configuration for &apos;actiongroups&apos; created or updated</span><br><span class="line">Done with success</span><br></pre></td></tr></table></figure><p>4、后续修改权限，如果后续需要新增帐号、变更密码等操作，直接更新 <code>Search Guard</code> 的 3 个配置文件，重新执行一次激活步骤即可。</p><p>也就说 <code>Search Guard</code> 插件安装激活成功后，帐号权限可以使用 <code>sgadmin.sh</code> 管理，通过更新配置文件，支持添加、删除角色、帐号。</p><p>5、开启 <code>Elasticsearch</code> 重分配，在重启 <code>Elasticsearch</code> 集群恢复绿色之后再执行，如果集群默认是开启的，会自动开启，无需关心。</p><p>配置更新：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /_cluster/settings/</span><br><span class="line">&#123;</span><br><span class="line">    &quot;transient&quot;: &#123;</span><br><span class="line">        &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="简单验证"><a href="# 简单验证" class="headerlink" title="简单验证"></a>简单验证 </h3><p> 可以打开集群详情页面：<code>http://dev4:9200</code> ，提示需要输入用户名、密码。</p><p>或者打开 <code>Search Guard</code> 帐号详情页面进行简单验证：<code>http://dev4:9200/_searchguard/authinfo</code> ，提示需要输入用户名、密码查看帐号信息。</p><p>启动后，如果没有激活 <code>Search Guard</code>，无法查看 <code>Elasticsearch</code> 集群的状态，集群详情页面显示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Search Guard not initialized (SG11). See https://github.com/floragunncom/search-guard-docs/blob/master/sgadmin.md</span><br></pre></td></tr></table></figure><p>只要登录后，此时使用 <code>head</code> 插件或者 <code>sense</code> 工具都可以正常访问。</p><h3 id="部分配置信息"><a href="# 部分配置信息" class="headerlink" title="部分配置信息"></a>部分配置信息 </h3><p> 提示：</p><p>1、<code>network.host: 0.0.0.0</code>，避免执行 <code>sgadmin.sh</code> 命令时报错。</p><p>2、<code>xpack.security.enabled: false</code>，禁用 <code>xpack</code>。</p><p>3、<code>es-head</code> 支持：<code>http://[es-head]:9100/?base_uri=https://[es-node]:9200&amp;auth_user=xx&amp;auth_password=yy</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">http.cors.allow-headers: &quot;Authorization,X-Requested-With,-Content-Length,Content-Type&quot;</span><br></pre></td></tr></table></figure><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p> 以下配置文件信息仅供参考，实际部署时，<code>Elasticsearch</code> 配置信息随证书而生成，直接复制即可，权限配置信息由实际情况而定。</p><p>参考链接：<a href="https://docs.search-guard.com/v5/internal-users-database" target="_blank" rel="noopener">internal-users-database</a> 。</p><h2 id="用户配置"><a href="# 用户配置" class="headerlink" title="用户配置"></a>用户配置 </h2><p><code>sg_internal_users.yml</code> 为用户信息配置，包含用户名、密码及角色【这里的角色是后台角色，不是 <code>sg</code> 角色，目前用不到，不用配置，以最终的 <code>sg_roles_mapping.yml</code> 为准】。</p><p> 密码 <code>hash</code> 使用自带的脚本生成：<code>./tools/hasher.sh -p mycleartextpassword</code>。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">admin:</span><br><span class="line">    hash: $2a$12$qDsJtWx/IIkqhOVZXKh4M.bBLpjBmG6tL00vNhsfb4WS6wH7M1M3C</span><br><span class="line">    #password is: admin-!#%</span><br><span class="line">    #roles:</span><br><span class="line">    #    - admin</span><br><span class="line">    #    - can-read-all</span><br><span class="line">    #    - can-write-all</span><br><span class="line"></span><br><span class="line">custom:</span><br><span class="line">    hash: $2a$12$URJTPgsK9v7iYcq/dAYJVeH2t/VftkoHr2DraNnYS/ooqW3sZrJhS</span><br><span class="line">    #password is: custom-$@~</span><br><span class="line">    #roles:</span><br><span class="line">    #    - custom</span><br><span class="line">    #    - can-read-all</span><br></pre></td></tr></table></figure><h2 id="角色配置"><a href="# 角色配置" class="headerlink" title="角色配置"></a>角色配置 </h2><p><code>sg_roles.yml</code> 为角色权限配置【定义 2 种角色】，可自定义角色名及其权限。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">admin:</span><br><span class="line">    cluster:</span><br><span class="line">        - UNLIMITED</span><br><span class="line">    indices:</span><br><span class="line">        &apos;*&apos;:</span><br><span class="line">            &apos;*&apos;:</span><br><span class="line">                - UNLIMITED</span><br><span class="line"></span><br><span class="line">custom:</span><br><span class="line">    cluster:</span><br><span class="line">        - CLUSTER_MONITOR</span><br><span class="line">        - CLUSTER_COMPOSITE_OPS_RO</span><br><span class="line">        - indices:data/read/scroll*</span><br><span class="line">    indices:</span><br><span class="line">        &apos;*&apos;:</span><br><span class="line">            &apos;*&apos;:</span><br><span class="line">                - READ</span><br><span class="line">                - SEARCH</span><br></pre></td></tr></table></figure><h2 id="关联权限配置"><a href="# 关联权限配置" class="headerlink" title="关联权限配置"></a> 关联权限配置 </h2><p><code>sg_roles_mapping.yml</code> 角色、用户的映射【2 个用户分属于 2 种角色】，必须在这里配置映射，只在第一个 <code>sg_internal_users.yml</code> 文件配置用户的后台角色不生效。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">admin:</span><br><span class="line">    users:</span><br><span class="line">        - admin</span><br><span class="line"></span><br><span class="line">custom:</span><br><span class="line">    users:</span><br><span class="line">        - custom</span><br></pre></td></tr></table></figure><h2 id="Elasticsearch- 配置"><a href="#Elasticsearch- 配置" class="headerlink" title="Elasticsearch 配置"></a>Elasticsearch 配置</h2><p> 在 <code>elasticsearch.yml</code> 中增加以下与 <code>Search Guard</code> 相关的配置，以 <code>dev4</code> 作为示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">searchguard.ssl.transport.pemcert_filepath: dev4.pem</span><br><span class="line">searchguard.ssl.transport.pemkey_filepath: dev4.key</span><br><span class="line">searchguard.ssl.transport.pemkey_password: 9NdKF2PBoU8A</span><br><span class="line">searchguard.ssl.transport.pemtrustedcas_filepath: root-ca.pem</span><br><span class="line">searchguard.ssl.transport.enforce_hostname_verification: false</span><br><span class="line">searchguard.ssl.transport.resolve_hostname: false</span><br><span class="line">searchguard.ssl.http.enabled: false</span><br><span class="line">searchguard.ssl.http.pemcert_filepath: dev4_http.pem</span><br><span class="line">searchguard.ssl.http.pemkey_filepath: dev4_http.key</span><br><span class="line">searchguard.ssl.http.pemkey_password: YVI8mGC654TQ</span><br><span class="line">searchguard.ssl.http.pemtrustedcas_filepath: root-ca.pem</span><br><span class="line">searchguard.nodes_dn:</span><br><span class="line">- CN=dev4.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br><span class="line">- CN=dev5.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br><span class="line">- CN=dev6.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br><span class="line">searchguard.authcz.admin_dn:</span><br><span class="line">- CN=client-admin.playpi.com,OU=Ops,O=Playpi Com\, Inc.,DC=playpi,DC=com</span><br></pre></td></tr></table></figure><h2 id="一些问题"><a href="# 一些问题" class="headerlink" title="一些问题"></a>一些问题 </h2><p>0、在线生成证书文件，<code>Search Guard</code> 也提供了在线生成证书文件的工具，见：<a href="https://search-guard.com/tls-certificate-generator" target="_blank" rel="noopener">tls-certificate-generator</a> ，但是如果 <code>Elasticsearch</code> 节点很多，配置也就多，还是通过离线工具自己生成比较方便，效果是一样的。</p><p>1、嗅探问题，可以同步开启，集群节点自动更新，避免单个 <code>Elasticsearch</code> 节点出问题出现超时异常。</p><p><code>TransportClient</code> 方式有参数 <code>client.transport.sniff</code> 对应，设置为 <code>true</code> 即可。</p><p><code>HTTP</code> 方式有 <code>Sniffer.builder ()</code> 方法，可以使用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RestClientBuilder builder = RestClient.builder (hosts);</span><br><span class="line">RestHighLevelClient restHighLevelClient = new RestHighLevelClient (builder);</span><br><span class="line">Sniffer sniffer = Sniffer.builder (restHighLevelClient.getLowLevelClient ()).build ();</span><br></pre></td></tr></table></figure><p>2、节点变更新增证书</p><p> 如果有 <code>Elasticsearch</code> 节点被移除，则可以直接移除。但是如果有 <code>Elasticsearch</code> 节点需要被添加进入集群，证书怎么生成？</p><p>也是可以的，即可以手动生成证书文件，但是要保留当前生成的 <code>ca</code> 授权中心，即第一次生成证书时指定 <code>-ca</code> 参数输出到 <code>out</code> 目录的 <code>root-xx</code> 这 3 个文件。都很重要，一定要保留【要把 <code>config</code>、<code>out</code> 目录保留，甚至整个 <code>search-guard-tlstool</code> 目录保留，以后可以直接使用】。</p><p>在 <code>config</code> 中，就是一些配置文件，很重要，在 <code>out</code> 中，其中 <code>root-ca.readme</code> 用来查看密码，很重要，<code>root-ca.pem</code>、<code>root-ca.key</code> 是秘钥文件，也很重要。</p><p>以后需要添加 <code>Elasticsearch</code> 节点时，需要申请证书，必须利用这个 <code>ca</code> 授权中心，否则生成的证书无法使用。</p><p>准备完成后，具体操作：</p><p>把 <code>root-ca.readme</code> 中的密码配置在 <code>config/tlsconfig.yml</code> 文件的 <code>ca -&gt; root -&gt; pkPassword</code> 值上面【表示用这个密码、<code>root-ca</code> 来生成新的证书，第一次使用时配置的是 <code>auto</code>】，然后根据 <code>Elasticsearch</code> 节点名称配置 <code>nodes</code> 项。</p><p>然后生成证书时，去掉 <code>-ca</code> 参数，则会默认使用本地的 <code>ca</code>，即 <code>out</code> 里面的 <code>root-ca</code>，它会自动对比配置中的 <code>nodes</code> 节点和 <code>out</code> 目录中以前的证书文件，如果存在则跳过，不存在时会生成【即为新 <code>Elasticsearch</code> 节点生成可用的证书】。</p><p>备注 <code>Windows</code> 操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.\tools\sgtlstool.bat -c .\config\tlsconfig.yml -crt</span><br><span class="line"></span><br><span class="line"> 输出日志中会显示跳过了什么，生成了什么。</span><br><span class="line"></span><br><span class="line">xx.key does already exist. Skipping creation of certificate for yy</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Created 2 node certificates.</span><br><span class="line">Passwords for the private keys of the node certificates have been auto-generated.</span><br><span class="line">The passwords are stored in the config snippet files.</span><br></pre></td></tr></table></figure><p>2020-06-06 追加内容：</p><p>在实际操作中，发现了问题，导致无法新增节点，对于新生成的证书，由于 <code>nodesDn</code> 不在集群的列表中，无法被识别，总是有异常：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2020-06-04T22:53:18,346][WARN][o.e.d.z.UnicastZenPing] [xx_node0] [1] failed send ping to &#123;#zen_unicast_xx:9300_0#&#125;&#123;07QOvQd_Q9KEO7FIxcpzAQ&#125;&#123;xx&#125;&#123;192.168.1.x:9300&#125;</span><br><span class="line">java.lang.IllegalStateException: handshake failed with &#123;#zen_unicast_xx:9302_0#&#125;&#123;07QOvQd_Q9KEO7FIxcpzAQ&#125;&#123;xx&#125;&#123;192.168.20.x:9300&#125;</span><br><span class="line">	at org.elasticsearch.transport.TransportService.handshake (TransportService.java:413) ~[elasticsearch-5.6.8.jar:5.6.8]</span><br><span class="line">	at org.elasticsearch.transport.TransportService.handshake (TransportService.java:380) ~[elasticsearch-5.6.8.jar:5.6.8]</span><br><span class="line">	at org.elasticsearch.discovery.zen.UnicastZenPing$PingingRound.getOrConnect (UnicastZenPing.java:400) ~[elasticsearch-5.6.8.jar:5.6.8]</span><br><span class="line">	at org.elasticsearch.discovery.zen.UnicastZenPing$3.doRun (UnicastZenPing.java:507) [elasticsearch-5.6.8.jar:5.6.8]</span><br><span class="line">	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun (ThreadContext.java:674) [elasticsearch-5.6.8.jar:5.6.8]</span><br><span class="line">	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run (AbstractRunnable.java:37) [elasticsearch-5.6.8.jar:5.6.8]</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149) [?:1.8.0_161]</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624) [?:1.8.0_161]</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748) [?:1.8.0_161]</span><br><span class="line">Caused by: org.elasticsearch.transport.RemoteTransportException: [xx_master][192.168.20.x:9300][internal:transport/handshake]</span><br><span class="line">Caused by: org.elasticsearch.ElasticsearchException: Illegal parameter in http or transport request found.</span><br><span class="line">This means that one node try to connect to another with </span><br><span class="line">a non-node certificate (no OID or searchguard.nodes_dn incorrect configured) or that someone </span><br><span class="line">is spoofing requests. Check you TLS certificate setup as described here: See http://docs.search-guard.com/latest/troubleshooting-tls</span><br><span class="line">	at com.floragunn.searchguard.ssl.util.ExceptionUtils.createBadHeaderException (ExceptionUtils.java:58) ~[?:?]</span><br><span class="line">	at com.floragunn.searchguard.transport.SearchGuardRequestHandler.messageReceivedDecorate (SearchGuardRequestHandler.java:165) ~[?:?]</span><br></pre></td></tr></table></figure><p>此时去更新集群中所有节点的 <code>elasticsearch.yml</code> 配置文件中的 <code>searchguard.nodes_dn</code> 属性也没有用处了，新增节点始终无法加入集群。</p><p>通过分析，发现了问题所在：</p><p>一开始安装插件时，<code>searchguard.nodes_dn:</code> 配置项没有使用正则通配符的方式，导致后续的新增节点证书无法被识别，进而新增节点无法加入集群。</p><p>同时，一开始生成证书时没有使用 <code>nodeOid</code> 配置，导致无法使用 <code>searchguard.cert.oid</code> 来标记合法的证书，新增节点无法加入集群。</p><p>那么，解决方案也就有两种，一是重新配置 <code>searchguard.nodes_dn:</code> 项，并重启集群；二是使用 <code>nodeOid</code> 配置的方式重新生成证书，更改所有配置，重启集群。</p><p>3、单物理机多节点证书问题 </p><p> 开发环境中的 <code>Elasticsearch</code> 节点是一台物理机上有 2 个 <code>Elasticsearch</code> 节点，它们的节点名称不一样，但是 <code>ip</code> 是一样的，这种仍旧需要生成 2 份证书【每个 <code>Elasticsearch</code> 节点 1 份】，配置时全部使用 <code>Elasticsearch</code> 节点的名字来配置，多个 <code>node</code> 的 <code>ip</code> 地址可以一样。</p><p>4、用户更新 </p><p> 以后如果需要变更 <code>SaerchGuard</code> 的用户，例如新增、删除、添加权限，不需要重启 <code>Elasticsearch</code> 集群了，直接更改与权限相关的那几个配置文件就行，然后使用 <code>./sgadmin.sh</code> 工具重新激活一次即可。</p><p>5、<code>TransportClient</code> 方式使用起来比较麻烦，需要证书文件，以及很多配置【类似于 <code>Search Guard</code> 在 <code>Elasticsearch</code> 中的那些配置】，本质是通过 <code>tcp</code> 与 <code>Elasticsearch</code> 进行连接【所以不需要密码了，证书已经表明了合法用户】。详细使用方式以及权限管理参考：<a href="https://search-guard.com/searchguard-elasicsearch-transport-clients" target="_blank" rel="noopener">transport-clients</a> 。</p><p>条件描述：</p><blockquote><p>The Transport Client needs to identify itself against the cluster by sending a trusted TLS certificate<br>For that, you need to specify the location of your keystore and truststore containing the respective certificates<br>A role with appropriate permissions has to be configured in Search Guard, either based on the hostname of the client, or the DN of the certificate</p></blockquote><p>当然，集群层面也需要开启相应的配置。</p><p>首先在配置文件 <code>sgconfig/sg_config.yml</code> 中开启认证方式：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">transport_auth_domain:</span><br><span class="line">  enabled: true</span><br><span class="line">  order: 2</span><br><span class="line">  http_authenticator:</span><br><span class="line">  authentication_backend:</span><br><span class="line">    type: internal</span><br></pre></td></tr></table></figure><p>其次需要证书完整的 DN 信息，配置在 <code>sgconfig/sg_internal_users.yml</code> 文件中：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CN=root-ca.playpi.com, OU=Ops, O=&quot;Playpi Com, Inc.&quot;, DC=playpi, DC=com</span><br><span class="line">    hash: $2a$12$1HqHxm3QTfzwkse7vwzhFOV4gDv787cZ8BwmCwNEyJhn0CZoo8VVu</span><br></pre></td></tr></table></figure><p>当然，如果忘记了 <code>DN</code> 信息，可以使用 <code>Java</code> 自带的工具获取：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">keytool -printcert -file ./config/client-custom.pem</span><br></pre></td></tr></table></figure><p>同样，需要在角色映射文件 <code>sgconfig/sg_roles_mapping.yml</code> 中配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">custom:</span><br><span class="line">    users:</span><br><span class="line">        - custom</span><br><span class="line">        - &apos;root-ca.playpi.com, OU=Ops, O=&quot;Playpi Com, Inc.&quot;, DC=playpi, DC=com&apos;</span><br><span class="line"></span><br><span class="line"> 注意单引号的使用 </span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>HTTP</tag>
        <tag>SearchGuard</tag>
        <tag>TLS</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Github 的 WebHooks 实现代码自动更新</title>
    <url>/2019030601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>我的静态博客为了百度爬虫单独部署了一个镜像，放在了我的 VPS 上面【在 vultr 购买的主机】，并单独设置了二级域名 blog.playpi.org。但是，每次 GitHub 有新的提交时【基本每周都会有至少三次提交】，为了及时更新，我都会登录到 VPS 上面，到指定的项目下做一下拉取更新的操作，即执行 <strong>git pull</strong>。这样操作了三五次，我就有点不耐烦了，自己身为做技术的人，怎么能忍受这个呢，做法既低效又不优雅。于是，我就在想有没有更好的方法来实现自动拉取更新。一开始想到，直接在 VPS 起一个周期性脚本不就行了，比如每隔 1 分钟自动执行 <strong>git pull</strong>，但是立马又被我否定了，虽然做法很简单，但是太不优雅了，而且极大浪费 CPU。后来想到，GitHub 自带了 WebHooks 功能，概念类似于回调钩子，可以给 GitHub 的项目设置各种各样的行为，满足一定的场景才会触发【例如当有新的 push 时，就会向设置的 url 发送请求，并且在请求体中携带 push 的相关信息】。我的自动化构建就是这样的原理，每当 source 分支有提交时，都会通知 tavis-ci【这就是一个行为】，然后在 travis-ci 中设置好脚本，自动运行脚本，就完成了自动生成、部署的操作。</p><p>根据这个思路，就可以给 GitHub 的项目设置一个 WebHooks，每当 master 分支有提交时【代表着静态博客有更新了】，会根据设置的链接自动发送消息到 VPS 上面，然后 VPS 再执行拉取更新，这样的话就优雅多了。但是问题又来了，满足这种场景还需要在 VPS 设置一个后台服务，用来接收 GitHub 的消息通知并执行拉取更新的操作。我想了一下，既然 VPS 上面已经起了 Nginx 服务，那就要充分利用起来，给 Nginx 设置好反向代理，把指定的请求转给另外一个服务就行了。那这个服务怎么选呢，当然是选择 PHP 后台了，毕竟 PHP 号称世界上最好的语言， PHP 后台搭建起来也容易。本文就记录从基础环境安装配置到成功实现自动拉取更新的整个过程，本文涉及的系统环境是 CentOS 7 x64，软件版本会在操作中具体指明。</p><a id="more"></a><h1 id="配置服务器的 -PHP- 支持"><a href="# 配置服务器的 -PHP- 支持" class="headerlink" title="配置服务器的 PHP 支持"></a>配置服务器的 PHP 支持 </h1><p>VPS 上面的 Nginx 已经安装好了，就不再赘述过程，不清楚的可以参考我的另外一篇文章：<a href="https://www.playpi.org/2019010501.html">GitHub Pages 禁止百度蜘蛛爬取的问题</a> 。配置 PHP 的后台服务支持主要有三个步骤：一是配置安装 PHP，包括附加模块 PHP-FPM，二是配置启动 PHP-FPM 模块，三是配置重启 Nginx。由于我的机器资源问题【配置太低】，在这个过程踩了很多坑，我也会一一记录下来。</p><p> 毕竟我是新手，有很多地方不是太懂，所以先参考了官网和一些别人的博客，有时候看多了也会迷惑，有些内容大家描述的不一样，所以要结合自己的实际环境来操作，有些步骤是可以省略的。这些链接我放在这里给大家参考：<a href="https://secure.php.net/manual/zh/install.unix.nginx.php" target="_blank" rel="noopener">参考 PHP 官网 </a> 、<a href="https://segmentfault.com/a/1190000013344675" target="_blank" rel="noopener">CentOS 7.2 环境搭建实录 (第二章：php 安装)</a> 、<a href="https://learnku.com/articles/23694" target="_blank" rel="noopener">PHP-FPM 与 Nginx 的通信机制总结</a> 、<a href="https://qq52o.me/2482.html" target="_blank" rel="noopener"> 使用 Github 的 WebHooks 实现生产环境代码自动更新 </a> 。</p><p> 先安装软件仓库，我的已经安装好了，重复安装也没影响。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install epel-release</span><br></pre></td></tr></table></figure><h2 id="踩着坑安装 -PHP"><a href="# 踩着坑安装 -PHP" class="headerlink" title="踩着坑安装 PHP"></a>踩着坑安装 PHP</h2><p>1、下载指定版本的 PHP 源码，我这里选择了最新的版本 7.3.3，然后解压。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 下载 </span><br><span class="line">wget http://php.net/get/php-7.3.3.tar.gz/from/this/mirror -O ./php-7.3.3.tar.gz</span><br><span class="line">-- 解压 </span><br><span class="line">tar zxvf php-7.3.3.tar.gz</span><br></pre></td></tr></table></figure><p>2、configure【配置】，指定 PHP 安装目录【默认是 /usr/local/php，使用 <strong>--prefix</strong> 参数】和 PHP 配置目录【默认和 PHP 安装目录一致，使用 <strong>--with-config-file-path</strong> 参数】，我这里特意指定各自的目录，更方便管理。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 配置，并且开启 PHP-FPM 模块 [使用 --enable-fpm 参数]</span><br><span class="line">./configure --prefix=/site/php/  --with-config-file-path=/site/php/conf/  --enable-fpm</span><br></pre></td></tr></table></figure><p>遇到报错：<strong>configure: error: no acceptable C compiler found in $PATH</strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167nenhspj20jt06tglu.jpg" alt="缺少 c 编译器" title="缺少 c 编译器"></p><p>竟然缺少 c 编译器，那就安装吧。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 安装 gcc 编译器 </span><br><span class="line">yum install gcc</span><br></pre></td></tr></table></figure><p>安装 gcc 编译器成功 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167o1kn4dj21hc0mrgna.jpg" alt="安装 gcc 编译器 1" title="安装 gcc 编译器 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167ol7hilj21hc0mrjsx.jpg" alt="安装 gcc 编译器 2" title="安装 gcc 编译器 2"></p><p> 安装 gcc 编译器完成后，接着执行配置，又报错：<strong>configure: error: libxml2 not found. Please check your libxml2 installation.</strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167p2bqdaj20l20bxq3h.jpg" alt="缺少对应的依赖环境库" title="缺少对应的依赖环境库"></p><p>这肯定是缺少对应的依赖环境库，接着安装就行。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 安装 2 个，环境库 </span><br><span class="line">yum install libxml2</span><br><span class="line">yum install libxml2-devel -y</span><br></pre></td></tr></table></figure><p>安装依赖环境库成功 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167pq2doqj21hc0mrabc.jpg" alt="安装环境库完成" title="安装环境库完成"></p><p> 接着就重复上述的配置操作，顺利通过配置。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167qgfhy8j21hc0mrta5.jpg" alt="执行配置完成" title="执行配置完成"></p><p>3、编译、安装。<br></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 编译，安装一起进行 </span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p></p><p>遇到报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cc: internal compiler error: Killed (program cc1)</span><br><span class="line">Please submit a full bug report,</span><br><span class="line">with preprocessed source if appropriate.</span><br><span class="line">See &lt;http://bugzilla.redhat.com/bugzilla&gt; for instructions.</span><br><span class="line">make: *** [ext/fileinfo/libmagic/apprentice.lo] Error 1</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167qyojuij20rn0563yp.jpg" alt="编译安装内存不够报错" title="编译安装内存不够报错"></p><p>这是由于服务器内存小于 1G 所导致编译占用资源不足【好吧，我的服务器一共就 512M 的内存，当然不足】。解决办法：在配置【configure】参数后面加上一行内容 <strong>--disable-fileinfo</strong>，减少内存的开销。</p><p>接着执行编译安装又报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cc: internal compiler error: Killed (program cc1)</span><br><span class="line">Please submit a full bug report,</span><br><span class="line">with preprocessed source if appropriate.</span><br><span class="line">See &lt;http://bugzilla.redhat.com/bugzilla&gt; for instructions.</span><br><span class="line">make: *** [Zend/zend_execute.lo] Error 1</span><br></pre></td></tr></table></figure><p>这是因为虚拟内存不够用，我的主机只有 512M。没办法了，降低版本试试，先降为 v7.0.0【或者开启 swap 试试，后面发现不用了，切换低版本后就成功了】，接着重新下载、配置、编译、安装，从头再来一遍。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 下载的时候更改版本号就行 </span><br><span class="line">wget http://php.net/get/php-7.0.0.tar.gz/from/this/mirror -O ./php-7.0.0.tar.gz</span><br></pre></td></tr></table></figure><p>更换了版本后，一切操作都很顺利，就不再考虑开启 swap 了，最终执行编译、安装完成。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167tfxfarj20iv0mr3zs.jpg" alt="执行编译安装完成" title="执行编译安装完成"></p><h2 id="真正开始配置"><a href="# 真正开始配置" class="headerlink" title="真正开始配置"></a>真正开始配置 </h2><p> 配置、编译、安装完成后，开始编辑各个模块的配置文件，更改默认参数，包括配置 PHP 与 PHP-FPM 模块。确认配置无误，再启动对应的服务或者重新加载对应的配置【也可以使用命令验证参数配置是否正确，下文会有描述】。</p><h3 id="PHP- 配置文件"><a href="#PHP- 配置文件" class="headerlink" title="PHP 配置文件"></a>PHP 配置文件 </h3><p> 在执行编译安装的目录，复制配置文件 <strong>php.ini-development</strong> 粘贴到 PHP 的配置目录【如果一开始 configure 时没有显示指定 PHP 的配置目录，默认应该和 PHP 的安装目录一致，也就是要复制粘贴在 /usr/local/php 中，而我指定了 PHP 的配置目录 /site/php/conf】。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp php.ini-development/site/php/conf/php.ini</span><br></pre></td></tr></table></figure><p>更改 PHP 的配置文件，修改部分参数，更改 <strong>cgi.fix_pathinfo</strong> 的值为 0，以避免遭受恶意脚本注入的攻击。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /site/php/conf/php.ini</span><br><span class="line">cgi.fix_pathinfo=0</span><br></pre></td></tr></table></figure><h3 id="PHP-FPM- 配置文件"><a href="#PHP-FPM- 配置文件" class="headerlink" title="PHP-FPM 配置文件"></a>PHP-FPM 配置文件 </h3><p> 在 PHP 的安装目录中，找到 etc 目录【如果在一开始的 configure 时没有显示指定 PHP 的安装目录，默认安装在 /usr/local/php 中，则需要到此目录下寻找 etc 目录，而我指定了 PHP 的安装目录 /site/php/】，复制 PHP-FPM 模块的配置文件 <strong>php-fpm.conf.default</strong>，内容不需要更改。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- PHP 的附加模块的配置默认安装在了 etc 目录下 </span><br><span class="line">cd /site/php/etc</span><br><span class="line">cp php-fpm.conf.default php-fpm.conf</span><br></pre></td></tr></table></figure><p>在上面的 etc 目录中，继续复制 PHP-FPM 模块的默认配置文件。因为在上述的配置文件 <strong>php-fpm.conf</strong> 中，指定了 <strong>include=/site/php/etc/php-fpm.d/*.conf</strong>，也就是会从此目录 <strong>/site/php/etc/php-fpm.d/</strong> 加载多份有效的配置文件，至少要有一份存在，否则后续启动 PHP-FPM 的时候会报错。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 先直接使用模板，不改配置参数，后续需要更改用户和组 </span><br><span class="line">cp php-fpm.d/www.conf.default php-fpm.d/www.conf</span><br></pre></td></tr></table></figure><p>配置完成后，开始启动 PHP-FPM 模块，在 PHP 的安装目录中执行。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- PHP 的附加模块的脚本默认安装在了 sbin 目录下 </span><br><span class="line">-- 为了方便可以添加环境变量，把 sbin、bin 这 2 个目录都加进去 </span><br><span class="line">cd /site/php</span><br><span class="line">-- 配置文件合法性测试 </span><br><span class="line">./sbin/php-fpm -t</span><br><span class="line">-- 启动，现在还不能使用 service php-fpm start 的方式，因为没有把此模块配置到系统里面 </span><br><span class="line">./sbin/php-fpm</span><br><span class="line">-- 检验是否启动 </span><br><span class="line">ps aux|grep php-fpm</span><br></pre></td></tr></table></figure><p>配置文件合法性检测 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167zej3snj20ja02t0sm.jpg" alt="配置文件合法性检测" title="配置文件合法性检测"></p><p> 可以看到正常启动了 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g167zqai4zj20nb03zt8s.jpg" alt="PHP-FPM 启动成功" title="PHP-FPM 启动成功"></p><p> 那怎么关闭以及重启呢，PHP 5.3.3 以后的 PHP-FPM 模块不再支持 PHP-FPM 以前具有的 <strong>./sbin/php-fpm (start|stop|reload)</strong> 等命令，所以不要再看这种古老的命令了，需要使用信号控制：</p><ul><li>INT，TERM，立刻终止 </li><li>QUIT 平滑终止</li><li>USR1 重新打开日志文件</li><li>USR2 平滑重载所有 worker 进程并重新载入配置和二进制模块</li></ul><p> 注意，这里的信号标识和 Unix 系统中的一样，被 kill 命令所使用，其中 USR1、USR2 是用户自定义信号，PHP-FPM 模块需要自定义实现，仅供参考。</p><p>其中，根据 Unix 基础知识，INT【2】表示中断信号，等价于 Ctrl + C，TERM【15】表示终止信号【清除后正常终止，不同于编号 9 KILL 的强制终止而不清除】，QUIT【3】表示退出信号，等价于 Ctrl + \，USR1【10】、USR2【12】这 2 个表示用户自定义信号。</p><p>所以可以使用命令 <strong>kill -INT pid</strong> 来停止 PHP-FPM 模块，pid 的值可以使用 <strong>ps aux|grep php-fpm</strong> 获取。当然，也可以使用 <strong>kill -INT pid 配置文件路径 </strong>来停止 PHP-FPM 模块，pid 配置文件路径 可以在 php-fpm.conf 中查看，<strong>pid 参数 </strong>，默认是关闭的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1681vrhobj20om071mxh.jpg" alt="使用信号控制的方式停止 PHP-FPM" title="使用信号控制的方式停止 PHP-FPM"></p><p>为了能使用 <strong>service php-fpm start|stop|restart|reload</strong> 的方式来进行启动、停止、重启、重载配置，这种方式显得优雅，需要把此模块配置到系统里面。在 PHP 的编译安装目录，复制文件 <strong>sapi/fpm/init.d.php-fpm</strong> ，粘贴到系统指定的目录即可。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /site/php-7.0.0</span><br><span class="line">-- 复制文件 </span><br><span class="line">cp sapi/fpm/init.d.php-fpm/etc/init.d/php-fpm</span><br><span class="line">-- 添加执行权限 </span><br><span class="line">chmod +x /etc/init.d/php-fpm</span><br><span class="line">-- 添加服务 </span><br><span class="line">chkconfig --add php-fpm</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g16828okbij20nq06zaaf.jpg" alt="使用 service 操作 PHP-FPM" title="使用 service 操作 PHP-FPM"></p><h3 id="Nginx- 的配置文件"><a href="#Nginx- 的配置文件" class="headerlink" title="Nginx 的配置文件"></a>Nginx 的配置文件 </h3><p> 接下来就是更改 Nginx 的配置文件，让 Nginx 支持 PHP 请求，并且同时设置好反向代理，把请求转给 PHP-FPM 模块处理【前提是在不影响 html 请求的情况下】，在 server 中增加一个配置 location。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 打开配置文件 </span><br><span class="line">vi /etc/nginx/nginx.conf</span><br><span class="line">-- 更改 server 模块的内容，增加 php 的配置 </span><br><span class="line">-- 80 端口就不用管了，直接在 443 端口下配置 </span><br><span class="line">location ~* \.php$ &#123;</span><br><span class="line">      fastcgi_index   index.php;</span><br><span class="line">      fastcgi_pass    127.0.0.1:9000;</span><br><span class="line">      include         fastcgi_params;</span><br><span class="line">      fastcgi_param   SCRIPT_FILENAME    $document_root$fastcgi_script_name;</span><br><span class="line">      fastcgi_param   SCRIPT_NAME        $fastcgi_script_name;</span><br><span class="line">    &#125;</span><br><span class="line">-- 重新加载 nginx 配置，不需要重启 </span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><p>这样配置好，就会把所有的 PHP 请求转给 PHP-FPM 模块处理，同时并不会影响原来的 html 请求。</p><h3 id="额外优化配置项"><a href="# 额外优化配置项" class="headerlink" title="额外优化配置项"></a>额外优化配置项 </h3><p> 此外，还有一些环境变量配置、开机启动配置，这里就不再赘述了，这些配置好了可以方便后续的命令简化，不配置也是可以的。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 设置开机启动的 chkconfig 方法，以下是添加服务 </span><br><span class="line">cp sapi/fpm/init.d.php-fpm/etc/init.d/php-fpm</span><br><span class="line">chmod +x /etc/init.d/php-fpm</span><br><span class="line">chkconfig --add php-fpm</span><br><span class="line">-- 设置开机启动 </span><br><span class="line">chkconfig php-fpm on</span><br><span class="line">-- 添加环境变量，之后 php 的相关命令就可以直接使用了 </span><br><span class="line">vi /etc/profile</span><br><span class="line">export PATH=$PATH:/site/php/bin:/site/php/sbin</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h1 id="PHP- 脚本"><a href="#PHP- 脚本" class="headerlink" title="PHP 脚本"></a>PHP 脚本 </h1><p> 先在静态站点的根目录下，添加默认的 index.php 文件，用来测试，内容如下，内容的意思是输出 PHP 的所有信息。注意，PHP 文件的格式是以 <strong>&lt;?php</strong> 开头，以 <strong>?&gt;</strong> 结尾。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi index.php</span><br><span class="line">&lt;?php phpinfo (); ?&gt;</span><br></pre></td></tr></table></figure><p>打开浏览器访问，可以看到成功，这就代表着 PHP 与 Nginx 的配置都没有问题，已经能正常提供服务。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1685gzg77j21hk0s6did.jpg" alt="成功访问 index.php" title="成功访问 index.php"></p><p>接下来就来测试一下复杂的脚本，可以用来自动拉取 GitHub 的提交。再创建一个 auto_pull.php 文件，内容如下，会自动到执行目录拉取 GitHub 的更新，这样就能实现镜像的自动更新了，还加入了秘钥验证【先不用管功能性是否可用，而是先测试一下复杂的 PHP 脚本能不能正常执行，脚本内容后续还要优化更改】，内容大致如下。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi auto_pull.php</span><br><span class="line">&lt;?php</span><br><span class="line">// 生产环境 web 目录 </span><br><span class="line">$target = &apos;/site/iplaypi.github.io&apos;;</span><br><span class="line">// 密钥，验证 GitHub 的请求 </span><br><span class="line">$secret = &quot;test666&quot;;</span><br><span class="line">// 获取 GitHub 发送的内容 </span><br><span class="line">$json = file_get_contents (&apos;php://input&apos;);</span><br><span class="line">$content = json_decode ($json, true);</span><br><span class="line">// GitHub 发送过来的签名 </span><br><span class="line">$signature = $_SERVER [&apos;HTTP_X_HUB_SIGNATURE&apos;];</span><br><span class="line">if (!$signature) &#123;</span><br><span class="line">   return http_response_code (404);</span><br><span class="line">&#125;</span><br><span class="line">list ($algo, $hash) = explode (&apos;=&apos;, $signature, 2);</span><br><span class="line">// 计算签名 </span><br><span class="line">$payloadHash = hash_hmac ($algo, $json, $secret);</span><br><span class="line">// 获取分支名字 </span><br><span class="line">$branch = $content [&apos;ref&apos;];</span><br><span class="line">// 判断签名是否匹配，分支是否匹配 </span><br><span class="line">if ($hash === $payloadHash &amp;&amp; &apos;refs/heads/master&apos; === $branch) &#123;</span><br><span class="line">    $cmd = &quot;cd $target &amp;&amp; git pull&quot;;</span><br><span class="line">    $res = shell_exec ($cmd);</span><br><span class="line">    $res_log = &apos;Success:&apos;.PHP_EOL;</span><br><span class="line">    $res_log .= $content [&apos;head_commit&apos;][&apos;committer&apos;][&apos;name&apos;] . &apos; 在 & apos; . date (&apos;Y-m-d H:i:s&apos;) . &apos; 向 & apos; . $content [&apos;repository&apos;][&apos;name&apos;] . &apos; 项目的 & apos; . $content [&apos;ref&apos;] . &apos; 分支 push 了 & apos; . count ($content [&apos;commits&apos;]) . &apos; 个 commit：&apos; . PHP_EOL;</span><br><span class="line">    $res_log .= $res.PHP_EOL;</span><br><span class="line">    $res_log .= &apos;=======================================================================&apos;.PHP_EOL;</span><br><span class="line">    echo $res_log;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    $res_log  = &apos;Error:&apos;.PHP_EOL;</span><br><span class="line">    $res_log .= $content [&apos;head_commit&apos;][&apos;committer&apos;][&apos;name&apos;] . &apos; 在 & apos; . date (&apos;Y-m-d H:i:s&apos;) . &apos; 向 & apos; . $content [&apos;repository&apos;][&apos;name&apos;] . &apos; 项目的 & apos; . $content [&apos;ref&apos;] . &apos; 分支 push 了 & apos; . count ($content [&apos;commits&apos;]) . &apos; 个 commit：&apos; . PHP_EOL;</span><br><span class="line">    $res_log .= &apos; 密钥不正确或者分支不是 master, 不能 pull&apos;.PHP_EOL;</span><br><span class="line">    $res_log .= &apos;=======================================================================&apos;.PHP_EOL;</span><br><span class="line">    echo $res_log;</span><br><span class="line">&#125;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure><p>接下来先手工测试一下 PHP 文件的访问是否正常，可以使用 curl 模拟请求，或者直接使用 GitHub 的 WebHooks 请求。我这里为了简单，先使用 curl 命令来测试，后续的步骤才使用 GitHub 来真正测试。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -H &apos;X-Hub-Signature:test&apos;  https://blog.playpi.org/auto_pull.php</span><br></pre></td></tr></table></figure><p>可以看到，访问正常，先不管功能上能不能正常实现，至少保证 PHP 可以正常提供服务，后面会和 GitHub 对接。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g168ab7ih9j20r206awep.jpg" alt="使用 curl 模拟访问正常" title="使用 curl 模拟访问正常"></p><h1 id="测试 -WebHooks- 效果"><a href="# 测试 -WebHooks- 效果" class="headerlink" title="测试 WebHooks 效果"></a>测试 WebHooks 效果 </h1><p> 在 GitHub 中使用 WebHooks，为了表现出它的效果是什么样，我画了一个流程图，可以直观地看到它优雅的工作方式。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g168bmzii3j20lo0jwwfi.jpg" alt="WebHooks 效果流程图" title="WebHooks 效果流程图"></p><p>在上一步骤中，自动拉取更新的脚本已经写好，并且使用 curl 测试过模拟访问可用，那接下来就测试功能是否可用，当然，踩坑是避免不了的，优化脚本内容也是必要的。特别要注意用户权限和脚本内容这两方面，用户权限方面我直接使用 nginx 用户，踩坑比较少，脚本内容方面要保证你的服务器支持 <strong>shell_exec ()</strong> 这个 PHP 函数，可以在 <strong>index.php</strong> 文件中加一段代码 <strong>echo shell_exec (‘ls -la’);</strong>，测试一下。我的机器经过测试时支持的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g168e04yz0j21hk0s6gs3.jpg" alt="测试 shell_exec 函数" title="测试 shell_exec 函数"></p><h2 id="在 -GitHub- 设置 -WebHooks"><a href="# 在 -GitHub- 设置 -WebHooks" class="headerlink" title="在 GitHub 设置 WebHooks"></a>在 GitHub 设置 WebHooks</h2><p>在 GitHub 对应项目的设置【Settings】中，找到 <strong>Webhooks</strong> 选项，可以看到已经有一些设置完成的 WebHook，这里面就包括 travis-ci 的自动构建配置。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1691o58jij20ty0en755.jpg" alt="Webhooks 列表" title="Webhooks 列表"></p><p>然后点击新建按钮，创建一个新的 WebHook【这个过程需要重新填写密码确认】，填写必要的参数，url 地址、秘钥、触发的事件，然后确认保存即可。注意，秘钥只是为了测试使用，实际应用时请更改，包括 WebHooks 的秘钥设置和 PHP 脚本里面的秘钥字符串。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1692ybibgj20su0qxgn6.jpg" alt="新建 WebHook" title="新建 WebHook"></p><p>如果是第一次创建完成，还没有触发请求的历史记录，可以先手动在 master 分支做一次变更提交，然后就会触发一次 WebHooks 事件。我这里已经有触发历史了，拿一个出来看就行了。注意，为了方便测试，只要有一次请求就行了，因为如果后续更改了脚本，不用再手动向 master 分支做一次变更提交，可以直接点击重新发送【redeliver】。<br>触发请求的信息，就是 http 请求头和请求体 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1694gk8tdj20pl0pi3zt.jpg" alt="WebHook 触发请求携带的信息" title="WebHook 触发请求携带的信息"></p><p>VPS 的 PHP 后台服务返回的信息，可以看到正常处理了 WebHooks 请求，但是没有做拉取更新的操作，原因可能是秘钥不对或者分支不对。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1694ke4dbj20or0judgk.jpg" alt="PHP 后台服务返回的信息" title="PHP 后台服务返回的信息"></p><h2 id="测试功能是否可用"><a href="# 测试功能是否可用" class="headerlink" title="测试功能是否可用"></a> 测试功能是否可用 </h2><p> 以下内容所需要的 PHP 脚本：index.php、auto_pull.php 。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">echo shell_exec (&quot;id -a&quot;);</span><br><span class="line">echo shell_exec (&apos;ls -la&apos;);</span><br><span class="line">phpinfo ();</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">// 生产环境 web 目录 </span><br><span class="line">$target = &apos;/site/iplaypi.github.io&apos;;</span><br><span class="line">// 密钥，验证 GitHub 的请求 </span><br><span class="line">$secret = &quot;test666&quot;;</span><br><span class="line">// 获取 GitHub 发送的内容，解析 </span><br><span class="line">$json = file_get_contents (&apos;php://input&apos;);</span><br><span class="line">$content = json_decode ($json, true);</span><br><span class="line">// GitHub 发送过来的签名，一定要大写，虽然 http 请求里面是驼峰法命名的 </span><br><span class="line">$signature = $_SERVER [&apos;HTTP_X_HUB_SIGNATURE&apos;];</span><br><span class="line">if (!$signature) &#123;</span><br><span class="line">   return http_response_code (404);</span><br><span class="line">&#125;</span><br><span class="line">// 使用等号分割，得到算法和签名 </span><br><span class="line">list ($algo, $hash) = explode (&apos;=&apos;, $signature, 2);</span><br><span class="line">// 在本机计算签名 </span><br><span class="line">$payloadHash = hash_hmac ($algo, $json, $secret);</span><br><span class="line">// 获取分支名字 </span><br><span class="line">$branch = $content [&apos;ref&apos;];</span><br><span class="line">// 日志内容 </span><br><span class="line">$logMessage = &apos;[&apos; . $content [&apos;head_commit&apos;][&apos;committer&apos;][&apos;name&apos;] . &apos;] 在 [&apos; . date (&apos;Y-m-d H:i:s&apos;) . &apos;] 向项目 [&apos; . $content [&apos;repository&apos;][&apos;name&apos;] . &apos;] 的分支 [&apos; . $content [&apos;ref&apos;] . &apos;] push 了 [&apos; . count ($content [&apos;commits&apos;]) . &apos;] 个 commit&apos; . PHP_EOL;</span><br><span class="line">$logMessage .= &apos;ret:[&apos; . $content [&apos;ref&apos;] . &apos;],payloadHash:[&apos; . $payloadHash . &apos;]&apos; . PHP_EOL;</span><br><span class="line">// 判断签名是否匹配，分支是否匹配 </span><br><span class="line">if ($hash === $payloadHash &amp;&amp; &apos;refs/heads/master&apos; === $branch) &#123;</span><br><span class="line">    // 增加执行脚本日志重定向输出到文件 </span><br><span class="line">    $cmd = &quot;cd $target &amp;&amp; git pull&quot;;</span><br><span class="line">    $res = shell_exec ($cmd);</span><br><span class="line">    $res_log = &apos;Success:&apos; . PHP_EOL;</span><br><span class="line">    $res_log .= $logMessage;</span><br><span class="line">    $res_log .= $res . PHP_EOL;</span><br><span class="line">    $res_log .= &apos;=======================================================================&apos;.PHP_EOL;</span><br><span class="line">    echo $res_log;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    $res_log  = &apos;Error:&apos; . PHP_EOL;</span><br><span class="line">    $res_log .= $logMessage;</span><br><span class="line">    $res_log .= &apos; 密钥不正确或者分支不是 master, 不能 pull&apos; . PHP_EOL;</span><br><span class="line">    $res_log .= &apos;=======================================================================&apos;.PHP_EOL;</span><br><span class="line">    echo $res_log;</span><br><span class="line">&#125;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure><p>上面已经测试了访问正常，但是为了保证 PHP 脚本的功能正常执行，接下来要优化 PHP 脚本内容了。我分析一下，根据脚本的内容，只有当秘钥正确并且当前变更的分支是 master 时才会执行拉取更新操作，看返回结果也是这样的。当前没有执行拉取更新的操作，但是我的这一个触发通知里面是表明了 master 分支【根据 ref 参数】，那就是秘钥的问题了，需要详细看一下秘钥计算的那段 PHP 代码。如果怕麻烦，直接把加密这个流程去掉【会导致恶意请求，浪费 CPU 资源】，GitHub 并没有要求一定要填写秘钥，但是我为了安全，仍旧填写。</p><p>我看了一下代码，并没有发现问题，于是加日志把后台处理的一些结果返回，看看哪里出问题了。最终发现竟然是分支名字的问题，PHP 代码通过 <strong>$content</strong> 没有获取到任何内容，包括分支名字、项目名字、提交信息等，而秘钥签名的处理是正常的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1697xx5vaj20nl0g00tb.jpg" alt="错误日志返回" title="错误日志返回"></p><p>思考了一下，然后我就发现，竟然是创建 WebHooks 的时候内容传输类型【Content type】设置错误，不能使用默认的，要设置为 <strong>application/json</strong>，否则后台的 PHP 代码处理不了内容解析，获取的全部是空内容。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g1699fp81lj20uf0oiwg0.jpg" alt="内容传输类型设置错误" title="内容传输类型设置错误"></p><p>好，一切准备就绪，再来试一次，问题又来了，果然用户权限问题是逃不了的。这个问题我早有防备，本质就是没有设置好 PHP 的用户，导致 PHP 执行脚本的时候，没有权限获取与 Git 有关的信息【执行脚本的用户没有自己的家目录，也没有存储 ssh 认证信息】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g169b32samj20pj0hpwf4.jpg" alt="PHP 执行权限问题" title="PHP 执行权限问题"></p><p>接下来就简单了，去设置 PHP 的执行用户，可能还要涉及到 Nginx。先在原先的 <strong>index.php</strong> 脚本中增加内容 <strong>echo shell_exec (“id -a”);</strong>，用来输出当前用户信息，发现是 nobody，那就和我想的一样了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g169d8f9fbj20sa0fsdi8.jpg" alt="输出 PHP 的执行用户信息" title="输出 PHP 的执行用户信息"></p><p>为了规范起来便于管理，还是改为和 Nginx 同一个用户比较好，还记得 PHP-FPM 模块的配置文件吗 <strong>/site/php/etc/php-fpm.d/www.conf </strong>，去里面找到用户和组的配置项 <strong>user、group</strong>，把 nobody 改为 nginx。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g169e1crm2j20gl02qwec.jpg" alt="设置 PHP-FPM 的用户名和组" title="设置 PHP-FPM 的用户名和组"></p><p>为什么选择 nginx 用户呢，因为我的 Nginx 服务使用的就是 nginx 用户，这样就不用再创建一个用户了，可以去配置文件 <strong>/etc/nginx/nginx.conf</strong> 里面查看。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g169fau9zzj20c806amx2.jpg" alt="查看 Nginx 的用户" title="查看 Nginx 的用户"></p><p>其实，用户的设置是随意的，如果把 PHP-FPM 的用户设置为 root 更方便，但是这样有很大风险，所以不要这么做。如果非要使用 nobody 也是可以的，我只是为了方便管理用户，和 Nginx 服务共同使用一个用户。一切配置完成后别忘记重启 PHP-FPM 模块。</p><p>接着就是最重要的步骤了，把本地的 GitHub 项目所属用户设置为 nginx，并且保证 nginx 用户的家目录有 ssh 认证相关的秘钥信息，这样在以后的自动拉取更新时才能畅通无阻。我把原先的项目删掉，然后使用 sudo 命令给 nginx 用户生成 ssh 认证信息，并且重新克隆项目，克隆的同时指定所属用户为 nginx。【由于用户 nginx 没有登录 Shell 的权限，所以不能直接使用 nginx 用户登录后再操作的方式解决】</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 目录不存在先创建，赋给 nginx 用户权限 </span><br><span class="line">mkdir -p /home/nginx/.ssh/</span><br><span class="line">chown nginx:nginx -R /home/nginx/.ssh/</span><br><span class="line">-- H 参数表示设置家目录环境，u 参数表示用户名 </span><br><span class="line">cd /site/</span><br><span class="line">sudo -Hu nginx ssh-keygen -t rsa -C &quot;plapyi@qq.com&quot;</span><br><span class="line">sudo -Hu nginx git clone https://github.com/iplaypi/iplaypi.github.io.git</span><br><span class="line">-- 如果没有 iplaypi.github.io 目录的权限，也要赋予 nginx 用户 </span><br><span class="line">mkdir iplaypi.github.io</span><br><span class="line">chown nginx:nginx iplaypi.github.io</span><br></pre></td></tr></table></figure><p>好，一切准备就绪，我再来试一次。可以看到，完美执行，热泪盈眶。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g169gkpo0cj20s30nfgmm.jpg" alt="解决所有问题后成功实现自动拉取" title="解决所有问题后成功实现自动拉取"></p><p>为了方便，本来我把这 2 个 php 文件直接放在项目里面了，放在 source 分支，再更新一下 travis-ci 的配置文件，把它们提交到 master 分支去。但是这样做的风险就是把秘钥暴露出去了，显然不可取，所以折中的办法就是把这 2 个文件当做模板，把秘钥隐去，放在 source 分支，以后用的时候直接复制就行了。</p><p>我想了一下，这个秘钥哪怕暴露出去看起来也没有什么大的危害，除了能伪造请求，产生多余的 pull 操作，浪费机器资源。</p><p>这里面还有一点需要注意，请确保 iplaypi.github.io 目录里面的文件特别是 auto_pull.php 文件的所属用户都是 nginx，主要是因为 php 脚本里面有 pull 操作，如果有文件所属用户不是 nginx，会导致 pull 时因为文件覆盖的权限问题而失败。而且，失败了也没有错误信息【不像前面的 Permission denied 有提示】，也就是说在 GitHub 里面的 WebHook 查看返回日志是看不到错误信息的，一片空白，说明没有成功 pull。我就遇到了这个问题，找不到原因折腾了很久，最后发现是文件权限的问题。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
        <tag>PHP</tag>
        <tag>WebHooks</tag>
        <tag>自动更新</tag>
        <tag>钩子</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Vultr 搭建 Shadowsocks（VPS 搭建 SS）</title>
    <url>/2018111601.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>本文讲述通过 <code>Vultr</code> 云主机搭建 <code>Shadowsocks</code> 的过程，图文并茂，非常详细。当然，关于云主机有很多 <code>VPS</code> 都可以选择，例如 <strong>搬瓦工 </strong>、<strong>Godaddy</strong>、<strong>Vultr</strong>，读者可以根据价格、配置、地区、操作系统等因素自由选择，但我还是推荐 <code>Vultr</code>，因为它扣费灵活、主机管理灵活、价格优惠，并且还支持支付宝和微信支付，简直太方便了。</p><p><strong>声明 </strong>：2019 年 08 月 09 日发现 <code>Vultr</code> 官方不会再赠送 <code>$10</code> 的代金券给新注册用户，只会给我发放代金券，但是 <code>$25</code> 的代金券仍然有效，请读者选择 <code>$25</code> 对应的链接打开注册，以免错失了代金券。</p><a id="more"></a><h1 id="主机购买"><a href="# 主机购买" class="headerlink" title="主机购买"></a>主机购买 </h1><p> 使用 <code>Vultr</code> 的云主机，最好选择洛杉矶地区的或者日本的服务器，我亲自测试这两个地区的服务器最稳定，已经推荐给很多人，而且网速相对来说较好，我的推广链接【可以获取 10 美元的代金券，只要充值 10 美元就能使用】：<a href="https://www.vultr.com/?ref=7443790" target="_blank" rel="noopener">我的 10 美元推广链接 </a> ，官网链接也在这里：<a href="https://my.vultr.com" target="_blank" rel="noopener">Vultr</a> 。</p><p> 这里再多说点，如果使用上面的推广链接注册 <code>Vultr</code> 帐号，可以获取 10 美元的代金券，需要在 30 天之内使用，使用的条件就是充值 10 美元以上的钱。例如充值 10 美元就会获取 20 美元的帐号余额，这些钱如果购买 3.5 美元的主机可以使用半年了，挺划算的。</p><p>此外还有一个限时的大优惠，如果准备长期使用 <code>Vultr</code>，肯定要充值多一点，我这里有一个限时的推广链接：<a href="https://www.vultr.com/?ref=8421997-6G" target="_blank" rel="noopener">我的 25 美元推广链接 </a> ，可以获取 100 美元的代金券，使用条件就是 <strong> 充值 25 美元以上的金额 </strong>。假如充值了 25 美元，总共获取 100 美元入账【账号需要活跃 30 天】，购买 3.5 美元的主机可以使用 29 个月，适合长期使用 <code>Vultr</code> 的。</p><p>以下列举 <code>Vultr</code> 的五大好处：</p><ul><li><strong>扣费灵活 </strong>，<code>Vultr</code> 有一个好处就是主机的费用并不是按照月份扣除的，而是按照天扣除的，每天扣除的费用是 <strong>月租 / 30</strong>。例如你的主机只用了 10 天，然后销毁不用了，实际只会扣除月租 1/3 的钱，这种方式很是灵活，哪怕主机的 <code>IP</code> 地址被屏蔽了也可以销毁重新生成一个，并不会浪费钱。它不像国内的云服务商，一般是按照月份扣费的。</li><li><strong>主机管理灵活 </strong>，它不像国内的云服务商，购买一台云主机后，直接先扣费，然后分配一台主机，<code>IP</code> 地址是固定的，如果有问题只能重启。而在 <code>Vultr</code> 中是可以随意创建、销毁虚拟主机的，根据你自己的需求，选择配置、主机机房位置、操作系统，几分钟就可以生成一台主机，如果用了几天觉得不好，或者 <code>IP</code> 地址被封，再销毁重新创建即可，<code>Vultr</code> 只会扣除你几天的费用，非常人性化。</li><li><strong>价格优惠 </strong>，根据配置的不同，价格有多个档次，有 <code>$2.5 / 月 </code>（只有 <code>IP6</code> 地址）、<code>$3.5 / 月</code>、<code>$5 / 月</code> 等等，更贵的也有，一般个人使用选择这三个中的一个就够用了，但是要注意便宜的经常售罄，而且最便宜的只支持 <code>IP6</code>，慎用。大家如果看到没有便宜的主机了不用着急，可以先买了贵的用着，反正费用是按照天数扣除的，等后续发现便宜的套餐赶紧购买，同时把贵的主机给销毁，不会亏钱的。</li><li><strong> 付费方式灵活 </strong>，付费方式除了支持常见的 <strong>Paypal</strong>、<strong> 信用卡 </strong>等方式，它还支持 <strong>比特比 </strong>、<strong> 支付宝 </strong>、<strong> 微信 </strong>等方式。就问你是不是很人性化，作为一家国外的公司，还特意支持 <strong>支付宝 </strong>、<strong> 微信 </strong>的方式支付，也从侧面反映了随着中国的日益强大，中国的电子支付方式正在走向全球，越来越流行。</li><li><strong>机房分布全球 </strong>，它的机房位置遍布全球，例如 <strong>日本 </strong>、<strong> 新加坡 </strong>、<strong> 澳大利亚 </strong>、<strong> 美国 </strong>、<strong> 德国 </strong>、<strong> 英国 </strong>、<strong> 加拿大 </strong>，读者根据网络的需求可以灵活选择。</li></ul><p>关于 <code>Vultr</code> 云主机的生成以及 <code>Vultr</code> 系统的常用功能使用，由于不在这篇博客的介绍内容中，所以在此不再赘述。但是，我会在以后的某一天把它补充完整，并放上链接：<a href="https://www.playpi.org/2019072801.html">使用 Vultr 创建云主机详细步骤 </a> 。</p><h1 id="Shadowsocks- 服务安装"><a href="#Shadowsocks- 服务安装" class="headerlink" title="Shadowsocks 服务安装"></a>Shadowsocks 服务安装</h1><p> 下文中涉及的 <code>shadowsocks</code> 配置文件模板已经被我上传至 <code>GitHub</code>，读者可以提前下载参考：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20181116" target="_blank" rel="noopener">shadowsocks_conf</a> ，有两份，一份是单用户的【只开一个端口】，一份是多用户的【开多个端口】。</p><p>另外还有一份安装过程的总结文档：<code>shadowsocks_install_guide</code>，给有技术基础的读者使用，可以参考，按照步骤安装即可。</p><p>再说明一下，如果有技术零基础的读者不想折腾，就不用往下看了，可以直接参考我的另外一篇博客：<a href="https://www.playpi.org/2019082801.html">CentOS7 自动安装 Shadowsocks 脚本 </a> ，只要下载对应的自动安装脚本，就可以一键运行、自动安装，不需要考虑是否有技术基础，边等边喝水，几分钟就会安装完成。</p><p> 下面开始进入正题，详细描述 <code>shadowsocks</code> 服务的手动安装过程。</p><p>云主机选择 <code>CentOS 7 x64</code> 版本，全程操作使用 <code>Linux</code> 命令【注意，如果选择其它系统命令会不一致，请自己查询，例如：<code>Debian/Ubuntu</code> 系统的安装命令更简洁，先 <code>apt-get install python-pip</code>，再 <code>pip install shadowsocks</code> 即可】。</p><p>注意如果安装了防火墙【更安全】，需要的端口一定要开启，否则启动 <code>Shandowsocks</code> 会失败。</p><p>安装组件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install m2crypto python-setuptools</span><br><span class="line">easy_install pip</span><br><span class="line">pip install shadowsocks</span><br></pre></td></tr></table></figure><p>过程如图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa31ivc8mj21hc0mhdh5.jpg" alt="python-setuptools 安装" title="python-setuptools 安装"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa3g9phq7j21hc0jb405.jpg" alt="pip 安装" title="pip 安装"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa3h3eeyaj210k04edfx.jpg" alt="ss 安装" title="ss 安装"></p><p>配置服务器参数：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi  /etc/shadowsocks.json</span><br></pre></td></tr></table></figure><p>如下列出主要参数解释说明 </p><table><thead><tr><th style="text-align:center"> 参数名称 </th><th style="text-align:center"> 解释说明 </th></tr></thead><tbody><tr><td style="text-align:center">server</td><td style="text-align:center"> 服务器地址，填 ip 或域名 </td></tr><tr><td style="text-align:center">local_address</td><td style="text-align:center"> 本地地址 </td></tr><tr><td style="text-align:center">local_port</td><td style="text-align:center"> 本地端口，一般 1080，可任意 </td></tr><tr><td style="text-align:center">server_port</td><td style="text-align:center"> 服务器对外开的端口 </td></tr><tr><td style="text-align:center">password</td><td style="text-align:center"> 密码，每个端口可以设置不同的密码 </td></tr><tr><td style="text-align:center">port_password</td><td style="text-align:center">server_port + password ，服务器端口加密码的组合</td></tr><tr><td style="text-align:center">timeout</td><td style="text-align:center"> 超时重连 </td></tr><tr><td style="text-align:center">method</td><td style="text-align:center"> 加密方法，默认：“aes-256-cfb”</td></tr><tr><td style="text-align:center">fast_open</td><td style="text-align:center">开启或关闭 <a href="https://github.com/shadowsocks/shadowsocks/wiki/TCP-Fast-Open" target="_blank" rel="noopener">TCP_FASTOPEN</a>，填 true /false，需要服务端支持 </td></tr></tbody></table><p> 配置多端口信息【多个帐号，多人也可用】：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"server"</span>: <span class="string">"你的 IP 地址"</span>（例如：<span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span>）,</span><br><span class="line">    <span class="attr">"local_address"</span>: <span class="string">"127.0.0.1"</span>（默认值）,</span><br><span class="line">    <span class="attr">"local_port"</span>:<span class="number">1080</span>（默认值）,</span><br><span class="line">    "port_password"（开启的端口和密码，自己按需配置，确保端口打开并不被其它程序占用）: &#123;</span><br><span class="line">        "1227": "pengfeivpn1227",</span><br><span class="line">        "1226": "pengfeivpn1226",</span><br><span class="line">        "1225": "pengfeivpn"</span><br><span class="line">    &#125;,</span><br><span class="line">    "timeout":300（超时时间，默认值）,</span><br><span class="line">    "method":"aes-256-cfb"（加密方法，默认值）,</span><br><span class="line">    "fast_open": false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置多端口信息【纯净版本，更改 <code>ip</code>、端口等信息直接复制使用】：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"server"</span>: <span class="string">"x.x.x.x"</span>,</span><br><span class="line">    <span class="attr">"local_address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="attr">"local_port"</span>:<span class="number">1080</span>,</span><br><span class="line">    <span class="attr">"port_password"</span>: &#123;</span><br><span class="line">        <span class="attr">"1227"</span>: <span class="string">"vpn1227"</span>,</span><br><span class="line">        <span class="attr">"1226"</span>: <span class="string">"vpn1226"</span>,</span><br><span class="line">        <span class="attr">"1225"</span>: <span class="string">"vpn"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"timeout"</span>:<span class="number">300</span>,</span><br><span class="line">    <span class="attr">"method"</span>:<span class="string">"aes-256-cfb"</span>,</span><br><span class="line">    <span class="attr">"fast_open"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置一个端口信息【只有一个帐号，多人也可用】：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"server"</span>:<span class="string">"你的 IP 地址"</span>（例如：<span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span>）,  </span><br><span class="line">    <span class="attr">"server_port"</span>:<span class="number">1225</span>（唯一的端口）,</span><br><span class="line">    <span class="attr">"local_address"</span>:<span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="attr">"local_port"</span>:<span class="number">1080</span>,</span><br><span class="line">    <span class="attr">"password"</span>:<span class="string">"pengfeivpn"</span>（唯一的密码）,</span><br><span class="line">    <span class="attr">"timeout"</span>:<span class="number">300</span>,</span><br><span class="line">    <span class="attr">"method"</span>:<span class="string">"aes-256-cfb"</span>,</span><br><span class="line">    <span class="attr">"fast_open"</span>:<span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置一个端口信息【纯净版本，更改 <code>ip</code>、端口等信息直接复制使用】：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"server"</span>:<span class="string">"x.x.x.x"</span>,  </span><br><span class="line">    <span class="attr">"server_port"</span>:<span class="number">1225</span>,</span><br><span class="line">    <span class="attr">"local_address"</span>:<span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="attr">"local_port"</span>:<span class="number">1080</span>,</span><br><span class="line">    <span class="attr">"password"</span>:<span class="string">"vpn"</span>,</span><br><span class="line">    <span class="attr">"timeout"</span>:<span class="number">300</span>,</span><br><span class="line">    <span class="attr">"method"</span>:<span class="string">"aes-256-cfb"</span>,</span><br><span class="line">    <span class="attr">"fast_open"</span>:<span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Shadowsocks</code> 性能优化：</p><p>另外还有很多参数可以优化性能，例如设置连接数、字节大小等，比较复杂，在此略过。</p><p>防火墙安装：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装防火墙 </span></span><br><span class="line">yum install firewalld</span><br><span class="line"><span class="comment"># 启动防火墙 </span></span><br><span class="line">systemctl start firewalld</span><br><span class="line"><span class="comment"># 查看目前已经开启的端口号 </span></span><br><span class="line">firewall-cmd --list-ports</span><br><span class="line"><span class="comment"># 端口号是你自己设置的端口 </span></span><br><span class="line">firewall-cmd --permanent --zone=public --add-port=1225/tcp</span><br><span class="line">firewall-cmd --permanent --zone=public --add-port=1226/tcp</span><br><span class="line">firewall-cmd --permanent --zone=public --add-port=1227/tcp</span><br><span class="line"><span class="comment"># 重载更新的端口信息 </span></span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure><p>过程如图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa3il37mlj20ka074dfy.jpg" alt="安装启动防火墙" title="安装启动防火墙"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa3hxmaftj20jd04zmx6.jpg" alt="开启端口重载" title="开启端口重载"></p><p>这里需要注意，如果没安装防火墙，或者安装防火墙但是没有开启端口，启动 <code>Shadowsocks</code> 时会报错：<strong>socket.error: [Errno 98] Address already in use</strong>，启动失败，无法提供翻墙服务，而且不要被错误信息误导，不是端口被占用，是端口没有开启。</p><p>启动 <code>Shadowsocks</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 后台运行    </span></span><br><span class="line">ssserver -c /etc/shadowsocks.json -d start</span><br><span class="line"><span class="comment"># 调试时使用下面命令，实时查看日志 </span></span><br><span class="line">ssserver -c /etc/shadowsocks.json</span><br><span class="line"><span class="comment"># 停止运行    </span></span><br><span class="line">ssserver -c /etc/shadowsocks.json -d stop</span><br></pre></td></tr></table></figure><p>过程如图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa3j16ymwj20hf03eglj.jpg" alt="启动 ss" title="启动 ss"></p><p>在使用 <strong>ssserver -c /etc/shadowsocks.json</strong> 查看启动日志时，发现除了正常的启动信息，还会有错误信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INFO: loading config from /etc/shadowsocks.json</span><br><span class="line">2019-05-06 15:46:11 INFO     loading libcrypto from libcrypto.so.10</span><br><span class="line">2019-05-06 15:46:11 INFO     starting server at 66.42.105.87:1227</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/usr/bin/ssserver&quot;, line 9, in &lt;module&gt;</span><br><span class="line">    load_entry_point (&apos;shadowsocks==2.8.2&apos;, &apos;console_scripts&apos;, &apos;ssserver&apos;)()</span><br><span class="line">  File &quot;/usr/lib/python2.7/site-packages/shadowsocks/server.py&quot;, line 68, in main</span><br><span class="line">    tcp_servers.append (tcprelay.TCPRelay (a_config, dns_resolver, False))</span><br><span class="line">  File &quot;/usr/lib/python2.7/site-packages/shadowsocks/tcprelay.py&quot;, line 582, in __init__</span><br><span class="line">    server_socket.bind (sa)</span><br><span class="line">  File &quot;/usr/lib64/python2.7/socket.py&quot;, line 224, in meth</span><br><span class="line">    return getattr (self._sock,name)(*args)</span><br><span class="line">socket.error: [Errno 98] Address already in use</span><br></pre></td></tr></table></figure><p>错误信息截图 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190507000812.png" alt="错误信息截图" title="错误信息截图"></p><p> 根据关键词 <strong>socket.error: [Errno 98] Address already in use</strong> 查阅资料，发现是主机的配置问题，停止的 <code>ss</code> 服务没有及时释放端口，导致启动时报错。但是我发现这种报错信息并没有影响到后台 <code>ss</code> 服务的正常启动，也就是说端口正常提供服务，可以顺利翻墙。同时，我按照其他人的解释说明，在 <strong>/etc/sysctl.conf</strong> 配置文件中增加了 <code>ip</code> 的配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_syncookies = 1 </span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.tcp_fin_timeout = 5</span><br></pre></td></tr></table></figure><p>然后使用 <strong>/sbin/sysctl -p</strong> 命令让内核参数生效，结果在重启 <code>ss</code> 服务时看到日志里面还会有上面那种错误信息。后续考虑到这种现象并没有影响正常的服务，也就先不放在心上，专心做其它的工作。</p><h1 id="客户端使用"><a href="# 客户端使用" class="headerlink" title="客户端使用"></a>客户端使用 </h1><h2 id="Windows- 平台使用"><a href="#Windows- 平台使用" class="headerlink" title="Windows 平台使用"></a>Windows 平台使用</h2><p> 下载 <code>Windows</code> 平台的客户端，下载地址：<a href="https://github.com/shadowsocks/shadowsocks-windows" target="_blank" rel="noopener">shadowsocks-windows GitHub</a>，<a href="http://shadowsocks.org/en/download/clients.html" target="_blank" rel="noopener">shadowsocks 官网 </a>，直接解压放入文件夹即可使用，不需要安装。</p><p> 但是注意配置内容【端口、密码、加密协议等等】，另外注意有些 <code>Windows</code> 系统缺失 <code>Shadowsocks</code> 必要的组件【<code>.NET Framework</code>】，需要安装，官网也有说明。</p><p>配置示例：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa3pjtymuj20g60dp75k.jpg" alt="ss 配置" title="ss 配置"></p><p>实际上下载程序后，无需安装，直接解压即可，解压后只有一个 <code>exe</code> 文件，双击即可运行【最好放入指定文件夹中，便于程序管理和升级】。第一次启动，需要设置参数，如上图所示，至少配置一台机器，另外还可以设置开机启动，以后不用重新打开。此外，如果有更新版本的程序，会放在 <code>ss_win_temp</code> 文件夹下，直接解压后复制替换掉当前的 <code>exe</code> 文件即可；如果文件夹中有 <code>gui-config.json</code>、<code>statistics-config.json</code> 这 2 个文本文件，它们是程序的配置以及前面设置的翻墙配置，不能删掉；如果使用系统代理的 <code>PAC</code> 模式（推荐使用），会生成 <code>pac.txt</code> 文本文件，存放从 <code>GFWList</code> 获取的被墙的网址，必要时才会通过翻墙代理访问，其它正常的网址则直接访问，这样可以节约流量。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3ly1fxbhx6e12jj20h004qgln.jpg" alt="ss 文件夹" title="ss 文件夹"></p><p>如果有切换代理的需求，搭配浏览器的插件来完成，例如 <a href="https://chrome.google.com/webstore/detail/proxy-switchyomega/padekgcemlokbadohgkifijomclgjgif?hl=zh-CN" target="_blank" rel="noopener">Proxy SwitchyOmega</a> 就可以。</p><p>关于启动系统代理并使用 <code>PAC</code> 模式【根据条件过滤，不满足的直连】，如果是入门级别使用，直接设置完就可以用了，不用再管其它设置，切记要定时更新 <code>GFWList</code> 列表，因为如果某些网站最近刚刚被屏蔽，不在以前的 <code>HFWList</code> 列表里面，就会导致无法连接，只有及时更新才能正常连接。但是还有一种极端情况，就是某些网站 <code>GFWList</code> 迟迟没有收录，怎么更新都不会起作用，别着急，此时可以使用用户自定义规则，模仿 <code>GFWList</code> 填写自己的过滤规则，即可实现灵活的切换，使用用户自定义规则后会在安装文件夹中生成 <code>user-rule.txt</code> 文本文件。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxbo5moanxj20cj0a5dga.jpg" alt="开启系统代理并使用 PAC 模式" title="开启系统代理并使用 PAC 模式"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxbo6rej96j20ip0axjs7.jpg" alt="PAC 模式下更新 GFWList 内容" title="PAC 模式下更新 GFWList 内容"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxbo7ifow9j20j80apt9k.jpg" alt="PAC 模式下自定义过滤规则" title="PAC 模式下自定义过滤规则"></p><p>其实，<code>PAC</code> 模式的原理就是根据公共的过滤规则【收集被屏蔽的网站列表】，自动生成了一个脚本文件，把脚本文件绑定到浏览器的代理设置中，使浏览器访问网站前都会运行这个脚本，根据脚本的结果决定是直接访问还是通过本地代理访问，脚本在 <code>Shadowsocks</code> 的 <code>PAC</code> 设置中可以看到，浏览器的设置信息可以在代理设置中看到【浏览器在 <code>Shadowsocks</code> 开启系统代理的时候会自动设置代理，无需人工干预】。</p><p>由此可以得知，通过本机访问网络，决定是直接连接还是通过 <code>Shadowsocks</code> 代理连接的是 <code>PAC</code> 脚本，并不是 <code>Shadowsocks</code> 本身，所以如果使用系统的 <code>Ping</code> 命令访问 <a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a> 仍然是不能访问的，因为直接 <code>Ping</code> 没有经过 <code>PAC</code> 脚本，还是直接连接了，不可能访问成功。除了浏览器之外，如果其它程序也想访问被屏蔽的网站【例如 <code>Git</code>、<code>Maven</code> 仓库】，只能通过程序自己的代理设置进行配置，完成访问的目的。【如果放弃 <code>PAC</code> 模式，直接使用全局模式，则不需要配置任何信息，本机所有的网络请求会全部经过翻墙代理，当然这样做会导致流量消耗过大，并且国内的正常网站访问速度也会很慢】</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxbof33m9dj20ij0aa0tl.jpg" alt="获取 PAC 的脚本地址" title="获取 PAC 的脚本地址"></p><p>获取到的 <code>PAC</code> 脚本地址为：<br><a href="http://127.0.0.1:1080/pac?t=20181118030355597&amp;secret=qZKsW49fDFezR4jJQtRDhUVPRqnFu6JC3Nc+vtXDb0g=" target="_blank" rel="noopener">http://127.0.0.1:1080/pac?t=20181118030355597&amp;secret=qZKsW49fDFezR4jJQtRDhUVPRqnFu6JC3Nc+vtXDb0g=</a></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxboiacqtbj20se0kojse.jpg" alt="浏览器代理配置" title="浏览器代理配置"></p><p>以上是查看 <code>Chrome</code> 浏览器和 <code>IE</code> 浏览器的代理设置信息，对于 <code>Microsoft Edge</code>【<code>Windows 10</code> 自带的】浏览器来说，界面有点不一样，在 <strong>设置 </strong>-&gt; <strong>高级 </strong>-&gt; <strong>代理设置 </strong>里面。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxbooa2ikvj20xc0pwq93.jpg" alt="Edge 浏览器设置代理脚本" title="Edge 浏览器设置代理脚本"></p><p>此外，如果在浏览器中有更灵活的需求应用， 例如在设置多个代理的情况下，针对公司内网是一套，针对指定的几个网站是一套，针对被屏蔽的网站是一套，剩余的直接连接。在这种情况下仅仅使用代理脚本就不能完成需求了，显得场景很单一，当然也可以把脚本写的复杂一点，但是成本太高，而且不方便维护更新。这个时候就需要浏览器的插件出场了，例如在 <code>Chrome</code> 下我选择了 <a href="https://chrome.google.com/webstore/detail/proxy-switchyomega/padekgcemlokbadohgkifijomclgjgif?hl=zh-CN" target="_blank" rel="noopener">SwitchyOmega</a> 这个插件，可以设置多种情景模式，根据实际情况自由切换，非常方便。我设置了三种情景模式：<code>hdpProxy</code>【公司内网】、<code>shadowSocks</code>【翻墙代理】、<code>auto switch</code>【根据条件自动切换】，前面两种情景模式直接设置完成即可，最后的 <code>auto switch</code> 需要配置得复杂一点，根据正则表达式或者通配符指定某些网站的访问方式必须使用 <code>hdpProxy</code> 代理，另外其它的根据规则列表 <br>【<a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" target="_blank" rel="noopener">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a> ，和 <code>Shadowsocks</code> 的 <code>GFWList</code> 列表类似】必须通过翻墙代理，剩余的才是直接连接。当然，此时就不需要把 <code>Shadowsocks</code> 设置为系统代理了，保持 <code>Shadowsocks</code> 后台运行就可以了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxbp79ywuej21hc0q20v7.jpg" alt="SwitchyOmega 插件配置" title="SwitchyOmega 插件配置"></p><h2 id="Android- 平台使用"><a href="#Android- 平台使用" class="headerlink" title="Android 平台使用"></a>Android 平台使用</h2><p><code>Android</code> 平台的安装使用方法就非常简单了，分为 <strong> 安装、配置、启动 </strong>这 3 个步骤，没有其它多余的操作。</p><h3 id="安装"><a href="# 安装" class="headerlink" title="安装"></a>安装 </h3><p> 下载 <code>Android</code> 平台的客户端，一般我们都称之为 <strong>影梭 </strong>，在应用商城是找不到的，因为通不过审核，所以只能去官网下载，下载地址：<a href="http://shadowsocks.org/en/download/clients.html" target="_blank" rel="noopener">shadowsocks 官网 </a>。切记，千万不要去第三方网站下载，因为下载的安装包可能带有其它的应用，导致给你的手机安装了一堆软件。当然，如果你连官网都不信，可以自己下载源代码，自己打包 <code>apk</code> 文件，也是可以的，懂一点点 <code>Android</code> 开发就行了，源代码全部是开源的，放在了 <code>GitHub</code> 上面：<a href="https://github.com/Jigsaw-Code/outline-client/" target="_blank" rel="noopener">https://github.com/Jigsaw-Code/outline-client/</a> 。</p><p> 下载完 <code>apk</code> 文件，安装也就是和安装普通的应用一样，需要注意的是有些 <code>Android</code> 手机会禁止外部来源的 <code>app</code>【不是从应用商店下载安装的】安装，所以需要同意一下，也就是 <strong>信任此应用 </strong>，才能顺利完成安装。</p><h3 id="配置"><a href="# 配置" class="headerlink" title="配置"></a>配置 </h3><p> 需要配置的内容和 <code>Windows</code> 平台的一样，把那些必要的参数填进去就行了，其它内容不需要关心。例如我这里配置了 <code>ip</code>、端口、密码、加密方式等。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pzdu7hdhj20u01me0xa.jpg" alt="配置信息" title="配置信息"></p><h3 id="启动"><a href="# 启动" class="headerlink" title="启动"></a>启动 </h3><p> 启动只要点击右上角的灰色圆形按钮，里面有一个小飞机，大概等待几秒钟，就会变绿，表示已经连接上 <code>VPN</code> 了，此时手机就可以连接被屏蔽的网站了。唯一的缺点就是，不支持设置类似于 <code>PAC</code> 规则的站点切换【<strong> 路由 </strong>默认设置的是绕过中国大陆地址】，因为只要一连上 <code>VPN</code>，手机上所有的国外连接都是走 <code>VPN</code>，会导致连某些正常的国外的网站也会慢一点，还浪费 <code>VPS</code> 的流量。当然，如果是在 <code>WIFI</code> 的环境下，通过 <code>Android</code> 系统的网络代理设置也可以设置一些类似于 <code>PAC</code> 的规则，就不细说了。启动后，还可以看到流量发送接收统计信息。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pzebvxr7j20u01mcae9.jpg" alt="启动成功" title="启动成功"></p><p>在手机的设置里面也可以看到 <code>VPN</code> 的开启 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pzegquf2j20u01jc0wu.jpg" alt="查看系统开启的 VPN" title="查看系统开启的 VPN"></p><h1 id="踩坑记录"><a href="# 踩坑记录" class="headerlink" title="踩坑记录"></a> 踩坑记录 </h1><p>1、在云主机安装服务端后，又安装了防火墙，但是没有开启 <code>Shadowsocks</code> 需要的端口，导致启动 <code>Shadowsocks</code> 总是失败，但是报错信息又是 <code>Python</code> 和 <code>Linux</code> 的，看不懂，搜索资料也搜不到，后来重装，并且想清楚每一步骤是干什么的，会造成什么影响，通过排除法找到了根本原因。</p><p>2、在 <code>Windows</code> 平台使用的时候，安装了客户端，也安装了 <code>.NET Framework</code> 组件，配置信息确认无误，但是就是上不了外网，同样的操作使用 <code>Android</code> 客户端却可以，所以有理由怀疑是自己的主机问题。后来，重启系统，检查网络，关闭杀毒软件，还是不行，后来，依靠搜索，找到了是杀毒软件 <code>Avast</code> 的问题，扫描 <code>SSL</code> 连接被开启了，大坑，关闭即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1fxa0mkrws7j20pc0nkglz.jpg" alt="Avast 截图"></p><p>3、参考：<a href="https://github.com/sirzdy/shadowsocks" target="_blank" rel="noopener"> 梯子搭建 </a> 。</p><p>4、本来以为 <code>Shadowsocks</code> 的 <strong> 启用系统代理 </strong>中的 <code>PAC</code> 模式会在接收到网络请求的基础上进行过滤，即 <code>Shadowsocks</code> 能控制所有的网络请求进行过滤判断，然后该翻墙的翻墙，该直连的直连。如果浏览器没有使用任何代理插件，类似于 <code>SwitchyOmega</code> 这种，还是可以自动根据 <code>PAC</code> 列表进行过滤的的，但是后来发现浏览器如果被代理插件给代理了，那么浏览器插件 <code>SwitchyOmega</code> 设置代理规则后，<code>PAC</code> 脚本就不会生效了，通过 <code>SwitchyOmega</code> 插件使用 <code>Shadowsocks</code> 代理的网站都直接翻墙，不会有任何关于 <code>PAC</code> 列表的判断。如果想拥有类似于 <code>PAC</code> 列表的判断，应该在 <code>Shadowsocks</code> 代理插件中好好配置，不应该交给 <code>Shadowsocks</code>。这也导致优酷视频消耗了大量的流量，而且速度还很慢。</p><p>这里面的根本原因就是 <code>PAC</code> 列表与 <code>SwitchyOmega</code> 代理插件的作用是类似的，都是为了区分网络请求，二者不可共存。如果谷歌浏览器安装了 <code>SwitchyOmega</code> 代理插件，但是 <code>IE</code> 浏览器没有安装，那么谷歌浏览器被 <code>SwitchyOmega</code> 代理，<code>IE</code> 浏览器还是按照 <code>PAC</code> 的规则来，都可以根据各自的网站规则进行访问。</p><p>另外，为了保证国内的网站不是经过翻墙代理，能直接连接，就不能使用 <code>Shadowsocks</code> 设置 <strong>系统代理模式 </strong>中的 <strong>全局模式 </strong>。</p><p>5、使用插件 <code>SwitchyOmega</code> 的过程中，一开始是自己整理一些规则，而没有使用<br><a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" target="_blank" rel="noopener">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a> 列表规则，导致配置信息很多，而且自己看着头都大，不好维护与查看，后来就发现了列表规则，解放了劳动力。</p><p>6、解决了 <code>Chrome</code> 浏览器的收藏跨平台自动更新同步的问题，以前在三台电脑之间添加取消收藏，总是不能更新同步，需要手动开启系统代理设置全局模式【<code>Chrome</code> 浏览器的收藏同步功能被屏蔽了，我又不知道 <code>url</code> 是什么】，等一会更新同步之后再关闭【防止其它场景也翻墙了】。目前使用规则列表，收藏可以自动更新同步了，不需要手动来回切换了，也不用担忘记同步的情况了。</p><!-- rebuild by neat -->]]></content>
      <tags>
        <tag>Shadowsocks</tag>
        <tag>Vultr</tag>
        <tag>VPS</tag>
        <tag>Avast</tag>
        <tag>影梭</tag>
      </tags>
  </entry>
  <entry>
    <title>那些年关于技术的未解之谜</title>
    <url>/2019030101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>由于技术能力的限制，平时会遇到一些自己觉得非常诡异的问题，感觉到莫名其妙。其实到头来发现，归根结底还是自己的认知问题：可能是技术水平不够，或者考虑不周全，甚至是一些低级别的错误判断。总而言之，遇到这些问题后，有时候请教人、查资料之后仍旧不得解，只能先记录下来，留做备注说明，等待以后解决。当然，随着时间的流逝，有些问题可能就被忘记了，有些问题在之后的某一个时间点被解决了。本文就是要记录这些问题，并在遇到新问题或者解决老问题之后，保持更新。</p><a id="more"></a><h1 id="常用链接"><a href="# 常用链接" class="headerlink" title="常用链接"></a>常用链接 </h1><p> 在这里先列出一些常用的网站链接，方便查看：</p><ul><li>es-hadoop 官网：<a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/5.6/configuration.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/hadoop/5.6/configuration.html</a> ；</li><li>x</li></ul><h1 id="es-spark- 读取 -es- 数据后 -count- 报错"><a href="#es-spark- 读取 -es- 数据后 -count- 报错" class="headerlink" title="es-spark 读取 es 数据后 count 报错"></a>es-spark 读取 es 数据后 count 报错 </h1><p> 使用 es-hadoop 组件，起 Spark 任务去查询 es 数据，然后过滤，过滤后做一个 count 算子，结果就报错了。而且，在报错后又重试了很多次（5 次以上），一直正常，没法重现问题。这个任务需要经常跑，以前从来没遇到过这样的异常，初步怀疑是 es 集群不稳定，具体原因不得而知。</p><p>错误截图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pyfelevwj20vj0mr0w0.jpg" alt="报错信息截图" title="报错信息截图"></p><p>完整错误信息如下（重要包名称被替换）：<br></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span>-<span class="number">02</span>-<span class="number">26_15</span>:<span class="number">01</span>:<span class="number">44</span> [main] ERROR spokesman3.SpokesAndBrand:<span class="number">510</span>: !!!!Spark 出错: org.codehaus.jackson.JsonParseException: Unexpected end-of-input in field name</span><br><span class="line"> at [Source: org.apache.commons.httpclient.AutoCloseInputStream@<span class="number">2687</span>cf14; line: <span class="number">1</span>, column: <span class="number">17581</span>]</span><br><span class="line">org.elasticsearch.hadoop.rest.EsHadoopParsingException: org.codehaus.jackson.JsonParseException: Unexpected end-of-input in field name</span><br><span class="line"> at [Source: org.apache.commons.httpclient.AutoCloseInputStream@<span class="number">2687</span>cf14; line: <span class="number">1</span>, column: <span class="number">17581</span>]</span><br><span class="line">	at org.elasticsearch.hadoop.rest.RestClient.parseContent (RestClient.java:<span class="number">171</span>)</span><br><span class="line">	at org.elasticsearch.hadoop.rest.RestClient.get (RestClient.java:<span class="number">155</span>)</span><br><span class="line">	at org.elasticsearch.hadoop.rest.RestClient.targetShards (RestClient.java:<span class="number">357</span>)</span><br><span class="line">	at org.elasticsearch.hadoop.rest.RestRepository.doGetReadTargetShards (RestRepository.java:<span class="number">306</span>)</span><br><span class="line">	at org.elasticsearch.hadoop.rest.RestRepository.getReadTargetShards (RestRepository.java:<span class="number">297</span>)</span><br><span class="line">	at org.elasticsearch.hadoop.rest.RestService.findPartitions (RestService.java:<span class="number">241</span>)</span><br><span class="line">	at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions$lzycompute (AbstractEsRDD.scala:<span class="number">73</span>)</span><br><span class="line">	at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions (AbstractEsRDD.scala:<span class="number">72</span>)</span><br><span class="line">	at org.elasticsearch.spark.rdd.AbstractEsRDD.getPartitions (AbstractEsRDD.scala:<span class="number">44</span>)</span><br><span class="line">	at org.apache.spark.rdd.RDD$$anonfun$partitions$<span class="number">2</span>.apply (RDD.scala:<span class="number">239</span>)</span><br><span class="line">	at org.apache.spark.rdd.RDD$$anonfun$partitions$<span class="number">2</span>.apply (RDD.scala:<span class="number">237</span>)</span><br><span class="line">	at scala.Option.getOrElse (Option.scala:<span class="number">120</span>)</span><br><span class="line">	at org.apache.spark.rdd.RDD.partitions (RDD.scala:<span class="number">237</span>)</span><br><span class="line">	at org.apache.spark.SparkContext.runJob (SparkContext.scala:<span class="number">1929</span>)</span><br><span class="line">	at org.apache.spark.rdd.RDD.count (RDD.scala:<span class="number">1157</span>)</span><br><span class="line">	at org.apache.spark.api.java.JavaRDDLike$class.count (JavaRDDLike.scala:440)</span><br><span class="line">	at org.apache.spark.api.java.AbstractJavaRDDLike.count (JavaRDDLike.scala:<span class="number">46</span>)</span><br><span class="line">	at com.package.to.class.SpokesAndBrand.getMention (SpokesAndBrand.java:508)</span><br><span class="line">	at com.package.to.class.SpokesAndBrand.runCelebrityByBrand (SpokesAndBrand.java:185)</span><br><span class="line">	at com.package.to.class.SpokesAndBrand.execute (SpokesAndBrand.java:116)</span><br><span class="line">	at com.package.to.class.SpokesmanAnalyzer.execute (SpokesmanAnalyzer.java:162)</span><br><span class="line">	at com.package.to.class.SpokesmanAnalyzeCli.execute (SpokesmanAnalyzeCli.java:154)</span><br><span class="line">	at com.package.to.class.SpokesmanAnalyzeCli.start (SpokesmanAnalyzeCli.java:75)</span><br><span class="line">	at com.package.to.class.util.AdvCli.initRunner (AdvCli.java:191)</span><br><span class="line">	at com.package.to.class.job.client.BasicInputOutputSystemWorker.run (BasicInputOutputSystemWorker.java:79)</span><br><span class="line">	at com.package.to.class.model.AbstractDataReportWorker.run (AbstractDataReportWorker.java:122)</span><br><span class="line">	at com.package.to.class.buffalo.job.AbstractBUTaskWorker.runTask (AbstractBUTaskWorker.java:63)</span><br><span class="line">	at com.package.to.class.report.cli.TaskLocalRunnerCli.start (TaskLocalRunnerCli.java:110)</span><br><span class="line">	at com.package.to.class.util.AdvCli.initRunner (AdvCli.java:191)</span><br><span class="line">	at com.package.to.class.report.cli.TaskLocalRunnerCli.main (TaskLocalRunnerCli.java:43)</span><br><span class="line">Caused by: org.codehaus.jackson.JsonParseException: Unexpected end-of-input in field name</span><br><span class="line"> at [Source: org.apache.commons.httpclient.AutoCloseInputStream@<span class="number">2687</span>cf14; line: <span class="number">1</span>, column: <span class="number">17581</span>]</span><br><span class="line">	at org.codehaus.jackson.JsonParser._constructError (JsonParser.java:<span class="number">1433</span>)</span><br><span class="line">	at org.codehaus.jackson.impl.JsonParserMinimalBase._reportError (JsonParserMinimalBase.java:<span class="number">521</span>)</span><br><span class="line">	at org.codehaus.jackson.impl.JsonParserMinimalBase._reportInvalidEOF (JsonParserMinimalBase.java:<span class="number">454</span>)</span><br><span class="line">	at org.codehaus.jackson.impl.Utf8StreamParser.parseEscapedFieldName (Utf8StreamParser.java:<span class="number">1503</span>)</span><br><span class="line">	at org.codehaus.jackson.impl.Utf8StreamParser.slowParseFieldName (Utf8StreamParser.java:<span class="number">1404</span>)</span><br><span class="line">	at org.codehaus.jackson.impl.Utf8StreamParser._parseFieldName (Utf8StreamParser.java:<span class="number">1231</span>)</span><br><span class="line">	at org.codehaus.jackson.impl.Utf8StreamParser.nextToken (Utf8StreamParser.java:<span class="number">495</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.mapObject (UntypedObjectDeserializer.java:<span class="number">219</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.deserialize (UntypedObjectDeserializer.java:<span class="number">47</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.mapArray (UntypedObjectDeserializer.java:<span class="number">165</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.deserialize (UntypedObjectDeserializer.java:<span class="number">51</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.mapArray (UntypedObjectDeserializer.java:<span class="number">165</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.deserialize (UntypedObjectDeserializer.java:<span class="number">51</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.MapDeserializer._readAndBind (MapDeserializer.java:<span class="number">319</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.MapDeserializer.deserialize (MapDeserializer.java:<span class="number">249</span>)</span><br><span class="line">	at org.codehaus.jackson.map.deser.std.MapDeserializer.deserialize (MapDeserializer.java:<span class="number">33</span>)</span><br><span class="line">	at org.codehaus.jackson.map.ObjectMapper._readValue (ObjectMapper.java:<span class="number">2704</span>)</span><br><span class="line">	at org.codehaus.jackson.map.ObjectMapper.readValue (ObjectMapper.java:<span class="number">1286</span>)</span><br><span class="line">	at org.elasticsearch.hadoop.rest.RestClient.parseContent (RestClient.java:<span class="number">166</span>)</span><br><span class="line">	... <span class="number">29</span> more</span><br><span class="line"><span class="number">2019</span>-<span class="number">02</span>-<span class="number">26_15</span>:<span class="number">01</span>:<span class="number">44</span> [main] INFO rdd.JavaEsRDD:<span class="number">58</span>: Removing RDD <span class="number">3086</span> from persistence list</span><br></pre></td></tr></table></figure><p></p><h1 id="Hexo- 生成 -html- 静态页面目录锚点失效"><a href="#Hexo- 生成 -html- 静态页面目录锚点失效" class="headerlink" title="Hexo 生成 html 静态页面目录锚点失效"></a>Hexo 生成 html 静态页面目录锚点失效 </h1><p> 我这些所有的博客文档是先写成 Markdown 文件，然后使用 Hexo 渲染生成 html 静态页面，再发布到 GitHub Pages 上面，还有一些是发布到我自己的 VPS 上面（为了百度爬虫）。</p><p>但是最近我发现一个现象，有一些文章的锚点无效，也就是表现为目录无法跳转，例如想直接查看某一级目录的内容，在右侧的 <strong>文章目录 </strong>中直接点击对应的标题，不会自动跳转过去。这个问题我发现了很久，但是一直没在意，也没有找到原因。最近才碰巧发现是因为标题内容里面有空格，这才导致生成的 html 静态页面里面的锚点失效，我随机又测试了几次其它的页面，看起来的确是这样。下面列出一些示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https://www.playpi.org/2019022501.html ，Hexo 踩坑记录的 </span><br><span class="line">https://www.playpi.org/2018121901.html ，js 字符串分割方法 </span><br><span class="line">https://www.playpi.org/2019020701.html ，itchat 0 - 初识 </span><br></pre></td></tr></table></figure><p>但是，我又发现其他人的博客，目录标题内容中也有空格，却可以正常跳转，我很疑惑。现在我猜测是 Hexo 的问题，或者哪里需要配置，等待以后的解决方法吧。别人的博客示例：<a href="https://blog.itnote.me/Hexo/hexo-chinese-english-space/" target="_blank" rel="noopener">https://blog.itnote.me/Hexo/hexo-chinese-english-space/</a> 。</p><h1 id="邮件依赖的诡异异常"><a href="# 邮件依赖的诡异异常" class="headerlink" title="邮件依赖的诡异异常"></a>邮件依赖的诡异异常 </h1><p> 在项目中新引入了邮件相关的依赖【没有其它任何变化】，这样就可以在需要时发送通知邮件，依赖内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 邮件相关依赖 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;commons-email&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.3.3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>然后神奇的事情发生了，实际执行时，程序抛出异常【去掉这个依赖则正常】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.StackOverflowError</span><br><span class="line">	at sun.nio.cs.UTF_8$Encoder.encodeLoop (UTF_8.java:619)</span><br><span class="line">	at java.nio.charset.CharsetEncoder.encode (CharsetEncoder.java:561)</span><br><span class="line">	at sun.nio.cs.StreamEncoder.implWrite (StreamEncoder.java:271)</span><br><span class="line">	at sun.nio.cs.StreamEncoder.write (StreamEncoder.java:125)</span><br><span class="line">	at java.io.OutputStreamWriter.write (OutputStreamWriter.java:207)</span><br><span class="line">	at java.io.BufferedWriter.flushBuffer (BufferedWriter.java:129)</span><br><span class="line">	at java.io.PrintStream.write (PrintStream.java:526)</span><br><span class="line">	at java.io.PrintStream.print (PrintStream.java:669)</span><br><span class="line">	at java.io.PrintStream.println (PrintStream.java:806)</span><br><span class="line">	at org.slf4j.impl.SimpleLogger.write (SimpleLogger.java:381)</span><br><span class="line">	at org.slf4j.impl.SimpleLogger.log (SimpleLogger.java:376)</span><br><span class="line">	at org.slf4j.impl.SimpleLogger.info (SimpleLogger.java:538)</span><br><span class="line">	at org.apache.maven.cli.logging.Slf4jLogger.info (Slf4jLogger.java:59)</span><br><span class="line">	at org.codehaus.plexus.archiver.AbstractArchiver$1.hasNext (AbstractArchiver.java:464)</span><br><span class="line">	at org.codehaus.plexus.archiver.AbstractArchiver$1.hasNext (AbstractArchiver.java:467)</span><br><span class="line">	at org.codehaus.plexus.archiver.AbstractArchiver$1.hasNext (AbstractArchiver.java:467)</span><br><span class="line">	at org.codehaus.plexus.archiver.AbstractArchiver$1.hasNext (AbstractArchiver.java:467)</span><br></pre></td></tr></table></figure><p>而根据这个异常信息，我搜索不到任何有效的信息，一直无法解决。最后，我对比了其它项目的配置，发现 手动设置 maven-assembly-plugin 插件的版本为 <version>2.6</version> 即可。而之前是没有设置这个版本号的，默认去仓库获取的最新版本，这个默认的版本可能刚好有问题。</p><h1 id="Python- 入门踩坑"><a href="#Python- 入门踩坑" class="headerlink" title="Python 入门踩坑"></a>Python 入门踩坑 </h1><p> 在一开始使用 Python 的时候，没有使用类似 Anaconda、Winpython 这种套件来帮我自动管理 Python 的第三方工具库，而是从 Python 安装开始，用到什么再用 pip 安装什么。整个过程真的可以把人搞崩溃，工具库之间的传递依赖、版本的不兼容等问题，令人望而却步，下面给出一些难忘的经历。</p><p>出现错误：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Install packages failed: Installing packages: error occurred</span><br><span class="line">numpy.distutils.system_info.NotFoundError: no lapack/blas resources found</span><br></pre></td></tr></table></figure><p>需要先手动安装 numpy+mkl，再手动安装 scipy，下载文件链接：<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs" target="_blank" rel="noopener">http://www.lfd.uci.edu/~gohlke/pythonlibs</a> 。我下载了 2 个文件：numpy-1.11.3+mkl-cp27-cp27m-win32.whl、scipy-0.19.0-cp27-cp27m-win32.whl，然后手动安装。</p><p>一开始我下载的是 64 位的安装包，结果发现我的 Windows 安装的 Python 是 32 位的，导致不支持【下载时没有选择位数，直接下载的默认的包】。另外，直接进入 Python 的命令行环境时也会打印出版本信息的。使用 import pip; print (pip.pep425tags.get_supported ()); 可以获取到 pip 支持的文件名和版本。</p><p>注意安装 scipy 之前还需要各种第三方库，官方介绍：<strong>Install numpy+mkl before installing scipy.</strong>。在 Shell 中验证安装第三方库是否成功，例如 numpy：from numpy import *。</p><p>scipy 包安装：pip install scipy==0.16.1【不推荐】，成功完成安装，如果缺少第三方包会报很多错误。网上查询后的总结：安装 numpy 后安装 scipy 失败，报错：<strong>numpy.distutils.system_info.NotFoundError</strong>，一般是缺少一些系统库，需要安装：libopenblas-dev、liblapack-dev、libatlas-dev、libblas-dev。</p><p>常见第三方库介绍：</p><ul><li>pandas，分析数据 </li><li>sklearn，机器学习，各种算法</li><li>jieba，分词工具</li><li>gensim nlp word2v，模块训练词向量模型</li><li>scipy，算法库，数学工具包</li><li>numpy，数据分析</li><li>matlptop，图形可视化</li></ul><p>Python 中的编码：<br>2.X 版本，python 编码过程： 输入 –&gt; str –&gt; decode –&gt; unicode –&gt; encode –&gt; str –&gt; 输出。<br>3.X 版本，不一样，直接是 unicode。</p><p>Python 中代码有 <strong>print u’xx’ + yy</strong>，yy 是中文，直接跑的时候打印到 Shell 不报错，但是使用后台挂起跑的时候，重定向到文件时，会报错，因为 Python 获取不到输出流的编码。</p><h1 id="Spark-UI- 无法显示"><a href="#Spark-UI- 无法显示" class="headerlink" title="Spark UI 无法显示"></a>Spark UI 无法显示</h1><p> 使用 yarn-client 模式起了一个 Spark 任务，在 Driver 端看到异常日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-01-16_14:53:31 [qtp192486017-1829 - /static/timeline-view.js] WARN servlet.DefaultServlet:587: EXCEPTION </span><br><span class="line">java.lang.IllegalArgumentException: MALFORMED</span><br><span class="line">	at java.util.zip.ZipCoder.toString (ZipCoder.java:58)</span><br><span class="line">	at java.util.zip.ZipFile.getZipEntry (ZipFile.java:583)</span><br><span class="line">	at java.util.zip.ZipFile.access$900 (ZipFile.java:60)</span><br><span class="line">	at java.util.zip.ZipFile$ZipEntryIterator.next (ZipFile.java:539)</span><br><span class="line">	at java.util.zip.ZipFile$ZipEntryIterator.nextElement (ZipFile.java:514)</span><br><span class="line">	at java.util.zip.ZipFile$ZipEntryIterator.nextElement (ZipFile.java:495)</span><br><span class="line">	at java.util.jar.JarFile$JarEntryIterator.next (JarFile.java:257)</span><br><span class="line">	at java.util.jar.JarFile$JarEntryIterator.nextElement (JarFile.java:266)</span><br><span class="line">	at java.util.jar.JarFile$JarEntryIterator.nextElement (JarFile.java:247)</span><br><span class="line">	at org.spark-project.jetty.util.resource.JarFileResource.exists (JarFileResource.java:189)</span><br><span class="line">	at org.spark-project.jetty.servlet.DefaultServlet.getResource (DefaultServlet.java:398)</span><br><span class="line">	at org.spark-project.jetty.servlet.DefaultServlet.doGet (DefaultServlet.java:476)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:707)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:820)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHolder.handle (ServletHolder.java:684)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1507)</span><br><span class="line">	at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter (AmIpFilter.java:164)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1478)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler.doHandle (ServletHandler.java:499)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandler.doHandle (ContextHandler.java:1086)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler.doScope (ServletHandler.java:427)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandler.doScope (ContextHandler.java:1020)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ScopedHandler.handle (ScopedHandler.java:135)</span><br><span class="line">	at org.spark-project.jetty.server.handler.GzipHandler.handle (GzipHandler.java:264)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle (ContextHandlerCollection.java:255)</span><br><span class="line">	at org.spark-project.jetty.server.handler.HandlerWrapper.handle (HandlerWrapper.java:116)</span><br><span class="line">	at org.spark-project.jetty.server.Server.handle (Server.java:366)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest (AbstractHttpConnection.java:494)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete (AbstractHttpConnection.java:973)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete (AbstractHttpConnection.java:1035)</span><br><span class="line">	at org.spark-project.jetty.http.HttpParser.parseNext (HttpParser.java:641)</span><br><span class="line">	at org.spark-project.jetty.http.HttpParser.parseAvailable (HttpParser.java:231)</span><br><span class="line">	at org.spark-project.jetty.server.AsyncHttpConnection.handle (AsyncHttpConnection.java:82)</span><br><span class="line">	at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle (SelectChannelEndPoint.java:696)</span><br><span class="line">	at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run (SelectChannelEndPoint.java:53)</span><br><span class="line">	at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob (QueuedThreadPool.java:608)</span><br><span class="line">	at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run (QueuedThreadPool.java:543)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">2019-01-16_14:53:31 [qtp192486017-1829 - /static/timeline-view.js] WARN servlet.ServletHandler:592: Error for /static/timeline-view.js</span><br><span class="line">java.lang.NoClassDefFoundError: org/spark-project/jetty/server/handler/ErrorHandler$ErrorPageMapper</span><br><span class="line">	at org.spark-project.jetty.server.handler.ErrorHandler.handle (ErrorHandler.java:71)</span><br><span class="line">	at org.spark-project.jetty.server.Response.sendError (Response.java:349)</span><br><span class="line">	at javax.servlet.http.HttpServletResponseWrapper.sendError (HttpServletResponseWrapper.java:118)</span><br><span class="line">	at org.spark-project.jetty.http.gzip.CompressedResponseWrapper.sendError (CompressedResponseWrapper.java:291)</span><br><span class="line">	at org.spark-project.jetty.servlet.DefaultServlet.doGet (DefaultServlet.java:589)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:707)</span><br><span class="line">	at javax.servlet.http.HttpServlet.service (HttpServlet.java:820)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHolder.handle (ServletHolder.java:684)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1507)</span><br><span class="line">	at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter (AmIpFilter.java:164)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1478)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler.doHandle (ServletHandler.java:499)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandler.doHandle (ContextHandler.java:1086)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler.doScope (ServletHandler.java:427)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandler.doScope (ContextHandler.java:1020)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ScopedHandler.handle (ScopedHandler.java:135)</span><br><span class="line">	at org.spark-project.jetty.server.handler.GzipHandler.handle (GzipHandler.java:264)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle (ContextHandlerCollection.java:255)</span><br><span class="line">	at org.spark-project.jetty.server.handler.HandlerWrapper.handle (HandlerWrapper.java:116)</span><br><span class="line">	at org.spark-project.jetty.server.Server.handle (Server.java:366)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest (AbstractHttpConnection.java:494)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete (AbstractHttpConnection.java:973)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete (AbstractHttpConnection.java:1035)</span><br><span class="line">	at org.spark-project.jetty.http.HttpParser.parseNext (HttpParser.java:641)</span><br><span class="line">	at org.spark-project.jetty.http.HttpParser.parseAvailable (HttpParser.java:231)</span><br><span class="line">	at org.spark-project.jetty.server.AsyncHttpConnection.handle (AsyncHttpConnection.java:82)</span><br><span class="line">	at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle (SelectChannelEndPoint.java:696)</span><br><span class="line">	at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run (SelectChannelEndPoint.java:53)</span><br><span class="line">	at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob (QueuedThreadPool.java:608)</span><br><span class="line">	at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run (QueuedThreadPool.java:543)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">2019-01-16_14:53:31 [qtp192486017-1829 - /static/timeline-view.js] WARN server.AbstractHttpConnection:552: /static/timeline-view.js</span><br><span class="line">java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted () Z</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler.doHandle (ServletHandler.java:608)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandler.doHandle (ContextHandler.java:1086)</span><br><span class="line">	at org.spark-project.jetty.servlet.ServletHandler.doScope (ServletHandler.java:427)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandler.doScope (ContextHandler.java:1020)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ScopedHandler.handle (ScopedHandler.java:135)</span><br><span class="line">	at org.spark-project.jetty.server.handler.GzipHandler.handle (GzipHandler.java:264)</span><br><span class="line">	at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle (ContextHandlerCollection.java:255)</span><br><span class="line">	at org.spark-project.jetty.server.handler.HandlerWrapper.handle (HandlerWrapper.java:116)</span><br><span class="line">	at org.spark-project.jetty.server.Server.handle (Server.java:366)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest (AbstractHttpConnection.java:494)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete (AbstractHttpConnection.java:973)</span><br><span class="line">	at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete (AbstractHttpConnection.java:1035)</span><br><span class="line">	at org.spark-project.jetty.http.HttpParser.parseNext (HttpParser.java:641)</span><br><span class="line">	at org.spark-project.jetty.http.HttpParser.parseAvailable (HttpParser.java:231)</span><br><span class="line">	at org.spark-project.jetty.server.AsyncHttpConnection.handle (AsyncHttpConnection.java:82)</span><br><span class="line">	at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle (SelectChannelEndPoint.java:696)</span><br><span class="line">	at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run (SelectChannelEndPoint.java:53)</span><br><span class="line">	at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob (QueuedThreadPool.java:608)</span><br><span class="line">	at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run (QueuedThreadPool.java:543)</span><br><span class="line">	at java.lang.Thread.run (Thread.java:748)</span><br></pre></td></tr></table></figure><p>这个日志在反复打印，也就是在任务的运行过程中，一直都有这个错误。它引发了什么问题呢，我检查了一下，对 Spark 任务的实际功能并没有影响，任务跑完后功能正常实现。但是，我发现在任务的运行过程中，Spark UI 页面打开后不正常显示【异常信息的开头就是关于某个 js 文件问题】：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12h3dbte0j20tr0ge3yv.jpg" alt="SparkUI 不正常显示" title="SparkUI 不正常显示"></p><p>点击进去，直接显示 Error 500：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12h42u9iuj20t50fa74n.jpg" alt="点击进去" title="点击进去"><br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12h48uvu5j20mj08imwz.jpg" alt="Error500" title="Error500"></p><p>服务器的 Driver 端日志截图：<br>日志截图 1<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12h4vfjokj20wu0mgwgs.jpg" alt="日志截图 1" title="日志截图 1"></p><p>日志截图 2<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12h4zran1j20ya0mgwgy.jpg" alt="日志截图 2" title="日志截图 2"></p><p>日志截图 3<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g12h53va2qj20xs0mgacl.jpg" alt="日志截图 3" title="日志截图 3"></p><p>等了几天，又遇到同样的问题，除了这 2 次，其它时间点就没遇到过了：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-01-24_22:51:49 [qtp697001207-1591 - /static/spark-dag-viz.js] WARN servlet.DefaultServlet:587: EXCEPTION </span><br><span class="line">java.lang.IllegalArgumentException: MALFORMED</span><br><span class="line">at java.util.zip.ZipCoder.toString (ZipCoder.java:58)</span><br><span class="line">at java.util.zip.ZipFile.getZipEntry (ZipFile.java:583)</span><br><span class="line">at java.util.zip.ZipFile.access$900 (ZipFile.java:60)</span><br><span class="line">at java.util.zip.ZipFile$ZipEntryIterator.next (ZipFile.java:539)</span><br><span class="line">at java.util.zip.ZipFile$ZipEntryIterator.nextElement (ZipFile.java:514)</span><br><span class="line">at java.util.zip.ZipFile$ZipEntryIterator.nextElement (ZipFile.java:495)</span><br><span class="line">at java.util.jar.JarFile$JarEntryIterator.next (JarFile.java:257)</span><br><span class="line">at java.util.jar.JarFile$JarEntryIterator.nextElement (JarFile.java:266)</span><br><span class="line">at java.util.jar.JarFile$JarEntryIterator.nextElement (JarFile.java:247)</span><br><span class="line">at org.spark-project.jetty.util.resource.JarFileResource.exists (JarFileResource.java:189)</span><br><span class="line">at org.spark-project.jetty.servlet.DefaultServlet.getResource (DefaultServlet.java:398)</span><br><span class="line">at org.spark-project.jetty.servlet.DefaultServlet.doGet (DefaultServlet.java:476)</span><br><span class="line">at javax.servlet.http.HttpServlet.service (HttpServlet.java:707)</span><br><span class="line">at javax.servlet.http.HttpServlet.service (HttpServlet.java:820)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHolder.handle (ServletHolder.java:684)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1507)</span><br><span class="line">at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter (AmIpFilter.java:164)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1478)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler.doHandle (ServletHandler.java:499)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandler.doHandle (ContextHandler.java:1086)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler.doScope (ServletHandler.java:427)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandler.doScope (ContextHandler.java:1020)</span><br><span class="line">at org.spark-project.jetty.server.handler.ScopedHandler.handle (ScopedHandler.java:135)</span><br><span class="line">at org.spark-project.jetty.server.handler.GzipHandler.handle (GzipHandler.java:264)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle (ContextHandlerCollection.java:255)</span><br><span class="line">at org.spark-project.jetty.server.handler.HandlerWrapper.handle (HandlerWrapper.java:116)</span><br><span class="line">at org.spark-project.jetty.server.Server.handle (Server.java:366)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest (AbstractHttpConnection.java:494)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete (AbstractHttpConnection.java:973)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete (AbstractHttpConnection.java:1035)</span><br><span class="line">at org.spark-project.jetty.http.HttpParser.parseNext (HttpParser.java:641)</span><br><span class="line">at org.spark-project.jetty.http.HttpParser.parseAvailable (HttpParser.java:231)</span><br><span class="line">at org.spark-project.jetty.server.AsyncHttpConnection.handle (AsyncHttpConnection.java:82)</span><br><span class="line">at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle (SelectChannelEndPoint.java:696)</span><br><span class="line">at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run (SelectChannelEndPoint.java:53)</span><br><span class="line">at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob (QueuedThreadPool.java:608)</span><br><span class="line">at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run (QueuedThreadPool.java:543)</span><br><span class="line">at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">2019-01-24_22:51:49 [qtp697001207-1591 - /static/spark-dag-viz.js] WARN servlet.ServletHandler:592: Error for /static/spark-dag-viz.js</span><br><span class="line">java.lang.NoClassDefFoundError: org/spark-project/jetty/server/handler/ErrorHandler$ErrorPageMapper</span><br><span class="line">at org.spark-project.jetty.server.handler.ErrorHandler.handle (ErrorHandler.java:71)</span><br><span class="line">at org.spark-project.jetty.server.Response.sendError (Response.java:349)</span><br><span class="line">at javax.servlet.http.HttpServletResponseWrapper.sendError (HttpServletResponseWrapper.java:118)</span><br><span class="line">at org.spark-project.jetty.http.gzip.CompressedResponseWrapper.sendError (CompressedResponseWrapper.java:291)</span><br><span class="line">at org.spark-project.jetty.servlet.DefaultServlet.doGet (DefaultServlet.java:589)</span><br><span class="line">at javax.servlet.http.HttpServlet.service (HttpServlet.java:707)</span><br><span class="line">at javax.servlet.http.HttpServlet.service (HttpServlet.java:820)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHolder.handle (ServletHolder.java:684)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1507)</span><br><span class="line">at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter (AmIpFilter.java:164)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler$CachedChain.doFilter (ServletHandler.java:1478)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler.doHandle (ServletHandler.java:499)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandler.doHandle (ContextHandler.java:1086)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler.doScope (ServletHandler.java:427)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandler.doScope (ContextHandler.java:1020)</span><br><span class="line">at org.spark-project.jetty.server.handler.ScopedHandler.handle (ScopedHandler.java:135)</span><br><span class="line">at org.spark-project.jetty.server.handler.GzipHandler.handle (GzipHandler.java:264)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle (ContextHandlerCollection.java:255)</span><br><span class="line">at org.spark-project.jetty.server.handler.HandlerWrapper.handle (HandlerWrapper.java:116)</span><br><span class="line">at org.spark-project.jetty.server.Server.handle (Server.java:366)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest (AbstractHttpConnection.java:494)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete (AbstractHttpConnection.java:973)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete (AbstractHttpConnection.java:1035)</span><br><span class="line">at org.spark-project.jetty.http.HttpParser.parseNext (HttpParser.java:641)</span><br><span class="line">at org.spark-project.jetty.http.HttpParser.parseAvailable (HttpParser.java:231)</span><br><span class="line">at org.spark-project.jetty.server.AsyncHttpConnection.handle (AsyncHttpConnection.java:82)</span><br><span class="line">at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle (SelectChannelEndPoint.java:696)</span><br><span class="line">at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run (SelectChannelEndPoint.java:53)</span><br><span class="line">at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob (QueuedThreadPool.java:608)</span><br><span class="line">at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run (QueuedThreadPool.java:543)</span><br><span class="line">at java.lang.Thread.run (Thread.java:748)</span><br><span class="line">2019-01-24_22:51:49 [qtp697001207-1591 - /static/spark-dag-viz.js] WARN server.AbstractHttpConnection:552: /static/spark-dag-viz.js</span><br><span class="line">java.lang.NoSuchMethodError: javax.servlet.http.HttpServletRequest.isAsyncStarted () Z</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler.doHandle (ServletHandler.java:608)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandler.doHandle (ContextHandler.java:1086)</span><br><span class="line">at org.spark-project.jetty.servlet.ServletHandler.doScope (ServletHandler.java:427)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandler.doScope (ContextHandler.java:1020)</span><br><span class="line">at org.spark-project.jetty.server.handler.ScopedHandler.handle (ScopedHandler.java:135)</span><br><span class="line">at org.spark-project.jetty.server.handler.GzipHandler.handle (GzipHandler.java:264)</span><br><span class="line">at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle (ContextHandlerCollection.java:255)</span><br><span class="line">at org.spark-project.jetty.server.handler.HandlerWrapper.handle (HandlerWrapper.java:116)</span><br><span class="line">at org.spark-project.jetty.server.Server.handle (Server.java:366)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest (AbstractHttpConnection.java:494)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete (AbstractHttpConnection.java:973)</span><br><span class="line">at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete (AbstractHttpConnection.java:1035)</span><br><span class="line">at org.spark-project.jetty.http.HttpParser.parseNext (HttpParser.java:641)</span><br><span class="line">at org.spark-project.jetty.http.HttpParser.parseAvailable (HttpParser.java:231)</span><br><span class="line">at org.spark-project.jetty.server.AsyncHttpConnection.handle (AsyncHttpConnection.java:82)</span><br><span class="line">at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle (SelectChannelEndPoint.java:696)</span><br><span class="line">at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run (SelectChannelEndPoint.java:53)</span><br><span class="line">at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob (QueuedThreadPool.java:608)</span><br><span class="line">at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run (QueuedThreadPool.java:543)</span><br><span class="line">at java.lang.Thread.run (Thread.java:748)</span><br></pre></td></tr></table></figure><p>此外，还有一点值得注意，Chrome 浏览器的某些端口是禁止访问的，所以遇到过有一个 Spark 任务使用了 4045 端口【locked】，在 Chrome 浏览器是看不了任务状态的，页面无法打开，被 Chrome 浏览器屏蔽了，此时并不是 Spark 的问题。</p><h1 id="关于 -Git- 的小问题"><a href="# 关于 -Git- 的小问题" class="headerlink" title="关于 Git 的小问题"></a>关于 Git 的小问题 </h1><p>1、本地版本落后，而且又与远程仓库冲突，git pull 报错警告，需要 merge，无法直接更新最新版本。下面的操作直接覆盖本地文件，强制更新到最新版本，本地未提交的更改会丢失。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git fetch --all</span><br><span class="line">git reset --hard origin/master</span><br></pre></td></tr></table></figure><p>2、在 2018 年 9 月的某一天，发现 Git 的代码推送总是需要输入帐号和密码，哪怕保存下来也不行，每次 push 都需要重新输入，感觉很奇怪。后来发现是版本太旧了，当时的版本是 v2.13.0，升级后的版本是 v2.18.0，升级后就恢复正常了。后来无意间在哪里看到过通知，说是 TSL 协议升级了，所以针对旧版本强制输入用户名密码，升级就可以解决。</p><p> 备注一下，HTTPS 是在 TCP 和 HTTP 之间增加了 TLS【Transport Layer Security，传输层安全】，提供了内容加密、身份认证和数据完整性三大功能。TLS 的前身是 SSL【Secure Sockets Layer，安全套接字层】，由网景公司开发，后来被 IETF 标准化并改名。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>基础技术知识</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Spark</tag>
        <tag>Python</tag>
        <tag>ElasticSearch</tag>
        <tag>es</tag>
      </tags>
  </entry>
  <entry>
    <title>解决 jar 包冲突的神器：maven-shade-plugin</title>
    <url>/2019120101.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近因为协助升级相关业务的 <code>sdk</code>，遇到过多次 <code>jar</code> 包冲突的问题，此外自己在业务中升级算法接口的 <code>sdk</code> 时，也遇到过 <code>jar</code> 冲突问题。而且，这种冲突是灾难性的，不要指望通过排除特定包、升级版本、降级版本解决，根本无济于事，还会越来越混乱。</p><p>那么，最高效的方法是使用 <code>maven-shade-plugin</code> 插件，只要加上冲突相关的 <code>relocation</code> 配置，变更包名，即可迅速化解冲突的问题。</p><a id="more"></a><p>在此提前说明，下文中涉及的代码已经被我上传至 <code>GtiHub</code>：<a href="https://github.com/iplaypi/iplaypistudy-shade" target="_blank" rel="noopener">iplaypistudy-shade</a> ，特别独立创建了一个 <code>Maven</code> 小项目，专供演示使用，读者可以提前下载使用。</p><h1 id="前提场景"><a href="# 前提场景" class="headerlink" title="前提场景"></a>前提场景 </h1><p> 在 <code>Maven</code> 项目中，当功能越来越丰富，需要的第三方依赖也就越来越多，此时很容易发生 <code>jar</code> 包冲突。而通常是因为，<code>Mavne</code> 项目中依赖了同一个 <code>jar</code> 包的多个版本，即坐标版本号不同。</p><p>一般的思路是只保留一个版本，删除掉不需要的版本，但是在复杂情况下，版本之间不兼容，不可能就这么删掉某一个【因为多个 <code>jar</code> 分别被引用了不同的方法】，所以这种思路行不通。</p><p>例如我最近遇到了一个下图这样的例子【本文开头指定的 <code>GitHub</code> 源代码可以直接下载】：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208195230.png" alt="依赖冲突的项目结构" title="依赖冲突的项目结构"></p><p>其中，<code>module-a</code>、<code>module-b</code>、<code>module-c</code> 是我项目中的三个模块，<code>module-a</code> 同时依赖了子模块 <code>module-b</code> 和 <code>module-c</code>，这个很容易理解。</p><p>但是，在 <code>module-b</code>、<code>module-c</code> 中分别依赖了不同版本的 <code>guava</code>，并且在代码中有实际调用不兼容的方法，高版本的方法在低版本中不存在，低版本的方法在高版本中不存在【这属于 <code>guava</code> 没有做到向前兼容的问题】。</p><p>代码具体内容在后面的演示中会详细描述，这里先探讨一下这种情况该怎么办。</p><p>如果排除掉 <code>guava v19.0</code> 的话【使用 <code>exclude</code> 特性】，<code>module-b</code> 会报错，如果排除掉 <code>guava v26.0-jre</code> 的话，<code>module-c</code> 会报错，但是我又希望在项目中可以同时使用 <code>guava v19.0</code> 和 <code>guava v26.0-jre</code>，为了功能考虑也必须同时使用，不能排除任何一个。</p><p>好像陷入了僵局，反正我一开始是没有什么好办法的，直到有一位同事，在我旁边偶尔提了一句，你可以使用 <code>maven-shade-plugin</code> 插件，能完美解决你这个需求场景，方便快捷，毫无痛苦。</p><p>我自己先去了解了一下，后来又听他解释了一遍，才恍然大悟，感觉技术观念再一次被刷新了，居然还有这种操作。</p><p>下面就简单描述一下具体怎么使用 <code>maven-shade-plugin</code> 插件解决这个问题。</p><h1 id="解决方案演示"><a href="# 解决方案演示" class="headerlink" title="解决方案演示"></a>解决方案演示 </h1><h2 id="案例说明"><a href="# 案例说明" class="headerlink" title="案例说明"></a> 案例说明 </h2><p> 由于是演示 <code>maven-shade-plugin</code> 插件的使用，所以仅仅只有几行核心代码、几个核心依赖，但是完全可以表达出解决冲突的思路，源代码请读者从本文开头指定的 <code>GitHub</code> 链接下载。</p><p>如上图所示，<code>module-a</code>、<code>module-b</code>、<code>module-c</code> 是我项目中的三个模块，<code>module-a</code> 同时依赖了子模块 <code>module-b</code> 和 <code>module-c</code>。在子模块 <code>module-b</code> 中，依赖了 <code>guava v19.0</code>，在 子模块 <code>module-c</code> 中，依赖了 <code>guava v26.0-jre</code>。</p><p>好，接下来重点来了，在 <code>guava</code> 的两个版本中有下面两个不兼容的方法，特意挑选出来，用来测试：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 这个方法在 v19.0 中有，在 v26.0-jre 中没有 </span><br><span class="line">@CheckReturnValue</span><br><span class="line">  @Deprecated</span><br><span class="line">  public static ToStringHelper toStringHelper (Object self) &#123;</span><br><span class="line">	return new ToStringHelper (self.getClass ().getSimpleName ());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 这个方法在 v26.0-jre 中有，在 v19.0 中没有 </span><br><span class="line">public static String lenientFormat (@Nullable String template, @Nullable Object... args) &#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，如果在 <code>module-b</code>、<code>module-c</code> 的依赖 <code>jar</code> 源码中有调用到，也是可以的，但是不直观，而且依赖 <code>jar</code> 的方法也不一定会执行，不好控制，所以我选择手动显式写代码调用的方式来演示。</p><h2 id="代码清单"><a href="# 代码清单" class="headerlink" title="代码清单"></a>代码清单 </h2><p> 演示代码主要内容如下。</p><p>在 <code>module-b</code> 中有一个类 <code>ModuleBRun</code>，调用了 <code>toStringHelper ()</code> 方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">public class ModuleBRun &#123;</span><br><span class="line">	public static void main (String [] args) &#123;</span><br><span class="line">		log.info (&quot;====Hello World!&quot;);</span><br><span class="line">		run ();</span><br><span class="line">	&#125;</span><br><span class="line">	public static void run () &#123;</span><br><span class="line">		// 这个方法在 v19.0 中有，在 v26.0-jre 中没有 </span><br><span class="line">		log.info (&quot;==== 开始执行 module-b 的代码 & quot;);</span><br><span class="line">		Objects.ToStringHelper toStringHelper = Objects.toStringHelper (new Object ());</span><br><span class="line">		toStringHelper.add (&quot;in&quot;, &quot;in&quot;);</span><br><span class="line">		toStringHelper.add (&quot;out&quot;, &quot;out&quot;);</span><br><span class="line">		log.info (&quot;====[&#123;&#125;]&quot;, toStringHelper.toString ());</span><br><span class="line">		log.info (&quot;====module-b 的代码执行完成 & quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208015421.png" alt="ModuleBRun" title="ModuleBRun"></p><p>在 <code>module-c</code> 中有一个类 <code>ModuleCRun</code>，调用了 <code>lenientFormat ()</code> 方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">public class ModuleCRun &#123;</span><br><span class="line">	public static void main (String [] args) &#123;</span><br><span class="line">		log.info (&quot;====Hello World!&quot;);</span><br><span class="line">		run ();</span><br><span class="line">	&#125;</span><br><span class="line">	public static void run () &#123;</span><br><span class="line">		log.info (&quot;==== 开始执行 module-c 的代码 & quot;);</span><br><span class="line">		// 这个方法在 v26.0-jre 中有，在 v19.0 中没有 </span><br><span class="line">		log.info (&quot;====[&#123;&#125;]&quot;, Strings.lenientFormat (&quot;&quot;, &quot;in&quot;, &quot;out&quot;));</span><br><span class="line">		log.info (&quot;====module-c 的代码执行完成 & quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208015600.png" alt="ModuleCRun" title="ModuleCRun"></p><p>在 <code>module-a</code> 中有一个类 <code>ModuleARun</code>，有一个 <code>run ()</code> 方法，分别调用了上面的 <code>ModuleBRun.run ()</code>、<code>ModuleCRun.run ()</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 依赖 b/c 时，无法成功运行 </span><br><span class="line">     * &lt;p&gt;</span><br><span class="line">     * 依赖 b/c-shade 时，可以成功运行 </span><br><span class="line">     */</span><br><span class="line">public static void run () &#123;</span><br><span class="line">	log.info (&quot;==== 开始执行 module-a 的代码 & quot;);</span><br><span class="line">	ModuleBRun.run ();</span><br><span class="line">	ModuleCRun.run ();</span><br><span class="line">	log.info (&quot;====module-a 的代码执行完成 & quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208015629.png" alt="ModuleARun" title="ModuleARun"></p><h2 id="运行效果"><a href="# 运行效果" class="headerlink" title="运行效果"></a>运行效果 </h2><p> 此时，尝试本地调试运行 <code>ModuleARun.run ()</code>，或者使用 <code>Maven</code> 打 <code>jar</code> 包后运行：<code>java -jar iplaypistudy-shade-module-a-1.0-SNAPSHOT-jar-with-dependencies.jar</code>，需要提前使用 <code>maven-shade-plugin</code> 配置 <code>mainClass</code> 后打包。</p><p>可以发现如下错误：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-02-08_01:27:25 [main] INFO study.ModuleARun:13: ====Hello World!</span><br><span class="line">2020-02-08_01:27:25 [main] INFO study.ModuleARun:24: ==== 开始执行 module-a 的代码 </span><br><span class="line">2020-02-08_01:27:25 [main] INFO study.ModuleBRun:19: ==== 开始执行 module-b 的代码 </span><br><span class="line">2020-02-08_01:27:25 [main] INFO study.ModuleBRun:23: ====[Object&#123;in=in, out=out&#125;]</span><br><span class="line">2020-02-08_01:27:25 [main] INFO study.ModuleBRun:24: ====module-b 的代码执行完成 </span><br><span class="line">2020-02-08_01:27:25 [main] INFO study.ModuleCRun:18: ==== 开始执行 module-c 的代码 </span><br><span class="line">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: com.google.common.base.Strings.lenientFormat (Ljava/lang/String;[Ljava/lang/Object;) Ljava/lang/String;</span><br><span class="line">	at org.playpi.study.ModuleCRun.run (ModuleCRun.java:20)</span><br><span class="line">	at org.playpi.study.ModuleARun.run (ModuleARun.java:26)</span><br><span class="line">	at org.playpi.study.ModuleARun.main (ModuleARun.java:14)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208014735.png" alt="调试运行结果" title="调试运行结果"></p><p>看到 <code>NoSuchMethodError</code> 就知道出现了严重的问题，如果试图使用搜索功能搜索 <code>Strings</code> 这个类，可以发现有 2 个一模一样的类，但是他们对应的 <code>guava jar</code> 的版本号不一致。这时候有经验的工程师就可以立马判断，编译运行 <code>JVM</code> 加载的 <code>jar</code> 对于 <code>ModuleCRun.run ()</code> 方法来说是有问题的，只加载了特定版本的 <code>guava jar</code>，确保了 <code>ModuleBRun.run ()</code> 方法可以顺利执行【和手动排除 <code>module-c</code> 中的 <code>guava v26.0-jre</code> 一个效果】。</p><p>如果是编译打包后使用 <code>java</code> 命令再运行，可以发现同样的错误，如果此时尝试解压 <code>jar</code> 包，反编译源码，查看具体的类，可以看到编译打包后有些类是不存在的【多版本的 <code>jar</code> 只会保留一个，就会导致另一个 <code>jar</code> 中的类全部丢失，如果此时恰好有不兼容的类，那就出问题】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208013756.png" alt="搜索 Strings 类" title="搜索 Strings 类"></p><p>那有人会想到，能不能手动排除 <code>module-a</code> 中的 <code>guava v19.0</code> 呢，我来试试，在 <code>module-a</code> 的 <code>pom.xml</code> 中对 <code>module-b</code> 添加 <code>exclude</code> 属性：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.playpi.study&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;iplaypistudy-shade-module-b&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;$&#123;parent.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;!-- 这里排除会导致调用 ModuleBRun.run () 时出现 NoSuchMethodError --&gt;</span><br><span class="line">    &lt;exclusions&gt;</span><br><span class="line">        &lt;exclusion&gt;</span><br><span class="line">            &lt;groupId&gt;com.google.guava&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;guava&lt;/artifactId&gt;</span><br><span class="line">        &lt;/exclusion&gt;</span><br><span class="line">    &lt;/exclusions&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>调试运行结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-02-08_01:40:33 [main] INFO study.ModuleARun:13: ====Hello World!</span><br><span class="line">2020-02-08_01:40:33 [main] INFO study.ModuleARun:24: ==== 开始执行 module-a 的代码 </span><br><span class="line">2020-02-08_01:40:33 [main] INFO study.ModuleBRun:19: ==== 开始执行 module-b 的代码 </span><br><span class="line">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: com.google.common.base.Objects.toStringHelper (Ljava/lang/Object;) Lcom/google/common/base/Objects$ToStringHelper;</span><br><span class="line">	at org.playpi.study.ModuleBRun.run (ModuleBRun.java:20)</span><br><span class="line">	at org.playpi.study.ModuleARun.run (ModuleARun.java:25)</span><br><span class="line">	at org.playpi.study.ModuleARun.main (ModuleARun.java:14)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208014710.png" alt="调试运行结果" title="调试运行结果"></p><p>可见还是有同样的问题，运行到 <code>ModuleBRun ()</code> 方法时已经出错了，根源就在于多版本的 <code>guava</code> 之间无法兼容。</p><p>这里需要注意的是，在 <code>module-a</code> 中并不能随意调用 <code>module-c</code> 中 <code>guava v26.0-jre</code> 的方法，如果方法不存在的话编译不会通过【<code>maven</code> 先加载了低版本的 <code>guava v19.0</code>】。而单独看 <code>module-c</code> 的话，它是一个独立的子模块，所以 <code>module-c</code> 中的方法不受编译的限制，只有在把 <code>module-a</code> 打包后，真正运行时才会抛出异常。</p><p>具体可以参考 <code>ModuleARun</code> 中的 <code>runGuava ()</code> 方法：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * 依赖 b/c 时或者依赖 b/c-shade 时:</span><br><span class="line">     * 在这里无法像 module-c 那样直接调用 26.0-jre 里面的方法，编译无法通过 </span><br><span class="line">     * 但是 module-c 里面的代码是单独处于模块里面，编译时无法检测，所以 ModuleCRun.run () 可以通过编译 (编译阶段不会检测 run 里面的代码)</span><br><span class="line">     * &lt;p&gt;</span><br><span class="line">     * 所以:</span><br><span class="line">     * 制作 shade 只是可以保证 ModuleCRun.run () 正常执行，并不能保证 Strings.lenientFormat 可用 (连编译都无法通过)</span><br><span class="line">     */</span><br><span class="line">public static void runGuava () &#123;</span><br><span class="line">	log.info (&quot;==== 开始执行 module-a 的 guava v19.0 代码 & quot;);</span><br><span class="line">	Objects.ToStringHelper toStringHelper = Objects.toStringHelper (new Object ());</span><br><span class="line">	toStringHelper.add (&quot;in&quot;, &quot;in&quot;);</span><br><span class="line">	toStringHelper.add (&quot;out&quot;, &quot;out&quot;);</span><br><span class="line">	log.info (&quot;====[&#123;&#125;]&quot;, toStringHelper.toString ());</span><br><span class="line">	log.info (&quot;====module-a 的 guava v19.0 代码执行完成 & quot;);</span><br><span class="line">	log.info (&quot;&quot;);</span><br><span class="line">	log.info (&quot;==== 开始执行 module-a 的 guava v26.0-jre 代码 & quot;);</span><br><span class="line">	//        log.info (&quot;====[&#123;&#125;]&quot;, Strings.lenientFormat (&quot;&quot;, &quot;in&quot;, &quot;out&quot;));</span><br><span class="line">	log.info (&quot;====module-a 的 guava v26.0-jre 代码执行完成 & quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="插件登场"><a href="# 插件登场" class="headerlink" title="插件登场"></a>插件登场 </h2><p> 看似疑无路，其实还有柳暗花明，使用 <code>maven-shade-plugin</code> 插件可以完美解决上述的问题。</p><p>在 <code>module-c</code> 的 <code>pom.xml</code> 配置文件中，给插件 <code>maven-shade-plugin</code> 添加 <code>relocation</code> 配置，把 <code>com.google.common</code> 包路径变为 <code>iplaypi.com.google.common</code>，要确保独一无二，总体内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 非常好用的 shade 插件 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;$&#123;maven-shade-plugin.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;!-- Maven 的生命周期 --&gt;</span><br><span class="line">            &lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;!-- 插件目标 --&gt;</span><br><span class="line">                &lt;goal&gt;shade&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;!-- 配置多版本 jar 包中类路径的重命名 --&gt;</span><br><span class="line">                &lt;relocations&gt;</span><br><span class="line">                    &lt;relocation&gt;</span><br><span class="line">                        &lt;pattern&gt;com.google.common&lt;/pattern&gt;</span><br><span class="line">                        &lt;shadedPattern&gt;iplaypi.com.google.common&lt;/shadedPattern&gt;</span><br><span class="line">                    &lt;/relocation&gt;</span><br><span class="line">                &lt;/relocations&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208185321.png" alt="给 C 模块添加 relocation" title="给 C 模块添加 relocation"></p><p>此外，在 <code>module-a</code> 中也需要配置常规的打包参数，使用 <code>mainClass</code> 指定主类，使用 <code>shadedClassifierName</code> 指定 <code>jar</code> 包后缀【不会用到 <code>relocation</code> 的功能】，内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;$&#123;maven-shade-plugin.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;!-- Maven 的生命周期 --&gt;</span><br><span class="line">            &lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;!-- 插件目标 --&gt;</span><br><span class="line">                &lt;goal&gt;shade&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;transformers&gt;</span><br><span class="line">                    &lt;!-- 使用资源转换器 ManifestResourceTransformer, 可执行的 jar 包 --&gt;</span><br><span class="line">                    &lt;transformer</span><br><span class="line">                                        implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;</span><br><span class="line">                        </span><br><span class="line">                     &lt;!-- 指定主类入口 --&gt;                       &lt;mainClass&gt;org.playpi.study.ModuleARun&lt;/mainClass&gt;</span><br><span class="line">                    &lt;/transformer&gt;</span><br><span class="line">                &lt;/transformers&gt;</span><br><span class="line">                &lt;!-- 指定 jar 包后缀 --&gt;</span><br><span class="line">                &lt;shadedClassifierName&gt;jar-with-dependencies&lt;/shadedClassifierName&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208185900.png" alt="给 A 模块添加打包参数" title="给 A 模块添加打包参数"></p><p>接着就可以编译打包了：<code>mvn clean package</code>，打包完成后，在 <code>target</code> 目录下找到最终的 <code>jar</code> 包，使用 <code>java</code> 命令执行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -jar iplaypistudy-shade-module-a-1.0-SNAPSHOT-jar-with-dependencies.jar</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleARun:12: ====Hello World!</span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleARun:23: ==== 开始执行 module-a 的代码 </span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleBRun:19: ==== 开始执行 module-b 的代码 </span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleBRun:23: ====[Object&#123;in=in, out=out</span><br><span class="line">]</span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleBRun:24: ====module-b 的代码执行完成 </span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleCRun:18: ==== 开始执行 module-c 的代码 </span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleCRun:20: ====[[in, out]]</span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleCRun:21: ====module-c 的代码执行完成 </span><br><span class="line">2020-02-08_19:08:04 [main] INFO study.ModuleARun:26: ====module-a 的代码执行完成 </span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208190909.png" alt="运行成功" title="运行成功"></p><p>可以看到运行结果，所有的方法都调用成功，说明不存在多版本的 <code>jar</code> 包冲突的问题了。</p><p>注意，此时不能使用 <strong>调试运行的方法 </strong>，读者会发现使用 <code>IDEA</code> 等工具直接调试运行，仍旧会出错，这是因为 <code>IDEA</code> 调试运行只是经过了 <code>compile</code> 阶段，而 <code>maven-shade-plugin</code> 插件中的 <code>shade relocation</code> 根本没有执行。由于我们配置的 <code>phase</code> 是 <code>package</code>【绑定到 <code>Maven</code> 的 <code>package</code> 生命周期】，因此，必须经过打包后，直接指定 <code>main</code> 主类运行 <code>jar</code> 包，才会看到效果。</p><p>为了知其然也知其所以然，我们肯定要看看 <code>jar</code> 包到底发生了什么变化，找到 <code>jar</code> 包，使用 <code>Java Decompiler</code> 工具反编译字节码文件，查看 <code>.java</code> 文件有什么变化，我们首先能想到的就是类路径变化了。</p><p>找到 <code>Strings</code> 类文件，可以看到它的类路径变化了，已经变为了 <code>iplaypi.com.google.common.base</code>，同时它所 <code>import</code> 的类路径也添加了 <code>iplaypi</code> 前缀。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208192045.png" alt="反编译查看源码" title="反编译查看源码"></p><p>也就是说，打包完成之后，在 <code>jar</code> 包里面可以看到原本 <code>com.google.common</code> 下面的类全部被保留，<code>guava v19.0</code> 的类路径没有变化，而 <code>guava v26.0-jre</code> 的所有类路径都被添加了前缀 <code>iplaypi.</code>，而这正是 <code>shade</code> 的功劳。如此一来，高、低版本的所有类都分离开了，调用方可以任意使用，不会再有冲突或者缺失的情况。</p><p>那我们再看看调用方的 <code>import</code> 是怎样的，分别找到 <code>ModuleBRun</code>、<code>ModuleCRun</code> 类。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208192409.png" alt="反编译后的 ModuleBRun" title="反编译后的 ModuleBRun"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208192525.png" alt="反编译后的 ModuleCRun" title="反编译后的 ModuleCRun"></p><p>从 <code>ModuleCRun</code> 中可以看到，调用方的代码类的 <code>import</code> 类路径也被同步替换。当然，由于 <code>ModuleBRun</code> 并没有参与 <code>shade relocation</code> 流程，所以 <code>import</code> 还是原来的样子。</p><p><strong>总结来说 </strong>，其实 <code>maven-shade-plugin</code> 插件并没有什么难以理解的地方，它只是帮助我们在构建 <code>jar</code> 包时，把特定的类路径转换为了我们指定的新路径，同时把所有调用方的 <code>import</code> 语句也改变了，这样就能确保这些类在加载到 <code>JVM</code> 中是独一无二的，也就不会冲突了【当然会造成最后的 <code>uber jar</code> 变大了，加载到 <code>JVM</code> 中的类也变多了】。</p><p>它的效果概念图如下：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208195142.png" alt="效果概念图" title="效果概念图"></p><p>当然，只看到现象还不够，下面我们来探讨一下它的实现方法，读者请看下一小节：<strong> 实现分析 </strong>。</p><h2 id="实现分析"><a href="# 实现分析" class="headerlink" title="实现分析"></a>实现分析 </h2><p> 想要分析 <code>maven-shade-plugin</code> 插件是如何实现这个功能的，源代码少不了，下面简单分析一下，可以直接打断点调试一下源代码，跟着源代码跑一遍打包的流程即可。</p><p>首先，需要下载源代码，在 <code>GitHub</code> 上面下载：<a href="https://github.com/apache/maven-shade-plugin/tree/maven-shade-plugin-3.2.1" target="_blank" rel="noopener">maven-shade-plugin</a> ，注意下载后切换到指定版本的，例如我使用的版本是 <code>v3.2.1</code>，则 <code>git clone</code> 后需要 <code>git checkout</code> 到指定的 <code>tag</code>【例如：<code>maven-shade-plugin-3.2.1</code>】。</p><p>源码下载成功后，它其实也是一个 <code>Maven</code> 项目【如果导入时 <code>IDEA</code> 识别不了，可以先 <code>Open</code> 看一下，需要一些初始化动作】，可以直接以 <code>Module</code> 的形式导入 <code>IDEA</code> 中，然后就可以直接被我们自己的项目依赖。</p><p>在 <code>IDEA</code> 中依次选择 <code>File</code>、<code>New</code>、<code>Module from existing Sources</code>【也可以在 <code>Project Structure</code> 中直接添加】，最终选择已经下载的项目源码，导入过程中还需要选择一些配置，例如项目为 <code>Maven</code> 类型、项目名称，直接使用默认值即可。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209205501.png" alt="添加模块" title="添加模块"></p><p>由于有部分 <code>jar</code> 包需要从远程仓库拉取，如果网络不好的话【或者没配置国内的仓库、镜像】，速度有点慢，需要耐心等待。</p><p>添加成功后，需要确保 <code>maven-shade-plugin</code> 模块正常，通过 <code>File</code>、<code>Project Structure</code>、<code>Module</code> 查看。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209205616.png" alt="检查模块" title="检查模块"></p><p>此时，我们 <code>module-a</code> 的 <code>pom.xml</code> 文件中配置的 <code>maven-shade-plugin</code> 插件，实际使用的就不是本地仓库的了，而是我们导入的 <code>Module</code>，这样就可以调试代码了。</p><p>找到 <code>maven-shade-plugin</code> 插件的入口，<code>Maven</code> 规定一般是 <code>@Mojo</code> 注解类的 <code>execute ()</code> 方法，我在这里找到类：<code>org.apache.maven.plugins.shade.mojo.ShadeMojo</code>，<code>execute ()</code> 方法在代码 381 行，在这个方法入口处 385 行：<code>setupHintedShader ();</code>，打上断点。</p><p>具体的生成 <code>jar</code> 包以及 <code>shade relocation</code> 功能的实现逻辑在 <code>org.apache.maven.plugins.shade.DefaultShader</code> 中，我们在 160 行的 <code>shadeJars ()</code> 方法中打上断点。</p><p>接着准备调试的步骤，可以增加一个 <code>Run/Debug Configuration</code>，把 <code>mvn clean package</code> 配置成为一个 <code>Application</code>，最后点击 <code>debug</code> 按钮就可以调试了。也可以直接选中项目右键，依次选择 <code>Debug Maven</code>、<code>debug: package</code>，直接进行调试，我使用的就是这种方式，如下图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209205712.png" alt="开始调试" title="开始调试"></p><p>首先进入到第一个断点：<code>execute ()</code> 方法，说明调试程序执行正常，直接进入到下一个断点：<code>shadeJars ()</code> 方法【注意，我这里截图执行的是 <code>module-c</code> 打包的流程，列出的 <code>jar</code> 包仅和 <code>module-c</code> 有关】：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209205731.png" alt="execute 方法" title="execute 方法"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209205746.png" alt="shadeJars 方法" title="shadeJars 方法"></p><p>可以从 <code>shadeRequest</code> 对象中看到 <code>jar</code> 包列表，以及 <code>relocators</code> 列表，<code>shade relocation</code> 的代码逻辑在 <code>org.apache.maven.plugins.shade.relocation.SimpleRelocator</code> 里面，里面有替换类路径、文件路径的操作实现。</p><p>接着进入到 <code>shadeSingleJar ()</code> 方法，可以看到对每一个文件进行处理，替换、合并等操作。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200209205801.png" alt="shadeSingleJar 方法" title="shadeSingleJar 方法"></p><p>最后也可以测试一下，如果不对 <code>module-c</code> 做 <code>shade relocation</code>，最终项目打包收集的所有 <code>jar</code> 包中，是没有 <code>guava v26.0-jre</code> 的，只有 <code>guava v19.0</code>，这也可以解释为什么运行时会缺失。</p><h2 id="另一种情况"><a href="# 另一种情况" class="headerlink" title="另一种情况"></a>另一种情况 </h2><p> 假设 <code>module-c</code> 不是我们自己维护的模块，我们无权限变更，更不可能直接去更改它的 <code>pom.xml</code> 文件，此时应该怎么办。可以把 <code>module-c</code> 类比成一个独立的 <code>jar</code> 包，拥有自己的坐标，由开源组织发布【例如 <code>hive-client</code>、<code>hbase-client</code>】，被 <code>module-a</code> 依赖引用，此时我们不可能去更改它的配置文件或者代码。</p><p>也有办法，那就是为这类 <code>jar</code> 包单独创建一个独立的 <code>module</code>，在这个 <code>module</code> 中完成 <code>shade</code> 操作，然后才把这个 <code>module</code> 给我们的项目引用。</p><p>在本例中，就以 <code>module-c</code> 为例，假如我们没有权限更改 <code>module-c</code> 中的代码、配置文件，只能新创建一个 <code>module-c-shade</code>，它里面什么代码都没有，只是简单地依赖 <code>module-c</code>，然后在配置文件 <code>pom.xml</code> 中做一个 <code>shade relocation</code>，把可能冲突的类解决掉。</p><p>项目结构如下图：</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200208200838.png" alt="复杂情况的传递依赖" title="复杂情况的传递依赖"></p><p>和上面的效果一致，编译打包后，依旧可以成功运行。</p><p>可以多思考一下，根据上面的情况，还有在什么场景下需要单独创建一个 <code>module</code>，里面没有任何代码，只是为了做影子依赖呢？</p><p>最先想到的肯定是类似上面那种，传递依赖导致的冲突，例如项目中依赖了 <code>es-hadoop</code>，而由此带来的 <code>guava</code>、<code>http</code> 等 <code>jar</code> 包冲突，我们不可能想着去改 <code>es-hadoop</code> 的 <code>pom.xml</code> 文件，因为我们不应当变更源码【太麻烦而且不利于管理】，当然也不一定能拿到源码。那么，只能单独创建一个 <code>module</code>，使用 <code>maven-shade-plugin</code> 插件做 <code>shade relocation</code>。</p><p>另外还有一种情况，如果传递依赖过多，例如 <code>es-hadoop</code> 中的 <code>guava</code>，<code>hbase</code> 中的 <code>commons-lang</code>，也没有必要为每一个 <code>jar</code> 包都单独创建一个 <code>module</code>，显得繁琐而且没必要。此时可以只创建一个 <code>module</code>，用来解决所有的依赖冲突，但是如果这些 <code>jar</code> 包之间的传递依赖本来就冲突，那还是得为每一个 <code>jar</code> 包都创建一个 <code>module</code>【此时这种 <code>Maven</code> 项目冲突过多，是不健康的，还是升级适配为好】。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><p>1、新建 <code>module</code> 时如果卡住，可以设置参数 <code>archetypeCatalog=internal</code> 解决。</p><p>2、还要注意一点，低版本的 <code>maven-shade-plugin</code> 插件并不支持 <code>relocation</code> 参数来制作影子，编译时会报错，例如 <code>v2.4.3</code> 就不行，需要 <code>v3.0</code> 以上，例如：<code>v3.1.0</code>、<code>v3.2.1</code>。</p><p>3、引入新依赖后，要确保传递依赖不能污染了当前项目的依赖，而制作 <code>shade</code> 的目的在于这个新依赖不会有异常。</p><p> 当前项目中或者当前项目的依赖中，会有一些调用，如果被传递依赖污染，会导致异常。如果是当前项目的代码显式调用，编译不会通过，但是如果是在依赖 <code>jar</code> 中调用，编译阶段是检测不出来的，只会在运行调用时抛出异常。</p><p>使用上面的例子来说，如果在 <code>module-a</code> 中与 <code>module-b</code> 中的依赖有相同的，则在 <code>module-a</code> 中代码引用使用时【不是 <code>module-a</code> 中我们写的代码，而是 <code>module-a</code> 中 <code>jar</code> 的源代码】，确保使用的是 <code>module-a</code> 中的版本对应的类或者方法【即把 <code>module-b</code> 中的依赖给排除掉】，否则编译会通过，但是打包后还是会缺失。</p><p>因为 <code>jar</code> 包中的源代码在编译阶段不会被检测调用的是哪个依赖里面的类或者方法【编译时只会检测我们写的代码】，必须是打包运行后才明确【其实运行前就会把所有 <code>jar</code> 包的类加载到 <code>JVM</code> 中，由于冲突会丢弃一些】，但是运行前的加载 <code>JVM</code> 过程对于多版本的依赖无法确定具体是哪个依赖生效，编译完成后到运行的时候【执行到 <code>jar</code> 中相应的代码】，就会出问题。注意这里虽然在 <code>module-b</code> 中对部分依赖做了 <code>shade</code>，但是只是对 <code>module-b</code> 生效，而对 <code>module-a</code> 是无效的，所以可能会导致 <code>module-a</code> 中的 <code>jar</code> 中源代码引用时找不到类或者方法，于是编译打包正常，运行时就会出现 <code>NoClassDefFoundError</code> 异常。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>踩坑系列</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>Java</tag>
        <tag>shade</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub Pages 禁止百度蜘蛛爬取的问题</title>
    <url>/2019010501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>最近才发现我的静态博客站点，大部分的网页没被百度收录，除了少量的网页是我自动提交【主动推动、自动推送】的，或者手动提交的，其它的网页都不被收录【网页全部是利用自动提交的 <code>sitemap</code> 方式提交的，一个都没收录】。我查看百度的站长工具后台，发现通过 <code>sitemap</code> 方式提交链接这种方式不可行，因为百度蜘蛛采集链接信息之前需要访问 <code>baidusitemap.xml</code> 文件，而这个文件是在 <code>GitHub Pages</code> 里面的，但是 <code>GitHub Pages</code> 是禁止百度蜘蛛爬取的，所以百度蜘蛛在获取 <code>baidusitemap.xml</code> 文件这一步骤就被禁止了，<code>GitHub Pages</code> 返回 403 错误【在 <code>http</code> 协议中表示禁止访问】，因此抓取失败【哪怕获取到 <code>baidusitemap.xml</code> 文件也不行，因为后续需要采集的静态网页全部是放在 <code>GitHub Pages</code> 中的，全部都会被禁止】。本文就详细描述这种现象，以及寻找可行的解决方案。</p><a id="more"></a><h1 id="问题出现"><a href="# 问题出现" class="headerlink" title="问题出现"></a>问题出现 </h1><h2 id="网页收录对比差距大"><a href="# 网页收录对比差距大" class="headerlink" title="网页收录对比差距大"></a> 网页收录对比差距大 </h2><p> 利用搜索引擎的 <code>site</code> 搜索可以看到百度与谷歌明显的差别 <br> 百度搜索结果【只有少量的收录，仅有的还是通过主动推送与自动推送提交的】</p><p>上面那个图片被封了，再来一张局部截图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ujsyasw0j20en0ie42d.jpg" alt="百度搜索结果 - 局部" title="百度搜索结果 - 局部"></p><p>谷歌搜索结果【收录很多，而且很全面】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojj5hv3qj20ng0pp0uv.jpg" alt="谷歌搜索结果" title="谷歌搜索结果"></p><p>首先在百度站长工具【官方主页：<a href="https://ziyuan.baidu.com/" target="_blank" rel="noopener">https://ziyuan.baidu.com/</a> 】后台看到 <code>baidusitemap.xml</code> 抓取失败，查看具体原因是抓取失败【<code>http</code> 状态码 403】。</p><p>抓取失败。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojjp6f0jj20um08h3yk.jpg" alt="抓取失败" title="抓取失败"></p><p>抓取失败原因概述。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojjzz7kaj20uj0l6wf0.jpg" alt="抓取失败原因概述" title="抓取失败原因概述"></p><p>根据抓取失败原因，我还以为是文件不存在，或者根据链接打不开【链接是：</p><p><a href="https://www.playpi.org/baidusitemap.xml">https://www.playpi.org/baidusitemap.xml</a> 】，我使用浏览器和 <code>curl</code> 命令都尝试过了，链接没有问题，可以正常打开。然后根据 403 错误发现是拒绝访问，那就有可能是百度爬虫的问题了【被 <code>GitHub Pages</code> 禁止爬取了】。</p><p>使用浏览器打开。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojkc7sggj212a0kbgmb.jpg" alt="浏览器能正常打开" title="浏览器能正常打开"></p><p>这里需要注意一点，百度站长工具里面显示的链接是 <code>http</code> 开头的【如上面抓取失败原因概述截图中红框圈出的，不是 <code>https</code> 开头的，我觉得百度爬虫抓取使用的就是 <code>http</code> 开头的链接】，不过没关系，我在域名解析里面已经配置了所有的域名情况，完全可以支持。但是有时候仍然会遇到打不开上面链接的情况【在某些电脑上面或者某些网络环境中】，我猜测这可能是电脑的缓存或者当前网络的 <code>DNS</code> 设置问题，不是我的站点的问题。因为，哪怕你在浏览器中输入以 <code>http</code> 开头的链接，也会自动跳转到以 <code>https</code> 开头的链接去。</p><p>浏览器打不开链接的情况【其实不是链接的问题】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojkvts8yj20v60jmjrm.jpg" alt="浏览器打不开链接的情况" title="浏览器打不开链接的情况"></p><p>使用命令行打开【如下使用 <code>curl</code> 命令】。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl https://www.playpi.org/baidusitemap.xml</span><br></pre></td></tr></table></figure><p>执行命令结果截图。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojlapxs2j20ke0f1t9f.jpg" alt="执行命令结果" title="执行命令结果"></p><h2 id="通过百度反馈寻找原因"><a href="# 通过百度反馈寻找原因" class="headerlink" title="通过百度反馈寻找原因"></a>通过百度反馈寻找原因 </h2><p> 于是接下来，我就给官方提交了反馈，官方只是回复我说是链接问题【意思就是链接无法正常打开，其实使用浏览器或者检测工具都是可以打开的，但是使用百度爬虫就不行】。</p><p>提交反馈【官方主页：<a href="https://ziyuan.baidu.com/feedback/apply" target="_blank" rel="noopener">https://ziyuan.baidu.com/feedback/apply</a> 】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojmrakf5j20v90c3dfy.jpg" alt="提交反馈" title="提交反馈"></p><p>反馈回复。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojn41t81j20r50n8jsy.jpg" alt="反馈回复" title="反馈回复"></p><p>前面我已经证明了链接没问题，那我就要猜想是百度蜘蛛爬虫的问题了，于是按照官方回复的建议，使用诊断工具看看是否可行。</p><p>诊断工具测试多次都失败。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojnhzr7xj21060gqq3w.jpg" alt="诊断工具测试多次都失败" title="诊断工具测试多次都失败"></p><p>如果抓取 <code>UA</code> 设置为移动端【即模拟手机、平板之类的设别】，会有部分成功的，而使用 <code>PC</code> 端全部都是失败的。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojnn4r5bj20zf0l3q49.jpg" alt="诊断工具 UA 代理部分成功" title="诊断工具 UA 代理部分成功"></p><p>失败原因仍旧是拒绝访问【<code>http</code> 403 状态码】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojnt73w4j20rb0ppgmu.jpg" alt="拒绝访问" title="拒绝访问"></p><p>我又接着查看文档【文档地址：<a href="https://ziyuan.baidu.com/college/courseinfo?id=267&amp;page=9#007" target="_blank" rel="noopener">https://ziyuan.baidu.com/college/courseinfo?id=267&amp;page=9#007</a> 】，发现拒绝访问的原因之一就是托管服务供应商阻止百度 <code>Spider</code> 访问我的网站，所以猜测是 <code>GitHub Pages</code> 拒绝了百度 <code>Spider</code> 的爬取请求，接着就想办法验证一下猜测是否正确。</p><p>文档说明截取片段。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojnz71jxj20rr04dmxf.jpg" alt="文档说明" title="文档说明"></p><p>接下来我又查找了资料，发现网上确实有很多这种说法，而且大家都遇到了这种问题，但是并没有官方的说明放出来。</p><p>于是，接着我又回复了百度站长对方的反馈，直接问是不是因为 <code>GitHub Pages</code> 禁止了百度爬虫，所以百度爬取的结果总是 403 错误。等了 2 天多【赶上周末】，对方没有明确回复，说的都是废话，可能是不想承认，那我也不管了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r3ajynl5j20z20ne76i.jpg" alt="百度反馈中心再次回复" title="百度反馈中心再次回复"></p><h2 id="通过 -GitHub-Pages- 找原因"><a href="# 通过 -GitHub-Pages- 找原因" class="headerlink" title="通过 GitHub Pages 找原因"></a>通过 GitHub Pages 找原因 </h2><p> 另一方面，我尝试给 <code>GitHub</code> 的技术支持发送邮件询问，得到了确认的答复，<code>GitHub</code> 已经禁止了百度蜘蛛爬虫的访问，并且不保证在未来的时间恢复。主要是因为以前百度爬虫爬取太猛了，导致 <code>GitHub Pages</code> 不可用或者访问速度变慢，影响了其他正常的用户浏览使用 <code>GitHub Pages</code>，所以把百度爬虫给禁止了【当然，这是官方说法】。</p><p><code>GitHub Pages</code> 的反馈链接【填写姓名、邮箱、内容描述即可】：<a href="https://github.com/contact" target="_blank" rel="noopener">https://github.com/contact</a> ；</p><p>我发送了一封邮件过去，当然是借助谷歌翻译完成的，勉强能看。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojt87natj235s1zw4k8.jpg" alt="邮件内容" title="邮件内容"></p><p>成功发送邮件后的通知页面。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojtr12gxj21hc0q9755.jpg" alt="成功发送邮件" title="成功发送邮件"></p><p>邮件内容已经被我上传至 <code>GitHub</code>，读者可以提前下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20190105" target="_blank" rel="noopener">feedback_to_GitHub.txt</a> ，内容全文如下，仅供参考：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A doubt with GitHub Pages</span><br><span class="line"></span><br><span class="line">Hello,</span><br><span class="line">I created my own homepage with GitHub Pages,it is https://github.com/iplaypi/iplaypi.github.io.If you input https://iplaypi.github.io,it jumps to https://www.playpi.org automatically because of CNAME file.The website is https://www.playpi.org,and my site only contains static pages and pictures.</span><br><span class="line"></span><br><span class="line">But I have a problem,the following is my detailed description:</span><br><span class="line">I use Google Search Console to crawl my pages and include them.I only need to provide a site file named website.xml,and it works fine.</span><br><span class="line"></span><br><span class="line">But when i use Baidu Webmaster Tools (a tool made by a Chinese search engine company),it doesn&apos;t work properly.I only need to provide a site file named baiduwebsite.xml,Baidu Spider will crawl the link in this file .But Baidu cannot include my pages finally,and the reason is Baidu Spider can&apos;t crawl my html pages.</span><br><span class="line"></span><br><span class="line">So,I am trying to find the real reason,then I succeeded.The real reason is Github Pages forbids the crawling of Baidu Spider.So when Baidu Spider crawls my pages,it will definitely fail.</span><br><span class="line"></span><br><span class="line">Here I want to know is this phenomenon real?If yes,why Github Pages forbids Baidu Spider?And what should i do?</span><br><span class="line"></span><br><span class="line">Thanks.</span><br><span class="line">Best regards.</span><br><span class="line">Perry</span><br></pre></td></tr></table></figure><p>没隔几个小时，就有回复了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0oju7wg4tj21ar0npjtb.jpg" alt="GitHub 邮件回复" title="GitHub 邮件回复"></p><p>邮件回复的部分内容已经被我上传至 <code>GitHub</code>，读者可以下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20190105" target="_blank" rel="noopener">GitHub_reply_to_me.txt</a> ，回复的重点内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">I&apos;ve confirmed that we are currently blocking the Baidu user agent from crawling GitHub Pages sites. We took this action in response to this user agent being responsible for an excessive amount of requests, which was causing availability issues for other GitHub customers. This is unlikely to change any time soon, so if you need the Baidu user agent to be able to crawl your site you will need to host it elsewhere.</span><br></pre></td></tr></table></figure><p>那么，我们再来回看一下百度站长里面爬取失败原因的页面，里面有一个用户代理的配置，其实就是构造 <code>http</code> 请求使用的消息头，可以看到正是 <code>Baiduspider/2.0</code>，所以才会被 <code>GitHub Pages</code> 给禁止了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ojur917gj20sp0hz0t7.jpg" alt="百度爬虫的 UA" title="百度爬虫的 UA"></p><h1 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案 </h1><p> 至此，我已经把问题的原因搞清楚了。本来这个问题是很好解决的【更换静态博客存储的主机即可，例如各种项目托管服务：码市、<code>gitcafe</code>、七牛云等，或者自己购买一台云主机】，但是我不能抛弃 <code>GitHub</code>，于是问题变得复杂了。</p><p>此时，我还有 3 个方案可以参考：</p><ul><li>使用 <code>CDN</code> 加速，把每个静态页面都缓存下来，这样百度爬虫的请求就可能不会到达 <code>GitHub Pages</code>，但是不知道有没有保证，可以试试 </li><li> 放弃 <strong>自动提交 </strong>方式里面的 <strong>sitemap 推送 </strong>，改为 <strong>主动推送 </strong>，<code>hexo</code> 里面有插件可以用。但是我是坚持大道至简的原则，不想再引用插件了，而且我看了那个插件，需要配置百度账号的信息，我不能把这些信息放在公共仓库里面，会暴露给别人，不想用 </li><li> 在更新博客的同时再部署一份相同的博客 <strong>【可以理解为镜像，需要在其它主机部署一份，可以自己搭建主机或者使用类似于 GitHub 的代码托管工具】</strong>，把 <code>master</code> 分支的内容复制过去即可，然后利用域名解析服务，把百度爬虫的流量引到这份服务器上面【只是为了让百度收录】，其他的流量仍然去访问 <code>GitHub Pages</code>，就可以让百度的爬虫顺利爬取到我的博客内容了。这个方法看起来虽然很绕，但是明白了细节实现起来就很简单，而且可靠，可以用 </li></ul><h2 id="CDN- 加速"><a href="#CDN- 加速" class="headerlink" title="CDN 加速"></a>CDN 加速</h2><p> 我先不选择这种方式了，因为需要收费或者免费的加广告，或者服务不稳定，我还是愿意选择稳妥的方式。可以选择的产品有：七牛云、又拍云、阿里云、腾讯云等。</p><h2 id="选择镜像方式"><a href="# 选择镜像方式" class="headerlink" title="选择镜像方式"></a>选择镜像方式 </h2><p> 既然选择了使用复制博客的方式，再加上域名解析服务转移流量，那接下来就开始动手部署了。我手里正好还有一台翻墙使用的 <code>VPS</code>，每个月的流量用不完，所以也不打算使用第三方托管服务了，直接部署在我自己的 <code>VPS</code> 上面就行了。只不过还需要动动手搭建一下 <code>Web</code> 服务，当然是使用强大的 <code>Nginx</code> 了。</p><h3 id="更改域名服务器和相关配置"><a href="# 更改域名服务器和相关配置" class="headerlink" title="更改域名服务器和相关配置"></a>更改域名服务器和相关配置 </h3><p>1、在 <code>DNSPod</code> 中添加域名</p><p><code>DNSPod</code> 账号自行注册，我使用免费版本，当然会有一些限制，例如解析的域名 A 记录个数限制为 2 个【<code>GitHub Pages</code> 有 4 个 <code>ip</code>，我在 <code>Godaddy</code> 中都是配置 4 个，但是没影响，配置 2 个也可以。或者直接配置 <code>CNAME</code> 记录就行了，以前我不懂就配置了 <code>ip</code>，多麻烦，<code>ip</code> 还要通过 <code>ping iplaypi.github.io</code> 获取，每次还不一样，一共得到了 4 个，多此一举。当然，如果域名被墙了而 <code>ip</code> 没被墙，还是需要这样配置的】。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0oviygtn3j21hc0qxgnz.jpg" alt="在 DNSPod 中添加域名" title="在 DNSPod 中添加域名"></p><p>2、添加域名解析记录</p><p> 我把 <code>Godaddy</code> 中的解析记录直接抄过来就行，不同的是由于使用的是 <code>DNSPod</code> 免费版本，<code>A</code> 记录会少配置 2 个，基本不会有啥影响 <strong>【其实不配置 A 记录最好，直接配置 CNAME 就行了，会根据域名自动寻找 ip，以前我不懂】</strong>。另外还有一个就是需要针对百度爬虫专门配置一条 <code>www</code> 的 <code>A</code> 记录，针对百度的线路指向自己服务器的 <code>ip</code>【截图只是演示，其中 <code>CNAME</code> 记录应该配置域名，<code>A</code> 记录才是配置 <code>ip</code>】，如果使用的是第三方托管服务，直接添加 <code>CNAME</code> 记录，配置域名就行【例如 <code>yoursite.gitcafe.io</code>】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovjinxzvj21hc0qxac2.jpg" alt="添加域名解析记录" title="添加域名解析记录"></p><p>不使用 <code>A</code> 记录的配置方式 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovk0xljij21hc0qxta3.jpg" alt="不使用 A 记录的配置方式" title="不使用 A 记录的配置方式"></p><p>3、在 <code>Godaddy</code> 中绑定自定义域名服务器</p><p> 第 2 个步骤完成，我们回到 <code>DNSPod</code> 的域名界面，可以看到提示我们修改 <code>NS</code> 地址，如果不知道是什么意思，可以点击提示链接查看帮助手册【其实就是去购买域名的服务商那里绑定 <code>DNSPod</code> 的域名服务器】。</p><p>提示我们修改 <code>NS</code> 地址 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovkf6k08j21hc0qxtb9.jpg" alt="提示我们修改 NS 地址" title="提示我们修改 NS 地址"></p><p> 帮助手册 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovkoigmaj20s60lymyk.jpg" alt="帮助手册" title="帮助手册"></p><p> 我是在 <code>Godaddy</code> 中购买的域名【不需要备案】，所以需要在 <code>Godaddy</code> 中取消默认的 <code>DNS</code> 域名服务器，然后把 <code>DNSPod</code> 分配的域名服务器配置在 <code>Godaddy</code> 中。这里需要注意，在配置了新的域名服务器的时候，以前的配置的解析记录都没用了，因为 <code>Godaddy</code> 直接把域名解析的工作转给了我配置的 <code>DNSPod</code> 域名服务器【配置信息都转到了 <code>DNSPod</code> 中，也就是步骤 1、步骤 2 中的工作】。</p><p>原有的解析记录与原有的域名服务器 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovn10ghwj20wt0mvgm6.jpg" alt="原有的解析记录" title="原有的解析记录"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovncqfzuj20ww0atdfw.jpg" alt="原有的域名服务器" title="原有的域名服务器"></p><p> 配置完成新的域名服务器【以前的解析记录都消失了】</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovnq0lhgj20yi0m7q3i.jpg" alt="配置完成新的域名服务器" title="配置完成新的域名服务器"></p><p>配置完成后使用 <strong>域名设置 </strong>里面的 <strong>自助诊断 </strong>功能，可以看到域名存在异常，主要是因为更改配置后的时间太少了，要耐心等待全球递归 DNS 服务器刷新【最多 72 小时】，不过一般 10 分钟就可以访问主页了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ovl23kqbj20tl0lfabk.jpg" alt="自助诊断" title="自助诊断"></p><h3 id="设置镜像服务器"><a href="# 设置镜像服务器" class="headerlink" title="设置镜像服务器"></a>设置镜像服务器 </h3><p> 我没有使用第三方托管服务器，例如：<code>gitcafe</code>、码市、<code>coding</code>，而是直接使用自己的 <code>VPS</code>，然后搭配 <code>Nginx</code> 使用。</p><h4 id="安装 -Nginx（基于 -CentOS-7-X64）"><a href="# 安装 -Nginx（基于 -CentOS-7-X64）" class="headerlink" title="安装 Nginx（基于 CentOS 7 X64）"></a>安装 Nginx（基于 CentOS 7 X64）</h4><p><code>CentOS</code> 的安装过程参考：<a href="https://gist.github.com/ifels/c8cfdfe249e27ffa9ba1" target="_blank" rel="noopener">https://gist.github.com/ifels/c8cfdfe249e27ffa9ba1</a> 。但是，不是全部可信，抽取有用的即可。而且这种方式安装的是已经规划好的一个庞大的包，里面包含了一些常用的模块，可能有一些模块没用，而且如果自己想再安装一些新的模块，就不支持了，必须重新下源码编译安装。总而言之，这种安装方式就是给入门级别的人使用的，不能自定义。</p><p>1、由于 <code>Nginx</code> 的源头问题，先创建配置文件 </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/yum.repos.d/</span><br><span class="line">vim nginx.repo</span><br></pre></td></tr></table></figure><p> 填写内容 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">name=nginx repo</span><br><span class="line">baseurl=http://nginx.org/packages/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure><p>2、安装配置 <code>Nginx</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装 </span></span><br><span class="line">yum install nginx -y</span><br><span class="line"><span class="comment"># 配置 </span></span><br><span class="line">vi /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><p> 以下配置内容的模板已经被我上传至 <code>GitHub</code>，读者可以下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20190105" target="_blank" rel="noopener">nginx_conf_http.template</a> 。</p><p>填写配置内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user  nginx;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">error_log  /var/log/nginx/error.log warn;</span><br><span class="line">pid        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    access_log  /site/nginx.access.log  main;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  blog.playpi.org www.playpi.org;</span><br><span class="line">    access_log   /site/iplaypi.github.io.access.log  main;</span><br><span class="line">    root         /site/iplaypi.github.io;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    #gzip  on;</span><br><span class="line"></span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、开启 80 端口【不开启不行】，启动 <code>Nginx</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看已经开启的端口 </span></span><br><span class="line">firewall-cmd --list-ports</span><br><span class="line"><span class="comment"># 开启端口 </span></span><br><span class="line">firewall-cmd --permanent --zone=public --add-port=80/tcp</span><br><span class="line"><span class="comment"># 重载更新的端口信息 </span></span><br><span class="line">firewall-cmd --reload</span><br><span class="line"><span class="comment"># 启动 Nginx</span></span><br><span class="line"><span class="comment"># 这种方式不行，找不到目录 </span></span><br><span class="line">/etc/init.d/nginx start</span><br><span class="line"><span class="comment"># 这种方式可以 </span></span><br><span class="line">service nginx start</span><br></pre></td></tr></table></figure><h4 id="额外考虑情况"><a href="# 额外考虑情况" class="headerlink" title="额外考虑情况"></a>额外考虑情况 </h4><p><strong>1、关于 https 认证</strong></p><p> 要不要考虑 <code>https</code> 的情况，如果百度爬虫没用到 <code>https</code> 抓取【除了 <code>sitemap.xml</code> 文件还要考虑文件里面的所有链接格式，也是 <code>https</code> 的】，就不考虑。其实一定要考虑，因为百度爬虫用到了 <code>https</code> 链接去抓取，所以还要想办法开启 <code>Nginx</code> 的 <code>https</code>。此外，在百度的 <code>https</code> 认证里面，也是需要开启 <code>https</code> 的，否则申请不通过。</p><p>我的域名不知道什么时候验证失败了，但是一开始的时候是验证成功的【可能是 <code>GitHub Pages</code> 禁止百度爬虫的原因，因为以前全部都是 <code>GitHub Pages</code> 提供站点支持】</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pmkhqwygj20z40lojsp.jpg" alt="https 验证失败" title="https 验证失败"></p><p>我想重新验证一下，没想到有次数限制，还是先把 <code>Nginx</code> 的 <code>https</code> 开启之后再验证吧 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pmkls6dkj20e008mweh.jpg" alt="重新验证次数限制" title="重新验证次数限制"></p><p> 开启 <code>Nginx</code> 的 <code>https</code>，并且保证站点全部的链接都是 <code>https</code> 的，但是同时也要支持 <code>http</code>，使用 301 重定向到 <code>https</code>。</p><p>1-1、查看 <code>Nginx</code> 的 <code>https</code> 模块 </p><p> 先查看我安装的小白版本的 <code>Nginx</code> 里面有没有关于 <code>https</code> 的模块，使用命令 <strong>nginx -V</strong>，可以看到是有的，这个模块就是 <strong>–with-http_ssl_module</strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0prgtihdkj21gr060js0.jpg" alt="查看 ssl 模块" title="查看 ssl 模块"></p><p>1-2、申请证书 </p><p> 可以购买或者从阿里云、腾讯云里面申请免费的，但是我还是觉得使用 <code>OpenSSL</code> 工具自己生成方便，先查看机器有没有安装 <code>OpenSSL</code> 工具，使用 <strong>openssl version</strong> 命令，如果没有则需要安装 <strong>yum install -y openssl openssl-devel</strong>，安装完成后开始生成证书。生成证书的命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl req -x509 -nodes -days 36500 -newkey rsa:2048 -keyout /site/ssl-nginx.key -out /site/ssl-nginx.crt</span><br></pre></td></tr></table></figure><p>在生成的过程中还需要填写一些参数信息：国家、城市、机构名称、机构单位名称、域名、邮箱等，这里特别注意我为了能让多个子域名公用一个证书，采用了泛域名的方式【星号的模糊匹配：<code>*.playpi.org</code>】。这种生成证书的方式只是为了测试使用，最终的证书肯定是不可信的，浏览器会提示此证书不受信任，所以还是通过其它方式获取证书比较好【后续我会通过阿里云或者 <code>letsencrypt</code> 获取免费的证书，具体博客参考可以使用相关关键词在站内搜索 <strong>证书 </strong>，或者直接查看：<a href="https://www.playpi.org/2019030401.html">利用阿里云申请免费的 SSL 证书 </a>】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0prhfu9p8j20p40chwf7.jpg" alt="证书参数" title="证书参数"></p><p> 完整信息填写 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Generating a 2048 bit RSA private key</span><br><span class="line">........+++</span><br><span class="line">..............+++</span><br><span class="line">writing new private key to &apos;/site/ssl-nginx.key&apos;</span><br><span class="line">-----</span><br><span class="line">You are about to be asked to enter information that will be incorporated</span><br><span class="line">into your certificate request.</span><br><span class="line">What you are about to enter is what is called a Distinguished Name or a DN.</span><br><span class="line">There are quite a few fields but you can leave some blank</span><br><span class="line">For some fields there will be a default value,</span><br><span class="line">If you enter &apos;.&apos;, the field will be left blank.</span><br><span class="line">-----</span><br><span class="line">Country Name (2 letter code) [XX]:CN</span><br><span class="line">State or Province Name (full name) []:Guangdong</span><br><span class="line">Locality Name (eg, city) [Default City]:Guangzhou</span><br><span class="line">Organization Name (eg, company) [Default Company Ltd]:playpi</span><br><span class="line">Organizational Unit Name (eg, section) []:playpi</span><br><span class="line">Common Name (eg, your name or your server&apos;s hostname) []:*.playpi.org</span><br><span class="line">Email Address []:playpi@qq.com</span><br></pre></td></tr></table></figure><p>1-3、更改配置并重启 <code>Nginx</code></p><p> 重新配置 <code>http</code> 与 <code>https</code> 的参数【只列出 <code>server</code> 的主要部分，<code>blog</code> 二级域名主要是为了测试使用的，<code>blog</code> 的流量全部导入我的 <code>VPS</code> 中】，特别注意 <code>rewrite</code> 的正则表达式，只替换域名部分，链接部分不能替换，否则都跳转到主页去了。</p><p>以下配置内容的模板已经被我上传至 <code>GitHub</code>，读者可以下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20190105" target="_blank" rel="noopener">nginx_conf_https.template</a> 。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 这里只是列出了 server 节点的部分，需要配合 nginx_conf_http.template 文件查看 </span><br><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  www.playpi.org;</span><br><span class="line">    access_log   /site/iplaypi.github.io.http-www-access.log  main;</span><br><span class="line">    rewrite ^/(.*)$ https://www.playpi.org/$1 permanent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  blog.playpi.org;</span><br><span class="line">    access_log   /site/iplaypi.github.io.http-blog-access.log  main;</span><br><span class="line">    rewrite ^/(.*)$ https://blog.playpi.org/$1 permanent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">    listen 443 ssl;# 监听端口 </span><br><span class="line">    server_name www.playpi.org blog.playpi.org;# 域名 </span><br><span class="line">    access_log   /site/iplaypi.github.io.https-access.log  main;</span><br><span class="line">    root         /site/iplaypi.github.io;</span><br><span class="line">    ssl_certificate /site/ssl-nginx.crt;# 证书路径 </span><br><span class="line">    ssl_certificate_key /site/ssl-nginx.key;#key 路径 </span><br><span class="line">    ssl_session_cache shared:SSL:1m;# 储存 SSL 会话的缓存类型和大小 </span><br><span class="line">    ssl_session_timeout 5m;# 配置会话超时时间 </span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;# 为建立安全连接，服务器所允许的密码格式列表 </span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_prefer_server_ciphers on;# 依赖 SSLv3 和 TLSv1 协议的服务器密码将优先于客户端密码 </span><br><span class="line">    #减少点击劫持 </span><br><span class="line">    add_header X-Frame-Options DENY;</span><br><span class="line">    #禁止服务器自动解析资源类型 </span><br><span class="line">    add_header X-Content-Type-Options nosniff;</span><br><span class="line">    #防 XSS 攻击 </span><br><span class="line">    add_header X-Xss-Protection 1;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>开启 443 端口，重启 <code>Nginx</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看已经开启的端口 </span></span><br><span class="line">firewall-cmd --list-ports</span><br><span class="line"><span class="comment"># 开启端口 </span></span><br><span class="line">firewall-cmd --permanent --zone=public --add-port=443/tcp</span><br><span class="line"><span class="comment"># 重载更新的端口信息 </span></span><br><span class="line">firewall-cmd --reload</span><br><span class="line"><span class="comment"># 验证 Nginx 配置是否准确 </span></span><br><span class="line">nginx -t</span><br><span class="line"><span class="comment"># 重新启动 Nginx</span></span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><p>1-4、打开链接查看 </p><p> 使用 <code>blog</code> 二级域名测试【也需要在 <code>DNSPod</code> 中配置一条 <code>A</code> 记录解析规则】</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pri38049j21hc0rymzk.jpg" alt="使用 blog 二级域名测试" title="使用 blog 二级域名测试"></p><p>或者使用 <code>curl</code> 命令模拟请求，由于有重定向的问题，所以失败 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0proxgda3j20u204q0ss.jpg" alt="curl 无法获取重定向的内容" title="curl 无法获取重定向的内容"></p><p> 既然开启了 <code>https</code>，可以使用 <code>curl</code> 关闭失效证书的方式【<code>-k</code> 参数】访问 <code>https</code> 链接 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0qmesphe5j20rb0g0q3o.jpg" alt="curl 关闭证书认证访问 https 链接" title="curl 关闭证书认证访问 https 链接"></p><p> 去百度站长里面重新提交 <code>https</code> 认证【使用上面的测试证书是认证失败的，我去阿里云重新申请了证书，认证成功了，申请证书的教程可以在本站搜索，为了给 2 个二级域名不同的证书，<code>Nginx</code> 还需要重新配置 <code>server</code> 信息】</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r33rvt0oj21hc0q9tdh.jpg" alt="blog 二级域名认证成功" title="blog 二级域名认证成功"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0r34hh1lxj21hc0q90xi.jpg" alt="www 二级域名认证成功" title="www 二级域名认证成功"></p><p><strong>2、端口的问题 </strong></p><p> 为什么在上面配置域名解析记录的时候，百度的 <code>A</code> 记录配置 <code>VPS</code> 的 <code>ip</code> 就行了呢，这是因为在 <code>VPS</code> 上面只有 <code>Nginx</code> 这一种 <code>Web</code> 服务，机器会分配给它一个端口【默认 80，也是 <code>http</code> 的默认端口，可以配置】，然后 <code>www</code> 的访问就使用这个端口【在 <code>Nginx</code> 的配置里面有，还有另外一个 <code>blog</code> 的】，所以可以忽略端口的信息。但是如果一台机器上面有各种 <code>Web</code> 服务，切记确保端口不要冲突【例如 <code>Tomcat</code> 和 <code>Nginx</code> 同时存在的情况】，并且给 <code>Nginx</code> 的就是 80 端口，然后如果有其它服务，可以使用 <code>Nginx</code> 做代理转发【例如把 <code>email</code> 二级域名转到一个端口，<code>blog</code> 二级域名转到另一个端口】。</p><h4 id="完善自动获取更新脚本，拉取 -mater- 分支的静态页面"><a href="# 完善自动获取更新脚本，拉取 -mater- 分支的静态页面" class="headerlink" title="完善自动获取更新脚本，拉取 mater 分支的静态页面"></a>完善自动获取更新脚本，拉取 mater 分支的静态页面 </h4><p><strong>1、先用简单的方式</strong></p><p> 使用 <code>git</code> 把项目克隆到：<code>/site/iplaypi.github.io</code> 即可。</p><p><strong>2、利用钩子自动拉取 master 分支内容到指定目录 </strong></p><p> 本来最简单的方式就是在 <code>travis</code> 自动构建的时候，把生成的静态页面直接拷贝到目标主机就行了。也就是把 <code>public</code> 目录里面的内容使用类似 <code>scp</code> 的命令拷贝到我的服务器即可。但是，我觉得这种方式太简易，我还是想利用起来 <code>GitHub</code> 的钩子功能，在项目有 <code>push</code> 发生的时候，自动触发我服务器上面的脚本，然后脚本就会执行 <code>pull</code> 的操作。</p><p>详情见我的另外一篇博客：<a href="https://www.playpi.org/2019030601.html">使用 Github 的 WebHooks 实现代码自动更新 </a> 。</p><h2 id="验证结果"><a href="# 验证结果" class="headerlink" title="验证结果"></a> 验证结果 </h2><p> 以下验证都是在没有开启 <code>https</code> 的情况下，即没有对 <code>http</code> 进行 301 重定向，如果做了 301 重定向截图内容会有一点不一样，<code>curl</code> 也会直接失败【需要访问 <code>https</code> 格式的链接】。</p><p>使用最简单的方式验证就是在百度站长工具里面使用 <strong>抓取诊断 </strong>来进行模拟抓取多次，看看成功率是否是 100%。通过测试，可以看到，每次抓取都会成功，那么接下来就等待百度自己抓取了【百度爬虫抓取 <code>sitemap.xml</code> 文件的频率很低，可能要等一周】。</p><p>使用抓取诊断方式来验证，这个过程有一个插曲，就是无论怎么验证都是失败的，但是使用 <code>curl</code> 模拟请求却是成功的。我看了失败原因概述里面，抓取的 <code>ip</code> 地址仍旧是 <code>GitHub Pages</code> 的，说明百度爬虫的流量没有到我自己的 <code>VPS</code> 上面。我一开始还以为是 <code>DNSPod</code> 配置没生效，但是通过 <code>curl</code> 模拟请求却可以，说明 <code>DNSPod</code> 配置没问题，那就是百度的问题了，应该是缓存。后来，我在移动端 <code>UA</code> 与 <code>PC</code> 端 <code>UA</code> 切换了一下，然后就行了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pmjyvmbtj218h0qx76r.jpg" alt="使用抓取诊断方式来验证" title="使用抓取诊断方式来验证"></p><p>此外，既然我们知道了百度爬虫设置的用户代理，那么就可以直接使用 <code>curl</code> 命令来模拟百度爬虫的请求，观察返回的 <code>http</code> 结果是否正常。模拟命令如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -A <span class="string">"Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)"</span> http://blog.playpi.org/baidusitemap.xml</span><br></pre></td></tr></table></figure><p>模拟请求的结果，可以看到也是正常的【下面的截图在没有开启 <code>https</code> 的情况下，如果开启 301 重定向就不行了，需要直接访问 <code>https</code> 链接】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pmjky1dwj20v50hnq3v.jpg" alt="模拟请求的结果" title="模拟请求的结果"></p><p>如果开启了 <code>https</code>，即对 <code>http</code> 请求进行 301 重定向，则可以直接访问 <code>https</code> 链接【如果证书是无效的，像我截图中的，则可以使用 <code>curl</code> 关闭无效证书的方式，加一个 <code>-k</code> 参数】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0qmguu51qj21660i9ab1.jpg" alt="curl 关闭证书认证访问 https 链接" title="curl 关闭证书认证访问 https 链接"></p><p>我也去看了 <code>VPS</code> 上面的 <code>Nginx</code> 日志，确实百度爬虫的流量都被引入到这里来了，皆大欢喜。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0pmj6s4syj21150a4dhn.jpg" alt="Nginx 日志" title="Nginx 日志"></p><p>后续还需要观察看看百度的收录结果【等待 3 天后更新了，结果如下】。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0uis3rezoj21hc0q9wgm.jpg" alt="sitemap 方式提交链接生效" title="sitemap 方式提交链接生效"></p><h1 id="问题总结"><a href="# 问题总结" class="headerlink" title="问题总结"></a>问题总结 </h1><p>1、这篇博客耗费了我一个多月才完成，当然不是写了一个多月，而是从发现问题到解决问题，最终写成这篇博客，前后经历了一个多月。在这一个多月里，我看了很多别人的博客，问了一些人，也看了一些技术资料，学到了很多以前不了解的知识，而且通过动手去解决问题，整个过程收获颇丰。</p><p>2、写 <code>Markdown</code> 文档，使用代码块标记的时候，使用 3 个反单引号来标记，如果不熟悉代码块里面的编程语言，可以省略类型【例如 <code>java</code>、<code>bash</code>、<code>javascript</code>】，不要填写，否则填错了生成的 <code>html</code> 静态文件是空白的。还有就是如果代码块里面放的是一段英文文本，和编程语言无关，也不要填写类型，否则生成的 <code>html</code> 静态文件也是空白的。</p><p>3、通过实战学习了一些网络知识，例如：<code>CNAME</code>、<code>A</code> 记录、域名服务器、二级域名等、<code>https</code> 证书，也学习了一些关于 <code>Nginx</code> 的知识。</p><p>4、关于访问速度的问题，<code>GitHub Pages</code> 的 <code>CDN</code> 还是很强大的，不会出现卡顿的情况。但是有时候貌似 <code>GitHub</code> 会被墙，打不开。此外，我搞这么久就是为了让百度爬虫能收录我的站点文章，所以自己搭建的 <code>VPS</code> 只是为了给百度爬虫爬取用的，其它正常人或者爬虫仍旧是访问 <code>GitHub Pages</code> 的链接。</p><p>5、关于 <code>https</code>，使用 <code>GitHub Pages</code> 的时候，服务全部是 <code>GitHub Pages</code> 提供的，我无需关心。但是，自己使用 <code>VPS</code> 做了一个镜像，就需要配置一模一样的环境给百度爬虫使用，否则会导致一些失败的现象，例如 <code>htps</code> 认证失败、链接抓取失败。因此，一定要开启 <code>https</code>，并且同时也支持 <code>http</code>。以下是整理的网络请求流程图，清晰明了。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/old/b7f2e3a3gy1g0ptlseegej20p00howf6.jpg" alt="网络请求流程图" title="网络请求流程图"></p><p> 以上流程图的原始文件已经被我上传至 <code>GitHub</code>，读者可以下载使用：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/resource/20190105" target="_blank" rel="noopener">网络请求流程图.gliffy</a> 。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>建站</tag>
        <tag>GitHub Pages</tag>
        <tag>SEO</tag>
        <tag>百度蜘蛛</tag>
        <tag>Baiduspider</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据平台框架常用参数优化</title>
    <url>/2019121901.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>本文记录大数据平台框架的一些常用参数，这些参数基本是我见过的或者实际使用过的，我会列出参数的含义以及使用效果，具有一定的参考意义。当然，根据实际的场景不同，参数值并不能随便设置为一样，必须要考虑到实际的情况，否则可能没有效果，或者具有反作用。</p><p>会保持更新。</p><a id="more"></a><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><p>选择 <code>HBase</code>、<code>Hadoop</code> 时注意版本适配的问题，<code>Hadoop</code> 选择 <code>v2.7.1</code> 还是很好的，能适配 <code>HBase v1.2.x</code> 以及以上的版本【<code>Hbase</code> 兼容的 <code>Hadoop</code> 版本参见：<a href="http://hbase.apache.org/book.html#configuration" target="_blank" rel="noopener">hbase-configuration</a> 】，也能适配 <code>Hive v0.10.0</code> 以及以上的版本【<code>Hive</code> 兼容的 <code>Hadoop</code> 版本参见：<a href="http://hive.apache.org/downloads.html" target="_blank" rel="noopener">hive-downloads</a> 】。</p><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><ul><li><code>fs.hdfs.impl.disable.cache</code>，如果设置为 <code>true</code>，表示关闭文件系统的缓存，这样多线程手动处理 <code>HDFS</code> 文件时，不会 <code>IOException: Filesystem closed</code></li></ul><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>配置文件：<code>mapred-site.xml</code>。</p><p><code>Yarn</code> 资源模型：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Node Manager -&gt; yarn.nodemanager.resource.memory-mb</span><br><span class="line">YARN container -&gt; yarn.scheduler.minimum-allocation-mb、yarn.scheduler.maximum-allocation-mb</span><br><span class="line">Mapper/Reducer -&gt; mapreduce.map.memory.mb、mapreduce.reduce.memory.mb</span><br><span class="line">JVM -&gt; mapred.map.child.java.opts、mapred.reduce.child.java.opts</span><br></pre></td></tr></table></figure><p>对于内存参数的配置，注意它们之间的受限关系，取值不能乱设置，总体来说越具体的参数取值越小，例如常见的一般把 <code>mapreduce.map.java.opts</code> 的值配置成 <code>mapreduce.map.memory.mb * 0.9</code> 。</p><ul><li><code>map</code> 并发大小：<code>mapreduce.job.running.map.limit</code>，可以设置大点，50、100 随便 </li><li><code>map</code> 内存大小：<code>mapreduce.map.memory.mb</code>，单位为 <code>MB</code>，一般 <code>4GB</code> 够用</li><li><code>reduce</code> 启动延迟：<code>mapred.reduce.slowstart.completed.maps</code>，表示 <code>reduce</code> 在 <code>map</code> 执行到什么程度可以启动，例如设置为 <code>1.0</code> 表示等待 <code>map</code> 全部完成后才能执行 <code>reduce</code></li><li><code>reduce</code> 内存大小：<code>mapreduce.reduce.memory.mb</code>，单位为 <code>MB</code>，要根据实际情况设置，一般 <code>4GB</code> 够用</li><li><code>reduce</code> 虚拟内存：<code>yarn.nodemanager.vmem-pmem-ratio</code>，一般 2-5 即可</li><li><code>reduce</code> 并发大小：<code>mapreduce.job.running.reduce.limit</code>，一般 5-10 个够用【根据业务场景、机器资源而定】</li><li><code>mapred.map.child.java.opts</code>，<code>Map</code> 的 <code>JVM</code> 参数，例如：<code>-Xmx200m</code></li><li><code>mapred.reduce.child.java.opts</code>，<code>Reduce</code> 的 <code>JVM</code> 参数，例如：<code>-Xmx200m</code></li><li><code>mapreduce.admin.map.child.java.opts</code>，作用同 <code>mapred.map.child.java.opts</code>，优先级最高，会覆盖掉用户设置的</li><li><code>mapreduce.admin.reduce.child.java.opts</code>，作用同 <code>mapred.reduce.child.java.opts</code>，优先级最高，会覆盖掉用户设置的</li></ul><h2 id="es-hadoop"><a href="#es-hadoop" class="headerlink" title="es-hadoop"></a>es-hadoop</h2><p> 使用 <code>es-hadoop</code> 框架处理 <code>Elasticsearch</code> 数据，可以专注于数据 <code>ETL</code> 处理逻辑，其它与集群交互的读写操作交给 <code>es-hadoop</code> 框架处理，这里面有一些常用的参数。</p><p>参考官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html" target="_blank" rel="noopener">configuration</a> 。</p><ul><li>读取，只读取指定的字段：<code>es.read.field.include</code>，默认为空，读取全部字段，注意，在 <code>query</code> 中设置 <code>_source</code> 是无效的 </li><li> 读取，排除指定的字段：<code>es.read.field.exclude</code>，默认为空，则不排除任何字段 </li><li> 读取，关闭日期的处理：<code>es.mapping.date.rich</code>，默认为 <code>true</code>，关闭后，读取 <code>Elasticsearch</code> 的 <code>date</code> 类型的字段，会自动转换为 <code>long</code> 类型，不再是 <code>date</code> 类型 </li><li> 读取，解析指定字段为数组类型：<code>es.read.field.as.array.include</code>，默认为空，则不解析任何字段【字段类型保持原样】</li><li>读取，排除解析指定字段为数组字段：<code>es.read.field.as.array.exclude</code>，默认为空，则不排除任何字段【字段该是数组的还是数组，不是数组的仍旧保持原样】</li></ul><h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><p>配置文件：<code>mapred-site.xml</code> 。</p><ul><li><code>yarn.nodemanager.local-dirs</code>，临时目录 </li></ul><h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h2 id="架构图"><a href="# 架构图" class="headerlink" title="架构图"></a> 架构图 </h2><p> 如下 </p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20200407021026.png" alt="架构图" title="架构图"></p><h2 id="部分知识点"><a href="# 部分知识点" class="headerlink" title="部分知识点"></a> 部分知识点 </h2><p>1、以下内容是关于 <code>major compaction</code>【大合并】、<code>minor compaction</code>【小合并】 的说明。</p><p><code>minor compaction</code> 操作只用来做部分文件【触发时相关的几个 <code>StoreFile</code> 文件】的合并操作，不做任何清除数据、多版本数据清理工作。</p><p><code>major compaction</code> 操作是对一个 <code>Region</code> 下的 <code>HStore</code> 下的所有 <code>StoreFile</code> 执行合并操作，最终的结果是整理合并出一个文件。此过程会真正删除标记为需要清理的数据，而且会消耗大量的磁盘 <code>IO</code>、网络 <code>IO</code>，甚至导致部分节点无法响应，严重影响读写性能，读请求会变慢，写请求会被阻塞。</p><p><code>major compaction</code> 的操作目的：</p><ul><li> 合并文件 </li><li> 真正清除标记为删除、过期、多余版本的数据【<code>minor compaction</code> 并不会真正清除数据】</li><li>提高读写数据的效率，当然，由于磁盘 <code>IO</code>、网络 <code>IO</code> 的消耗，此操作过程会严重影响读写性能，读请求会变慢，写请求会被阻塞【有时候甚至会降低 10 倍】</li></ul><p>一般情况下，<code>HBase</code> 集群的 <code>major compact</code> 都是关闭的，如果开启默认是 7 天执行一次，因此离线的 <code>major compact</code> 是必要的，可以定期手动触发，可以使用 <code>major_compact 表名称 </code> 对某个表进行操作。如果手动触发，操作命令很快就返回结果，但是后台操作其实一直在运行，可以通过 <code>grafana</code> 监控查看压缩队列的长度，当压缩队列长度超过 100 的时候，应该延迟操作。由于 <code>major compact</code> 是很重的后台操作，因此操作之前需要有仔细的观察和分析，例如通过 <code>grafana</code> -&gt; <code>HBase</code> 监控可以获得，关于触发时期的选择建议：</p><ul><li> 业务低峰时段运行，即读写请求不大的时候，可以避免影响正常的业务 </li><li> 分表执行【或者分 <code>Region</code> 执行】，不要整个集群集体执行，并且优先考虑含有 <code>TTL</code> 的表 </li><li><code>StoreFile</code> 短期内增加比较多的时候</li><li> 表中 <code>StoreFile</code> 平均大小比较小的时候 </li></ul><p>2、以下内容是关于租约时间的说明。</p><p> 参考官网的配置示例、异常信息：<a href="https://hbase.apache.org/1.4/book.html#hbase_default_configurations" target="_blank" rel="noopener">default_configurations</a> 。</p><p>一些默认配置：<a href="https://svn.apache.org/repos/asf/hbase/hbase.apache.org/trunk/0.94/hbase-default.xml" target="_blank" rel="noopener">hbase-default.xml</a> 。</p><p>关于客户端和 <code>Regionserver</code> 之间的租约时间【<code>LeaseException</code>】，所谓租约，是指 <code>Hbase client</code> 端每次和 <code>Regionserver</code> 交互的时候，都会在服务器端生成一个租约【<code>Lease</code>】，租约的有效期由参数 <code>hbase.client.scanner.timeout.period</code> 指定，默认的租约有效时间是 60 秒。</p><p>在 <code>scan</code> 操作过程中，客户端去 <code>Regionserver</code> 取数据的时候，<code>Hbase</code> 中存的数据量很大并且有很多 <code>Region</code> 的时候的，客户端请求的 <code>Region</code> 不在内存中，或是没有被 <code>cache</code> 住，需要从磁盘中加载。如果这时候加载过程需要的时间超过 <code>hbase.client.scanner.timeout.period</code> 所配置的时间，并且客户端没有向 <code>Regionserver</code> 报告其还活着，那么 <code>Regionserver</code> 就会认为本次租约已经过期，并从 <code>LeaseQueue</code> 中从删除掉本次租约。此后，当 <code>Regionserver</code> 加载完成后，拿已经被删除的租约再去取数据的时候，就会出现如下的错误现象。</p><p>异常示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.hbase.regionserver.LeaseException: lease &apos;-8841369309248784313&apos; does not exist</span><br></pre></td></tr></table></figure><p>一般的做法，就是在配置文件中增大 <code>hbase.client.scanner.timeout.period</code> 的时间，但也不能忽略 <code>RPC</code> 连接的超时问题，所以在增大 <code>hbase.client.scanner.timeout.period</code> 的时候应该同时增大 <code>hbase.rpc.timeout</code>，同时注意 <code>hbase.rpc.timeout</code> 的值应该等于或大于 <code>hbase.client.scanner.timeout.period</code> 的值。</p><blockquote><p>很多人都会误认为一次 <code>Scan</code> 操作就是一次 <code>RPC</code> 请求，其实是不对的。实际上，一次请求大量数据的 <code>Scan</code> 操作可能会导致多个很严重的后果：服务器端可能因为大量 <code>IO</code> 操作导致 <code>IO</code> 利用率很高，影响其它正常的业务请求；大量数据传输会导致网络带宽等系统资源被大量占用；客户端也可能因为内存无法缓存这些数据导致 <code>OOM</code>。基于此，<code>HBase</code> 会将一次大的 <code>Scan</code> 操作根据设置条件拆分为多个 <code>RPC</code> 请求，每次只返回规定数量的结果。代码示例 <code>ResultScanner rs = table.getScanner (scan); foreach (Result r ：rs){...}</code> 语句实际上等价于 <code>ResultScanner rs = table.getScanner (scan); Result r = rs.next ()</code>，每执行一次 <code>next ()</code> 操作就会调用客户端发送一次 <code>RPC</code> 请求，参数 <code>hbase.client.scanner.timeout.period</code> 就用来表示这么一次 <code>RPC</code> 请求的超时时间，默认为 <code>60000ms</code>，一旦请求超时，就会抛出 <code>SocketTimeoutException</code> 异常。</p></blockquote><h2 id="相关配置项"><a href="# 相关配置项" class="headerlink" title="相关配置项"></a>相关配置项 </h2><p><code>HBase</code> 相关配置说明：</p><ul><li><code>hbase.hregion.majorcompaction</code>，<code>HBase</code> 自动做 <code>major compaction</code> 的周期，会严重影响写入性能，建议定期手动做</li><li><code>hbase.hregion.majorcompaction=0</code>，关闭定期的 <code>major compaction</code> 操作，必要时只能手动执行</li><li><code>hbase.client.retries.number</code>，客户端连接重试次数，建议设置大一点，例如 24</li><li><code>hbase.rootdir</code>，<code>HBase</code> 在 <code>HDFS</code> 中的根目录</li><li><code>zookeeper.znode.parent</code>，<code>HBase</code> 在 <code>Zookeeper</code> 的根目录，例如使用 <code>Phoenix</code> 登录时需要</li><li><code>hbase.hregion.max.filesize</code>，设置 <code>HBase</code> 分区大小，超过此值时自动分裂，避免一个分区过大，默认值 10GB【10737418240B】，在创建表时合理预估数据大小，预设置合理的分区规则【利用 <code>rowkey</code>】，可以避免频繁分裂，也使数据分布更加均匀</li><li><code>hbase.rpc.timeout</code>，<code>RPC</code> 连接失效时间，默认 60 秒</li><li><code>hbase.client.scanner.timeout.period</code>，客户端和 <code>Regionserver</code> 之间租约过期的时间，默认是 60 秒，注意：参数 <code>hbase.regionserver.lease.period</code> 已经不建议使用</li><li><code>hbase.client.scanner.caching</code>，设置 <code>HBase Scanner</code> 一次从服务端读取的数据条数，默认情况下 1 次 1 条，通过将其设置成一个合理的值【例如 100-500 之间的数字】，可以减少 <code>Scan</code> 过程中 <code>next ()</code> 的时间开销，代价是 <code>Scanner</code> 需要通过客户端的内存来维持这些被 <code>cache</code> 的行记录</li><li><code>hbase.rootdir</code>，这个目录是 <code>region server</code> 的共享目录，用来持久化 <code>HBase</code></li><li><code>hbase.master.port</code>，<code>HBase</code> 的 <code>Master</code> 的端口，默认: 60000</li><li><code>hbase.cluster.distributed</code>，<code>HBase</code> 的运行模式，<code>false</code> 表示单机模式，<code>true</code> 表示分布式模式</li><li><code>hbase.tmp.dir</code>，本地文件系统的临时文件夹，可以设置为一个更为持久的目录上【<code>/tmp</code> 在重启时会被清楚】，默认：<code>${java.io.tmpdir}/hbase-${user.name}</code></li><li><code>hbase.local.dir</code>，作为本地存储，位于本地文件系统的路径，默认:<code>${hbase.tmp.dir}/local/</code></li></ul><h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><p> 总述，在设置 <code>Elasticsearch</code> 堆大小时需要通过 <code>$ES_HEAP_SIZE</code> 环境变量，遵循两个规则：</p><ul><li>不要超过可用 <code>RAM</code> 的 50%，<code>Lucene</code> 能很好利用文件系统的缓存，它是通过系统内核管理的，如果没有足够的文件系统缓存空间，性能会受到影响。 此外，专门用于堆的内存越多意味着其它可用的内存越少，例如 <code>fielddata</code></li><li>不要超过 <code>32GB</code>，如果堆大小小于 <code>32GB</code>，<code>JVM</code> 可以利用指针压缩，这可以大大降低内存的使用，每个指针是 4 字节而不是 8 字节 </li></ul><p> 分片的分配：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/shards-allocation.html" target="_blank" rel="noopener">shards-allocation</a> 。<br>脚本的使用：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-using.html" target="_blank" rel="noopener">modules-scripting-using</a> 。<br>熔断器相关：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/circuit-breaker.html" target="_blank" rel="noopener">circuit-breaker</a> 。<br>节点选举、故障检测：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/modules-discovery-zen.html" target="_blank" rel="noopener">modules-discovery-zen</a> 。</p><p><code>fielddata</code>，对字段进行 <code>agg</code> 时，会把数据加载到内存中【索引数据时不会】，记录的是占用内存空间情况，超过指定的值，开始回收内存，防止 <code>OOM</code>。</p><p><code>allocate</code> 表示分片的分配【第一次分配、负载均衡过程中的再次分配】；<code>relocate</code> 【负载均衡过程中的再次分配】表示分片再次进行 <code>allocate</code>。<code>Recovery</code> 表示将一个索引的未分配 <code>shard</code> <code>allocate</code> 到一个结点的过程，在快照恢复、更改索引副本数量、结点故障、结点启动时发生。</p><p><code>Elasticsearch</code> 慢查询日志、慢索引日志等一些配置信息只在 <code>master</code> 节点配置即可，不需要每个节点都配置。</p><p>如果设置索引副本数为 1，同一个索引的主分片、副本分片不会被分配在同一个节点上面，这才能保证数据高可用，挂了一个节点也没关系【如果一台物理节点开启了两个 <code>Elasticsearch</code> 节点，需要注意使用 <code>cluster.routing.allocation.same_shard.host</code> 参数】。</p><ul><li>磁盘空间使用占比上限：<code>cluster.routing.allocation.disk.watermark.high</code>，默认为 90%，表示如果当前节点的磁盘使用占比超过这个值，则分片【针对所有类型的分片：主分片、副本分片】会被自动 <code>relocate</code> 到其它节点，并且任何分片都不会 <code>allocate</code> 到当前节点【此外，对于新创建的 <code>primary</code> 分片也是如此，除非整个 <code>Elasticsearch</code> 集群只有一个节点了】</li><li>磁盘空间使用占比下限：<code>cluster.routing.allocation.disk.watermark.low</code>，默认为 85%，表示如果当前节点的磁盘使用占比超过这个值，则分片【新创建的 <code>primary</code> 分片、从来没有进行过 <code>allocate</code> 的分片除外】不会被 <code>allocate</code> 到当前节点 </li><li> 索引的分片副本数：<code>number_of_replicas</code>，一般设置为 1，表示总共有 2 份数据 </li><li><code>index.auto_expand_replicas</code>：副本数自动扩展，会根据可用 <code>Elasticsearch</code> 节点数来设置副本数，默认为 <code>false</code>，可以设置为 <code>0-all</code>、<code>0-5</code> 等等</li><li> 每个节点分配的分片个数：<code>total_shards_per_node</code>，一般设置为 2，一个节点只分配 2 个分片，分别为主分片、副本分片 </li><li> 索引的分片个数：<code>number_of_shards</code>，当索引数据很大时，一般设置为节点个数【例如 <code>索引数据大小 / 50GB</code> 大于节点个数，例如 10 个节点，索引大小 <code>800GB</code>，此时按照官方建议应该设置 16 个分片，但是分片过多也不好，就可以设置 10 个分片，每个分片大小 <code>80GB</code>】，再配合 <strong>分片副本数为 1</strong>、<strong> 每个节点分配的分片个数为 2</strong>，就可以确保分片分配在所有的节点上面，并且每个节点上有 2 个分片，分别为主分片、副本分片 </li><li> 数据刷新时间：<code>refresh_interval</code>，表示数据写入后等待多久可以被搜索到，默认值 <code>1s</code>，每次索引的 <code>refresh</code> 会产生一个新的 <code>lucene</code> 段，这会导致频繁的合并行为，如果业务需求对实时性要求没那么高，可以将此参数调大，例如调整为 <code>60s</code>，会大大降低 <code>cpu</code> 的使用率 </li><li> 索引的分片大小，官方建议是每个分片大小在 <code>30GB</code> 到 <code>50GB</code> 不要超过 <code>50GB</code>，所以当索引的数据很大时，就要考虑增加分片的数量 </li><li> 设置 <code>terms</code> 最大个数：<code>index.max_terms_count</code>，默认最大个数为 65535，可以根据集群情况降低，例如设置为 10000，为了集群稳定，一般不需要设置那么大 </li><li> 设置 <code>Boolean Query</code> 的子语句数量：<code>indices.query.bool.max_clause_count</code>，默认为 1024，不建议增大这个值，也可以根据集群情况适当减小 </li><li> 查看热点线程：<code>http://your_ip:your_port/_nodes/your_node_name/hot_threads</code>，可以判断热点线程是 <code>search</code>，<code>bulk</code>，还是 <code>merge</code>，从而进一步分析是查询还是写入导致负载过高 </li><li> 数据目录：<code>path.data: /path/to/data</code>，多个目录使用逗号分隔，里面存放数据文件 </li><li> 日志目录：<code>path.logs: /path/to/logs</code>，里面存放的是节点的日志、慢查询日志、慢索引日志 </li><li> 家目录：<code>path.home: /path/to/home</code>，<code>elasticsearch</code> 的家目录，里面有插件、<code>lib</code>、配置文件等 </li><li> 插件目录：<code>path.plugins: /path/to/plugins</code>，插件目录，里面存放的是插件，例如：分词器 </li><li> 设置慢获取时间边界：<code>index.search.slowlog.threshold.fetch.warn: 30s</code>，超过这个时间的信息会被记录在日志文件中，<code>path.logs</code> 参数指定的目录中 <code>cluster-name_index_fetch_slowlog.log</code> 文件 </li><li> 设置慢查询时间边界：<code>index.search.slowlog.threshold.query.warn: 60s</code>，超过这个时间的信息会被记录在日志文件中，<code>path.logs</code> 参数指定的目录中 <code>cluster-name_index_search_slowlog.log</code> 文件 </li><li> 设置慢索引时间边界：<code>index.search.slowlog.threshold.index.warn: 60s</code>，超过这个时间的信息会被记录在日志文件中，<code>path.logs</code> 参数指定的目录中 <code>cluster-name_index_indexing_slowlog.log</code> 文件 </li><li> 禁止集群重分配：<code>cluster.routing.allocation.enable=none</code>，手动操作分片前需要关闭，否则会引起分片的移动，造成不必要的 <code>IO</code></li><li>开启集群重分配：<code>cluster.routing.allocation.enable=all</code>，集群的分片管理权限交由集群，保持数据均衡 </li><li> 设置集群均衡分片时可以同时 <code>rebalance</code> 分片的个数，<code>cluster.routing.allocation.cluster_concurrent_rebalance:2</code>，不宜设置过大，一般 2-4 个为好，当然如果集群资源足够或者需要快速均衡分片，可以设置大一点 </li><li> 允许分片分配，<code>cluster.routing.allocation.enable=all</code>，开启后分片的分配交由集群管理，如果偶尔需要手动管理分片或者集群停机重启，可以临时关闭，取值设置为 <code>none</code> 即可 </li><li> 推迟索引的分片分配时间，在分片节点出故障或者重启时，可以避免分片数据的移动，前提是及时把节点恢复：<code>index.unassigned.node_left.delayed_timeout=5m</code>，通俗点说，就是趁分片不注意，节点已经恢复了，此时数据分片保持不变，避免了不必要的 <code>IO</code></li><li><code>index.max_slices_per_scroll</code>，除了传统的 <code>scroll</code> 读取数据的方式，<code>v5.x</code> 之后 <code>Elasticsearch</code> 又增加了对每个分片读取数据的功能，称之为切片处理【<code>sliced scroll</code>】，这种读取方式可以对多个分片并行读取数据，大大提高了取数效率，<code>elasticsearch-hadoop</code> 就是采用这种方式读取数据的。但是，这里面有一个限制，<code>Elasticsearch</code> 默认一个 <code>scroll</code> 最大的切片数量为 1024【一般小于等于分片数，也可以通过指定切片字段来创建大于分片数的切片】，可以通过 <code>index.max_slices_per_scroll</code> 参数来变更【不建议更改】</li><li><code>cluster.routing.allocation.same_shard.host</code>，在单台物理节点配置多个 <code>Elasticsearch</code> 实例时，这个参数才生效，用来检查同一个分片的多个实例【主分片、副本分片】是否能分配在同一台主机上面，默认值为 <code>false</code>。如果设置为 <code>true</code>，表示开启检查机制，一台物理机上面启动 2 个 <code>Elasticsearch</code> 节点，则分配相同编号的分片时，不会都在这台机器上面，尽管可以满足主分片、副本分片不在同一个 <code>Elasticsearch</code> 节点上 </li><li><code>script.groovy.sandbox.enabled: false</code>，禁用 <code>Grovvy</code> 脚本，默认是关闭的</li><li><code>script.inline: false</code>，允许使用内置 <code>painless</code> 脚本</li><li><code>script.stored: false</code>，允许使用保存在 <code>config/scripts</code> 中的脚本，调用时使用 <code>id</code> 即可，类似方法名</li><li><code>script.file: false</code>，允许使用外部脚本文件</li><li><code>http.port: 9200</code>，集群的 <code>HTTP</code> 端口号</li><li><code>transport.tcp.port: 9300</code>，集群的 <code>TCP</code> 端口号</li><li><code>thread_pool.bulk.queue_size: 1500</code>，<code>bulk</code> 队列的大小</li><li><code>indices.breaker.total.use_real_memory: true</code>，熔断器回收内存，防止 <code>OOM</code>，决定父熔断器是考虑实际内存使用情况，还是仅考虑子熔断器内存使用情况</li><li><code>indices.breaker.total.limit: 70%</code>，熔断器回收内存，防止 <code>OOM</code>，当 <code>use_real_memory</code> 为 <code>true</code> 时，设置为 70%，否则默认为 70%</li><li><code>indices.breaker.fielddata.limit: 40%</code>，熔断器回收内存，防止 <code>OOM</code>，默认 40%</li><li><code>indices.breaker.request.limit: 60%</code>，熔断器回收内存，防止 <code>OOM</code>，默认 60%</li><li><code>indices.fielddata.cache.size</code>，可以设置 <code>20%</code>，要低于 <code>fielddata.limit</code>，默认无界限</li><li><code>discovery.zen.fd.ping_timeout: 60s</code>，集群故障检测</li><li><code>discovery.zen.fd.ping_interval: 10s</code>，集群故障检测</li><li><code>discovery.zen.fd.ping_retries: 10</code>，集群故障检测</li><li><ul><li><code>discovery.zen.master_election.ignore_non_master_pings: true</code>，选举主节点，设置为 <code>true</code> 时非 <code>node.master</code> 节点不能参与选举，投票也无效</li></ul></li><li><code>discovery.zen.minimum_master_nodes: 2</code>，选举主节点，最少有多少个备选主节点参加选举，防止脑裂现象</li><li><code>discovery.zen.ping_timeout: 10s</code>，选举主节点</li><li><code>discovery.zen.ping.unicast.hosts: [&quot;ip1:port&quot;,&quot;ip2:port&quot;]</code>，选举主节点，主机列表</li><li><code>node.data: true</code>，数据节点</li><li><code>node.master: true</code>，有资格被选举为主节点</li><li><code>action.destructive_requires_name=true</code>，设置严格校验，对于删除数据、删除索引的破坏性行为进行严格校验，不支持通配符，防止类似于 <code>rm -rf /*</code> 的悲剧</li><li><code>network.host</code>，绑定主机名或者 <code>ip</code> 地址，用于向集群广播自己</li><li><code>cluster.routing.allocation.exclude._ip</code>，临时下线节点，类似于黑名单，分片不会往指定的主机移动，同时会把分片从指定的节点全部移除，最终可以下线该节点，可通过 <code>put transient</code> 设置临时生效</li></ul><h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p><a href="https://spark.apache.org/docs/1.6.2/running-on-yarn.html" target="_blank" rel="noopener">v1.6.2 官方说明文档</a> 。</p><ul><li> 序列化方式：<code>spark.serializer</code>，可以选择：<code>org.apache.spark.serializer.KryoSerializer</code></li><li><code>executor</code> 附加参数：<code>spark.executor.extraJavaOptions</code>，例如可以添加：<code>-Dxx=yy</code>【如果仅仅在 <code>driver</code> 端设置，<code>executor</code> 是不会有的】</li><li><code>driver</code> 附加参数：<code>spark.driver.extraJavaOptions</code>，例如可以添加：<code>-Dxx=yy</code></li><li>日志配置文件设置，<code>Spark</code> 使用的是 <code>log4j</code>，默认在 <code>Spark</code> 安装目录的 <code>conf</code> 下面，如果想要增加 <code>log4j</code> 相关配置，更改 <code>driver</code> 机器上面的 <code>log4j.properties</code> 配置文件是无效的，必须把所有的 <code>executor</code> 节点上的配置文件全部更新。如果没有权限，也可以自己上传配置文件，然后需要在 <code>executor</code> 附加参数中指定：<code>-Dlog4j.configuration=file:/path/to/file</code>，启动 <code>Spark</code> 任务时还需要使用 <code>--files</code> 指定配置文件名称，多个用逗号分隔，用来上传配置文件到 <code>Spark</code> 节点 </li><li> 开启允许多 <code>SparkContext</code> 存在：<code>spark.driver.allowMultipleContexts</code>，设置为 <code>true</code> 即可，在使用多个 <code>SparkContext</code> 时，需要先停用当前活跃的，使用 <code>stop</code> 方法【在 <code>Spark v2.0</code> 以及以上版本，已经取消了这个限制】</li><li><code>spark.executor.cores</code>，每个执行器上面的占用核数，会消耗 <code>CPU</code>，一般设置为 2-3</li><li><code>spark.executor.memory</code>，执行器上面的堆内存大小，一般设置为 <code>2048M</code>、<code>4096M</code></li><li><code>spark.port.maxRetries</code>，提交任务的 <code>Spark UI</code> 重试次数 </li><li><code>spark.default.parallelism</code>，默认并行度</li><li><code>spark.cores.max</code>，最大核心数</li><li><code>spark.executor.logs.rolling.strategy</code></li><li><code>spark.executor.logs.rolling.maxRetainedFiles</code></li><li><code>spark.executor.logs.rolling.size.maxBytes</code></li><li><code>spark.ui.showConsoleProgress</code></li><li><code>spark.yarn.max.executor.failures</code>，<code>task</code> 失败重试次数，默认为 <code>spark.executor.cores</code> 的 2 倍，最小值为 3，如果重试最大次数后 <code>task</code> 仍旧失败，则整个 <code>Application</code> 执行失败【容错性】</li><li><code>spark.yarn.maxAppAttempts</code>，提交申请的最大尝试次数，小于等于 <code>yarn</code> 配置中的全局最大尝试次数，尝试最大次数后仍旧无法提交，则 <code>Application</code> 提交失败【<code>yarn</code> 配置为 <code>yarn.resourcemanager.am.max-attempts</code>，默认为 2，即有 2 次提交机会】</li></ul><h2 id="Kafka- 输入数据源"><a href="#Kafka- 输入数据源" class="headerlink" title="Kafka 输入数据源"></a>Kafka 输入数据源</h2><p><code>Spark Streaming</code> 配置：</p><ul><li><code>spark.streaming.backpressure.enabled</code>，开启反压机制</li><li><code>spark.streaming.backpressure.pid.minRate</code>，</li><li><code>spark.streaming.kafka.maxRatePerPartition</code>，每个 <code>partition</code> 的最大读取速度，单位秒，一般设置 500-100 即可</li><li><code>spark.streaming.receiver.maxRate</code>，<code>receiver</code> 最大处理数据量，单位秒，与 <code>maxRatePerPartition</code>、<code>Durations</code> 有关，实际运行时由于反压机制，数据处理速度会低于这个值</li><li><code>spark.streaming.receiver.writeAheadLog.enable</code>，</li><li><code>spark.streaming.stopGracefullyOnShutdown</code>，优雅地退出</li><li><code>spark.streaming.gracefulStopTimeout</code>，</li><li><code>xx</code>，</li></ul><p><code>Kakfa</code> 配置：</p><ul><li><code>metadata.broker.list</code>，</li><li><code>offsets.storage</code>，设置为 <code>kafka</code></li><li><code>zookeeper.connect</code>，</li><li><code>zookeeper.connection.timeout.ms</code></li><li><code>group.id</code></li><li><code>fetch.message.max.bytes</code></li><li><code>auto.offset.reset</code>，消费的起始位置，这个参数高低版本之间的名称、值都会不同，需要注意</li><li><code>consumer.timeout.ms</code></li><li><code>rebalance.max.retries</code></li><li><code>rebalance.backoff.ms</code></li></ul><h2 id="集群参数"><a href="# 集群参数" class="headerlink" title="集群参数"></a> 集群参数 </h2><p><code>yarn</code> 集群：</p><ul><li><code>yarn.resourcemanager.am.max-attempts</code>，最大应用尝试次数，它是所有 <code>AM</code> 的全局设置，每个应用都可以通过 <code>API</code> 的参数指定其各自的最大应用尝试次数【参数 <code>spark.yarn.maxAppAttempts</code>】，但是单个数字不能超过这个全局上限，如果超过了，资源管理器将覆盖它。默认数量设置为 2，以允许至少 1 次重试，即有 2 次提交的机会</li></ul><p><code>standalone</code> 集群</p><ul><li> 临时目录：<code>SPARK_LOCAL_DIRS</code>，用来存放 <code>Spark</code> 任务运行过程中的临时数据，例如内存不足时把数据缓存到磁盘，就会有数据写入这个目录，当然，在启动 <code>Spark</code> 任务时也可以单独指定，但是最好还是设置在集群上面，可以在 <code>spark-env.sh</code> 脚本中设置，键值对的形式，例如：<code>SPARK_LOCAL_DIRS=/your_path/spark/local</code>。需要注意的是，启动 <code>Excutor</code> 的用户必须有这个目录的写权限，并且保证这个目录的磁盘空间足够使用，否则在 <code>Spark</code> 任务中会出现异常：<code>java.io.IOException: Failed to create local dir in xx</code>，进而导致 <code>Task</code> 失败 </li><li><code>Work</code> 目录：<code>SPARK_WORKER_DIR</code>，用来存放 <code>Work</code> 的信息，设置方式同上面的 <code>SPARK_LOCAL_DIRS</code>，如果 <code>Spark</code> 任务里面有 <code>System.out ()</code>，输出的内容在此目录下</li><li><code>SPARK_LOG_DIR</code>，<code>Spark</code> 集群自身的日志文件，例如 <code>Work</code> 接收 <code>Spark</code> 任务后通信的内容</li></ul><h1 id="Storm"><a href="#Storm" class="headerlink" title="Storm"></a>Storm</h1><ul><li><code>StormUI nimbus</code> 内容传输大小限制：<code>nimbus.thrift.max_buffer_size: 1048576</code>，取值的单位是字节，默认为 <code>1048576</code>，如果 <code>nimbus</code> 汇报的内容过多，超过这个值，则在 <code>StormUI</code> 上面无法查看 <code>Topology Summary</code> 信息，会报错：<code>Internal Server Error org.apache.thrift7.transport.TTransportException: Frame size (3052134) larger than max length (1048576)</code></li><li> 执行实例 <code>worker</code> 对应的端口号：<code>supervisor.slots.ports:</code>，可以设置多个，和 <code>CPU</code> 的核数一致，或者稍小，提高机器资源的使用率 </li><li><code>worker</code> 的 <code>JVM</code> 参数：<code>WORKER_GC_OPTS</code>，取值参考：<code>-Xms1G -Xmx5G -XX:+UseG1GC</code>，根据集群机器的资源多少而定，<code>G1</code> 是一种垃圾回收器</li><li><code>supervisor</code> 的 <code>JVM</code> 参数：<code>SUPERVISOR_GC_OPTS</code>，取值参考：<code>-Xms1G -Xmx5G -XX:+UseG1GC</code>，根据集群机器的资源多少而定，<code>G1</code> 是一种垃圾回收器</li><li><code>Storm UI</code> 的服务端口：<code>ui.port</code>，可以使用浏览器打开网页查看 <code>Topology</code> 详细信息</li><li><code>ZooKeeper</code> 服务器列表：<code>storm.zookeeper.servers</code></li><li><code>ZooKeeper</code> 连接端口：<code>storm.zookeeper.port</code></li><li><code>ZooKeeper</code> 中 <code>Storm</code> 的根目录位置：<code>storm.zookeeper.root</code>，用来存放 <code>Storm</code> 集群元信息</li><li> 客户端连接 <code>ZooKeeper</code> 超时时间：<code>storm.zookeeper.session.timeout</code></li><li><code>Storm</code> 使用的本地文件系统目录：<code>storm.local.dir</code>，注意此目录必须存在并且 <code>Storm</code> 进程有权限可读写 </li><li><code>Storm</code> 集群运行模式：<code>storm.cluster.mode</code>，取值可选：<code>distributed</code>、<code>local</code></li></ul><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><p> 注意，<code>Kafka</code> 的不同版本参数名、参数值会有变化，特别是 <code>v0.9.x</code> 之后，与之前的低版本差异很大，例如数据游标的参数可以参考我的另外一篇博文：<a href="https://www.playpi.org/2017060101.html">记录一个 Kafka 错误：OffsetOutOfRangeException</a> ，<code>Kafka</code> 官网参见：<a href="https://kafka.apache.org/090/documentation.html#consumerconfigs" target="_blank" rel="noopener">Kafka-v0.9.0.x-configuration</a> 。</p><p>配置优化都是修改 <code>server.properties</code> 文件中参数值。</p><ul><li><code>JVM</code> 参数：<code>KAFKA_HEAP_OPTS</code>，取值参考：<code>-Xmx2G</code></li><li>文件存放位置：<code>log.dirs</code>，多个使用逗号分隔，注意所有的 <code>log</code> 级别需要设置为 <code>INFO</code></li><li>单个 <code>Topic</code> 的文件保留策略：<code>log.retention.hours=72</code>【数据保留 72 小时，超过时旧数据被删除】，<code>log.retention.bytes=1073741824</code>【数据保留 1GB，超过时旧数据被删除】</li><li>数据文件刷盘策略：<code>log.flush.interval.messages=10000</code>【每当 <code>producer</code> 写入 10000 条消息时，刷数据到磁盘】，<code>log.flush.interval.ms=1000</code>【每间隔 1 秒钟时间，刷数据到磁盘】</li><li><code>Topic</code> 的分区数量：<code>num.partitions=8</code></li><li>启动 <code>Fetch</code> 线程给副本同步数据传输大小限制：<code>replica.fetch.max.bytes=10485760</code>，要比 <code>message.max.bytes</code> 大 </li><li><code>message.max.bytes=10485700</code>，这个参数决定了 <code>broker</code> 能够接收到的最大消息的大小，要比 <code>max.request.size</code> 大</li><li><code>max.request.size=10480000</code>，这个参数决定了 <code>producer</code> 生产消息的大小</li><li><code>fetch.max.bytes=10485760</code>，这个参数决定了 <code>consumer</code> 消费消息的大小，要比 <code>message.max.bytes</code> 大</li><li><code>broker</code> 处理消息的最大线程数：<code>num.network.threads=17</code>，一般 <code>num.network.threads</code> 主要处理网络 <code>IO</code>，读写缓冲区数据，基本没有 <code>IO</code> 等待，配置线程数量为 <code>CPU</code> 核数加 1</li><li><code>broker</code> 处理磁盘 <code>IO</code> 的线程数：<code>num.io.threads=32</code>，<code>num.io.threads</code> 主要进行磁盘 <code>IO</code> 操作，高峰期可能有些 <code>IO</code> 等待，因此配置需要大些，配置线程数量为 <code>CPU</code> 核数 2 倍，最大不超过 3 倍</li><li> 强制新建一个 <code>segment</code> 的时间：<code>log.roll.hour=72</code></li><li>是否允许自动创建 <code>Topic</code>：<code>auto.create.topics.enable=true</code>，如果设置为 <code>false</code>，则代码无法创建，需要通过 <code>kafka</code> 的命令创建 <code>Topic</code></li><li><code>auto.offset.reset</code>，关于数据游标的配置【<code>earliest</code> 与 <code>latest</code>、<code>smallest</code>、<code>largest</code>】，由于不同版本之间的差异，可以参考：<a href="https://www.playpi.org/2017060101.html">记录一个 Kafka 错误：OffsetOutOfRangeException</a></li><li><code>advertised.host.name</code>、<code>advertised.port</code>，关于外网集群可以访问的配置，跨网络生产、消费数据，<code>v082</code> 以及之前的版本【之后的版本有保留这两个参数，但是不建议使用】</li><li><code>advertised.listeners</code>、<code>listeners</code>，关于外网集群可以访问的配置，跨网络生产、消费数据，<code>v090</code> 以及之后的版本 </li></ul><p> 留意参数取值大小的限制：<code>fetch.max.bytes</code> 大于 <code>message.max.bytes</code> 大于 <code>max.request.size</code>，<code>replica.fetch.max.bytes</code> 大于 <code>message.max.bytes</code> 大于 <code>max.request.size</code>。</p><h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><p>配置 <code>zoo.cfg</code> 文件：</p><ul><li><code>dataDir</code>，表示快照日志目录</li><li><code>dataLogDir</code>，表示事务日志目录，不配置的时候事务日志目录同 <code>dataDir</code></li><li><code>clientPort=2181</code>，服务的监听端口</li><li><code>tickTime=2000</code>，<code>Zookeeper</code> 的时间单元，<code>Zookeeper</code> 中所有时间都是以这个时间单元的整数倍去配置的，例如，<code>session</code> 的最小超时时间是 <code>2*tickTime</code>【单位：毫秒】</li><li><code>syncLimit=5</code>，表示 <code>Follower</code> 和 <code>Observer</code> 与 <code>Leader</code> 交互时的最大等待时间，只不过是在与 <code>leader</code> 同步完毕之后，进入正常请求转发或 <code>ping</code> 等消息交互时的超时时间</li><li><code>initLimit=10</code>，<code>Observer</code> 和 <code>Follower</code> 启动时，从 <code>Leader</code> 同步最新数据时，<code>Leader</code> 允许 <code>initLimit * tickTime</code> 的时间内完成，如果同步的数据量很大，可以相应地把这个值设置大一些</li><li><code>maxClientCnxns=384</code>，最大并发客户端数，用于防止 <code>Ddos</code> 的，默认值是 10，设置为 0 是不加限制</li><li><code>maxSessionTimeout=120000</code>，<code>Session</code> 超时时间限制，如果客户端设置的超时时间不在这个范围，那么会被强制设置一个最大时间，默认的 <code>Session</code> 超时时间是在 <code>2 * tickTime ~ 20 * tickTime</code> 这个范围</li><li><code>minSessionTimeout=4000</code>，同 <code>maxSessionTimeout</code></li><li><code>server.x=hostname:2888:3888</code>，<code>x</code> 是一个数字，与每个服务器的 <code>myid</code> 文件中的 <code>id</code> 是一样的，<code>hostname</code> 是服务器的 <code>hostname</code>，右边配置两个端口，第一个端口用于 <code>Follower</code> 和 <code>Leader</code> 之间的数据同步和其它通信，第二个端口用于 <code>Leader</code> 选举过程中投票通信</li><li><code>autopurge.purgeInterval=24</code>，在 <code>v3.4.0</code> 及之后的版本，<code>Zookeeper</code> 提供了自动清理事务日志文件和快照日志文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个 1 或更大的整数。默认是 0，表示不开启自动清理功能</li><li><code>autopurge.snapRetainCount=30</code>，参数指定了需要保留的事务日志文件和快照日志文件的数目，默认是保留 3 个，和 <code>autopurge.purgeInterval</code> 搭配使用</li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据技术知识</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
        <tag>HDFS</tag>
        <tag>HBase</tag>
        <tag>Zookeeper</tag>
        <tag>MapReduce</tag>
        <tag>Kafka</tag>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title>郴州东江湖之行</title>
    <url>/2019062301.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>从 2019 年 06 月 21 日 18:30 点到 2019 年 06 月 23 日 18:30 点，我与公司部门的同事们进行了一次为期两天两夜的郴州东江湖之旅，一行总共 25 人，其中还有两位同事的老家就在东江湖周边，这也为此次旅途带来了一些特别的安排。以前每天在喧嚣的城市中工作，面对的都是闪烁霓虹的高楼大厦，车水马龙的街道，现在选择一个合适的时间点，为自己放一个小假，去拥抱大自然的风光，走走路动动腿，看看山山水水。本文简单记录这次旅途的过程，仅为存念，请读者跟着我的文字，带你们领略 <strong>小东江 </strong>自然风光的旖旎。</p><p>注意，本文图片较多，我已经尽量把每张图片都压缩在几百 KB 的大小，浏览时请耐心等待。</p><a id="more"></a><h1 id="出发"><a href="# 出发" class="headerlink" title="出发"></a>出发 </h1><h2 id="去程记录"><a href="# 去程记录" class="headerlink" title="去程记录"></a> 去程记录 </h2><p>2019 年 06 月 21 日 18:00，大家开始吃晚饭或者零食，补充体力，我吃了一份简单的盒饭、一个粽子、一杯酸奶，算是勉强吃饱。</p><p> 我的晚饭 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190703002916.jpg" alt="我的晚饭" title="我的晚饭"></p><p> 接着从公司出发，四人组队打车去 <strong>广州南站 </strong>，由于是在下班期间，而且还是在周五，所以路上难免堵车，我们也预估了时间，提前出发，以免迟到而赶不上车。打出租车不好打，网约车也不好叫，我们等了十几分钟才坐上车，我选择了走高速，因为之前已经咨询过同事，走高速不会堵车的，只有高速出口会堵一会。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717000630.png" alt="去程地图导航" title="去程地图导航"></p><p>从上车到到达，全程消耗了 45 分钟，加上等车的十几分钟，总共一个小时的时间，顺利提前到达 <strong>广州南站 </strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717000754.png" alt="去程打车详情" title="去程打车详情"></p><p>由于提前到达了高铁站，还需要等待 40 分钟，才能进站乘车。还有一些没吃晚饭的同事们去找吃的了，我就留在长凳上照看行李。中途我还去周围逛了一下，发现便利店的饮料真的贵，和火车上的价格差不多了，这比上海火车站可差远了。我在上海火车站候车室见到的快餐店、便利店、奶茶店，不仅种类繁多，价格也和外面平常的店铺一样，只贵了一点点。<br>广州南站便利店饮料价目表 <br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190703002932.jpg" alt="广州南站便利店饮料价目表" title="广州南站便利店饮料价目表"></p><p> 时间走到了 20:40，终于可以上车了，坐高铁前往郴州，整个过程大概一个半小时，预计 22:10 到达 <strong>郴州西站 </strong>。在高铁上，大家有的看电影，有的玩游戏，有的玩手机，全程轻松愉悦，不必细说。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190703002947.jpg" alt="上了高铁出发" title="上了高铁出发"></p><p>22:10 顺利到达 <strong>郴州西站 </strong>，我们换乘预定的大巴，紧接着前往住宿地点，大概 23:30 到达住宿地点。</p><h2 id="关于交通工具的选择"><a href="# 关于交通工具的选择" class="headerlink" title="关于交通工具的选择"></a>关于交通工具的选择 </h2><p> 如果坐高铁，全程换乘两次，转车也痛苦，并没有节约时间，但是对于晕车的人来说是首选。如果坐大巴，可以从公司门口出发，直接开往目的地，但是也要 5 个小时以上，坐大巴的好处是不用换乘，上车就睡，直接到达目的地，但是有些人可能会晕车。</p><p>总的来说，从广州到郴州 <strong>东江湖 </strong>，全程要 5-6 个小时，我们是 18:30 出发，23:30 到达住宿地。</p><p>是的，就是需要这么久，主要是 <strong>广州高铁站 </strong>离出发地、<strong> 郴州西高铁站 </strong>离目的地都太远了，下了班打的去 <strong>广州高铁站 </strong>将近一个小时【25 公里】，到了 <strong>郴州西高铁站 </strong>再坐大巴去景区住宿地也要一个小时【40 公里】，晚上郴州的大巴是限速的，最高 40km / 小时。</p><p>我在高铁上和一个郴州本地人聊天，他说去 <strong>东江湖 </strong>游玩千万不要住太远，如果住市区的话，早上要起的很早赶过去，太累了。看来我们一开始就选择住在景区门口【从住宿地出来走路 2 分钟就到景区大门口】还是明智的，住的这么近还要在 05:45 起床，06:00 吃早餐，06:10 出发，否则赶不上看 <strong>小东江 </strong>的雾景了【07:00 左右景色最好】。可以想象，如果住在市区，早上五点前就要起床了吧。</p><h1 id="到达"><a href="# 到达" class="headerlink" title="到达"></a>到达 </h1><p> 折腾了五个小时，转了两次车【打的转高铁，高铁转大巴】，终于到达了住宿地点【东江芳鑫酒店】，开始分房间，领了钥匙，坐下来聊聊天、喝几口水。接着看到有同事拎着一篮子杨梅，在分发，我上前问了问，原来是大哥的表妹【我们公司 CTO 旭日大哥的表妹，接送我们，并协助我们全程游玩】专门带来给我们品尝的，从她家的果园刚刚摘出来，我吃了几个，不得不说，真好吃，放在嘴里咬一口，杨梅汁渗出来，酸酸甜甜，这才是正宗的杨梅。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190714222847.jpg" alt="新鲜的杨梅真好吃" title="新鲜的杨梅真好吃"></p><p>此时已经 23:40 了，我们是真的疲惫，但是又感到饥饿，于是想着出去逛逛，吃点宵夜。问了几个人，果然也有想出去吃点东西的人，于是我们一合计，就一起出去吃宵夜吧。凑了八九个人，就一起出去了，其中包括旭日大哥，我一想坏了，肯定又少不了喝酒吃肉，今天的睡眠时间注定不足了。</p><p>由熟悉地形的同事【家就在附近】带我们来到一个叫做 <strong>吊桥 </strong>的地方，他说这里有整条街的大排档，通常到夜里一两点仍旧人声鼎沸。听着这个描述，我感觉与住宿周围的环境形成鲜明的对比，因为住宿周围基本没有人出来活动，除了路灯，所有地方基本都是漆黑一片。</p><p>步行大概十几分钟，转了一个弯，突然霓虹闪烁、人声鼎沸，聊天的声音、吵闹的声音、商家宣传的声音不绝于耳，行人、车辆来来往往，感觉是到了另外一个世界。旭日大哥先带我们来到江边吹风，给我们介绍 <strong>吊桥 </strong>，没错，它是一个标准的小桥，只不过在这个时间被封路了，不能上去，我们只能站在旁边观看、吹风。</p><p>其实，周围漆黑一片，啥也看不清，只能吹吹风。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190714223133.jpg" alt="在吊桥江边吹风" title="在吊桥江边吹风"></p><p>稍微休息了一会儿，我们就选定了一家大排档，开吃开喝。当然，基本所有的菜都是辣的，特意叮嘱了服务员不要放那么多辣，毕竟在场的广东人居多。</p><p>点了两斤小龙虾，买二送一。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190714223207.jpg" alt="两斤小龙虾" title="两斤小龙虾"></p><p>这里的啤酒是以桶为单位的，一桶五公斤，我们一群人喝了两桶，当然我由于过敏没喝。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190714223229.jpg" alt="珠江啤酒一桶五公斤" title="珠江啤酒一桶五公斤"></p><p>聊天吹水，吃饱喝足，结账走人。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721023017.jpg" alt="吃饱喝足" title="吃饱喝足"></p><p>接着回住宿点，往回走，此时已经第二天凌晨 01:30，路上也没人了，只有我们一群孤单的身影。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190714223334.jpg" alt="回去酒店的路上" title="回去酒店的路上"></p><p>回到酒店，已经 01:40，洗漱完毕，看到桌子上还剩下一些杨梅，为了不浪费，我又吃了一些杨梅，一口气吃了十几个。由于刚刚吃过宵夜，又吃了杨梅，一开始睡不着，熬到凌晨 02:30 才睡着。</p><p>我觉得这真的是作，只能睡三个小时了，不知道第二天还能不能起来，体力还能不能跟得上。</p><p>住了一晚，第二天【06 月 22 日】早上 05:30 起床，我多睡了十分钟，最后还是坚持起床了，因为其他人都已经出发了，我是最后一个。到旁边的早餐店吃早餐：鱼粉、鸡蛋、咸菜，说真的，鱼粉虽然材料简单，味道真不错，吃完早餐，准备上山【景点都在高处】。</p><p>步行几分钟，就到了景区的大门口，住得近就是好，走两步就到。注意图中，我们有人拉着行李箱过来玩的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190714223406.jpg" alt="景区大门口" title="景区大门口"></p><h1 id="小东江"><a href="# 小东江" class="headerlink" title="小东江"></a>小东江 </h1><p> 进了景区的大门，接着就是乘坐大巴上山，当然你也可以选择步行，但是距离太远了，如果不是特意为了徒步锻炼还是坐大巴上去吧【就像在韶关丹霞山，可以选择徒步爬上去而不坐大巴也不坐缆车】。大概十分钟左右，就可以到达 <strong>小东江 </strong>景点。</p><p>刚下车，我就被眼前的景色惊到了，同时旁边有一群游客大姐特别激动，不断地发出惊讶的表情与赞美之声，场面一度非常欢乐。</p><p><strong>小东江 </strong>是东江湖的一条支流，岸边有几公里的人行道，可以散步，看 <strong>雾漫小东江 </strong>的景色。中途还会有延伸到江心的平台，可以近距离感受小东江的雾气，以及拍照留念。</p><p>先放出来几张图：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715010459.jpg" alt="雾漫小东江之一" title="雾漫小东江之一"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715010528.jpg" alt="雾漫小东江之二" title="雾漫小东江之二"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715010539.jpg" alt="雾漫小东江之三" title="雾漫小东江之三"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715010552.jpg" alt="雾漫小东江之四" title="雾漫小东江之四"></p><p>为了配合游客拍照，景点特意安排工作人员驾小舟在江心撒网捕鱼，当然，只是做动作，并不是真的捕鱼，主要就是为了配合游客拍照。我拿着一个相机竟然不会使用连拍功能，还是旁边的大叔提醒我：不使用连拍你怎么可能拍得到想要的画面，我当场查看了相机的所有设置，也没有找到连拍的设置在哪，最后只能悻悻地走了。</p><p>请看下图，靠我眼疾手快拍到的：<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715011242.jpg" alt="撒网之一" title="撒网之一"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715011253.jpg" alt="撒网之二" title="撒网之二"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715011313.jpg" alt="撒网之三" title="撒网之三"></p><p>在江心的平台上稍作休息，我第一次拿起了自拍杆，试拍效果。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715012623.jpg" alt="我第一次拿起了自拍杆" title="我第一次拿起了自拍杆"></p><p>可以看到环境监测大屏显示的环境信息，空气质量超级好，温度适宜，湿度太高【大雾的原因】，负氧离子超级多，停下来每呼吸一口，感觉都是赚的。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715012640.jpg" alt="环境监测大屏" title="环境监测大屏"></p><p>这条线路如果慢慢走，边走边赏景、边拍照，可以走大概两个小时。如果不是特别沉迷其中，没有必要走完全程，因为看到的景色都差不多，而且随着时间的消逝，雾气也会渐渐消散，后面就没有什么看头了。再者，还要适当保存体力进行后面的活动，不能在一个景点中消耗过多的时间。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715011737.jpg" alt="人行道上面的游客" title="人行道上面的游客"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717002354.jpg" alt="人行道上的阶梯" title="人行道上的阶梯"></p><p>前后算起来，我们徒步了大概一个多小时，最后在一个江心平台合照留念，996 专属团队，引起了路人的围观。蹲在 C 位拿着白色自拍杆的就是我。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190715012652.jpg" alt="团队合照留念" title="团队合照留念"></p><h1 id="龙景峡谷"><a href="# 龙景峡谷" class="headerlink" title="龙景峡谷"></a>龙景峡谷 </h1><p> 看完小东江雾景，我们来到一个中途服务点，稍作休息，此处有水果、饮料、小吃出售。</p><p>休息几分钟，接着坐车前往 <strong>龙景峡谷 </strong>，当然你也可以选择步行过去【去的路途中我看到有人背着包在步行】，但是实在是太远了，而且没有行人徒步专用道，都是直接走在机动车道上，太危险。</p><p>让人意外的是，第一辆车来到很快就坐满了【51 座的大巴，来到时上面已经有部分游客，应该是从上一个服务点过来的】，我们还有几个人没有上去，只好选择等待下一班车。但是，下一班车竟然是公交车，而且人已经满了，我们还是硬挤上去了，没想到在山上挤了一趟公交车。</p><p>我上车就来一张自拍，纪念一下山上的公交车。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717003028.jpg" alt="挤山上的公交车" title="挤山上的公交车"></p><p>坐车大概十几分钟，我们来到了 <strong>龙景峡谷 </strong>入口处的游客服务中心，准备进入游览。</p><p><strong>龙景峡谷 </strong>，其实就是一个峡谷，顺带有一座小山可以爬，爬的过程中可以看到小瀑布、周围的风景。围绕着小山的阶梯绕一圈，全程大概四十分钟。</p><p>在爬山图中，看到了小瀑布，很对得起这个 <strong>小 </strong>字。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717012231.jpg" alt="小瀑布" title="小瀑布"></p><p>在山上的某个角落看看山下的景色。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720224515.jpg" alt="山上一角的景色" title="山上一角的景色"></p><p>接着全程就很热了，太阳很晒，没有风，衣服基本被汗水浸透。而且，我还背着重重的背包，非常消耗体力，我还一路奇怪，我只睡了三个小时，是怎么坚持得了的。</p><p>从山上下来后，经过 <strong>浮桥 </strong>，也就是一些空桶做成的水中走道，可以从上面走过去。由于天气太热，可以看到上面基本没人，但是为了不虚此行，我们几个人还是冒着烈日上去走了一趟，上去之前我穿上了防晒衣。</p><p>浮桥的场景，看看这天气有多热。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717010920.jpg" alt="浮桥的场景 1" title="浮桥的场景 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717010937.jpg" alt="浮桥的场景 2" title="浮桥的场景 2"></p><p>在浮桥上，转头又看到一个小瀑布。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717010900.jpg" alt="又一个小瀑布" title="又一个小瀑布"></p><p>从 <strong>龙景峡谷 </strong>下来后，回到入口，此时全身都湿透了，汗水哗哗地往下流。我们买了饮料、雪糕，给自己降降温。</p><p>没想到我们几个人是率先下山的，四人组自拍，这镜头显胖。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717010824.jpg" alt="四人组率先归来" title="四人组率先归来"></p><p>接着我们几个人就先回到游客中心，在大厅等着其他人回来，准备一起坐船去 <strong>兜率岛 </strong>。</p><p>我在游客中心洗了脸，衣服全部湿透了，看看我背后的风景，再看看懵逼的我。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190717011134.jpg" alt="游客中心的某个角落" title="游客中心的某个角落"></p><h1 id="兜率岛灵岩溶洞"><a href="# 兜率岛灵岩溶洞" class="headerlink" title="兜率岛灵岩溶洞"></a>兜率岛灵岩溶洞 </h1><p> 等人全部到齐后，我们一起坐游船前往 <strong>兜率岛【读音 Doushuai，但门票上印的却是 Tushi】</strong>，沿途风景很好，还可以穿上救生衣，走上甲板，吹吹风，无论是近处还是远处的景色都一览无余，尽收眼底。</p><p><strong>兜率岛 </strong>是东江湖中的一座岛，总面积 5.6 平方公里，也是湖南第一大岛，岛上山清水秀，景色宜人。有人形容东江湖的景象：<strong> 山中有湖，湖中有岛，岛上有庙，庙里有洞，洞中有洞 </strong>，这里的岛就是 <strong>兜率岛 </strong>。</p><p>走到这里，必须要把行程路线说明一下，我们购买的是 <strong>精品线路 2</strong> 通票，等坐游船前往 <strong>兜率岛 </strong>玩一圈后，理论上就应该返程了，因为已经把所有景点全部游览一遍。但是我们不走一般的路线，后面还会有自由行路线，这全靠大哥的表妹在安排。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720174908.jpg" alt="门票上的游玩线路图" title="门票上的游玩线路图"></p><p>坐船出发啦，在游船起步的几分钟内，可以看到 <strong>东江大坝 </strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720175614.JPG" alt="坐船出发" title="坐船出发"></p><p>在坐船的过程中，我只顾着看风景、拍视频了，基本没有拍照片，可惜不能把大好河山展现出来。坐船过程大概 20 分钟。</p><p>船上的小伙伴，可能是刚刚在 <strong>龙景峡谷 </strong>太累了，或者是晕船，坐下来就不想动了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720231555.jpg" alt="坐船的小伙伴" title="坐船的小伙伴"></p><p>甲板上的小伙伴，连带后面的风景。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720231624.jpg" alt="甲板上的小伙伴" title="甲板上的小伙伴"></p><p>此情此景，老大们怎能不登场。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720231632.jpg" alt="老大们登场" title="老大们登场"></p><p>游船大概行驶 20 分钟后，到达 <strong>兜率岛 </strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720231640.jpg" alt="到达兜率岛" title="到达兜率岛"></p><p>先随便来两张照片看看这里的秀丽风景。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720231731.jpg" alt="辽阔的景色 1" title="辽阔的景色 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720231745.jpg" alt="辽阔的景色 2" title="辽阔的景色 2"></p><p>由于有人把票弄丢了，几个人陪着在补票，所以没跟着同一艘船过来，我们一群人要等着他们。看到有人在卖水果，老大请客，先买西瓜吃。由于路途劳顿，汗水流出来了，再看着这切开的西瓜，口水又流出来了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720231830.jpg" alt="准备买西瓜" title="准备买西瓜"></p><p>看着这一群吃瓜群众，在这个时刻吃上一块西瓜，简直就是人生中一大幸福事。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232005.jpg" alt="吃瓜群众" title="吃瓜群众"></p><p>吃好后，后面的几个人也来到了，我们先休息一会儿。此时此刻，我们多数人已经很累了，坐在地上不想动，也不想说话，有些人已经表现出一副生无可恋的样子。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232033.jpg" alt="南国明珠东江湖" title="南国明珠东江湖"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232105.jpg" alt="坐在地上休息一会" title="坐在地上休息一会"></p><p>休息好后，我们开始前往 <strong>灵岩溶洞 </strong>，从大门入口处走几十个台阶就是溶洞的入口，观赏全程大概 30-40 分钟。<strong> 灵岩溶洞 </strong>又是一处神奇的景色，它处在一座庙中，里面的钟乳石光怪陆离、千姿百态、变化莫测，看了让人叹为观止。走在里面，一会儿迂回狭窄，一会儿豁然开朗，周围的环境怪石嶙峋、冷风习习，一会儿让人毛骨悚然，一会儿让人震撼不已。</p><p>溶洞的入口小门：<strong> 福地洞天 </strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232158.jpg" alt="溶洞的入口小门" title="溶洞的入口小门"></p><p>刚刚走进去的时候，就感觉到凉风习习，阴森森的，有人惊叹：是不是开空调啦！</p><p>不得不说，<strong> 灵岩溶洞 </strong>里面真是凉快，温度估计 20 摄氏度都不到，而且有风，里面绝对没有开空调、放冷气之类的，全部是自然的凉爽，但是确实有点冷。在行走的过程中，洞顶会有水滴滴下来，简直是冰水滴，滴下来很冷，如果你用手摸一下路边的石头，也是很冰的。</p><p>至于景观，主要是一些钟乳石、笋石、石柱，在五颜六色的灯光的照射下，显示出各种形态。当然，最终你看到的是什么全靠自己的想象，因为解说员在整个过程中重复了好多次：三分神似，七分想象，不同的人眼里看到的是不同的形态。在这里面拍照也是拍不清，一片漆黑，灯光太暗，除了石头上面会打一些光。</p><p>不信？来，看看这些都是什么，我反正是看不出来。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232224.jpg" alt="溶洞的钟乳石 1" title="溶洞的钟乳石 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232237.jpg" alt="溶洞的钟乳石 2" title="溶洞的钟乳石 2"></p><p>一路走下来，我就一个感觉：真是太凉快了，把整个人的温度都降下来了，出去的时候，眼镜瞬间被蒙了一层水雾，可见里外的温差有多大。在里面走的久了，我就觉得此地不宜久留，疲惫加上饥饿，如果再被冷气压制一下，很担心下一步就感冒。所以加快步伐，想快点出去。</p><p>总结一下：洞内真的像一个天然的冰箱，非常的凉爽，特别是在出洞口，从洞内一阵阵凉风刮来，纯天然空调啊，站在洞口让人挪不开脚步。不过这样的巨大温差，如果还站在洞口直接吹冷风，估计很容易就感冒了，反正我是吹了一会就站的远一点，不敢吹了。</p><p>我们几个人出来后，发现很多人还没出来，只好坐在路边，边休息边等。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232313.jpg" alt="坐在出口吹风等待" title="坐在出口吹风等待"></p><p>有几个人在门口吹风，试图自拍：<strong> 道法自然 </strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190720232324.jpg" alt="在出口吹风自拍" title="在出口吹风自拍"></p><p><strong>灵岩溶洞 </strong>观赏结束后，所有人到齐，我们将要前往 <strong>水上乐园 </strong>。</p><h1 id="水上乐园"><a href="# 水上乐园" class="headerlink" title="水上乐园"></a>水上乐园 </h1><p><strong> 水上乐园 </strong>本来是为游客开发的水上项目，可以在这里体验各种项目的玩法，例如 <strong>水上摩托艇 </strong>、<strong> 香蕉船 </strong>，当然是要额外收费的。由于时间点不合适，我们也没有提前安排这类活动，所以没有关心具体的项目。</p><p>给大家看一下 <strong>兜率岛 </strong>的地图指引，了解一下 <strong>水上乐园 </strong>的位置，其实它就在 <strong>返程码头 </strong>的旁边。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721030229.jpg" alt="兜率岛地图指引" title="兜率岛地图指引"></p><p>从 <strong>灵岩溶洞 </strong>走过去，大概十几分钟，而且路上有树荫有风，不是很热。沿途风光大好，美不胜收，随便拍一张照片都是壮阔的景色。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721030239.jpg" alt="随便拍一张壮阔的景色" title="随便拍一张壮阔的景色"></p><p>如果按照正常的官方线路图，到这里已经结束了，可以直接在 <strong>返程码头 </strong>乘坐游船返程，还不耽误回去吃午饭。但是我们至此才开始自由行，由大哥的表妹安排，先在 <strong>水上乐园 </strong>门口乘坐自己租的小船，前往我们预定的 <strong>东江湖避暑休闲农庄 </strong>，在那里度过下午和明天。</p><p>在 <strong>水上乐园 </strong>门口，有很多卖特产的，水果、鱼干、烤鱼，可以买来吃。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721030245.JPG" alt="水上乐园门口" title="水上乐园门口"></p><h1 id="直奔东江湖避暑休闲农庄"><a href="# 直奔东江湖避暑休闲农庄" class="headerlink" title="直奔东江湖避暑休闲农庄"></a>直奔东江湖避暑休闲农庄 </h1><p> 一开始我们走错路了，直接走到 <strong>返程码头 </strong>了，以为会在那里上船。其实不是，而是在另外一个简陋的停靠点，算不上码头，大家依次上小船。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721182527.JPG" alt="大家依次上小船" title="大家依次上小船"></p><p>上了小船，先来一张自拍合照。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721182555.jpg" alt="自拍合照" title="自拍合照"></p><p>在柴油机的轰隆声，大概过了二十分钟，我们到达了 <strong>休闲农庄 </strong>。给大家看一下地图，<strong> 休闲农庄 </strong>的位置，它的所在地其实是一个半岛，如果从另外一个方向过去是可以直接开车的，但是从我们这个方向【兜率岛的位置】过去只能坐船。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721182628.png" alt="半岛上的农庄" title="半岛上的农庄"></p><p>到了休闲农庄，时间大概是 12:00，我们大部分人又累又饿，已经不想动了。在等午饭的过程中，我就躺在沙发上立即睡着了，大概迷迷糊糊睡了十几分钟。</p><p>到达农庄里的小宿舍，我在二楼看风景。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721183852.jpg" alt="我在二楼看风景" title="我在二楼看风景"></p><p>这里设施很齐全，有乒乓球桌、K 歌设备、麻将桌、吊床、躺椅、游泳池、自家果园，大家可以在这里面朝大湖，谈笑风声。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721182658.jpg" alt="面朝大湖谈笑风生" title="面朝大湖谈笑风生"></p><h1 id="吃午饭自由活动"><a href="# 吃午饭自由活动" class="headerlink" title="吃午饭自由活动"></a>吃午饭自由活动 </h1><p> 终于等到开饭了，时间大概是 13:00，非常丰盛，非常好吃，大家饱餐一顿。</p><p>吃完午饭，时间大概是 14:00，大家自由活动，可以回房间休息，可以去游泳，可以打牌，可以到周围逛一逛。</p><p>我实在是太累了，不想动了，把换掉的衣服简单洗了一下，然后就准备睡觉了。</p><p>衣服刚洗完，到走廊外面晾衣服，突然发现烈日消失了，天空开始出现了乌云，大风也刮起来了，看来是要下雨了，那些出去逛的小伙伴也要回来了吧。</p><p>用下面的几张照片来多角度展现当时的情景，乌云密布，简直就是 <strong>黑云压城城欲摧，山雨欲来风满楼 </strong>。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191705.jpg" alt="乌云密布 1" title="乌云密布 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191728.jpg" alt="乌云密布 2" title="乌云密布 2"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191740.jpg" alt="乌云密布 3" title="乌云密布 3"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191751.jpg" alt="乌云密布 4" title="乌云密布 4"></p><p>我下楼看了看，看着这湖里逐渐泛起了波浪，远处的乌云也已经压过来，一场风雨不可避免了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191837.jpg" alt="湖中的波浪" title="湖中的波浪"></p><p>接着我就撑不住了，回到房间倒在床上就睡着了，时间大概是 15:30。</p><h1 id="吃晚饭自由活动"><a href="# 吃晚饭自由活动" class="headerlink" title="吃晚饭自由活动"></a>吃晚饭自由活动 </h1><p> 我一觉睡了三个小时，到 18:30 才醒来，而且睡得很稳，睡眠质量超级好。接着刚洗漱完毕就听到有人喊下楼吃晚饭，时间大概是 19:00。</p><p>吃完晚饭又是自由活动，还有一部分人在玩喝酒游戏，还有两条大黄狗在趴着。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191916.jpg" alt="吃完晚饭喝酒的人" title="吃完晚饭喝酒的人"></p><p>大部分人还是很累就回去继续休息了，准备明天的活动，剩下的人在 K 歌、打麻将、游泳、逗狗。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191951.jpg" alt="K 歌的人" title="K 歌的人"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721191959.jpg" alt="打麻将的人" title="打麻将的人"></p><p>此时，吹着微风，听着水声，让人有一种 <strong>面朝大海，唱 K 打牌 </strong>的错觉。</p><p>大家玩到 00:00 左右，陆续有人回去休息了。</p><p>我大概 03:30 才睡，主要是下午睡太久了，睡不着，再加上聊天、唱歌、吃东西，变得有点亢奋。虽然身体上很累，但是精神上有点亢奋，回顾这一天的活动，真的感觉累成狗，还好现在年轻，还能撑得住。</p><p>看，农庄的两条大黄狗都困得不行，不理我们了。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721192041.jpg" alt="看狗困的 1" title="看狗困的 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721192051.jpg" alt="看狗困的 2" title="看狗困的 2"></p><h1 id="游泳晨跑去果园"><a href="# 游泳晨跑去果园" class="headerlink" title="游泳晨跑去果园"></a>游泳晨跑去果园 </h1><p> 第三天的早上我们定的行程是 09:00 出发，因为要坐船、坐大巴前往 <strong>郴州火车站 </strong>【预计两个小时】，赶 12:10 的火车，还要吃午饭。</p><p>本来是早上 07:00 吃早餐，然后自由活动，大家可以去跑步、逛果园、游泳，但是我太累了，早上醒来看到外面又在下雨，于是接着睡了。当然，他们大部分人还是起来了，进行各自的活动，只有包括我在内的几个人在睡觉。</p><p>我大概在 08:30 起床，然后被人催着吃早饭，啥也没玩，听说早上一直在下小雨，导致小部分人没起床，也就是直接睡到了饭点。</p><p>虽然下着小雨，风景还是不错，几个人在乡间的小路上跑步。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721192140.jpg" alt="早晨的风景 1" title="早晨的风景 1"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721192147.jpg" alt="早晨的风景 2" title="早晨的风景 2"></p><p>吃完早饭，09:00，大家收拾东西返程，准时出发，去赶火车。我们在返程的小船上再来一张合照。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190721192155.jpg" alt="返程合照" title="返程合照"></p><h1 id="返程"><a href="# 返程" class="headerlink" title="返程"></a>返程 </h1><p> 说真的，不知道为啥，吃早餐的时候天气还不错，然后从上船那一刻起，雨就变大了。在船上下雨，换乘大巴还在下雨，整个返程的路上一直在下雨，但是到了火车站雨就停了。</p><p>经过两个小时的舟车劳顿，我们大概在 11:20 到了 <strong>郴州火车站 </strong>，由于经费紧张，我们回程是坐普通火车，没有再坐高铁，预计需要四个半小时，在 16:40 可以到达 <strong>广州东站 </strong>，反正时间也比较充足。</p><p>到了火车站，大家各自吃午饭，或者买点零食、饮料带着。我和几个人一起去找了一个小店【佳兴鱼粉】，我吃了 <strong>招牌黄鸭叫鱼粉 </strong>，香辣口味的，真的有鱼，味道很好，汤很鲜。吃了一半我觉得有点辣也有点热，就配了一根油条，不得不说，人间美味。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190722010843.jpg" alt="美味的招牌黄鸭叫鱼粉" title="美味的招牌黄鸭叫鱼粉"></p><p>临走时，发现店里的 <strong>香辣猪脚 </strong>【或者叫猪蹄】才十二块钱一只，忍不住买了一只打包带着，准备在火车上吃。不得不说，真的买对了，太好吃了，比广州的还好吃。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190722010853.jpg" alt="美味的香辣猪脚" title="美味的香辣猪脚"></p><p>有一些小伙伴准时进站后，发现火车晚点了 20 分钟，然后先到的小伙伴就在群里通知了大家，让大家吃午饭的的速度慢下来，不要着急。</p><p><strong>郴州火车站 </strong>的车站面积很小，安检、检票、进站全程不到五分钟。</p><p>插播一个小意外，我在候车室拍视频，持续拍了几分钟，然后被工作人员拦下来，他拦了一下我的手机，提示我说：<strong> 收起来，在这里不要乱拍 </strong>。在我专心寻找画面的时候，这突如其来的提醒着实把我吓了一跳。</p><h1 id="到达广州"><a href="# 到达广州" class="headerlink" title="到达广州"></a>到达广州 </h1><p> 经过四个半小时的火车旅途，我们到达 <strong>广州东站 </strong>，由于火车晚点了二十分钟，我们到达火车站的时间大概是 17:00 。没想到刚出火车站，就是狂风大作、乌云密布，看样子又是一场暴风雨。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190722010904.jpg" alt="火车站的狂风乌云" title="火车站的狂风乌云"></p><p>由于住的地方离地铁站比较远，我一看这天气等会步行也不太方便，决定坐公交回去。在火车站广场走了一圈，发现以前的公交站消失了，取而代之的是一片施工围栏。我跟着人流走了一会，发现公交站搬迁了，原来的公交站位置被围栏围起来，听说在修地铁站。新的公交站在草暖公园，以前是常规的停车场，不过距离有点远，估计步行要十分钟以上。<br><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190722010913.jpg" alt="新公交站在草暖公园" title="新公交站在草暖公园"></p><p>都已经走了这么远，也不能回去坐地铁，看着天气也快下雨了，于是加快步伐走向公交站，在路上看到几乎所有人都在奔跑。果然，刚到公交站，暴雨就来了，还好我已经上车了。</p><p>顺利到家，到家一下子就放松了。</p><h1 id="终结"><a href="# 终结" class="headerlink" title="终结"></a>终结 </h1><p> 此刻放下打字的键盘，需要好好休息，明天又要开始拿起打代码的键盘，回归工作。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>游玩</category>
      </categories>
      <tags>
        <tag>Hunan</tag>
        <tag>Chenzhou</tag>
        <tag>fun</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 让进程在后台运行的几种方法</title>
    <url>/2019051501.html</url>
    <content><![CDATA[<!-- build time:Sat Jul 04 2020 00:58:49 GMT+0800 (China Standard Time) --><p>在 <code>Linux</code> 系统中，运行程序时经常需要把进程放在后台运行，并且退出终端等待，也可以说是守护进程，<code>daemon</code> 的概念，可能过几个小时或者十几个小时之后再去观察。此种场景，需要把进程放入后台运行，并且为了防止进程挂起，也需要设置进程忽略挂起信号【使用 <code>nohup</code> 命令】，这样就可以保证进程在我退出终端后仍旧能正常运行，无论我多久之后再来观察，仍可以看到进程的运行信息。本文记录关于进程后台运行【<code>daemon</code>】的几种方法，并给出实际的操作示例，属于入门级别。</p><a id="more"></a><h1 id="回顾"><a href="# 回顾" class="headerlink" title="回顾"></a>回顾 </h1><p> 在我刚刚开始步入社会时，算是一个职场新手，很多东西都不会，可以说是一张白纸。经过一路上走弯路、披荆斩棘，现在总算积累了一些经验。</p><p>记得在刚刚开始工作时，经常碰到这样的场景，使用 <code>telnet</code> 或者 <code>ssh</code> 登录了远程的 <code>Linux</code> 服务器【很多工作需要在 <code>Linux</code> 上面完成】，在上面跑了几个 <code>Shell</code> 脚本，或者起了几个 <code>Java</code> 进程，而且这些脚本或者进程耗时都比较长，可能需要几个小时或者几天。我一开始的做法就是打开 <code>XShell</code> 工具的多个会话窗口，分别跑脚本或者起进程，不仅不能关掉，而且还要时刻担心网络问题导致与 <code>Linux</code> 的会话断开，这样一切工作就白费了。</p><p>我在操作过程中被其他同事看到了，他们说我这种做法太蠢了，是在浪费生命。经过他们指点，其实可以使用后台挂起的命令【即 <code>nohup</code> 加上 <code>&amp;</code>】，这样就可以让进程自由自在地在系统后台运行，我也可以安心地做其它事情了。</p><p>我第一次受到了经验方面的冲击，觉得这种方式太酷了，一开始我为什么不多思考一下、查询一下或者咨询一下同事。现在回想起来当时甚至都没有这方面的想法，只是知道埋头苦干，我想这些实用的知识点肯定还有很多，这也敦促了我从此以后我更加努力，多学多看多问。</p><p>在后来的工作或者生活当中，我又接触到了很多类似的知识点或者说是小技巧，不仅提高了我的工作效率，还丰富了我的认知。其中，基于进程的后台运行这个场景，还有很多很好的工具可以使用，而且还有很多实际操作的小技巧可以使用，以下的内容会一一介绍。</p><p>读者在继续阅读之前，最好先了解一下 <strong>信号 </strong>的概念，也可以直接参考我的另外一篇博文：<a href="https://www.playpi.org/2019042101.html">Linux 之 kill 命令入门实践 </a> ，里面会有一些入门级别的介绍。</p><h1 id="前言"><a href="# 前言" class="headerlink" title="前言"></a> 前言 </h1><p> 在工程师或者运维人员的职业生涯中，肯定会碰到这样的场景：使用 <code>ssh</code> 或者 <code>telnet</code> 登录了远程 <code>Linux</code> 服务器，然后在上面跑一些程序任务或者脚本。如果是临时任务或者几分钟就能搞定的任务，基本不会有什么问题，但是如果是耗时比较长的任务、需要在系统后台长期运行的任务，如果没有人为正确操作，就会因为网络不稳定或者手抖退出了连接会话，从而导致进程任务中断。最终还要从头再来，如果遇到这种问题，所有人都是崩溃的。</p><p>那么我不禁思考，有没有什么办法可以让进程任务在提交后不受网络中断、连接会话退出的影响呢，从而可以一直保持在后台稳定运行，直到结束。肯定是有的，读者在工作中一定也见过周围的技术大神同事操作，或者自己就是技术大神，下面列举一些常用的方式，读者可以参考，选择自己喜欢的方式使用。</p><p>内容中涉及到的 <code>SIGHUP</code> 信号，先来了解一下它的由来：</p><blockquote><p>在 <code>Unix</code> 的早期版本中，每个终端都会通过 <code>modem</code> 和系统通信，当用户 <code>logout</code> 时，<code>modem</code> 就会挂断（hang up）电话。同理，当 <code>modem</code> 断开连接时，就会给终端发送 <code>hangup</code> 信号来通知其关闭所有子进程。这里的子进程包含前台子进程、后台子进程，前台子进程是被直接关闭的（如果被手动设置了 <code>nohup</code> 则除外），后台子进程要根据操作系统的 <code>huponexit</code> 设置而定，不一定会被关闭。其中，这里的后台子进程还会包括正在运行的子进程（使用 <code>jobs</code> 工具查看 处于 <code>running</code> 状态）、暂停的子进程（使用 <code>jobs</code> 工具查看 处于 <code>stopped</code> 状态，处于这个状态的子进程无论有没有被手动设置 <code>nohup</code> 都会被关闭）。</p></blockquote><p>再看一下维基百科给它的定义：</p><blockquote><p><strong>nohup</strong> is a POSIX command to ignore the HUP (hangup) signal. The HUP signal is, by convention, the way a terminal warns dependent processes of logout.<br>Output that would normally go to the terminal goes to a file called nohup.out if it has not already been redirected.</p></blockquote><p>下面简单总结一下终端会话退出时发生了什么：</p><ul><li>当终端被挂断或伪终端程序被关掉，若终端的 <code>CLOCAL</code> 标志没有被设置，则 <code>SIGHUP</code> 信号会被发送到与该终端相关的控制进程【即会话首进程，通常为 <code>Shell</code>】</li><li>而 <code>SIGHUP</code> 的默认行为是终止程序的运行，当会话首进程终止，也会将 <code>SIGHUP</code> 信号发送给前台进程组中的每一个进程【根据 <code>Shell</code> 的具体实现，还可能会把 <code>SIGNHUP</code> 发送给后台进程组】</li></ul><h1 id="直接忽略挂起信号"><a href="# 直接忽略挂起信号" class="headerlink" title="直接忽略挂起信号"></a>直接忽略挂起信号 </h1><p> 众所周知，当发生用户注销会话、网络断开等事件时，终端会收到 <code>SIGHUP</code> 信号从而关闭其所有的子进程，它是通过把 <code>SIGHUP</code> 信号发送给所有子进程实现。当然，<strong> 前台 </strong>子进程如果没有设置忽略 <code>SIGHUP</code> 信号直接会停掉，如果设置了会继续运行【父进程会变化】。但是 <strong>后台 </strong>子进程除了人为设置可能还会因为操作系统的设置而忽略 <code>SIGHUP</code> 信号【所以有些人会觉得莫名其妙，怎么退出了再登录发现有些进程还在】，而且还要区分后台子进程的状态【使用 <code>jobs</code> 命令查看，处于 <code>running</code>、<code>stopped</code> 等状态】。</p><p>梳理到这里，我就能想到两种解决方案：一是让进程忽略掉 <code>SIGHUP</code> 信号，二是让进程脱离会话父进程的运行，附属于其它父进程，从而不会接收到当前终端对应的进程发出的 <code>SIGHUP</code> 信号，这两种方法都可以让进程不受外界因素影响，稳定地运行。</p><p>下面逐一演示。</p><h2 id="nohup- 方式"><a href="#nohup- 方式" class="headerlink" title="nohup 方式"></a>nohup 方式 </h2><p> 思路有了，我首先能想到的就是 <code>nohup</code> 工具，顾名思义，<code>nohup</code> 这个工具的作用就是让进程忽略掉所有的 <code>SIGHUP</code> 信号，不受它的影响。</p><p><code>nohup</code> 的核心代码为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">signal (SIGHUP, SIG_IGN);</span><br><span class="line"></span><br><span class="line">char **cmd = argv + optind;</span><br><span class="line">execvp (*cmd, cmd);</span><br></pre></td></tr></table></figure><p>让我们先来看一下帮助文档信息，使用 <code>man nohup</code> 命令查看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NOHUP (1)                         User Commands                        NOHUP (1)</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">       nohup - run a command immune to hangups, with output to a non-tty</span><br><span class="line"></span><br><span class="line">SYNOPSIS</span><br><span class="line">       nohup COMMAND [ARG]...</span><br><span class="line">       nohup OPTION</span><br><span class="line"></span><br><span class="line">DESCRIPTION</span><br><span class="line">       Run COMMAND, ignoring hangup signals.</span><br><span class="line"></span><br><span class="line">       --help display this help and exit</span><br><span class="line"></span><br><span class="line">       --version</span><br><span class="line">              output version information and exit</span><br><span class="line"></span><br><span class="line">       If standard input is a terminal, redirect it from /dev/null.  If standard output is a terminal, append output to ‘nohup.out’ if possible, ‘$HOME/nohup.out’ otherwise.  If standard error is a terminal, redirect it to standard output.  To save output to FILE, use ‘nohup COMMAND &gt; FILE’.</span><br><span class="line"></span><br><span class="line">       NOTE: your shell may have its own version of nohup, which usually supersedes the version described here.  Please refer to your shell’s documentation for details about the options it supports.</span><br><span class="line"></span><br><span class="line">AUTHOR</span><br><span class="line">       Written by Jim Meyering.</span><br><span class="line"></span><br><span class="line">REPORTING BUGS</span><br><span class="line">       Report nohup bugs to bug-coreutils@gnu.org</span><br><span class="line">       GNU coreutils home page: &lt;http://www.gnu.org/software/coreutils/&gt;</span><br><span class="line">       General help using GNU software: &lt;http://www.gnu.org/gethelp/&gt;</span><br><span class="line">       Report nohup translation bugs to &lt;http://translationproject.org/team/&gt;</span><br><span class="line"></span><br><span class="line">COPYRIGHT</span><br><span class="line">       Copyright © 2010 Free Software Foundation, Inc.  License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;.</span><br><span class="line">       This is free software: you are free to change and redistribute it.  There is NO WARRANTY, to the extent permitted by law.</span><br><span class="line"></span><br><span class="line">SEE ALSO</span><br><span class="line">       The full documentation for nohup is maintained as a Texinfo manual.  If the info and nohup programs are properly installed at your site, the command</span><br><span class="line"></span><br><span class="line">              info coreutils &apos;nohup invocation&apos;</span><br><span class="line"></span><br><span class="line">       should give you access to the complete manual.</span><br><span class="line"></span><br><span class="line">GNU coreutils 8.4                December 2011                        NOHUP (1)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190831173014.png" alt="nohup 帮助文档信息" title="nohup 帮助文档信息"></p><p>从中可以挑出重点信息查看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup COMMAND [ARG]...</span><br><span class="line">Run COMMAND, ignoring hangup signals.</span><br><span class="line">If  standard  output is a terminal, append output to ‘nohup.out’ if possible,‘$HOME/nohup.out’ otherwise.</span><br></pre></td></tr></table></figure><ul><li>使用方式：在执行的任务命令前面加上 <code>nohup</code> 即可。</li><li>作用：可以让执行的进程忽略 <code>SIGHUP</code> 信号。也会关闭标准输入，该进程不能接收任何输入，即使运行在前台。</li><li>输出：在终端执行的进程，输出信息会重定向到 <code>nohup.out</code> 文件。</li></ul><p>可见，<code>nohup</code> 的使用是十分简单方便的，标准输入被关闭，标准输出和标准错误默认会被重定向到 <code>nohup.out</code> 文件中，此文件会自动生成于执行命令的当前目录。</p><p>但是要注意，一般我会在命令结尾加上 <code>&amp;</code> 来将任务进程放入后台运行【而且进程的 <code>stdin</code>、<code>stdout</code>、<code>stderr</code> 都脱离了终端会话，让它在前台运行似乎意义不大】，如果不加的话，进程会一直占用终端【其实就是标准输入一直等待终端的输入，一般等待 30 秒会释放】，这样就没法在当前会话窗口进行其它操作了。</p><p>这里需要注意一点，如果把进程放在后台运行，由于进程不再占用会话窗口，它的本质其实是不再从标准输入【<code>stdin</code>】读取输入参数指令，如果此时进程中有从标准输入读取指令的代码逻辑【只会得到 <code>EOF</code>】，会导致暂停【处于 <code>stopped</code> 状态】。因此，对于一些交互式的任务，肯定不适合放在后台运行，况且本来就是交互式任务【与前台用户交互】，还放在后台运行干什么。如果非要放在后台运行，可以在执行任务时加上输入重定向【注意不是输出重定向】：<code>nohup command &lt; /dev/null &amp;</code>，这样遇到读取输入的逻辑就不会暂停，但是可能会从 <code>/dev/null</code> 接收到一些奇怪的指令。</p><p>那么，为什么输出流没有这个问题呢，其实是 <code>nohup</code> 的功劳，它已经把标准输出、标准错误都重定向到 <code>nohup.out</code> 文件了。如果没有使用 <code>nohup</code>，而是直接执行 <code>command &lt; /dev/null &amp;</code>，同时退出了当前会话窗口【任务放在后台运行，退出会话不会影响任务继续运行】，则后台运行的任务已经失去了标准输出、标准错误这两个输出流。如果代码中有输出内容到标准输出或者标准错误的逻辑【例如打印日志】，会导致任务暂停【处于 <code>stopped</code> 状态】，但是当前会话窗口已经被关闭，进程找不到父进程，进而终止。所以，为了保证安全性，需要把输出信息输出到指定的文件，除了 <code>nohup</code> 默认的输出流，此时也可以使用 <code>command &gt;filename 2&gt;&amp;1 &amp;</code> 来更改默认的输出流，这样可以保证后台任务的正常运行，而且更方便观察每个进程的输出日志【全部输出到指定的文件】。</p><p>知识点绕的有点远了，言归正传，下面举一个例子，来演示 <code>nohup</code> 的使用：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、nohup tail -f xx.log &amp;，提交一个后台进程，忽略 SIGHUP 信号 </span><br><span class="line">2、ps -ef |grep &apos;tail -f&apos; |grep -v grep，查看进程的状态 </span><br><span class="line">3、kill -SIGHUP 245058，手动发送 SIGHUP 信号 </span><br><span class="line">4、同 2 再查看进程的状态 </span><br></pre></td></tr></table></figure><p>依次执行上述步骤，输出信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ nohup tail -f xx.log &amp;</span><br><span class="line">[1] 245058</span><br><span class="line">[pengfei@dev2 ~]$ nohup: ignoring input and appending output to `nohup.out&apos;</span><br><span class="line"></span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">pengfei  245058 201491  0 01:36 pts/0    00:00:00 tail -f xx.log</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ kill -SIGHUP 245058</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">pengfei  245058 201491  0 01:36 pts/0    00:00:00 tail -f xx.log</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190831173717.png" alt="nohup 简单演示" title="nohup 简单演示"></p><p>可以看到，进程已经不受 <code>SIGHUP</code> 信号的影响了，并没有被杀死，仍旧在运行中。因此，此时退出会话终端，对它也是没有影响的。</p><h2 id="setsid- 方式"><a href="#setsid- 方式" class="headerlink" title="setsid 方式"></a>setsid 方式 </h2><p><code>nohup</code> 的秘密是什么，显而易见是通过忽略 <code>SIGHUP</code> 信号，使用户的进程避免被中断。这好像是具有很高权限的系统对进程说：你可以去死了，然而进程却不听，并捂住耳朵摇头：我不听！我不听！这种公然违抗系统指令的行为，使进程继续活下去，并可以自由自在地运行。</p><p> 那其实不妨换一个角度思考，有没有可能不让系统发送 <code>SIGHUP</code> 信号，注意这里的含义是系统不会发送 <code>SIGHUP</code> 信号给进程，进程本身并没有忽略 <code>SIGHUP</code> 信号。</p><p>略加思考，我基本有了方案：让进程独立运行，不再属于当前会话的子进程，这样会话在关闭时不会再给这个进程发送 <code>SIGHUP</code> 信号【因为独立运行的进程不属于当前会话的子进程了，与当前会话无关】。</p><p>好，有一个工具可以帮到我，那就是 <code>setsid</code>，它的核心是 <code>setsid</code> 函数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pid_t setsid (void);</span><br></pre></td></tr></table></figure><p>先来看一下它的帮助信息，使用 <code>man setsid</code> 查看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SETSID (1)                  Linux Programmer’s Manual                 SETSID (1)</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">       setsid - run a program in a new session</span><br><span class="line"></span><br><span class="line">SYNOPSIS</span><br><span class="line">       setsid program [arg...]</span><br><span class="line"></span><br><span class="line">DESCRIPTION</span><br><span class="line">       setsid runs a program in a new session.</span><br><span class="line"></span><br><span class="line">SEE ALSO</span><br><span class="line">       setsid (2)</span><br><span class="line"></span><br><span class="line">AUTHOR</span><br><span class="line">       Rick Sladkey &lt;jrs@world.std.com&gt;</span><br><span class="line"></span><br><span class="line">AVAILABILITY</span><br><span class="line">       The setsid command is part of the util-linux-ng package and is available from ftp://ftp.kernel.org/pub/linux/utils/util-linux-ng/.</span><br><span class="line"></span><br><span class="line">Linux 0.99                     20 November 1993                      SETSID (1)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190904010120.png" alt="setsid 帮助信息" title="setsid 帮助信息"></p><p>可见，<code>setsid</code> 的作用就是在一个新的会话中启动进程，这样就可以保证启动的进程与当前会话无关。而且使用方法也很简单，只需要在命令前面加 <code>setsid</code> 即可，格式如：<code>setsid command</code> 。</p><p>执行示例：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、setsid tail -f xx.log &amp;&gt; tail.log，提交进程，默认在后台运行 </span><br><span class="line">2、ps -ef |grep &apos;tail -f&apos; |grep -v grep，查看进程的状态 </span><br><span class="line">3、退出当前会话 </span><br><span class="line">4、重新登录再查看进程的状态：ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br></pre></td></tr></table></figure><p>依次执行上述步骤，输出信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ setsid tail -f xx.log &amp;&gt; tail.log</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">pengfei   53334      1  0 00:49 ?        00:00:00 tail -f xx.log</span><br><span class="line">[pengfei@dev2 ~]$</span><br><span class="line">... 重新登录 </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">pengfei   53334      1  0 00:49 ?        00:00:00 tail -f xx.log</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190904010155.png" alt="setsid 示例演示" title="setsid 示例演示"></p><p>可以看到，进程一直在运行，退出会话并没有影响到它。值得注意的是，这个进程的编号为 53334，但是它的父进程编号却为 1【即 <code>init</code> 进程】，并不是当前会话对应进程的编号，读者可以和上述的 <code>nohup</code> 作比较，可见 <code>setsid</code> 的作用就在此。</p><p>此时这个进程虽然在正常运行，退出当前会话也不会影响到它，但是它并没有忽略 <code>SIGHUP</code> 信号，所以还会受到 <code>SIGHUP</code> 信号的影响。不妨手动发送一个 <code>SIGHUP</code> 信号给它，再查看一下进程的状态。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kill -SIGHUP 53334，手动使用 kill 发送信号 </span><br><span class="line">ps -ef |grep &apos;tail -f&apos; |grep -v grep，再查看进程的状态 </span><br></pre></td></tr></table></figure><p>依次执行上述步骤，输出信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">pengfei   53334      1  0 00:49 ?        00:00:00 tail -f xx.log</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ kill -SIGHUP 53334</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190904010219.png" alt="手动 kill 测试" title="手动 kill 测试"></p><p>可见进程已经被杀死了，不复存在。</p><p>下面再简单介绍一下 <code>setsid</code> 的原理，核心在于 <code>pid_t setsid (void);</code> 函数。</p><p>首先需要了解一下两种调用场景。</p><p>如果调用 <code>setsid</code> 函数的进程不是一个进程组的组长，就会创建一个新会话，具体来说会经历下面三个流程：</p><ul><li>该进程会变成新会话的会话首进程【会话首进程即创建该会话的进程】，此时新会话中只有该进程这么一个进程 </li><li> 该进程会变成一个新进程组的组长进程，新进程组 <code>PGID</code> 就是该进程的 <code>PID</code></li><li>该进程与控制终端的联系被切断 </li></ul><p> 如果调用 <code>setsid</code> 函数的进程本身就是一个进程组的组长，则该函数会返回出错。为了解决这种情况，通常函数需要先 <code>fork</code>，然后父进程退出，由子进程执行 <code>setsid</code>。由于子进程继承的是父进程的进程组 <code>PGID</code>，而其 <code>PID</code> 是新分配的 <code>ID</code>，因此这两者不可能相等，即子进程不可能是进程组的组长。在这种情况下，由于父进程先于子进程退出，因此子进程的父进程会由 <code>init</code> 进程【进程编号为 1】接管。而这就是 <code>setsid</code> 命令的实现原理。</p><p>可以做一个简单的测试来观察一下 <code>setsid</code> 具体做了什么。首先编写一个测试程序，文件名为：<code>setsid_test.c</code>，源代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">int main ()</span><br><span class="line">&#123;</span><br><span class="line">  pid_t sid=getsid (0);          /* 会话 id */</span><br><span class="line">  pid_t pgrp=getpgrp ();         /* 进程组 id */</span><br><span class="line">  pid_t ppid=getppid ();         /* 父进程 id */</span><br><span class="line">  pid_t pid=getpid ();           /* 进程 ID */</span><br><span class="line">  printf (&quot; 会话 id:% d\n 进程组 id:% d\n 父进程 id:% d\n 进程 id:% d\n&quot;,sid,pgrp,ppid,pid);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 <code>gcc</code> 编译器进行编译，执行 <code>gcc setsid_test.c -o setsid_test.out</code> 后，输出 <code>setsid_test.out</code> 可执行文件，然后运行可执行文件。</p><p>在 <code>Shell</code> 下直接运行【其实是通过 <code>bash</code> 进程来启动子进程】，使用：<code>./setsid_test.out</code>，输出内容如下【不妨再执行一次 <code>ps -f</code> 查看 <code>bash</code> 进程的信息】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ ./setsid_test.out </span><br><span class="line"> 会话 id:205689</span><br><span class="line"> 进程组 id:179572</span><br><span class="line"> 父进程 id:205689</span><br><span class="line"> 进程 id:179572</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ ps -f</span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">pengfei  179660 205689  2 17:01 pts/2    00:00:00 ps -f</span><br><span class="line">pengfei  205689 205681  0 15:10 pts/2    00:00:00 -bash</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908172023.png" alt="直接运行结果" title="直接运行结果"></p><p>可以看到，启动的进程为 179572，同时它也是这个进程组的组长，它的父进程是 205689，从下面的输出可以看出 205689 进程即为 <code>bash</code> 进程。</p><p>接着在 <code>Shell</code> 下通过 <code>setsid</code> 运行，使用：<code>setsid ./setsid_test.out</code>，输出内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ setsid ./setsid_test.out </span><br><span class="line">[pengfei@dev2 ~]$ 会话 id:198498</span><br><span class="line"> 进程组 id:198498</span><br><span class="line"> 父进程 id:1</span><br><span class="line"> 进程 id:198498</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908172048.png" alt="通过 setsid 运行结果" title="通过 setsid 运行结果"></p><p>对比这两个输出信息，读者会发现，<code>setsid</code> 新建了一个全新的会话，会话首进程是 198498，而且其父进程变成了 <code>init</code> 进程【进程编号为 1】。由于会话和父进程都与 <code>Shell</code> 无关，也就达到了不会接收到会话进程发送的 <code>SIGHUP</code> 信号的目的【当然，手动发送 SIGHUP 信号给进程，进程仍会正常接收】。</p><p>上文中涉及的 <code>c</code> 脚本已经被我上传至 <code>GitHub</code>，读者可以下载查看：<a href="https://github.com/iplaypi/iplaypistudy/tree/master/iplaypistudy-normal/src/bin/20190515" target="_blank" rel="noopener">setsid_test</a> ，脚本命名与上文中描述一致。</p><h2 id="amp- 方式"><a href="#amp- 方式" class="headerlink" title="&amp; 方式"></a>&amp; 方式 </h2><p> 有些读者可能还知道有一个关于 <code>subshell</code> 的小技巧，将一个或多个命令包含在括号 <code>()</code> 中，就能让这些命令在子 <code>Shell</code> 中运行，从而扩展出很多有趣的功能，我在这里演示一下后台运行的功能。</p><p>将 <code>command &amp;</code> 直接放入 <code>()</code> 中，读者就会发现提交的进程并不在作业列表中，也就是说，无法通过 <code>jobs</code> 来查看。这个现象背后的原因是什么呢，以及为什么这样就能躲过 <code>SIGHUP</code> 信号的影响呢？下面来演示一下。</p><p>先执行 <code>(tail -f xx.log &amp;)</code> 命令启动进程，然后使用 <code>ps -ef |grep &#39;tail -f&#39;</code> 查看进程的状态，输出信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ (tail -f xx.log &amp;)</span><br><span class="line">[pengfei@dev2 ~]$ 100</span><br><span class="line"></span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos;</span><br><span class="line">pengfei   20009      1  0 17:35 pts/2    00:00:00 tail -f xx.log</span><br><span class="line">pengfei   20742 205689  0 17:35 pts/2    00:00:00 grep tail -f</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908173857.png" alt="子 shell 演示结果" title="子 shell 演示结果"></p><p>紧接着再使用 <code>jobs</code> 命令验证一下这个进程是否在当前会话终端进程的作业列表中【看不到任何进程的信息输出】：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ jobs</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908174319.png" alt="使用 jobs 查看" title="使用 jobs 查看"></p><p>从上面的演示可以看出，新提交的进程的父进程为 <code>init</code> 进程，并不是当前会话终端进程，因此并不属于当前会话终端的子进程，从而也就不会收到当前会话终端的 <code>SIGHUP</code> 信号。</p><p>但是需要注意，使用 <code>(command &amp;)</code> 的 <code>subshell</code> 方式，并不会改变子进程原本的输入流、输出流的状态，仍旧是继承自父进程，也就是会话终端，所以仍需要考虑进程与 <code>I/O</code> 的交互，避免出现问题。</p><h1 id="忽略挂起的后悔药"><a href="# 忽略挂起的后悔药" class="headerlink" title="忽略挂起的后悔药"></a>忽略挂起的后悔药 </h1><p> 通过前面的内容，读者已经知道，如果提交任务时，在命令前加上 <code>nohup</code> 或者 <code>setsid</code> 就可以避免 <code>SIGHUP</code> 信号的影响。但是如果我们未加任何处理就提交了命令，该如何补救才能让它避免 <code>SIGHUP</code> 信号的影响呢？</p><p>或者说，系统的 <code>Shell</code> 参数 <code>huponexit</code> 被设置为 <code>on</code>，此时会不会由此引发什么问题，需要我们注意呢？</p><p>以上这些考虑都是基于意外的情况，当然有时候读者可能也会遇到，下面给出解决的方法。</p><h2 id="正常启动后台任务"><a href="# 正常启动后台任务" class="headerlink" title="正常启动后台任务"></a>正常启动后台任务 </h2><p> 有时候直接运行任务后，才发现没有手动设置忽略挂起【没有使用 <code>nohup</code>】，或者也没有使用 <code>setsid</code> 工具新建会话。已经运行了一段时间后，又不想停掉任务重新启动【如果参数 <code>huponexit</code> 设置为 <code>on</code>，会话进程在退出时就会给后台子进程发送 <code>SIGHUP</code> 信号，导致进程终止】，那么有没有可以事后弥补的方案呢？有，当然有。</p><p>以上情况重点在于忘记使用 <code>nohup</code>、<code>setsid</code> 等命令，由于这些命令与 <code>Shell</code> 无关【所以才需要在提交任务的命令前使用】，所以在提交任务后不可能再弥补，除非杀死进程重新启动。但是，我这里还有别的方案，这个工具就是 <code>bash</code> 的内置命令，它只能在 <code>bash</code> 下使用，它就是 <code>disown</code> 命令。</p><p>所以，此时可以通过 <code>disown</code> 工具来操作后台进程，先来看一下帮助文档，使用 <code>man disown</code> 命令查看：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">disown [-ar] [-h] [jobspec ...]</span><br><span class="line">              Without options, each jobspec is removed from the table of active jobs.  </span><br><span class="line">              If jobspec is not present, and neither -a nor -r is supplied, the shell’s notion of the current job is used.  </span><br><span class="line">              If the -h option is given, each jobspec is not removed  from  the table, but is marked so that SIGHUP is not sent to the job if the shell receives a SIGHUP.  </span><br><span class="line">              If no jobspec is present, and neither the -a nor the -r option is supplied, the current job is used.  </span><br><span class="line">              If no jobspec is supplied, the -a option means to remove or mark all jobs; the -r option without a jobspec argument restricts operation to running jobs. </span><br><span class="line">              The return value is 0 unless a jobspec does not specify a valid job.</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908220734.png" alt="disown 帮助文档" title="disown 帮助文档"></p><p>可以看出，我们可以用如下方式来达成我们的目的：</p><ul><li>用 <code>disown -h jobspec</code> 将某个作业从 <code>jobs</code> 列表中移除 </li><li> 用 <code>disown -ah</code> 将所有的作业从 <code>jobs</code> 列表中移除 </li><li> 用 <code>disown -rh</code> 将正在运行的作业从 <code>jobs</code> 列表中移除 </li></ul><p> 这样，当退出会话时，会话进程并不会将 <code>SIGHUP</code> 信号发送给被移除的进程【被移除的进程已经不在后台作业列表中】，因此这个被移除的进程可以一直在后台运行下去。</p><p>需要注意的是，当使用过 <code>disown</code> 之后，将把目标作业从 <code>jobs</code> 列表中移除，读者将不能再使用 <code>jobs</code> 命令来查看它，但是依然能够使用 <code>ps -ef</code> 查找到它。</p><p>然而，还要注意流的影响，使用 <code>disown</code> 并不会切断进程与会话终端的关联关系，这样当会话终端被关闭后，若进程尝试从 <code>stdin</code> 中读取或输出信息到 <code>stdout</code>、<code>stderr</code> 中，会导致异常退出，这点读者需要注意。</p><p>下面简单演示一下 <code>disown</code> 的使用，输入以及输出内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ tail -f xx.log &amp;</span><br><span class="line">[1] 141302</span><br><span class="line">[pengfei@dev2 ~]$ 100</span><br><span class="line"></span><br><span class="line">[pengfei@dev2 ~]$ jobs</span><br><span class="line">[1]+  Running                 tail -f xx.log &amp;</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ disown %1</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ jobs</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908221314.png" alt="disown 简单验证" title="disown 简单验证"></p><p>可以看到，先启动一个后台任务，使用 <code>jobs</code> 还可以看到，接着使用 <code>disown</code> 将它移除，再使用 <code>jobs</code> 就看不到进程了。</p><p>如果退出会话，读者可能怀疑此时进程被杀死了吗，还是仍在运行，使用 <code>ps -ef |grep &#39;tail -f&#39;</code> 查看便知，为了对比观察，在退出会话前后各查看一次。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 退出会话前 </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos;</span><br><span class="line">pengfei  141302 205689  0 22:11 pts/2    00:00:00 tail -f xx.log</span><br><span class="line">pengfei  146581 205689  0 22:14 pts/2    00:00:00 grep tail -f</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ exit</span><br><span class="line">logout</span><br><span class="line">Connection closing...Socket close.</span><br><span class="line"></span><br><span class="line">Connection closed by foreign host.</span><br><span class="line"></span><br><span class="line"> 重新登录 </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos;</span><br><span class="line">pengfei  141302      1  0 22:11 ?        00:00:00 tail -f xx.log</span><br><span class="line">pengfei  153383 198673  0 22:17 pts/1    00:00:00 grep tail -f</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908222344.png" alt="退出会话前查看" title="退出会话前查看"></p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908222353.png" alt="退出会话后查看" title="退出会话后查看"></p><p>从上图可以看到，进程 141302 无论是在退出会话前还是在退出会话后，一直在运行，说明退出会话对进程没有影响，唯一的影响就是父进程变化了，退出会话后父进程由 <code>init</code> 进程接管。</p><h2 id="直接启动前台任务"><a href="# 直接启动前台任务" class="headerlink" title="直接启动前台任务"></a>直接启动前台任务 </h2><p> 还有一种场景，如果在启动进程时没有使用 <code>&amp;</code> 将进程放在后台运行，占用着当前的会话窗口，一不小心就会导致进程终止，那怎么办？其实也很简单。</p><p>使用 <code>Ctrl + z</code> 命令，把正在前台运行的进程暂停，并放在后台，程序并没有被杀死。其实这个组合快捷键是一种控制信号，编号为 <code>19</code>，标识为 <code>SIGSTOP</code>，读者可以参考我的另外一篇博文：<a href="https://playpi.org/2019042101.html" target="_blank" rel="noopener">Linux 之 kill 命令入门实践 </a> 。当然，如果使用终端工具，再开一个会话窗口，使用 <code>ps</code> 命令查询这个进程的 <code>pid</code> 编号，然后使用 <code>kill -19 pid</code> 命令发送一个 <code>SIGSTOP</code> 信号给进程也可以达到把程序暂停并放在后台的效果【不过肯定没有快捷键方便了】。</p><p> 然后读者就可以使用 <code>jobs</code> 命令来查询它的作业编号，紧接着使用 <code>bg job_num</code> 就可以把这个进程放在后台运行了【由 <code>stopped</code> 状态变为 <code>running</code> 状态】。</p><p>但是需要注意的是，如果暂停进程会影响当前进程的运行结果，所以慎用此方法。</p><p>只要放在了后台运行，就可以继续使用 <code>disown</code> 命令将它从作业列表中移除了，下面简单演示一下，以下为输入与输出信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ tail -f xx.log</span><br><span class="line">100</span><br><span class="line">^Z</span><br><span class="line">[1]+  Stopped                 tail -f xx.log</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ jobs</span><br><span class="line">[1]+  Stopped                 tail -f xx.log</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ bg 1</span><br><span class="line">[1]+ tail -f xx.log &amp;</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ jobs</span><br><span class="line">[1]+  Running                 tail -f xx.log &amp;</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ disown %1</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ jobs</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos;</span><br><span class="line">pengfei   29540 198673  0 23:20 pts/1    00:00:00 tail -f xx.log</span><br><span class="line">pengfei   30418 198673  0 23:20 pts/1    00:00:00 grep tail -f</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190908232405.png" alt="前台任务到后台任务演示" title="前台任务到后台任务演示"></p><p>可见，启动进程时没有把它放在后台运行，先使用 <code>ctrl + z</code> 快捷键将它放在后台【处于 <code>stopped</code> 状态】，再使用 <code>bg</code> 使它运行【处于 <code>running</code> 状态】，紧接着就可以正常使用 <code>disown</code> 将它从 <code>jobs</code> 列表移除了。</p><h1 id="批量管理进程"><a href="# 批量管理进程" class="headerlink" title="批量管理进程"></a>批量管理进程 </h1><p> 前面的描述都是单个进程或者几个进程，管理起来也挺方便，但是如果遇到大量的进程需要管理，例如运维人员日常需要手动管理大量的进程，几百个几千个都是有可能的，那么怎么办呢，如果每次都需要这么操作【使用 <code>nohup</code>、<code>setsid</code> 等等】很麻烦。为了简化管理，并且保证进程能在后台稳定运行，此时就需要通过 <code>screen</code> 工具来操作，对于进程的后台运行，以及会话的模拟，这是一个利器。</p><h2 id="功能使用"><a href="# 功能使用" class="headerlink" title="功能使用"></a>功能使用 </h2><p> 简单概括来说，<code>screen</code> 提供了 <code>ANSI/VT100</code> 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端【它的思路就是终端复用器，即 <code>terminal multiplexer</code>】。</p><p>它可以在当前 <code>session</code> 里面，新建另外一个 <code>session</code>，这样的话，当前 <code>session</code> 一旦结束，并不影响其它 <code>session</code>。而且，以后重新登录，还可以再连上早先新建的 <code>session</code>。</p><p><code>screen</code> 的参数很多，具有很强大的功能，我在此仅介绍其常用的功能以及简要分析一下为什么使用 <code>screen</code> 能够避免 <code>SIGHUP</code> 信号的影响。</p><p>首先我们来看一下帮助文档信息，使用 <code>man screen</code> 命令输出：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SCREEN (1)                                                            SCREEN (1)</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">       screen - screen manager with VT100/ANSI terminal emulation</span><br><span class="line"></span><br><span class="line">SYNOPSIS</span><br><span class="line">       screen [-options] [cmd [ args] ]</span><br><span class="line">       screen -r [[pid.] tty [.host]]</span><br><span class="line">       screen -r sessionowner/[[pid.] tty [.host]]</span><br><span class="line"></span><br><span class="line">DESCRIPTION</span><br><span class="line">       Screen  is  a full-screen window manager that multiplexes a physical terminal between several processes (typically interactive shells).</span><br><span class="line">       Each vir-tual terminal provides the functions of a DEC VT100 terminal and, in addition, several control functions from the ISO 6429 (ECMA 48,  ANSI  X3.64)</span><br><span class="line">and  ISO  2022 standards (e.g. insert/delete line and support for multiple character sets).</span><br><span class="line">There is a scrollback history buffer for each virtual terminal and a copy-and-paste mechanism that allows moving text regions between windows.</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190911011009.png" alt="screen 帮助文档" title="screen 帮助文档"></p><p>由于信息比较多，只截取了其中一部分。总之，使用 <code>screen</code> 很方便，有以下几个常用选项：</p><ul><li>screen，建立一个会话，并登录【在此会话下可以不使用 nohup、setsid 等工具，退出会话后不影响进程的运行】</li><li>screen -dm，建立一个处于断开模式下的会话【detached mode】</li><li>screen -dmS session_name，建立一个处于断开模式下的会话【参数 S 用来指定其会话名】</li><li>screen -list，列出所有的会话【或者参数也可以是 -ls，一样的效果】</li><li>screen -r session_name，重新连接指定会话【指定会话名字，如果有重名的会话，需要同时带上 pid_number 前缀】</li><li>screen -r pid_number，重新连接指定会话【指定会话编号】</li><li>快捷键 ctrl + a、ctrl + d，暂时退出当前会话【不影响会话的状态，会话并没有关闭，还可以重新登录】</li><li>快捷键 ctrl + c、ctrl + d，终止当前会话【会话不存在，里面的进程也就不存在了】</li></ul><p>上面列出了一些常用的功能，下面就开始简单演示一下。</p><p>先新建一个名字为 <code>s1</code> 的会话，然后列出所有的会话，按照如下命令操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ screen -dmS s1</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ screen -ls</span><br><span class="line">There is a screen on:</span><br><span class="line">	17651.s1	(Detached)</span><br><span class="line">1 Socket in /tmp/uscreens/S-pengfei.</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190914023446.png" alt="screen 新建会话" title="screen 新建会话"></p><p>可以看到，我新建了一个处于断开模式的会话 <code>s1</code>，如果我用 <code>-r</code> 参数连接到 <code>screen</code> 创建的 <code>s1</code> 会话后，我就可以在这个伪终端里面放心大胆地启动进程，再也不用担心 <code>SIGHUP</code> 信号会对我的进程造成影响，也不用给每个命令前都加上 <code>nohup</code> 或者 <code>setsid</code> 了。这是为什么呢？来看一下下面两个对比的例子吧。</p><p>1、在 <code>s1</code> 会话里面启动一个后台进程，并查看进程树，按照如下命令操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ screen -r s1</span><br><span class="line">[pengfei@dev2 ~]$ tail -f xx.log &amp;</span><br><span class="line">[1] 45061</span><br><span class="line">[pengfei@dev2 ~]$ 100</span><br><span class="line"></span><br><span class="line">[pengfei@dev2 ~]$ pstree -H 45061 |grep &apos;tail\|screen\|init&apos;</span><br><span class="line">init-+-abrt-dump-oops</span><br><span class="line">     |-screen-+-bash-+-grep</span><br><span class="line">     |        |      `-tail</span><br><span class="line">     |      |-sshd---sshd---bash---screen</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190914023453.png" alt="使用 screen 会话启动进程" title="使用 screen 会话启动进程"></p><p>可以看到，使用了 <code>screen</code> 后进程树有一些特殊，此时 <code>bash</code> 是 <code>screen</code> 的子进程，而 <code>screen</code> 是 <code>init</code>【进程号为 1】的子进程。那么，当 <code>ssh</code> 断开会话连接时，<code>SIGHUP</code> 信号自然不会影响到 <code>screen</code> 下面的子进程。</p><p>2、在当前登录的会话里面启动一个后台进程，并查看进程树，按照如下命令操作：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ tail -f xx.log &amp;</span><br><span class="line">[1] 61916</span><br><span class="line">[pengfei@dev2 ~]$ 100</span><br><span class="line"></span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ pstree -H 61916 |grep &apos;tail\|screen\|init\|bash&apos;</span><br><span class="line">init-+-abrt-dump-oops</span><br><span class="line">     |-bash---java---186*[&#123;java&#125;]</span><br><span class="line">     |-sshd-+-sshd---sshd---bash</span><br><span class="line">     |      |-sshd---sshd---bash-+-grep</span><br><span class="line">     |      |                    `-tail</span><br><span class="line">     |`-sshd---sshd-+-2*[bash]</span><br><span class="line">     |                    `-bash---java---37*[&#123;java&#125;]</span><br><span class="line">[pengfei@dev2 ~]$</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190914023457.png" alt="在当前登录会话启动进程" title="在当前登录会话启动进程"></p><p>可以看到，未使用 <code>screen</code> 而是直接在当前会话启动进程时，我所处的 <code>bash</code> 是 <code>sshd</code> 的子进程，当 <code>ssh</code> 断开连接时，<code>sshd</code> 进程关闭，<code>SIGHUP</code> 信号自然会影响到它下面的所有子进程【当然也包括我新建立的 <code>tail</code> 进程】。</p><p>通过对比这两种启动进程方式，读者可以发现，<code>screen</code> 的作用就在于新建会话，在 <code>screen</code> 会话中启动的进程与 <strong>当前登录会话 </strong>无关，这样无论什么时候，都不会影响 <code>screen</code> 会话中的进程，除非手动终止 <code>screen</code> 会话。而且，无论什么时候登录，还可以继续连接 <code>screen</code> 会话，并管理里面的进程，很方便。</p><h2 id="关于安装"><a href="# 关于安装" class="headerlink" title="关于安装"></a>关于安装 </h2><p><code>screen</code> 的安装比较简单，如果是 <code>root</code> 用户，直接使用 <code>yum install screen</code> 即可一键安装完成【不同的操作系统类型使用的命令会不一样】，安装过程在此不需要赘述。但是如果是非 <code>root</code> 用户或者在网络无连接的情况下，则不能直接一键安装，需要使用源码编译安装的方式进行安装，过程比较繁琐，而且也容易出现各种各样的错误，主要是依赖环境不完整的问题。</p><p> 下面列举常规的安装步骤：</p><p>1、下载 <code>screen</code> 源码包，地址在这里：<a href="http://ftp.gnu.org/gnu/screen" target="_blank" rel="noopener">screen 源码包 </a> ，选择最新的版本。</p><p>2、解压、配置、编译、安装流程。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解压 </span><br><span class="line">tar -zxvf screen-4.6.2.tar.gz</span><br><span class="line"># 配置，如果是非 root 用户需要自定义安装目录，即 prefix 参数 </span><br><span class="line">./configure --prefix=/home/pengfei/soft/screen</span><br><span class="line"># 编译 </span><br><span class="line">make</span><br><span class="line"># 安装 </span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p> 注意在 <code>configure</code> 阶段可能会出错：<code>no tgetent - no screen</code>，错误原因就是缺少 <code>ncurses</code> 依赖环境，需要再次单独安装。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 错误信息 </span><br><span class="line">configure: checking libncurses...</span><br><span class="line">configure: checking libtinfo...</span><br><span class="line">configure: error: !!! no tgetent - no screen</span><br></pre></td></tr></table></figure><p>3、安装 <code>ncurses</code>，先去下载源码包，地址在这里：<a href="http://ftp.gnu.org/gnu/ncurses" target="_blank" rel="noopener">ncurses 源码包 </a> ，选择最新的版本。</p><p>4、解压、配置、编译、安装流程。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解压 </span><br><span class="line">tar -zxvf ncurses-6.1.tar.gz</span><br><span class="line"># 配置，如果是非 root 用户需要自定义安装目录，即 prefix 参数 </span><br><span class="line"># 指定安装目录时注意结尾不要带文件分隔符 /, 否则 ncurses 在创建文件目录时会创建一个错误的目录 </span><br><span class="line"># 例如 bin 目录:/home/pengfei/soft/ncurses//bin, 它会自动在指定的目录后面追加 /bin, 从而导致 / 出现两次 </span><br><span class="line"># 这点在配置完成之后的日志输出中也可以看到 </span><br><span class="line"># 如果在输出日志中看到 Include-directory is not in a standard location, 这并不是一个错误，可以添加 --enable-overwrite 参数避免 </span><br><span class="line">./configure --prefix=/home/pengfei/soft/ncurses</span><br><span class="line"># 编译 </span><br><span class="line">make</span><br><span class="line"># 安装 </span><br><span class="line"># 安装如果出错，可以在配置时指定多个参数 </span><br><span class="line"># ./configure --prefix=/home/pengfei/soft/ncurses --with-shared --without-debug --without-ada --enable-overwrite</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>5、回到 <code>screen</code> 解压目录，继续安装，这里需要注意设置两个全局变量。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 编译器选项 </span><br><span class="line"># 链接相关选项，如果你有自定义的函数库 (lib dir), 即可以用 - L&lt;lib dir&gt; 指定 </span><br><span class="line">export LDFLAGS=-L/home/pengfei/soft/ncurses/lib</span><br><span class="line"># 预编译器选项 </span><br><span class="line"># C/C++ 预处理器选项，如果你自定义的头文件，可以用 - I&lt;include dir&gt;</span><br><span class="line">export CPPFLAGS=-I/home/pengfei/soft/ncurses/include</span><br></pre></td></tr></table></figure><p>6、安装完成后配置环境变量，全局可用，在家目录的 <code>.bashrc</code> 文件里设置 <code>screen</code> 执行路径：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH=/home/pengfei/soft/screen/bin:$PATH</span><br></pre></td></tr></table></figure><p> 紧接着执行 <code>source ~/.bashrc</code> 更新 <code>PATH</code> 路径，以后在终端输入 <code>screen</code> 就能进入 <code>screen</code> 界面了。</p><p>7、我的安装总结，我在三台服务器上面尝试使用编译源码的方式安装，都出现各种各样的诡异错误，我也不是搞服务器端应用开发的，有些问题实在解决不了，折腾了一天最终放弃了，还是直接使用 <code>root</code> 用户一键安装比较快捷。</p><p>错误一，<code>screen</code> 配置过程报错，通过安装 <code>ncurces</code> 解决。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190913221335.png" alt="screen 配置过程报错" title="screen 配置过程报错"></p><p>错误二，<code>ncurses</code> 安装过程报错，通过添加配置的参数重新来过解决。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190913221441.png" alt="ncurses 安装过程报错" title="ncurses 安装过程报错"></p><p>错误三，<code>screen</code> 配置过程继续报错，已经和 <code>ncurces</code> 无关，找不到问题原因。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190913221345.png" alt="screen 配置过程继续报错" title="screen 配置过程继续报错"></p><p>错误四，<code>screen</code> 安装过程报错，找不到问题原因。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190913221433.png" alt="screen 安装过程报错" title="screen 安装过程报错"></p><h1 id="简单总结"><a href="# 简单总结" class="headerlink" title="简单总结"></a>简单总结 </h1><p> 以上内容把几种方法已经介绍完毕，读者可以根据不同的场景来选择不同的方案。<code>nohup</code>、<code>setsid</code>、<code>&amp;</code> 无疑是临时需要时最方便的方法，<code>disown</code> 能帮助我们来事后补救已经在运行的作业，而 <code>screen</code> 则是在大批量操作时不二的选择。</p><h1 id="前台任务与后台任务"><a href="# 前台任务与后台任务" class="headerlink" title="前台任务与后台任务"></a>前台任务与后台任务 </h1><p> 本文中涉及了这两个概念：<strong> 前台任务 </strong>【<code>foreground job</code>】、<strong> 后台任务 </strong>【<code>background job</code>】，并且很多示例演示也离不开这两个概念，读者如果不了解这两个概念，就会对很多内容看的云里雾里，所以有必要总结一下。</p><p>下面会对这两个概念做一些总结介绍，以加深读者的认识，达到知其然知其所以然的地步。</p><h2 id="前台任务"><a href="# 前台任务" class="headerlink" title="前台任务"></a>前台任务 </h2><p> 如果直接启动一个进程或者脚本，例如 <code>sh example.sh</code>、<code>python example.py</code>、<code>java example.jar</code> 等，都可以提交一个 <strong>前台任务 </strong>。它会独自占用当前的会话窗口【输入流、输出流】，导致在当前会话窗口什么都不能做【要么开启其它会话窗口继续操作、要么暂停当前任务、要么终止当前任务】，只有等它运行完成或者被用户手动终止，用户才能继续在当前会话窗口进行各种操作。</p><h2 id="后台任务"><a href="# 后台任务" class="headerlink" title="后台任务"></a>后台任务 </h2><p> 提交 <strong>后台任务 </strong>的方法很简单，在前台任务的提交命令末尾加上 <code>&amp;</code> 符号，例如 <code>sh example.sh &amp;</code>、<code>python example.py &amp;</code>、<code>java example.jar &amp;</code> 等，就表示把当前进程放在后台运行，变成后台任务，也可以说是守护进程【<code>daemon</code>】。这种类型的任务不会再占用当前会话窗口，用户可以继续进行其它操作【如果没有对输出做重定向的话，任务的输出信息仍旧会出现在窗口屏幕上，用户会时不时看到输出内容，不要觉得奇怪】。</p><p>后台任务有两个特点：</p><ul><li>继承当前会话（session）的标准输出（stdout）、标准错误（stderr），因此，后台任务的所有输出仍然会同步地在当前会话窗口中显示（可见，如果关闭当前会话窗口，会引起任务暂停，但是由于父进程不存在，任务进而终止退出）。</li><li>不再继承当前会话（session）的标准输入（stdin），因此，用户无法再向这个任务输入参数指令了，如果任务试图去读取标准输入（可能代码中有这个逻辑），任务就会暂停执行（只是暂停，即 stopped 状态，不是终止）。</li></ul><p>可以看到，<strong> 后台任务 </strong>与 <strong>前台任务 </strong>的本质区别只有一个，那就是是否继承当前会话【<code>session</code>】的标准输入。从这个区别不难理解，在执行后台任务时，会话窗口没有被占用，用户可以继续在当前会话窗口进行其它操作。而在执行前台任务时，会话窗口被占用，用户无法继续使用这个会话窗口。</p><h2 id="状态互换"><a href="# 状态互换" class="headerlink" title="状态互换"></a>状态互换 </h2><p> 其实，<strong> 前台任务 </strong>和 <strong>后台任务 </strong>可以非常自如地切换，以满足用户的各种使用场景，否则就会显得难以使用。上文中已经非常详细地演示了几种方式，下面总结列举出来：</p><ul><li>添加 <code>&amp;</code> 方式，可以非常简单地把前台任务变为后台任务 </li><li> 针对后台任务，可以使用 <code>fg job_num</code> 调取出来，变为前台任务 </li><li> 使用 <code>setsid</code>，把任务变为另一个新会话进程的子进程，并且放在后台运行【但是使用 <code>jobs</code> 无法查看，也无法使用 <code>fg</code>、<code>bg</code> 等命令操作】</li><li>对于正在运行的前台任务，贸然地使用 <code>ctrl + c</code> 会导致任务终止，此时可以使用 <code>ctrl + z</code> 暂停任务【任务状态被置为 <code>stopped</code>】，然后使用 <code>bg job_num</code> 把任务放在后台运行【任务状态被置为 <code>running</code>】</li><li>对于当前进程下的子进程，即 <code>jobs</code> 列表，可以使用 <code>disown</code> 把子进程移除，变为 <code>init</code> 进程的子进程 </li><li> 使用 <code>(command &amp;)</code> 的 <code>subshell</code> 方式把启动的进程变为 <code>init</code> 进程的子进程 </li></ul><h1 id="总结 -SIGHUP- 信号的问题"><a href="# 总结 -SIGHUP- 信号的问题" class="headerlink" title="总结 SIGHUP 信号的问题"></a> 总结 SIGHUP 信号的问题 </h1><p> 关于后台任务在会话【<code>session</code>】退出后，再次登录，为什么有的人看到任务还在运行，有的人看到任务已经终止，这是玄学吗，根本原因是什么呢？要想了解根本原因，必须先了解 <code>SIGHUP</code> 信号的知识点，以及 <code>Linux</code> 系统关于给后台任务发送信号的规则设置。</p><p>看看 <code>Linux</code> 系统是怎么设计的：</p><ul><li>用户准备退出会话【<code>session</code>】</li><li>用户退出会话，系统向该会话发送 <code>SIGHUP</code> 信号 </li><li> 会话把 <code>SIGHUP</code> 信号发送给所有子进程【包括前台子进程、后台子进程】</li><li>子进程收到 <code>SIGHUP</code> 信号后，自动退出 </li></ul><p> 根据这个流程，首先可以明白为什么前台子进程会随着会话的关闭而终止，就是因为前台子进程收到了会话发送的 <code>SIGHUP</code> 信号，不得不终止。</p><p>那么后台子进程呢，看起来也会收到 <code>SIGHUP</code> 信号，为什么上文在演示时后台子进程不会被终止呢，有什么蹊跷吗？其实，会话在关闭前是否发送给子进程 <code>SIGHUP</code> 信号还会受到一个参数的限制，那就是 <code>Shell</code> 的 <code>huponexit</code> 参数，在 <code>Linux</code> 系统中可以使用 <code>shopt | grep huponexit</code> 命令查看。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190901235345.png" alt="huponexit 参数查看" title="huponexit 参数查看"></p><p>可以看到，在我的 <code>Linux</code> 系统中，这个参数的设置是 <code>off</code>，是关闭的，也就是会话在退出前不会把 <code>SIGHUP</code> 信号发送给后台子进程。</p><p>其实，在大多数 <code>Linux</code> 系统中，这个参数的值都是默认设置为 <code>off</code>，这样的话，在会话退出的时候，不会把 <code>SIGHUP</code> 信号发送给后台子进程，则后台子进程也就不会随着会话的退出而终止了【但是处于 <code>stopped</code> 状态的后台子进程仍旧会终止】。这也是读者在自己的操作系统测试时，可能会见到不同的现象的根本原因，所以觉得奇怪的读者可以查看自己的设置。</p><h1 id="输入流输出流的问题"><a href="# 输入流输出流的问题" class="headerlink" title="输入流输出流的问题"></a>输入流输出流的问题 </h1><p> 为了讲清楚让进程在后台运行的几种方法，上面的内容除了描述 <code>SIGHUP</code> 信号的问题，还夹杂着输入流、输出流的问题。其实，除了 <code>SIGHUP</code> 信号的影响，输入流、输出流也会影响着任务的运行状态，有时候虽然躲过了 <code>SIGHUP</code> 信号的攻击，但是却一不小心败给了输入流、输出流。</p><h2 id="输入流"><a href="# 输入流" class="headerlink" title="输入流"></a>输入流 </h2><p> 如果进程的代码逻辑中需要读取用户输入的指令，例如从键盘中读取指令，再执行对应的操作，这种询问应答的交互模式很常见。这里面就涉及了输入流的概念，进程需要一个输入流用来传输用户的指令，默认就是标准输入，即 <code>stdin</code> 。</p><h2 id="输出流"><a href="# 输出流" class="headerlink" title="输出流"></a>输出流 </h2><p> 如果进程的代码逻辑中需要输出信息，例如打印日志，输出报错信息，这里就涉及了输出流的概念，默认有两个，分别是：标准输出、标准错误，即 <code>stdout</code> 与 <code>stderr</code>。</p><h2 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h2><p> 为了演示输入流、输出流的影响，在这里只考虑一种特殊的场景：用户退出会话【<code>session</code>】。此时，进程会受到 <code>SIGHUP</code> 信号的影响，前面已经详细说明并且演示，假设进程躲过了所有的 <code>SIGHUP</code> 信号并一直保持正常运行。</p><p>那么问题来了，如果这个正常运行的进程与 <code>标准 IO</code> 有交互的话，它还是会终止，可能不是立即终止，只有执行到与 <code>标准 IO</code> 进行交互的代码才会终止。读者是不是很惊讶，其实这与前台任务、后台任务的流继承有关，前面已经详细说明了，下面会举一个更具体的例子。</p><p>后台任务【使用 <code>&amp;</code>】的输入流、输出流继承自当前会话进程，即分别为：<code>stdin</code>、<code>stdout</code>、<code>stderr</code>，如果使用其它工具操作，会改变流的状态，例如使用 <code>nohup</code>【关闭 <code>stdin</code>，重定向 <code>stdout</code>、<code>stderr</code>】、<code>disown</code>【不改变流的状态】、<code>setsid</code>【切断流与会话终端的联系】、<code>(command &amp;)</code>【不改变流的状态】。</p><p>假如有一个任务，使用 <code>nohup command &amp;</code> 执行，然后退出当前会话。我来分析一下：输出默认被重定向到 <code>nohup.out</code> 文件，忽略 <code>SIGHUP</code> 信号，任务放入后台运行，看起来是不是很完美。</p><p>但是如果任务与标准输入有交互，即需要从 <code>stdin</code> 读取指令，那么就完了。由于会话已经被关闭，<code>stdin</code> 已经不存在【况且 <code>nohup</code> 已经把进程的 <code>stdin</code> 关闭了】，任务会先进入 <code>stopped</code> 状态，紧接着退出。【即使用户不退出会话，任务也会永久处于 <code>stopped</code> 状态，无法再次激活正常运行】</p><p>如果任务与标准输出有交互，不需要多虑，因为 <code>nohup</code> 已经默默地把输出重定向到文件了。</p><p>如果在进程的代码中，就是存在与输入流、输出流的交互，有没有什么办法可以彻底解决问题，当然，就是重定向这个利器，除了把输出流重定向之外，也要把输入流重定向，使用形如 <code>command &gt; stdout.txt 2&gt; stderr.txt &lt; /dev/null &amp;</code> 这个格式的命令启动任务即可，不会再有问题。</p><p>如果启动任务使用的是 <code>setsid command &amp;</code> 命令，需要特别考虑输入流、输出流这个问题，因为 <code>setsid</code> 在启动进程后，父进程变更为 <code>init</code> 进程，而且中间还有几步操作【子进程、新建会话、<code>init</code> 托管】。无论退出会话与否，输入流、输出流都已经被切断，进程无法与 <code>I/O</code> 交互。【但是我测试发现，脚本代码中如果有输入处理逻辑，进程会卡住；如果有输出处理逻辑，进程会正常把信息输出到当前会话窗口。如果关闭会话窗口则看不到输出，但是也不影响进程的正常运行，状态仍旧是 <code>running</code>，父进程变为 <code>init</code>。这说明输出流变更在关闭会话后才生效，如果没有关闭会话仍旧是 <code>stdout</code>，我没有找到相关资料，这个问题的根本原因暂时存疑。】</p><p>如果使用 <code>disown</code> 命令把后台的进程从 <code>jobs</code> 列表中移除，不会改变进程原本的输入流、输出流的状态，所以需要考虑进程与 <code>I/O</code> 的交互，避免出现问题。</p><p>如果使用 <code>(command &amp;)</code> 的 <code>subshell</code> 方式，不会改变子进程原本的输入流、输出流的状态，继承自父进程，也就是会话终端，仍需要考虑进程与 <code>I/O</code> 的交互，避免出现问题。</p><h1 id="备注"><a href="# 备注" class="headerlink" title="备注"></a>备注 </h1><h2 id="关于挂起的测试"><a href="# 关于挂起的测试" class="headerlink" title="关于挂起的测试"></a> 关于挂起的测试 </h2><p> 我使用 <code>XShell</code> 测试退出终端时，发现并不会挂起普通的后台子进程【说明后台子进程没有接收到 <code>SIGHUP</code> 信号，或者接收到但是忽略了】，反而把进程的父进程设置为了 <code>init</code>【进程号为 1】，这样进程就不会退出，下次登录的时候还能查看。但是这个现象违反了前面的知识点：退出终端会话时所有子进程会收到 <code>SIGHUP</code> 信号，后来我发现，原来这个操作是针对 <strong>前台任务 </strong>而言的，如果是 <strong>后台任务 </strong>则不一定，要看系统的参数设置：<code>shopt | grep huponexit</code>，<code>huponexit</code> 这个参数决定了是否向后台任务发送 <code>SIGHUP</code> 信号。而在大多数 <code>Linux</code> 系统中，这个参数一般默认是关闭的【取值为 <code>off</code>】，所以才出现了终端会话退出后后台子进程没有挂起的现象。</p><p>这里面还有两个有趣的现象。</p><h3 id="前台任务 -1"><a href="# 前台任务 -1" class="headerlink" title="前台任务"></a>前台任务 </h3><p> 一是 <strong>前台任务 </strong>如果被人为设置了 <code>nohup</code>，则在会话关闭时会忽略掉 <code>SIGHUP</code> 信号，从而一直保持运行。下面演示一下。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、tail -f xx.log &amp;&gt; tail.log【加输出重定向是为了排除输出流的影响】</span><br><span class="line">2、断开网络或者关闭会话窗口 </span><br><span class="line">3、nohup tail -f yy.log</span><br><span class="line">4、断开网络或者关闭会话窗口 </span><br><span class="line">5、重新登录，使用 ps 工具查看进程：ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br></pre></td></tr></table></figure><p>输出信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">pengfei  199496      1  0 01:16 ?        00:00:00 tail -f yy.log</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190902000501.png" alt="子进程仍旧存在" title="子进程仍旧存在"></p><p>使用上述步骤依次操作，可以发现 <code>nohup tail -f yy.log</code> 对应的进程还在【父进程号已经变更为 1，表示 <code>init</code> 进程】，而 <code>tail -f xx.log</code> 对应的进程已经不在了，这就是因为前者在执行命令时手动添加了 <code>nohup</code>，从而可以保障不受因会话关闭发送的 <code>SIGHUP</code> 信号影响，而后者直接被杀死。</p><p>读者可能会怀疑这个没被杀死的进程是处于运行状态吗【<code>running</code>】，会不会处于暂停状态【<code>stopped</code>】，这个很容易证明，直接使用 <code>pstack</code> 工具可以查看：<code>pstack pid</code>。例如我这里的进程号是 199496 ，则使用 <code>pstack 199496</code> 查看。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ pstack 199496</span><br><span class="line">#0  0x00000031fd8db7f0 in __read_nocancel () from /lib64/libc.so.6</span><br><span class="line">#1  0x0000000000408df6 in ?? ()</span><br><span class="line">#2  0x0000000000403b56 in ?? ()</span><br><span class="line">#3  0x0000000000404ae0 in ?? ()</span><br><span class="line">#4  0x00000031fd81ed20 in __libc_start_main () from /lib64/libc.so.6</span><br><span class="line">#5  0x0000000000401959 in ?? ()</span><br><span class="line">#6  0x00007ffdc74bdb48 in ?? ()</span><br><span class="line">#7  0x000000000000001c in ?? ()</span><br><span class="line">#8  0x0000000000000003 in ?? ()</span><br><span class="line">#9  0x00007ffdc74be606 in ?? ()</span><br><span class="line">#10 0x00007ffdc74be60b in ?? ()</span><br><span class="line">#11 0x00007ffdc74be60e in ?? ()</span><br><span class="line">#12 0x0000000000000000 in ?? ()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190902000522.png" alt="使用 pstack 验证进程状态" title="使用 pstack 验证进程状态"></p><p>可以看到，进程仍旧在运行中，如果是暂停状态的进程，会显示 <code>stopped</code> 标记，下面的例子会演示这个，请读者继续往下看。</p><h3 id="后台任务 -1"><a href="# 后台任务 -1" class="headerlink" title="后台任务"></a>后台任务 </h3><p> 二是 <strong>后台任务 </strong>如果处于 <code>stopped</code> 状态，无论有没有设置 <code>nohup</code>，在会话关闭或者网络断开时，进程会被杀死。而如果是处于 <code>ruuning</code> 状态，无论有没有设置 <code>nohup</code>，在会话关闭或者网络断开时，进程都不会被杀死。出现这个现象的原因是会话在退出时不会向子进程发送 <code>SIGHUP</code> 信号，则处于 <code>running</code> 的子进程仍旧运行，只不过父进程会变更为 <code>init</code>，而处于 <code>stopped</code> 状态的子进程因为父进程的退出而退出。下面举两个例子演示一下。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、tail -f xx.log &amp;&gt; tail.log &amp;，这里只是简单后台运行，并没有设置 nohup，所以发送 SIGHUP 信号可以杀死进程，加输出重定向是为了排除输出流的影响 </span><br><span class="line">2、断开网络或者关闭会话窗口 </span><br><span class="line">3、nohup tail -f yy.log，然后使用 ctrl + z 暂停任务，状态处于 stopped，并置于后台 </span><br><span class="line">4、使用 jobs 工具查看进程状态 </span><br><span class="line">5、断开网络或者关闭会话窗口 </span><br><span class="line">6、重新登录，使用 ps 工具查看进程：ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br></pre></td></tr></table></figure><p>在执行第二个任务时，可以在关闭会话前使用 <code>jobs</code> 工具查看进程状态，输出信息如下，可见是 <code>stopped</code> 状态：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ nohup tail -f yy.log</span><br><span class="line">nohup: ignoring input and appending output to `nohup.out&apos;</span><br><span class="line">^Z</span><br><span class="line">[1]+  Stopped                 nohup tail -f yy.log</span><br><span class="line">[pengfei@dev2 ~]$ </span><br><span class="line">[pengfei@dev2 ~]$ jobs</span><br><span class="line">[1]+  Stopped                 nohup tail -f yy.log</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190902001410.png" alt="使用 jobs 查看后台任务" title="使用 jobs 查看后台任务"></p><p>或者再次使用上面的 <code>pstack</code> 工具查看：<code>pstack pid</code>，我这里的进程号是 98537 ，则使用 <code>pstack 98537</code> 查看。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ pstack 98537</span><br><span class="line">#0  0x00000031fd8db7f0 in __read_nocancel () from /lib64/libc.so.6</span><br><span class="line">#1  0x0000000000408df6 in ?? ()</span><br><span class="line">#2  0x0000000000403b56 in ?? ()</span><br><span class="line">#3  0x0000000000404ae0 in ?? ()</span><br><span class="line">#4  0x00000031fd81ed20 in __libc_start_main () from /lib64/libc.so.6</span><br><span class="line">#5  0x0000000000401959 in ?? ()</span><br><span class="line">#6  0x00007fff911d07e8 in ?? ()</span><br><span class="line">#7  0x000000000000001c in ?? ()</span><br><span class="line">#8  0x0000000000000003 in ?? ()</span><br><span class="line">#9  0x00007fff911d1606 in ?? ()</span><br><span class="line">#10 0x00007fff911d160b in ?? ()</span><br><span class="line">#11 0x00007fff911d160e in ?? ()</span><br><span class="line">#12 0x0000000000000000 in ?? ()</span><br><span class="line"></span><br><span class="line">[1]+  Stopped                 nohup tail -f yy.log</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190902001454.png" alt="使用 pstack 查看后台任务" title="使用 pstack 查看后台任务"></p><p>也可以看到是 <code>stopped</code> 状态。</p><p>接着我在退出会话时【我使用 <code>XShell</code> 的 <code>ctrl + d</code> 快捷键，或者使用 <code>layout</code> 命令】，可以看到第一次退出时系统会提醒我有暂停的进程：<code>There are stopped jobs.</code>，继续再执行一次退出，第二次才真正退出。</p><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190902001829.png" alt="layout 两次的提示" title="layout 两次的提示"></p><p>接着重新登录并使用 <code>ps</code> 工具查看进程输出信息如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[pengfei@dev2 ~]$ ps -ef |grep &apos;tail -f&apos; |grep -v grep</span><br><span class="line">pengfei   20331      1  0 01:45 ?        00:00:00 tail -f xx.log</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/iplaypi/img-playpi/master/img/2019/20190902001703.png" alt="使用 ps 查看进程" title="使用 ps 查看进程"></p><p>使用上述步骤依次操作，可以发现 <code>nohup tail -f yy.log</code> 对应的进程已经不在了，尽管我手动给它设置了 <code>nohup</code>，也无济于事。而对于 <code>tail -f xx.log &amp;&gt; tail.log &amp;</code> 对应的进程，我并没有手动设置 <code>nohup</code>，进程仍旧在运行。</p><p>这里可以认定的是，操作系统的设置导致会话关闭时不会给运行的【<code>running</code> 状态】后台子进程发送 <code>SIGHUP</code> 信号，会话关闭后，当前进程的父进程已经是 <code>init</code>，这个托管过程读者应该可以理解，在此不再赘述。</p><h2 id="继续探索其它高效的工具"><a href="# 继续探索其它高效的工具" class="headerlink" title="继续探索其它高效的工具"></a>继续探索其它高效的工具 </h2><p> 读者可以继续探索一下 <code>tmux</code> 工具的使用，这类工具可以更加高效、安全地帮助我们管理后台进程，从而让我们脱离手动管理后台进程的苦海。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Linux 命令系列</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>nohup</tag>
        <tag>setsid</tag>
        <tag>disown</tag>
        <tag>screen</tag>
        <tag>daemon</tag>
      </tags>
  </entry>
</search>
